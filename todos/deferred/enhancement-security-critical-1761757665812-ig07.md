---
id: "enhancement-security-1761757665807-bwkc"
type: "guardian-enhancement"
assigned_agent: "Marcus-Backend"
priority: "critical"
category: "security"
confidence: 85
estimated_effort: "8.5 hours"
originated_from: "root-cause-learning"
created: "2025-10-29T17:07:45.807Z"
auto_applicable: false
requires_manual_review: true
approval_tier: 3
approval_required: true
---

# üöÄ Enhancement Suggestion - Auto-fix security vulnerabilities

## üîê Approval Status

- **Approval Tier**: üî¥ **TIER 3** - Manual Review Required
- **Approval Required**: YES
- **Reason**: Critical priority requires explicit approval, Complex root cause (3 secondary causes), High effort (8.5h > 8h)

### Manual Review Actions

üî¥ **This enhancement requires careful manual review** (low confidence <80% or high risk).

**Review Checklist**:
- [ ] Verify root cause analysis is accurate
- [ ] Confirm implementation steps are appropriate
- [ ] Check for potential side effects
- [ ] Validate estimated effort and ROI
- [ ] Test in non-production environment first

**Commands**:
- `/work enhancement-security-critical-1761757665812-5mt9.md` - Start implementation with assigned agent (Marcus-Backend)
- `/approve enhancement-security-1761757665807-bwkc` - Force approval (after manual review)
- `/reject enhancement-security-1761757665807-bwkc "reason"` - Reject permanently

---

## Pattern Detected

**Issue**: Tests failed: Command failed: npm test -- --passWithNoTests
ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
FAIL UNIT tests/mcp/mcp-health-check.test.ts (22.306 s, 38 MB heap size)
  MCP Health Check - All 11 MCPs
    MCP Configuration
      ‚úï should have 11 MCPs configured (6 ms)
      ‚úì should have all expected MCPs in config (31 ms)
      ‚úì should have valid command and args for each MCP (13 ms)
    Individual MCP Health Checks
      ‚úì should check Playwright MCP health (1073 ms)
      ‚úì should check Playwright Stealth MCP health (1038 ms)
      ‚úì should check GitHub MCP health (1 ms)
      ‚úì should check GitMCP health (1036 ms)
      ‚úì should check Exa MCP health (9 ms)
      ‚úì should check Vertex AI MCP health (3 ms)
      ‚úì should check Supabase MCP health (1 ms)
      ‚úì should check n8n MCP health
      ‚úì should check Semgrep MCP health (1 ms)
      ‚úì should check Sentry MCP health (17 ms)
      ‚úì should check Claude Code MCP health (1215 ms)
    Batch Health Check
      ‚úï should check health of all MCPs in batch (5246 ms)
    Performance Metrics
      ‚úì should track response times for all MCPs (5278 ms)
      ‚úì should identify slow MCPs (5187 ms)
    Error Handling
      ‚úì should handle missing MCP configuration gracefully (73 ms)
      ‚úì should timeout for unresponsive MCPs (1042 ms)

  ‚óè MCP Health Check - All 11 MCPs ‚Ä∫ MCP Configuration ‚Ä∫ should have 11 MCPs configured

    expect(received).toBe(expected) // Object.is equality

    Expected: 11
    Received: 12

      342 |     it('should have 11 MCPs configured', () => {
      343 |       const mcpCount = configLoader.getMCPCount();
    > 344 |       expect(mcpCount).toBe(11);
          |                        ^
      345 |     });
      346 |
      347 |     it('should have all expected MCPs in config', () => {

      at Object.<anonymous> (tests/mcp/mcp-health-check.test.ts:344:24)

  ‚óè MCP Health Check - All 11 MCPs ‚Ä∫ Batch Health Check ‚Ä∫ should check health of all MCPs in batch

    expect(received).toBe(expected) // Object.is equality

    Expected: 11
    Received: 12

      531 |       const results = await healthChecker.checkAllMCPs(mcpConfigs);
      532 |
    > 533 |       expect(results.length).toBe(11);
          |                              ^
      534 |
      535 |       // Verify all MCPs were checked
      536 |       const checkedNames = results.map(r => r.name);

      at Object.<anonymous> (tests/mcp/mcp-health-check.test.ts:533:30)

(node:3299) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 SIGTERM listeners added to [process]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
(Use `node --trace-warnings ...` to show where the warning was created)
(node:3299) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 SIGINT listeners added to [process]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
(node:3299) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 SIGUSR2 listeners added to [process]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
(node:3299) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 uncaughtException listeners added to [process]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
(node:3299) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 unhandledRejection listeners added to [process]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
FAIL UNIT tests/unit/audit/rule3-daily-audit-scheduling.test.ts (47 MB heap size)
  Rule 3: Daily Audit Scheduling
    Daemon Lifecycle
      ‚úì should start daemon successfully (57 ms)
      ‚úì should create PID file on start (5 ms)
      ‚úì should create log file on start (2 ms)
      ‚úì should prevent multiple daemon instances (2 ms)
      ‚úì should stop daemon gracefully (2 ms)
      ‚úì should remove PID file on stop (4 ms)
      ‚úì should restart daemon successfully (1009 ms)
    Cron Scheduling
      ‚úï should schedule audit for 2 AM daily (11 ms)
      ‚úì should calculate next scheduled audit time (10 ms)
      ‚úì should support custom cron schedule (5 ms)
    Immediate Audit Triggers
      ‚úì should run immediate audit on demand (3 ms)
      ‚úì should run immediate audit on critical issues (1 ms)
      ‚úì should track audit count (2 ms)
      ‚úì should track last audit status (2 ms)
    Daemon Status
      ‚úì should report correct status when running (2 ms)
      ‚úì should report correct status when stopped (12 ms)
      ‚úì should track uptime correctly (2016 ms)
    Graceful Shutdown
      ‚úì should handle SIGTERM gracefully (6 ms)
      ‚úì should execute shutdown handlers (10 ms)
      ‚úì should close log stream on shutdown (7 ms)
    Error Handling
      ‚úì should track error count on audit failures (7 ms)
      ‚úì should emit error events on audit failures (4 ms)
    Event Emission
      ‚úì should emit daemon:started event (4 ms)
      ‚úì should emit daemon:stopped event (4 ms)
      ‚úì should emit audit:scheduled:completed event (3 ms)
    Static Methods
      ‚úì should detect if daemon is running via PID file (5 ms)
      ‚úì should return false if PID file does not exist (3 ms)
      ‚úì should remove stale PID file if process not running (17 ms)
    Integration with DailyAuditSystem
      ‚úì should execute audit via audit system (6 ms)
      ‚úì should trigger immediate audit on critical issues (7 ms)
    Logging
      ‚úï should write logs to log file (11 ms)
      ‚úì should include timestamps in logs (7 ms)
      ‚úì should log different severity levels (3 ms)
    Configuration
      ‚úì should use default configuration when not provided (4 ms)
      ‚úì should allow custom configuration (3 ms)

  ‚óè Rule 3: Daily Audit Scheduling ‚Ä∫ Cron Scheduling ‚Ä∫ should schedule audit for 2 AM daily

    expect(jest.fn()).toHaveBeenCalledWith(...expected)

    Expected: "0 2 * * *", Any<Function>, ObjectContaining {"scheduled": true, "timezone": "America/New_York"}
    Received: "0 2 * * *", [Function anonymous], {"timezone": "America/New_York"}

    Number of calls: 1

      152 |       await daemon.start();
      153 |
    > 154 |       expect(cron.schedule).toHaveBeenCalledWith(
          |                             ^
      155 |         '0 2 * * *',
      156 |         expect.any(Function),
      157 |         expect.objectContaining({

      at Object.<anonymous> (tests/unit/audit/rule3-daily-audit-scheduling.test.ts:154:29)

  ‚óè Rule 3: Daily Audit Scheduling ‚Ä∫ Logging ‚Ä∫ should write logs to log file

    expect(received).toContain(expected) // indexOf

    Expected substring: "Starting Daily Audit Daemon"
    Received string:    "[2025-10-29T16:52:57.060Z] [INFO] PID file written: /var/folders/k5/kx1wf16921dfgq2963mb476w0000gn/T/versatil-test-1761756777053/run/audit-daemon.pid
    [2025-10-29T16:52:57.060Z] [INFO] Cron scheduler started. Next run: 2025-10-30T00:00:00.000Z
    [2025-10-29T16:52:57.060Z] [INFO] Daemon started successfully. PID: 3299
    [2025-10-29T16:52:57.060Z] [INFO] Scheduled audits at: 0 2 * * * (America/New_York)
    [2025-10-29T16:52:57.060Z] [INFO] Running immediate audit
    [2025-10-29T16:52:57.060Z] [INFO] Audit daily_audit_1761756777060 completed
    [2025-10-29T16:52:57.061Z] [INFO] Immediate audit completed. Status: warning, Health: 10%
    [2025-10-29T16:52:57.061Z] [INFO] Stopping Daily Audit Daemon
    [2025-10-29T16:52:57.061Z] [INFO] PID file removed
    "

      485 |       const logContent = await fs.readFile(testLogPath, 'utf8');
      486 |
    > 487 |       expect(logContent).toContain('Starting Daily Audit Daemon');
          |                          ^
      488 |       expect(logContent).toContain('Daemon started successfully');
      489 |       expect(logContent).toContain('Running immediate audit');
      490 |       expect(logContent).toContain('Stopping Daily Audit Daemon');

      at Object.<anonymous> (tests/unit/audit/rule3-daily-audit-scheduling.test.ts:487:26)

FAIL UNIT tests/mcp/docs-search-engine.test.ts (8.103 s, 183 MB heap size)
  DocsSearchEngine
    buildIndex
      ‚úì should build documentation index successfully (11 ms)
      ‚úì should index documents with required metadata (1 ms)
      ‚úì should extract meaningful titles from documents (205 ms)
      ‚úì should categorize documents correctly (21 ms)
      ‚úì should extract keywords from documents (86 ms)
    search
      ‚úï should find documents by title keywords (170 ms)
      ‚úì should find documents by content keywords (300 ms)
      ‚úì should return results sorted by relevance (86 ms)
      ‚úì should filter by category when specified (5 ms)
      ‚úì should return empty array for non-existent terms (3 ms)
      ‚úì should handle multi-word queries (360 ms)
      ‚úì should extract relevant excerpts (126 ms)
      ‚úì should return top 10 results maximum (190 ms)
      ‚úì should include match count in results (183 ms)
    getDocument
      ‚úì should retrieve full document content (59 ms)
      ‚úì should throw error for non-existent document (4 ms)
    getDocumentsByCategory
      ‚úì should return all documents in category (1 ms)
      ‚úì should return empty array for category with no documents
      ‚úì should return all documents when category is "all"
      ‚úì should sort results alphabetically by title (39 ms)
    extractExcerpt
      ‚úì should extract context around query terms
      ‚úì should add ellipsis when truncating
      ‚úì should return first lines if no matches found (1 ms)
    performance
      ‚úì should build index in reasonable time (2198 ms)
      ‚úì should search efficiently (112 ms)
    edge cases
      ‚úì should handle empty query gracefully
      ‚úì should handle special characters in query (2 ms)
      ‚úì should be case-insensitive (189 ms)
      ‚úì should handle queries with multiple spaces (205 ms)
      ‚úì should handle very long queries (507 ms)
    relevance scoring
      ‚úì should prioritize title matches over content matches (73 ms)
      ‚úì should weight keyword matches appropriately (89 ms)
    concurrent access
      ‚úì should handle concurrent searches (267 ms)
      ‚úì should handle concurrent document retrievals (60 ms)

  ‚óè DocsSearchEngine ‚Ä∫ search ‚Ä∫ should find documents by title keywords

    expect(received).toContain(expected) // indexOf

    Expected substring: "maria"
    Received string:    "auto-learning with public/private rag separation (v7.8.0)"

      70 |       const results = await searchEngine.search('maria');
      71 |       expect(results.length).toBeGreaterThan(0);
    > 72 |       expect(results[0].document.title.toLowerCase()).toContain('maria');
         |                                                       ^
      73 |     });
      74 |
      75 |     it('should find documents by content keywords', async () => {

      at Object.<anonymous> (tests/mcp/docs-search-engine.test.ts:72:55)

FAIL UNIT tests/unit/parallel-task-todowrite-integration.test.ts (200 MB heap size)
  ParallelTaskManager - TodoWrite Integration
    Todo Creation on Task Start
      ‚úì should emit todowrite:task-start event when task begins (101 ms)
      ‚úì should emit todowrite:parallel-start for multiple tasks (1 ms)
    Progress Updates
      ‚úì should emit progress updates at key milestones (0% ‚Üí 20% ‚Üí 50% ‚Üí 100%) (1 ms)
      ‚úì should track progress for multiple parallel tasks independently (1 ms)
    Completion Marking
      ‚úï should emit todowrite:task-complete when task finishes successfully
      ‚úì should emit todowrite:parallel-complete with summary after all tasks finish (1 ms)
    Parallel Progress Tracking
      ‚úï should get current progress for all running tasks (101 ms)
      ‚úì should provide execution summary with running/completed/failed counts (1 ms)
      ‚úï should format progress for statusline display (204 ms)
    Error Handling
      ‚úì should emit todowrite:task-failed when task fails (1 ms)
    TodoWrite Feature Flag
      ‚úì should allow disabling TodoWrite integration
      ‚úì should allow re-enabling TodoWrite integration
    Three-Tier Parallel Development
      ‚úï should show all three-tier agents working in parallel (1 ms)
      ‚úì should calculate time savings for parallel vs sequential execution (1 ms)

  ‚óè ParallelTaskManager - TodoWrite Integration ‚Ä∫ Completion Marking ‚Ä∫ should emit todowrite:task-complete when task finishes successfully

    expect(received).toBe(expected) // Object.is equality

    Expected: 1
    Received: 2

      266 |
      267 |       const completeEvents = todoWriteEvents.filter(e => e.event === 'task-complete');
    > 268 |       expect(completeEvents.length).toBe(1);
          |                                     ^
      269 |
      270 |       const completeEvent = completeEvents[0];
      271 |       expect(completeEvent.data.taskId).toBe('complete-task');

      at Object.<anonymous> (tests/unit/parallel-task-todowrite-integration.test.ts:268:37)

  ‚óè ParallelTaskManager - TodoWrite Integration ‚Ä∫ Parallel Progress Tracking ‚Ä∫ should get current progress for all running tasks

    expect(received).toBeGreaterThan(expected)

    Expected: > 0
    Received:   0

      353 |
      354 |       const progress = manager.getParallelProgress();
    > 355 |       expect(progress.size).toBeGreaterThan(0);
          |                             ^
      356 |
      357 |       await execPromise; // Wait for completion
      358 |     });

      at Object.<anonymous> (tests/unit/parallel-task-todowrite-integration.test.ts:355:29)

  ‚óè ParallelTaskManager - TodoWrite Integration ‚Ä∫ Parallel Progress Tracking ‚Ä∫ should format progress for statusline display

    expect(received).toContain(expected) // indexOf

    Expected substring: "working in parallel"
    Received string:    "No parallel tasks running"

      466 |
      467 |       // Should show format like "dana-database (30%) + marcus-backend (45%) + james-frontend (60%) working in parallel"
    > 468 |       expect(statusline).toContain('working in parallel');
          |                          ^
      469 |
      470 |       await execPromise; // Wait for completion
      471 |     });

      at Object.<anonymous> (tests/unit/parallel-task-todowrite-integration.test.ts:468:26)

  ‚óè ParallelTaskManager - TodoWrite Integration ‚Ä∫ Three-Tier Parallel Development ‚Ä∫ should show all three-tier agents working in parallel

    expect(received).toBe(expected) // Object.is equality

    Expected: 3
    Received: 6

      626 |       // Check task completion
      627 |       const taskCompleteEvents = todoWriteEvents.filter(e => e.event === 'task-complete');
    > 628 |       expect(taskCompleteEvents.length).toBe(3);
          |                                         ^
      629 |
      630 |       // Check parallel complete
      631 |       const parallelComplete = todoWriteEvents.find(e => e.event === 'parallel-complete');

      at Object.<anonymous> (tests/unit/parallel-task-todowrite-integration.test.ts:628:41)

FAIL UNIT tests/unit/contracts/contract-tracker.test.ts (221 MB heap size)
  ContractTracker
    Initialization
      ‚úï should create stats directory on initialization
      ‚úï should load existing data on initialization (1 ms)
      ‚úì should handle missing stats directory gracefully
      ‚úì should handle corrupted data files gracefully
    Contract Creation Tracking
      ‚úì should track contract creation
      ‚úì should track contract creation with validation result
      ‚úì should initialize performance tracking on creation
      ‚úì should calculate estimated effort from work items
      ‚úì should track quality gates count
      ‚úï should persist contract creation to disk
    Status Change Tracking
      ‚úì should track status change to sent (1 ms)
      ‚úì should track status change to accepted
      ‚úì should track status change to completed
      ‚úì should calculate effort accuracy on completion
      ‚úì should calculate quality gate pass rate on completion (1 ms)
      ‚úì should calculate duration on completion (11 ms)
      ‚úì should handle status change without contract gracefully (1 ms)
    Validation Tracking
      ‚úì should track validation result
      ‚úì should track validation errors count
    Statistics Calculation
      ‚úì should return default statistics when no data
      ‚úì should calculate contracts by status
      ‚úì should calculate contracts by type (1 ms)
      ‚úì should calculate contracts by sender
      ‚úì should calculate contracts by receiver
      ‚úì should calculate average quality score
      ‚úì should calculate success rate
      ‚úì should calculate average effort accuracy (1 ms)
      ‚úì should calculate average quality pass rate
    Report Generation
      ‚úï should generate comprehensive report
      ‚úï should handle empty data in report
      ‚úì should include recent events in report (1 ms)
    Query Operations
      ‚úì should get events for specific contract
      ‚úì should get performance for specific contract
      ‚úì should return undefined for nonexistent contract
      ‚úì should get events by time range
      ‚úì should exclude events outside time range (1 ms)
    Cleanup Operations
      ‚úì should cleanup old events
      ‚úï should persist cleaned data
    Singleton Pattern
      ‚úì should return same instance from getGlobalContractTracker
      ‚úì should initialize singleton automatically
    Error Handling
      ‚úï should handle file write errors gracefully
      ‚úì should handle concurrent tracking (4 ms)

  ‚óè ContractTracker ‚Ä∫ Initialization ‚Ä∫ should create stats directory on initialization

    TypeError: Cannot read properties of undefined (reading 'isDirectory')

      57 |     it('should create stats directory on initialization', async () => {
      58 |       const stats = await fs.stat(testStatsDir);
    > 59 |       expect(stats.isDirectory()).toBe(true);
         |                    ^
      60 |     });
      61 |
      62 |     it('should load existing data on initialization', async () => {

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:59:20)

  ‚óè ContractTracker ‚Ä∫ Initialization ‚Ä∫ should load existing data on initialization

    expect(received).toBe(expected) // Object.is equality

    Expected: 1
    Received: 0

      69 |
      70 |       const stats = newTracker.getStatistics();
    > 71 |       expect(stats.totalContracts).toBe(1);
         |                                    ^
      72 |     });
      73 |
      74 |     it('should handle missing stats directory gracefully', async () => {

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:71:36)

  ‚óè ContractTracker ‚Ä∫ Contract Creation Tracking ‚Ä∫ should persist contract creation to disk

    TypeError: Cannot read properties of undefined (reading 'then')

      152 |
      153 |       const eventsPath = path.join(testStatsDir, 'contract-events.json');
    > 154 |       const fileExists = await fs.access(eventsPath).then(() => true).catch(() => false);
          |                                                     ^
      155 |       expect(fileExists).toBe(true);
      156 |
      157 |       const content = await fs.readFile(eventsPath, 'utf-8');

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:154:53)

  ‚óè ContractTracker ‚Ä∫ Report Generation ‚Ä∫ should generate comprehensive report

    expect(received).toContain(expected) // indexOf

    Expected substring: "Total Contracts: 1"
    Received string:    "# Contract Tracking Report¬∑
    **Generated**: 2025-10-29T16:53:05.719Z¬∑
    ## Summary Statistics¬∑
    - **Total Contracts**: 1
    - **Success Rate**: 0.00%
    - **Average Quality Score**: 95.0/100
    - **Average Effort Accuracy**: 0.0%
    - **Average Quality Pass Rate**: 0.0%
    - **Average Duration**: 0.0 minutes¬∑
    ## Contracts by Status¬∑
    - **pending**: 1¬∑
    ## Contracts by Type¬∑
    - **sequential**: 1¬∑
    ## Contracts by Sender¬∑
    - **alex-ba**: 1¬∑
    ## Contracts by Receiver¬∑
    - **marcus-backend**: 1¬∑
    ## Recent Events (Last 5)¬∑¬∑
    ### 2025-10-29T16:53:05.719Z - created
    - Contract: contract-1761756785719-mi7g9l
    - Sender: alex-ba
    - Receivers: marcus-backend
    - Type: sequential
    - Priority: normal
    - Validation Score: 95/100¬∑¬∑
    ---
    *Generated by VERSATIL Contract Tracker*"

      495 |
      496 |       expect(report).toContain('Contract Tracking Report');
    > 497 |       expect(report).toContain('Total Contracts: 1');
          |                      ^
      498 |       expect(report).toContain('Average Quality Score: 95');
      499 |       expect(report).toContain('alex-ba');
      500 |       expect(report).toContain('marcus-backend');

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:497:22)

  ‚óè ContractTracker ‚Ä∫ Report Generation ‚Ä∫ should handle empty data in report

    expect(received).toContain(expected) // indexOf

    Expected substring: "Total Contracts: 0"
    Received string:    "# Contract Tracking Report¬∑
    **Generated**: 2025-10-29T16:53:05.719Z¬∑
    ## Summary Statistics¬∑
    - **Total Contracts**: 0
    - **Success Rate**: 0.00%
    - **Average Quality Score**: 0.0/100
    - **Average Effort Accuracy**: 0.0%
    - **Average Quality Pass Rate**: 0.0%
    - **Average Duration**: 0.0 minutes¬∑
    ## Contracts by Status¬∑¬∑¬∑
    ## Contracts by Type¬∑¬∑¬∑
    ## Contracts by Sender¬∑¬∑¬∑
    ## Contracts by Receiver¬∑¬∑¬∑
    ## Recent Events (Last 5)¬∑¬∑¬∑
    ---
    *Generated by VERSATIL Contract Tracker*"

      505 |
      506 |       expect(report).toContain('Contract Tracking Report');
    > 507 |       expect(report).toContain('Total Contracts: 0');
          |                      ^
      508 |     });
      509 |
      510 |     it('should include recent events in report', async () => {

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:507:22)

  ‚óè ContractTracker ‚Ä∫ Cleanup Operations ‚Ä∫ should persist cleaned data

    TypeError: Cannot read properties of undefined (reading 'then')

      592 |       // Verify files still exist
      593 |       const eventsPath = path.join(testStatsDir, 'contract-events.json');
    > 594 |       const fileExists = await fs.access(eventsPath).then(() => true).catch(() => false);
          |                                                     ^
      595 |       expect(fileExists).toBe(true);
      596 |     });
      597 |   });

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:594:53)

  ‚óè ContractTracker ‚Ä∫ Error Handling ‚Ä∫ should handle file write errors gracefully

    TypeError: fs.chmod is not a function

      616 |   describe('Error Handling', () => {
      617 |     it('should handle file write errors gracefully', async () => {
    > 618 |       await fs.chmod(testStatsDir, 0o444);
          |                ^
      619 |
      620 |       await expect(
      621 |         tracker.trackContractCreated(createTestContract())

      at Object.<anonymous> (tests/unit/contracts/contract-tracker.test.ts:618:16)

FAIL UNIT tests/unit/mcp/oliver-mcp-orchestrator.test.ts (243 MB heap size)
  OliverMCPAgent
    MCP Selection
      ‚úï should recommend Playwright for browser testing tasks (1 ms)
      ‚úï should recommend GitMCP for framework documentation (9 ms)
      ‚úì should recommend Supabase for database operations (1 ms)
      ‚úï should recommend GitHub MCP for repository operations
      ‚úì should provide alternative MCP recommendations
    Anti-Hallucination Detection
      ‚úì should detect hallucination risk for outdated framework knowledge (1 ms)
      ‚úì should recommend GitMCP for React documentation
      ‚úï should have low hallucination risk for well-known patterns
      ‚úì should recommend specific file paths for targeted queries
    Agent-Specific MCP Routing
      ‚úì should route Maria-QA to testing MCPs (1 ms)
      ‚úì should route Marcus-Backend to backend MCPs
      ‚úì should route James-Frontend to UI MCPs
      ‚úï should route Sarah-PM to project management MCPs
      ‚úï should route Dr.AI-ML to AI/ML MCPs
    MCP Registry
      ‚úï should have all 12 MCPs registered (1 ms)
      ‚úï should classify MCPs by type correctly
      ‚úï should have write operation flags set correctly
    Confidence Scoring
      ‚úï should have high confidence for exact matches (1 ms)
      ‚úï should have lower confidence for ambiguous requests
      ‚úì should increase confidence with more context
    Error Handling
      ‚úì should handle missing agent ID gracefully
      ‚úì should provide fallback when no perfect match exists
    Integration with Agents
      ‚úï should provide MCP suggestions for all OPERA agents
      ‚úï should suggest different MCPs for different agents
  OliverMCPAgent - Integration
    ‚úï should activate and return status
    ‚úï should provide MCP selection through activation

  ‚óè OliverMCPAgent ‚Ä∫ MCP Selection ‚Ä∫ should recommend Playwright for browser testing tasks

    expect(received).toContain(expected) // indexOf

    Expected substring: "browser"
    Received string:    "playwright is optimized for testing tasks with capabilities: navigate, click, screenshot, test, accessibility_snapshot"

      29 |       expect(recommendation.mcpType).toBe('integration');
      30 |       expect(recommendation.confidence).toBeGreaterThan(0.8);
    > 31 |       expect(recommendation.reasoning).toContain('browser');
         |                                        ^
      32 |     });
      33 |
      34 |     it('should recommend GitMCP for framework documentation', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:31:40)

  ‚óè OliverMCPAgent ‚Ä∫ MCP Selection ‚Ä∫ should recommend GitMCP for framework documentation

    expect(received).toBe(expected) // Object.is equality

    Expected: "github"
    Received: "gitmcp"

      41 |       });
      42 |
    > 43 |       expect(recommendation.mcpName).toBe('github');
         |                                      ^
      44 |       expect(recommendation.confidence).toBeGreaterThan(0.9);
      45 |       expect(recommendation.reasoning).toContain('documentation');
      46 |       expect(recommendation.parameters).toHaveProperty('repository');

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:43:38)

  ‚óè OliverMCPAgent ‚Ä∫ MCP Selection ‚Ä∫ should recommend GitHub MCP for repository operations

    expect(received).toBe(expected) // Object.is equality

    Expected: "github"
    Received: "sentry"

      68 |       });
      69 |
    > 70 |       expect(recommendation.mcpName).toBe('github');
         |                                      ^
      71 |       expect(recommendation.mcpType).toBe('hybrid');
      72 |       expect(recommendation.confidence).toBeGreaterThan(0.9);
      73 |     });

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:70:38)

  ‚óè OliverMCPAgent ‚Ä∫ Anti-Hallucination Detection ‚Ä∫ should have low hallucination risk for well-known patterns

    expect(received).toBe(expected) // Object.is equality

    Expected: "low"
    Received: "medium"

      120 |       });
      121 |
    > 122 |       expect(gitMCPRec.hallucination_risk).toBe('low');
          |                                            ^
      123 |     });
      124 |
      125 |     it('should recommend specific file paths for targeted queries', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:122:44)

  ‚óè OliverMCPAgent ‚Ä∫ Agent-Specific MCP Routing ‚Ä∫ should route Sarah-PM to project management MCPs

    expect(received).toContain(expected) // indexOf

    Expected value: "sentry"
    Received array: ["github", "n8n"]

      174 |       });
      175 |
    > 176 |       expect(['github', 'n8n']).toContain(recommendation.mcpName);
          |                                 ^
      177 |     });
      178 |
      179 |     it('should route Dr.AI-ML to AI/ML MCPs', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:176:33)

  ‚óè OliverMCPAgent ‚Ä∫ Agent-Specific MCP Routing ‚Ä∫ should route Dr.AI-ML to AI/ML MCPs

    expect(received).toBe(expected) // Object.is equality

    Expected: "vertex-ai"
    Received: "supabase"

      185 |       });
      186 |
    > 187 |       expect(recommendation.mcpName).toBe('vertex-ai');
          |                                      ^
      188 |     });
      189 |   });
      190 |

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:187:38)

  ‚óè OliverMCPAgent ‚Ä∫ MCP Registry ‚Ä∫ should have all 12 MCPs registered

    TypeError: oliver.getMCPRegistry is not a function

      191 |   describe('MCP Registry', () => {
      192 |     it('should have all 12 MCPs registered', () => {
    > 193 |       const mcps = oliver.getMCPRegistry();
          |                           ^
      194 |
      195 |       expect(Object.keys(mcps).length).toBe(12);
      196 |       expect(mcps).toHaveProperty('playwright');

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:193:27)

  ‚óè OliverMCPAgent ‚Ä∫ MCP Registry ‚Ä∫ should classify MCPs by type correctly

    TypeError: oliver.getMCPRegistry is not a function

      205 |
      206 |     it('should classify MCPs by type correctly', () => {
    > 207 |       const mcps = oliver.getMCPRegistry();
          |                           ^
      208 |
      209 |       // Integration MCPs
      210 |       expect(mcps.playwright.type).toBe('integration');

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:207:27)

  ‚óè OliverMCPAgent ‚Ä∫ MCP Registry ‚Ä∫ should have write operation flags set correctly

    TypeError: oliver.getMCPRegistry is not a function

      221 |
      222 |     it('should have write operation flags set correctly', () => {
    > 223 |       const mcps = oliver.getMCPRegistry();
          |                           ^
      224 |
      225 |       expect(mcps.playwright.writeOperations).toBe(true);
      226 |       expect(mcps.github.writeOperations).toBe(true);

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:223:27)

  ‚óè OliverMCPAgent ‚Ä∫ Confidence Scoring ‚Ä∫ should have high confidence for exact matches

    expect(received).toBeGreaterThan(expected)

    Expected: > 0.95
    Received:   0.9

      237 |       });
      238 |
    > 239 |       expect(recommendation.confidence).toBeGreaterThan(0.95);
          |                                         ^
      240 |     });
      241 |
      242 |     it('should have lower confidence for ambiguous requests', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:239:41)

  ‚óè OliverMCPAgent ‚Ä∫ Confidence Scoring ‚Ä∫ should have lower confidence for ambiguous requests

    expect(received).toBeLessThan(expected)

    Expected: < 0.8
    Received:   0.8

      247 |       });
      248 |
    > 249 |       expect(recommendation.confidence).toBeLessThan(0.8);
          |                                         ^
      250 |     });
      251 |
      252 |     it('should increase confidence with more context', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:249:41)

  ‚óè OliverMCPAgent ‚Ä∫ Integration with Agents ‚Ä∫ should provide MCP suggestions for all OPERA agents

    TypeError: oliver.suggestMCPsForAgent is not a function

      299 |
      300 |       for (const agentId of agents) {
    > 301 |         const suggestions = await oliver.suggestMCPsForAgent(agentId);
          |                                          ^
      302 |
      303 |         expect(suggestions).toBeDefined();
      304 |         expect(suggestions.length).toBeGreaterThan(0);

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:301:42)

  ‚óè OliverMCPAgent ‚Ä∫ Integration with Agents ‚Ä∫ should suggest different MCPs for different agents

    TypeError: oliver.suggestMCPsForAgent is not a function

      307 |
      308 |     it('should suggest different MCPs for different agents', async () => {
    > 309 |       const mariaSuggestions = await oliver.suggestMCPsForAgent('maria-qa');
          |                                             ^
      310 |       const jamesSuggestions = await oliver.suggestMCPsForAgent('james-frontend');
      311 |
      312 |       expect(mariaSuggestions).not.toEqual(jamesSuggestions);

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:309:45)

  ‚óè OliverMCPAgent - Integration ‚Ä∫ should activate and return status

    expect(received).toBe(expected) // Object.is equality

    Expected: true
    Received: undefined

      331 |
      332 |     expect(response).toBeDefined();
    > 333 |     expect(response.success).toBe(true);
          |                              ^
      334 |   });
      335 |
      336 |   it('should provide MCP selection through activation', async () => {

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:333:30)

  ‚óè OliverMCPAgent - Integration ‚Ä∫ should provide MCP selection through activation

    expect(received).toBe(expected) // Object.is equality

    Expected: true
    Received: undefined

      344 |     });
      345 |
    > 346 |     expect(response.success).toBe(true);
          |                              ^
      347 |     expect(response.data).toBeDefined();
      348 |   });
      349 | });

      at Object.<anonymous> (tests/unit/mcp/oliver-mcp-orchestrator.test.ts:346:30)

FAIL UNIT tests/mcp/setup-validation.test.ts (210 MB heap size)
  MCP Setup Validation
    Configuration Files
      ‚úì should have MCP config file
      ‚úì should have valid JSON in MCP config
      ‚úì should have credentials directory
      ‚úì should have environment file (or template)
    Isolation Enforcement
      ‚úì should NOT have .env in project directory
      ‚úì should NOT have framework files in project (1 ms)
      ‚úï should have secure permissions on credentials file
    MCP Configuration
      ‚úì should have mcpServers section
      ‚úì should have at least 3 MCPs configured
      ‚úì should have github MCP configured
      ‚úì github MCP should have command
      ‚úì github MCP should have args
      ‚úì should have playwright MCP configured
      ‚úì playwright MCP should have command (1 ms)
      ‚úì playwright MCP should have args
      ‚úì should have supabase MCP configured
      ‚úì supabase MCP should have command
      ‚úì supabase MCP should have args
      ‚úì should use environment variable substitution
    Environment Variables
      ‚úì should have GitHub token
      ‚úì should have Playwright browsers path
      ‚úì should have Supabase credentials
      ‚úì should NOT contain placeholder values
    Credential Formats
      ‚úï GitHub token should start with ghp_ (39 ms)
      ‚úï Supabase URL should be HTTPS
      ‚úì Sentry DSN should be valid format
    Framework Integration
      ‚úì should have health check script (1 ms)
      ‚úì should have setup wizard script
      ‚úì should have isolation validation script
    Documentation
      ‚úì should have main MCP setup guide
      ‚úì should have quick start guide
      ‚úì should have troubleshooting guide
      ‚úì should have individual setup guides
    Templates
      ‚úì should have MCP environment template
      ‚úì should have MCP config template (1 ms)

  ‚óè MCP Setup Validation ‚Ä∫ Isolation Enforcement ‚Ä∫ should have secure permissions on credentials file

    expect(received).toBe(expected) // Object.is equality

    Expected: 384
    Received: 420

      128 |
      129 |       // Should be 0o600 (owner read/write only)
    > 130 |       expect(mode).toBe(0o600);
          |                    ^
      131 |     });
      132 |   });
      133 |

      at Object.<anonymous> (tests/mcp/setup-validation.test.ts:130:20)

  ‚óè MCP Setup Validation ‚Ä∫ Credential Formats ‚Ä∫ GitHub token should start with ghp_

    expect(received).toMatch(expected)

    Expected pattern: /^ghp_/
    Received string:  "gho_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX" (redacted)

      232 |
      233 |       if (token && !token.includes('xxxx')) {
    > 234 |         expect(token).toMatch(/^ghp_/);
          |                       ^
      235 |         expect(token.length).toBe(40);
      236 |       }
      237 |     });

      at Object.<anonymous> (tests/mcp/setup-validation.test.ts:234:23)

  ‚óè MCP Setup Validation ‚Ä∫ Credential Formats ‚Ä∫ Supabase URL should be HTTPS

    expect(received).toMatch(expected)

    Expected pattern: /^https:\/\//
    Received string:  "http://localhost:54321"

      241 |
      242 |       if (url && !url.includes('xxxx')) {
    > 243 |         expect(url).toMatch(/^https:\/\//);
          |                     ^
      244 |         expect(url).toMatch(/\.supabase\.co$/);
      245 |       }
      246 |     });

      at Object.<anonymous> (tests/mcp/setup-validation.test.ts:243:21)

FAIL UNIT tests/mcp/gitmcp-integration.test.ts (231 MB heap size)
  GitMCP Integration
    Repository Query
      ‚úì should query FastAPI repository (3 ms)
      ‚úì should query specific documentation path
      ‚úì should provide SHA for content verification (1 ms)
      ‚úì should include last updated timestamp
      ‚úì should throw error for non-existent repository (22 ms)
    Framework Documentation Search
      ‚úï should search FastAPI OAuth documentation
      ‚úï should search React Hooks documentation
      ‚úï should extract code examples from documentation
      ‚úì should throw error for unsupported framework (1 ms)
      ‚úï should determine correct documentation path for topic
    Anti-Hallucination Validation
      ‚úì should provide 99%+ confidence for GitMCP responses
      ‚úï should mark documentation as low hallucination risk
      ‚úì should validate content freshness
      ‚úï should recommend using fresh content (1 ms)
    Oliver-MCP Integration
      ‚úì should detect when GitMCP should be used
      ‚úï should detect recent features requiring GitMCP
      ‚úì should not require GitMCP for general queries
      ‚úï should route framework query to GitMCP
      ‚úï should validate documentation before use (1 ms)
    Multiple Framework Support
      ‚úï should support 30+ frameworks (Backend)
      ‚úï should support 30+ frameworks (Frontend)
      ‚úï should support 30+ frameworks (ML)
    OPERA Agent Integration
      ‚úï should support Marcus-Backend framework research
      ‚úï should support James-Frontend component patterns
      ‚úï should support Dr.AI-ML model deployment
      ‚úï should support Alex-BA requirements research

  ‚óè GitMCP Integration ‚Ä∫ Framework Documentation Search ‚Ä∫ should search FastAPI OAuth documentation

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:463:33)

  ‚óè GitMCP Integration ‚Ä∫ Framework Documentation Search ‚Ä∫ should search React Hooks documentation

    Repository not found or path invalid: facebook/react/docs

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:473:33)

  ‚óè GitMCP Integration ‚Ä∫ Framework Documentation Search ‚Ä∫ should extract code examples from documentation

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:481:33)

  ‚óè GitMCP Integration ‚Ä∫ Framework Documentation Search ‚Ä∫ should determine correct documentation path for topic

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:494:37)

  ‚óè GitMCP Integration ‚Ä∫ Anti-Hallucination Validation ‚Ä∫ should mark documentation as low hallucination risk

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:508:33)

  ‚óè GitMCP Integration ‚Ä∫ Anti-Hallucination Validation ‚Ä∫ should recommend using fresh content

    expect(received).toBe(expected) // Object.is equality

    Expected: "use"
    Received: "outdated"

      525 |
      526 |       // Mock data is recent, should recommend use
    > 527 |       expect(freshness.recommendation).toBe('use');
          |                                        ^
      528 |     });
      529 |   });
      530 |

      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:527:40)

  ‚óè GitMCP Integration ‚Ä∫ Oliver-MCP Integration ‚Ä∫ should detect recent features requiring GitMCP

    expect(received).toContain(expected) // indexOf

    Expected substring: "Recent features"
    Received string:    "Framework React detected. GitMCP ensures 99%+ accuracy with real-time docs."

      552 |
      553 |       expect(decision.useGitMCP).toBe(true);
    > 554 |       expect(decision.reason).toContain('Recent features');
          |                               ^
      555 |     });
      556 |
      557 |     it('should not require GitMCP for general queries', async () => {

      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:554:31)

  ‚óè GitMCP Integration ‚Ä∫ Oliver-MCP Integration ‚Ä∫ should route framework query to GitMCP

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at OliverMCPGitMCPIntegration.routeToGitMCP (tests/mcp/gitmcp-integration.test.ts:397:30)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:566:36)

  ‚óè GitMCP Integration ‚Ä∫ Oliver-MCP Integration ‚Ä∫ should validate documentation before use

    Repository not found or path invalid: facebook/react/docs

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at OliverMCPGitMCPIntegration.routeToGitMCP (tests/mcp/gitmcp-integration.test.ts:397:30)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:574:36)

  ‚óè GitMCP Integration ‚Ä∫ Multiple Framework Support ‚Ä∫ should support 30+ frameworks (Backend)

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:587:35)

  ‚óè GitMCP Integration ‚Ä∫ Multiple Framework Support ‚Ä∫ should support 30+ frameworks (Frontend)

    Repository not found or path invalid: facebook/react/docs/tutorial

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:596:35)

  ‚óè GitMCP Integration ‚Ä∫ Multiple Framework Support ‚Ä∫ should support 30+ frameworks (ML)

    Repository not found or path invalid: huggingface/transformers/docs/source

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:605:35)

  ‚óè GitMCP Integration ‚Ä∫ OPERA Agent Integration ‚Ä∫ should support Marcus-Backend framework research

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial/security

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:613:33)

  ‚óè GitMCP Integration ‚Ä∫ OPERA Agent Integration ‚Ä∫ should support James-Frontend component patterns

    Repository not found or path invalid: facebook/react/docs

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:620:33)

  ‚óè GitMCP Integration ‚Ä∫ OPERA Agent Integration ‚Ä∫ should support Dr.AI-ML model deployment

    Repository not found or path invalid: huggingface/transformers/docs/source

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:627:33)

  ‚óè GitMCP Integration ‚Ä∫ OPERA Agent Integration ‚Ä∫ should support Alex-BA requirements research

    Repository not found or path invalid: tiangolo/fastapi/docs/tutorial

       96 |
       97 |     if (!mockContent) {
    >  98 |       throw new Error(`Repository not found or path invalid: ${owner}/${repo}${path ? `/${path}` : ''}`);
          |             ^
       99 |     }
      100 |
      101 |     return {

      at MockGitMCPClient.queryRepository (tests/mcp/gitmcp-integration.test.ts:98:13)
      at MockGitMCPClient.searchDocumentation (tests/mcp/gitmcp-integration.test.ts:127:33)
      at Object.<anonymous> (tests/mcp/gitmcp-integration.test.ts:635:33)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
PASS INTEGRATION tests/update/update-manager.test.ts (223 MB heap size)
  UpdateManager
    1. checkForUpdates - no updates available
      ‚úì should return hasUpdate=false when current version is latest (1 ms)
      ‚úì should handle check when already on future version
    2. checkForUpdates - new version available
      ‚úì should detect when a new version is available
      ‚úì should correctly identify minor version updates
      ‚úì should correctly identify patch version updates (1 ms)
    3. installUpdate - successful installation
      ‚úì should successfully install an update with backup
      ‚úì should skip backup if backupBeforeUpdate is false
      ‚úì should record successful update in history
    4. installUpdate - network failure
      ‚úì should handle network errors gracefully during update check (1 ms)
      ‚úì should handle npm update failures gracefully
      ‚úì should continue with failed backup warning
    5. installUpdate - checksum validation
      ‚úì should detect version mismatch after installation
      ‚úì should accept version without v prefix
    6. crashRecovery - restore from crash
      ‚úì should rollback to previous version from backup (1 ms)
      ‚úì should find and use most recent backup if none specified
      ‚úì should handle rollback failure gracefully
      ‚úì should handle no backups found
    7. updateLock - prevent concurrent updates
      ‚úì should handle concurrent update attempts
    8. backupCreation - verify backup before update
      ‚úì should create backup before starting update (1 ms)
      ‚úì should create backup with correct naming convention
      ‚úì should create backups directory if it does not exist
    Additional UpdateManager Features
      getUpdateHistory
        ‚úì should retrieve update history from file
        ‚úì should return empty array if history file does not exist
      getChangelog
        ‚úì should retrieve changelog for specific version
        ‚úì should retrieve latest changelog when no version specified
        ‚úì should return fallback message when changelog unavailable (1 ms)
      listBackups
        ‚úì should list all available backups
        ‚úì should filter out non-backup files
        ‚úì should return empty array if backups directory does not exist
      Configuration
        ‚úì should initialize with default configuration
        ‚úì should accept custom configuration
      Update History Recording
        ‚úì should record failed updates with error message
        ‚úì should limit history to 50 entries (1 ms)
        ‚úì should not fail update if history recording fails
      No Update Scenario
        ‚úì should return true and log message when already on latest version
        ‚úì should install specific target version even if no update available

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
ls: config.js: No such file or directory
ls: component.ts: No such file or directory
FAIL UNIT tests/unit/security/credential-encryptor.test.ts (37.321 s, 39 MB heap size)
  CredentialEncryptor
    encrypt
      ‚úì should encrypt credentials successfully (772 ms)
      ‚úì should produce different ciphertext for same plaintext (unique IV) (1417 ms)
      ‚úì should encrypt with optional password (1700 ms)
      ‚úì should handle empty credentials (1458 ms)
    decrypt
      ‚úì should decrypt credentials successfully (2448 ms)
      ‚úì should decrypt with correct password (2803 ms)
      ‚úì should fail with wrong password (2875 ms)
      ‚úì should fail with wrong project context (1970 ms)
      ‚úì should fail with corrupted ciphertext (1739 ms)
      ‚úì should fail with tampered auth tag (2241 ms)
      ‚úì should fail with unsupported version (557 ms)
      ‚úì should fail with unsupported algorithm (805 ms)
    encryptToFile
      ‚úï should encrypt and save to file (906 ms)
      ‚úï should create parent directories if needed (521 ms)
    decryptFromFile
      ‚úï should decrypt from file (699 ms)
      ‚úï should return empty credentials if file does not exist (1 ms)
      ‚úì should fail with corrupted file (27 ms)
    validateCredentialsFile
      ‚úï should validate valid credentials file (973 ms)
      ‚úï should detect missing required fields (1 ms)
      ‚úï should detect unsupported version
      ‚úï should detect unsupported algorithm (3 ms)
    reencryptWithPassword
      ‚úï should reencrypt with new password (1009 ms)
      ‚úï should fail to decrypt without password after reencryption (654 ms)
    round-trip consistency
      ‚úì should maintain data integrity through multiple encrypt/decrypt cycles (8693 ms)
      ‚úì should handle large credential sets (2112 ms)

  ‚óè CredentialEncryptor ‚Ä∫ encryptToFile ‚Ä∫ should encrypt and save to file

    TypeError: Cannot read properties of undefined (reading 'isFile')

      180 |       // Check file exists
      181 |       const stats = await fs.stat(filePath);
    > 182 |       expect(stats.isFile()).toBe(true);
          |                    ^
      183 |
      184 |       // Check file permissions (Unix only)
      185 |       if (process.platform !== 'win32') {

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:182:20)

  ‚óè CredentialEncryptor ‚Ä∫ encryptToFile ‚Ä∫ should create parent directories if needed

    TypeError: Cannot read properties of undefined (reading 'isFile')

      199 |
      200 |       const stats = await fs.stat(filePath);
    > 201 |       expect(stats.isFile()).toBe(true);
          |                    ^
      202 |     });
      203 |   });
      204 |

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:201:20)

  ‚óè CredentialEncryptor ‚Ä∫ decryptFromFile ‚Ä∫ should decrypt from file

    Failed to load credentials: "undefined" is not valid JSON

      291 |
      292 |       this.logger.error('Failed to load encrypted credentials', { error, filePath });
    > 293 |       throw new Error(`Failed to load credentials: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      294 |     }
      295 |   }
      296 |

      at CredentialEncryptor.decryptFromFile (src/security/credential-encryptor.ts:293:13)
      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:210:25)

  ‚óè CredentialEncryptor ‚Ä∫ decryptFromFile ‚Ä∫ should return empty credentials if file does not exist

    Failed to load credentials: "undefined" is not valid JSON

      291 |
      292 |       this.logger.error('Failed to load encrypted credentials', { error, filePath });
    > 293 |       throw new Error(`Failed to load credentials: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      294 |     }
      295 |   }
      296 |

      at CredentialEncryptor.decryptFromFile (src/security/credential-encryptor.ts:293:13)
      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:218:25)

  ‚óè CredentialEncryptor ‚Ä∫ validateCredentialsFile ‚Ä∫ should validate valid credentials file

    expect(received).toBe(expected) // Object.is equality

    Expected: true
    Received: false

      239 |       const validation = await encryptor.validateCredentialsFile(filePath);
      240 |
    > 241 |       expect(validation.valid).toBe(true);
          |                                ^
      242 |       expect(validation.version).toBe('1.0.0');
      243 |       expect(validation.projectId).toBe('test-project-123');
      244 |     });

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:241:32)

  ‚óè CredentialEncryptor ‚Ä∫ validateCredentialsFile ‚Ä∫ should detect missing required fields

    expect(received).toContain(expected) // indexOf

    Expected substring: "Missing required fields"
    Received string:    "Invalid file format: \"undefined\" is not valid JSON"

      255 |
      256 |       expect(validation.valid).toBe(false);
    > 257 |       expect(validation.error).toContain('Missing required fields');
          |                                ^
      258 |     });
      259 |
      260 |     it('should detect unsupported version', async () => {

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:257:32)

  ‚óè CredentialEncryptor ‚Ä∫ validateCredentialsFile ‚Ä∫ should detect unsupported version

    expect(received).toContain(expected) // indexOf

    Expected substring: "Unsupported version: 2.0.0"
    Received string:    "Invalid file format: \"undefined\" is not valid JSON"

      270 |
      271 |       expect(validation.valid).toBe(false);
    > 272 |       expect(validation.error).toContain('Unsupported version: 2.0.0');
          |                                ^
      273 |     });
      274 |
      275 |     it('should detect unsupported algorithm', async () => {

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:272:32)

  ‚óè CredentialEncryptor ‚Ä∫ validateCredentialsFile ‚Ä∫ should detect unsupported algorithm

    expect(received).toContain(expected) // indexOf

    Expected substring: "Unsupported algorithm: des"
    Received string:    "Invalid file format: \"undefined\" is not valid JSON"

      285 |
      286 |       expect(validation.valid).toBe(false);
    > 287 |       expect(validation.error).toContain('Unsupported algorithm: des');
          |                                ^
      288 |     });
      289 |   });
      290 |

      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:287:32)

  ‚óè CredentialEncryptor ‚Ä∫ reencryptWithPassword ‚Ä∫ should reencrypt with new password

    Re-encryption failed: Failed to load credentials: "undefined" is not valid JSON

      368 |     } catch (error) {
      369 |       this.logger.error('Re-encryption failed', { error, filePath });
    > 370 |       throw new Error(`Re-encryption failed: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      371 |     }
      372 |   }
      373 | }

      at CredentialEncryptor.reencryptWithPassword (src/security/credential-encryptor.ts:370:13)
      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:300:7)

  ‚óè CredentialEncryptor ‚Ä∫ reencryptWithPassword ‚Ä∫ should fail to decrypt without password after reencryption

    Re-encryption failed: Failed to load credentials: "undefined" is not valid JSON

      368 |     } catch (error) {
      369 |       this.logger.error('Re-encryption failed', { error, filePath });
    > 370 |       throw new Error(`Re-encryption failed: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      371 |     }
      372 |   }
      373 | }

      at CredentialEncryptor.reencryptWithPassword (src/security/credential-encryptor.ts:370:13)
      at Object.<anonymous> (tests/unit/security/credential-encryptor.test.ts:312:7)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
FAIL INTEGRATION tests/integration/marcus-james-handoff.test.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/src/agents/opera/marcus-backend/enhanced-marcus.ts:42
    const __filename = (0, url_1.fileURLToPath)(import.meta.url);
          ^

    SyntaxError: Identifier '__filename' has already been declared

      13 |
      14 | import { describe, it, expect, beforeAll, afterAll } from '@jest/globals';
    > 15 | import { EnhancedMarcus } from '../../src/agents/opera/marcus-backend/enhanced-marcus.js';
         | ^
      16 | import { EnhancedJames } from '../../src/agents/opera/james-frontend/enhanced-james.js';
      17 | import { EnhancedVectorMemoryStore } from '../../src/rag/enhanced-vector-memory-store.js';
      18 | import type { AgentActivationContext, AgentResponse } from '../../src/agents/core/base-agent.js';

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)
      at Object.<anonymous> (tests/integration/marcus-james-handoff.test.ts:15:1)

FAIL INTEGRATION tests/integration/agent-auto-activation.test.ts (77 MB heap size)
  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Alex-BA (Requirements Analyst) ‚Ä∫ should activate on requirements/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Alex-BA (Requirements Analyst) ‚Ä∫ should activate on *.feature files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Alex-BA (Requirements Analyst) ‚Ä∫ should activate on GitHub issues (keyword trigger)

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dana-Database (Database Architect) ‚Ä∫ should activate on *.sql files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dana-Database (Database Architect) ‚Ä∫ should activate on migrations/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dana-Database (Database Architect) ‚Ä∫ should activate on supabase/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dana-Database (Database Architect) ‚Ä∫ should activate on prisma/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dana-Database (Database Architect) ‚Ä∫ should activate on RLS policy keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Marcus-Backend (API Architect) ‚Ä∫ should activate on *.api.* files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Marcus-Backend (API Architect) ‚Ä∫ should activate on routes/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Marcus-Backend (API Architect) ‚Ä∫ should activate on controllers/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Marcus-Backend (API Architect) ‚Ä∫ should activate on API keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ James-Frontend (UI/UX Expert) ‚Ä∫ should activate on *.tsx files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ James-Frontend (UI/UX Expert) ‚Ä∫ should activate on *.jsx files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ James-Frontend (UI/UX Expert) ‚Ä∫ should activate on *.vue files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ James-Frontend (UI/UX Expert) ‚Ä∫ should activate on *.css and *.scss files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ James-Frontend (UI/UX Expert) ‚Ä∫ should activate on component keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Maria-QA (Quality Guardian) ‚Ä∫ should activate on *.test.* files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Maria-QA (Quality Guardian) ‚Ä∫ should activate on __tests__/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Maria-QA (Quality Guardian) ‚Ä∫ should activate on *.spec.* files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Maria-QA (Quality Guardian) ‚Ä∫ should activate on test keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Sarah-PM (Project Coordinator) ‚Ä∫ should activate on *.md files (docs)

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Sarah-PM (Project Coordinator) ‚Ä∫ should activate on docs/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Sarah-PM (Project Coordinator) ‚Ä∫ should activate on project event keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dr.AI-ML (AI/ML Specialist) ‚Ä∫ should activate on *.py files (ML code)

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dr.AI-ML (AI/ML Specialist) ‚Ä∫ should activate on *.ipynb files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dr.AI-ML (AI/ML Specialist) ‚Ä∫ should activate on models/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Dr.AI-ML (AI/ML Specialist) ‚Ä∫ should activate on ML keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Oliver-MCP (MCP Orchestrator) ‚Ä∫ should activate on **/mcp/** files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Oliver-MCP (MCP Orchestrator) ‚Ä∫ should activate on *.mcp.* files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Core Agent Auto-Activation ‚Ä∫ Oliver-MCP (MCP Orchestrator) ‚Ä∫ should activate on MCP keywords

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should activate marcus-node for Node.js projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should activate marcus-python for Python projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should activate marcus-rails for Ruby/Rails projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should activate marcus-go for Go projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should activate marcus-java for Java/Spring Boot projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ Marcus Backend Sub-Agents (5) ‚Ä∫ should detect framework from file content (FastAPI)

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should activate james-react for React projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should activate james-vue for Vue projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should activate james-nextjs for Next.js projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should activate james-angular for Angular projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should activate james-svelte for Svelte projects

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Auto-Activation ‚Ä∫ James Frontend Sub-Agents (5) ‚Ä∫ should detect React from imports

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ False Positive Prevention ‚Ä∫ should not activate agents on irrelevant files

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ False Positive Prevention ‚Ä∫ should not activate duplicate agents simultaneously

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ False Positive Prevention ‚Ä∫ should not activate sub-agents when tech stack does not match

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ False Positive Prevention ‚Ä∫ should handle unknown file types gracefully

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Routing Accuracy ‚Ä∫ should achieve 95%+ accuracy on tech stack detection

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Routing Accuracy ‚Ä∫ should route to correct sub-agent based on file content

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Sub-Agent Routing Accuracy ‚Ä∫ should provide confidence scores for all selections

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Performance & Efficiency ‚Ä∫ should detect tech stack in < 100ms

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Performance & Efficiency ‚Ä∫ should handle large projects efficiently

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Performance & Efficiency ‚Ä∫ should cache tech stack detection results

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Validation Summary ‚Ä∫ should validate all 8 core agents have activation patterns

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Validation Summary ‚Ä∫ should validate all 10 sub-agents have routing logic

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)

  ‚óè Agent Auto-Activation Validation ‚Ä∫ Validation Summary ‚Ä∫ should confirm zero false positives in test suite

    TypeError: fs.mkdtemp is not a function

      28 |   beforeAll(async () => {
      29 |     // Create temporary test directory
    > 30 |     tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'versatil-agent-activation-'));
         |                        ^
      31 |   });
      32 |
      33 |   afterAll(async () => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:30:24)


  ‚óè Test suite failed to run

    TypeError: fs.rm is not a function

      33 |   afterAll(async () => {
      34 |     // Cleanup temporary directory
    > 35 |     await fs.rm(tempDir, { recursive: true, force: true });
         |              ^
      36 |   });
      37 |
      38 |   beforeEach(() => {

      at Object.<anonymous> (tests/integration/agent-auto-activation.test.ts:35:14)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "üîß Initializing GraphRAG Store (centering-vine-454613-b3)...".

      42 |   target: string;  // Node ID
      43 |   relationship: string;  // e.g., "uses", "relates_to", "implements"
    > 44 |   weight: number;  // Strength of relationship (0-1)
         |                 ^
      45 | }
      46 |
      47 | export interface PatternNode extends GraphNode {

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at GraphRAGStore.initialize (src/lib/graphrag-store.ts:44:17)
      at EnhancedVectorMemoryStore.initializeGraphRAG (src/rag/enhanced-vector-memory-store.ts:113:57)
      at EnhancedVectorMemoryStore.initialize (src/rag/enhanced-vector-memory-store.ts:85:20)

FAIL INTEGRATION tests/agents/sub-agent-activation.test.ts (112 MB heap size)
  Sub-Agent Activation Test Suite
    Marcus-Node Auto-Activation
      ‚úì should detect Node.js from package.json (2 ms)
      ‚úì should detect Express.js patterns (1 ms)
      ‚úì should detect Fastify patterns
      ‚úì should detect NestJS patterns
    Marcus-Python Auto-Activation
      ‚úì should detect Python from .py extension
      ‚úì should detect FastAPI patterns
      ‚úì should detect Django patterns (1 ms)
      ‚úì should detect Flask patterns
    Marcus-Rails Auto-Activation
      ‚úì should detect Ruby from .rb extension
      ‚úì should detect Rails patterns
      ‚úì should detect ActiveRecord patterns
    Marcus-Go Auto-Activation
      ‚úì should detect Go from .go extension
      ‚úì should detect Gin patterns (1 ms)
      ‚úì should detect Echo patterns
    Marcus-Java Auto-Activation
      ‚úì should detect Java from .java extension
      ‚úì should detect Spring Boot patterns
    James-React Auto-Activation
      ‚úì should detect React from .tsx extension
      ‚úì should detect React hooks patterns
      ‚úì should detect JSX syntax (1 ms)
    James-Vue Auto-Activation
      ‚úì should detect Vue from .vue extension
      ‚úì should detect Vue Composition API
    James-NextJS Auto-Activation
      ‚úì should detect Next.js from imports
      ‚úï should detect App Router patterns (2 ms)
    James-Angular Auto-Activation
      ‚úì should detect Angular from decorators
      ‚úì should detect Angular modules (1 ms)
    James-Svelte Auto-Activation
      ‚úï should detect Svelte from .svelte extension
      ‚úï should detect Svelte stores
    Sub-Agent Validation Report
      ‚úï should generate sub-agent activation report (1 ms)

  ‚óè Sub-Agent Activation Test Suite ‚Ä∫ James-NextJS Auto-Activation ‚Ä∫ should detect App Router patterns

    expect(received).toBe(expected) // Object.is equality

    Expected: "james-nextjs"
    Received: "james-react"

      520 |       const selection = await SubAgentSelector.selectFrontendSubAgent(filePath, content, projectPath);
      521 |
    > 522 |       expect(selection.subAgentId).toBe('james-nextjs');
          |                                    ^
      523 |     });
      524 |   });
      525 |

      at Object.<anonymous> (tests/agents/sub-agent-activation.test.ts:522:36)

  ‚óè Sub-Agent Activation Test Suite ‚Ä∫ James-Svelte Auto-Activation ‚Ä∫ should detect Svelte from .svelte extension

    expect(received).toBeGreaterThan(expected)

    Expected: > 0.7
    Received:   0.7

      590 |       expect(selection.subAgentId).toBe('james-svelte');
      591 |       expect(selection.baseAgentId).toBe('james-frontend');
    > 592 |       expect(selection.confidence).toBeGreaterThan(0.7);
          |                                    ^
      593 |       expect(latency).toBeLessThan(500);
      594 |
      595 |       tracker.trackActivation({

      at Object.<anonymous> (tests/agents/sub-agent-activation.test.ts:592:36)

  ‚óè Sub-Agent Activation Test Suite ‚Ä∫ James-Svelte Auto-Activation ‚Ä∫ should detect Svelte stores

    expect(received).toBe(expected) // Object.is equality

    Expected: "james-svelte"
    Received: "marcus-node"

      611 |       const selection = await SubAgentSelector.selectFrontendSubAgent(filePath, content, projectPath);
      612 |
    > 613 |       expect(selection.subAgentId).toBe('james-svelte');
          |                                    ^
      614 |       expect(selection.confidence).toBeGreaterThan(0.7);
      615 |     });
      616 |   });

      at Object.<anonymous> (tests/agents/sub-agent-activation.test.ts:613:36)

  ‚óè Sub-Agent Activation Test Suite ‚Ä∫ Sub-Agent Validation Report ‚Ä∫ should generate sub-agent activation report

    expect(received).toBeGreaterThanOrEqual(expected)

    Expected: >= 85
    Received:    0

      624 |       const report = tracker.generateReport();
      625 |
    > 626 |       expect(report.overallAccuracy).toBeGreaterThanOrEqual(85);
          |                                      ^
      627 |       expect(report.overallLatency).toBeLessThan(500);
      628 |
      629 |       console.log('\n=== SUB-AGENT ACTIVATION REPORT ===\n');

      at Object.<anonymous> (tests/agents/sub-agent-activation.test.ts:626:38)


ReferenceError: You are trying to `import` a file after the Jest environment has been torn down. From tests/integration/rag-pattern-storage-e2e.test.ts.

      at ClientPool.clientFactory (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:504:39)
      at ClientPool.acquire (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/pool.js:121:35)
      at ClientPool.run (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/pool.js:260:29)
      at node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:1412:30
      at Firestore._retry (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:1270:30)
      at node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/reference/query-util.js:189:33

ReferenceError: You are trying to `import` a file after the Jest environment has been torn down. From tests/integration/rag-pattern-storage-e2e.test.ts.

      at Firestore.get (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:1540:16)
      at ClientPool.clientFactory (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:526:45)
      at ClientPool.acquire (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/pool.js:121:35)
      at ClientPool.run (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/pool.js:260:29)
      at node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:1412:30
      at Firestore._retry (node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/index.js:1270:30)
      at node_modules/.pnpm/@google-cloud+firestore@7.11.6_encoding@0.1.13/node_modules/@google-cloud/firestore/build/src/reference/query-util.js:189:33
FAIL INTEGRATION tests/integration/dana-marcus-handoff.test.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/node_modules/.pnpm/@anthropic-ai+claude-agent-sdk@0.1.28_zod@3.25.76/node_modules/@anthropic-ai/claude-agent-sdk/sdk.mjs:6203
    import { join as join3 } from "path";
    ^^^^^^

    SyntaxError: Cannot use import statement outside a module

       5 |  */
       6 |
    >  7 | import { query, type AgentDefinition } from '@anthropic-ai/claude-agent-sdk';
         | ^
       8 | import { OPERA_AGENTS } from './agent-definitions.js';
       9 | import type { AgentResponse, AgentActivationContext } from '../core/base-agent.js';
      10 | import type { EnhancedVectorMemoryStore } from '../../rag/enhanced-vector-memory-store.js';

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)
      at Object.<anonymous> (src/agents/sdk/sdk-agent-adapter.ts:7:1)
      at Object.<anonymous> (src/agents/opera/dana-database/dana-sdk-agent.ts:11:1)
      at Object.<anonymous> (tests/integration/dana-marcus-handoff.test.ts:15:1)

FAIL INTEGRATION tests/agents/mcp/oliver-mcp-integration.test.ts (137 MB heap size)
  Oliver-MCP Integration Tests
    MCP Selection Engine
      ‚úì should select Playwright for browser testing tasks (2 ms)
      ‚úì should select GitHub MCP for repository operations (22 ms)
      ‚úì should select Exa for general research tasks
      ‚úì should select Supabase for database operations
      ‚úì should select Semgrep for security scanning (1 ms)
    Anti-Hallucination Detector
      ‚úì should detect high hallucination risk for FastAPI queries
      ‚úì should detect high hallucination risk for React queries (1 ms)
      ‚úï should detect high hallucination risk for Django queries
      ‚úì should detect high hallucination risk for Next.js queries (1 ms)
      ‚úï should provide direct anti-hallucination detection
    GitMCP Query Generator
      ‚úï should generate precise GitMCP query for FastAPI OAuth
      ‚úì should generate precise GitMCP query for React Server Components
      ‚úï should generate precise GitMCP query for Next.js App Router (4 ms)
      ‚úï should generate GitMCP query for Django database migrations (1 ms)
      ‚úï should generate direct GitMCP query
    Main Orchestrator Integration
      ‚úì should route research task with full anti-hallucination flow (1 ms)
      ‚úì should provide execution parameters for GitMCP
      ‚úì should provide execution parameters for Playwright
      ‚úï should provide execution parameters for GitHub (1 ms)
      ‚úì should provide expected duration for all MCPs (1 ms)
    Agent Activation
      ‚úì should activate successfully
      ‚úì should provide MCP suggestions on activation
    MCP Registry
      ‚úì should have all 11 MCPs registered (1 ms)
      ‚úì should classify MCPs correctly (3 ms)
      ‚úì should get MCP definition (1 ms)
      ‚úì should get MCPs for specific agent
      ‚úì should get MCPs by type
    Usage Statistics
      ‚úì should track MCP usage
      ‚úì should track usage for different MCPs
    Edge Cases & Error Handling
      ‚úï should handle minimal request information
      ‚úì should handle unknown framework gracefully (1 ms)
      ‚úï should handle very long descriptions
      ‚úì should handle multiple framework mentions
      ‚úì should handle conflicting task type signals

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ Anti-Hallucination Detector ‚Ä∫ should detect high hallucination risk for Django queries

    expect(received).toBe(expected) // Object.is equality

    Expected: "gitmcp"
    Received: "exa"

      151 |       const result = await oliver.routeTask(request);
      152 |
    > 153 |       expect(result.recommendedMCP).toBe('gitmcp');
          |                                     ^
      154 |       expect(result.hallucinationRisk).toBeDefined();
      155 |       expect(result.hallucinationRisk!.level).toMatch(/high|medium/);
      156 |     });

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:153:37)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ Anti-Hallucination Detector ‚Ä∫ should provide direct anti-hallucination detection

    expect(received).toBe(expected) // Object.is equality

    Expected: "FastAPI"
    Received: undefined

      180 |       expect(risk.recommendation).toBeDefined();
      181 |       expect(risk.recommendation!.action).toBe('use-gitmcp');
    > 182 |       expect(risk.recommendation!.framework).toBe('FastAPI');
          |                                              ^
      183 |     });
      184 |   });
      185 |

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:182:46)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ GitMCP Query Generator ‚Ä∫ should generate precise GitMCP query for FastAPI OAuth

    expect(received).toContain(expected) // indexOf

    Expected substring: "security"
    Received string:    "docs/reference"

      202 |       expect(result.gitMCPQuery).toBeDefined();
      203 |       expect(result.gitMCPQuery!.repository).toBe('tiangolo/fastapi');
    > 204 |       expect(result.gitMCPQuery!.path).toContain('security');
          |                                        ^
      205 |       expect(result.gitMCPQuery!.confidence).toBeGreaterThanOrEqual(70);
      206 |     });
      207 |

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:204:40)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ GitMCP Query Generator ‚Ä∫ should generate precise GitMCP query for Next.js App Router

    expect(received).toBe(expected) // Object.is equality

    Expected: "vercel/next.js"
    Received: "unknown/unknown"

      234 |       expect(result.recommendedMCP).toBe('gitmcp');
      235 |       expect(result.gitMCPQuery).toBeDefined();
    > 236 |       expect(result.gitMCPQuery!.repository).toBe('vercel/next.js');
          |                                              ^
      237 |     });
      238 |
      239 |     test('should generate GitMCP query for Django database migrations', async () => {

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:236:46)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ GitMCP Query Generator ‚Ä∫ should generate GitMCP query for Django database migrations

    expect(received).toBe(expected) // Object.is equality

    Expected: "gitmcp"
    Received: "exa"

      247 |       const result = await oliver.routeTask(request);
      248 |
    > 249 |       expect(result.recommendedMCP).toBe('gitmcp');
          |                                     ^
      250 |       expect(result.gitMCPQuery).toBeDefined();
      251 |       expect(result.gitMCPQuery!.repository).toBe('django/django');
      252 |       expect(result.gitMCPQuery!.path).toContain('migrations');

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:249:37)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ GitMCP Query Generator ‚Ä∫ should generate direct GitMCP query

    expect(received).toContain(expected) // indexOf

    Expected substring: "security"
    Received string:    "docs/reference"

      262 |
      263 |       expect(query.repository).toBe('tiangolo/fastapi');
    > 264 |       expect(query.path).toContain('security');
          |                          ^
      265 |       expect(query.fileType).toMatch(/docs|tutorial/);
      266 |       expect(query.confidence).toBeGreaterThanOrEqual(70);
      267 |       expect(query.reasoning).toBeDefined();

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:264:26)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ Main Orchestrator Integration ‚Ä∫ should provide execution parameters for GitHub

    expect(received).toBe(expected) // Object.is equality

    Expected: "github"
    Received: "gitmcp"

      338 |       const result = await oliver.routeTask(request);
      339 |
    > 340 |       expect(result.recommendedMCP).toBe('github');
          |                                     ^
      341 |       expect(result.execution.parameters.repository).toBe('tiangolo/fastapi');
      342 |     });
      343 |

      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:340:37)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ Edge Cases & Error Handling ‚Ä∫ should handle minimal request information

    TypeError: Cannot read properties of undefined (reading 'mcpName')

      426 |     this.emit('mcp-selected', {
      427 |       taskId: task.id,
    > 428 |       selectedMCP: result.primary.mcpName,
          |                                   ^
      429 |       confidence: result.primary.confidence
      430 |     });
      431 |

      at MCPSelectionEngine.selectMCP (src/agents/mcp/mcp-selection-engine.ts:428:35)
      at OliverMCPAgent.routeTask (src/agents/mcp/oliver-mcp-orchestrator.ts:393:53)
      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:503:22)

  ‚óè Oliver-MCP Integration Tests ‚Ä∫ Edge Cases & Error Handling ‚Ä∫ should handle very long descriptions

    TypeError: Cannot read properties of undefined (reading 'mcpName')

      426 |     this.emit('mcp-selected', {
      427 |       taskId: task.id,
    > 428 |       selectedMCP: result.primary.mcpName,
          |                                   ^
      429 |       confidence: result.primary.confidence
      430 |     });
      431 |

      at MCPSelectionEngine.selectMCP (src/agents/mcp/mcp-selection-engine.ts:428:35)
      at OliverMCPAgent.routeTask (src/agents/mcp/oliver-mcp-orchestrator.ts:393:53)
      at Object.<anonymous> (tests/agents/mcp/oliver-mcp-integration.test.ts:532:22)

ls: non-existent-0.ts: No such file or directory
ls: non-existent-1.ts: No such file or directory
ls: non-existent-2.ts: No such file or directory
ls: non-existent-3.ts: No such file or directory
ls: non-existent-4.ts: No such file or directory
ls: non-existent-5.ts: No such file or directory
ls: non-existent-6.ts: No such file or directory
ls: non-existent-7.ts: No such file or directory
ls: non-existent-8.ts: No such file or directory
ls: non-existent-9.ts: No such file or directory
FAIL INTEGRATION tests/agents/auto-activation.test.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/src/agents/opera/marcus-backend/enhanced-marcus.ts:42
    const __filename = (0, url_1.fileURLToPath)(import.meta.url);
          ^

    SyntaxError: Identifier '__filename' has already been declared

      15 | import { EnhancedMaria } from '../agents/opera/maria-qa/enhanced-maria.js';
      16 | import { EnhancedJames } from '../agents/opera/james-frontend/enhanced-james.js';
    > 17 | import { EnhancedMarcus } from '../agents/opera/marcus-backend/enhanced-marcus.js';
         | ^
      18 | import { getProactiveCapabilityEnhancer } from './proactive-capability-enhancer.js';
      19 | import type { RequiredCapabilities, EnhancementResult } from './proactive-capability-enhancer.js';
      20 |

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)
      at Object.<anonymous> (src/orchestration/proactive-agent-orchestrator.ts:17:1)
      at Object.<anonymous> (tests/agents/auto-activation.test.ts:18:1)

PASS INTEGRATION tests/update/rollback-manager.test.ts (121 MB heap size)
  RollbackManager
    Scenario 1: Create Rollback Point
      ‚úì should create rollback point successfully (1 ms)
      ‚úì should handle tar compression failure (13 ms)
      ‚úì should cleanup old rollback points when exceeding max (1 ms)
    Scenario 2: Rollback to Previous Version
      ‚úì should rollback to previous version successfully (28 ms)
      ‚úì should throw error when no rollback points exist
      ‚úì should return false on rollback extraction failure
    Scenario 3: Rollback to Specific Version
      ‚úì should rollback to specific version
      ‚úì should throw error when version not found
    Scenario 4: Health Check After Update
      ‚úì should pass all health checks (1 ms)
      ‚úì should detect missing framework directories
      ‚úì should detect command failures
      ‚úì should identify warnings vs critical issues (1 ms)
    Scenario 5: Auto-Rollback on Failure
      ‚úì should auto-rollback when health check fails
      ‚úì should not rollback when health check passes
      ‚úì should rollback when update function throws (1 ms)
    Scenario 6: Emergency Rollback
      ‚úì should perform emergency rollback bypassing checks
      ‚úì should throw when no rollback points for emergency
      ‚úì should return false on emergency extraction failure (1 ms)
    Scenario 7: Rollback Storage Management
      ‚úì should calculate total rollback storage
      ‚úì should get individual rollback point size
      ‚úì should return 0 for missing rollback file
    Scenario 8: List and Query Rollback Points
      ‚úì should list rollback points sorted by newest first
      ‚úì should return empty array when no rollback points
      ‚úì should handle missing history file
    Scenario 9: Rollback Chain (Multiple Updates)
      ‚úì should rollback multiple updates at once (1 ms)
      ‚úì should throw when not enough rollback points

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
fatal: Unable to read current working directory: No such file or directory
PASS STRESS tests/stress/anti-hallucination-agents.stress.test.ts (10.019 s, 268 MB heap size)
  Anti-Hallucination Agents Stress Test
    Test 1: Claim Extraction & Verification
      ‚úì Verify 30 synthetic claims across 6 categories (1038 ms)
    Test 2: Framework Risk Detection
      ‚úì Detect risk scores for 25 frameworks (9 ms)
    Test 3: Chain-of-Verification Accuracy
      ‚úì Verify 20 complex multi-part claims (2833 ms)
    Test 4: High-Load Parallel Verification
      ‚úì Process 100 claims in parallel (5376 ms)
    Test 5: Hallucination Detection & Flagging
      ‚úì Detect 30 intentional hallucinations (600 ms)

FAIL STRESS tests/stress/memory-throughput.stress.test.ts (129 MB heap size)
  Stress Test 4: Memory Operation Throughput
    ‚úï Handles 1000 operations/minute (16.7 ops/sec) (141 ms)
    ‚úï Handles 100 concurrent operations
    ‚úï Handles large patterns (10KB+ each)
    ‚úï Realistic operation mix (70% read, 20% write, 10% update)
    ‚úï No memory leaks over 5000 operations (1 ms)
    ‚úï Recovers from 20% operation failures (2 ms)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ Handles 1000 operations/minute (16.7 ops/sec)

    expect(received).toBeGreaterThan(expected)

    Expected: > 95
    Received:   0

      132 |     const successRate = (results.filter(r => r.success).length / results.length) * 100;
      133 |     console.log(`\n  Success rate: ${successRate.toFixed(1)}%`);
    > 134 |     expect(successRate).toBeGreaterThan(95); // 95%+ success
          |                         ^
      135 |   }, 120000); // 2 minute timeout
      136 |
      137 |   /**

      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:134:25)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ Handles 100 concurrent operations

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      149 |     const operations = Array.from({ length: CONCURRENT_OPS }, (_, i) => {
      150 |       const agentId = agents[i % agents.length];
    > 151 |       const memory = getAgentMemoryAPI(agentId as any);
          |                                       ^
      152 |
      153 |       return {
      154 |         id: i,

      at tests/stress/memory-throughput.stress.test.ts:151:39
          at Array.from (<anonymous>)
      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:149:30)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ Handles large patterns (10KB+ each)

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      204 |
      205 |     for (const agentId of agents) {
    > 206 |       const memory = getAgentMemoryAPI(agentId as any);
          |                                       ^
      207 |
      208 |       console.log(`\n  Testing ${agentId}:`);
      209 |

      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:206:39)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ Realistic operation mix (70% read, 20% write, 10% update)

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      266 |
      267 |     const operations: Array<{ type: string; latency: number }> = [];
    > 268 |     const memory = getAgentMemoryAPI('maria-qa');
          |                                     ^
      269 |
      270 |     // Pre-populate some patterns for view/update operations
      271 |     for (let i = 0; i < 50; i++) {

      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:268:37)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ No memory leaks over 5000 operations

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      358 |     const CHECKPOINT_INTERVAL = 1000;
      359 |
    > 360 |     const memory = getAgentMemoryAPI('maria-qa');
          |                                     ^
      361 |     const checkpoints: Array<{ ops: number; latency: number }> = [];
      362 |
      363 |     // Execute 5000 operations and measure latency trend

      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:360:37)

  ‚óè Stress Test 4: Memory Operation Throughput ‚Ä∫ Recovers from 20% operation failures

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      414 |     const FAILURE_RATE = 0.20; // 20% failure rate
      415 |
    > 416 |     const memory = getAgentMemoryAPI('maria-qa');
          |                                     ^
      417 |     const results: Array<{ success: boolean; recovered: boolean }> = [];
      418 |
      419 |     for (let i = 0; i < TOTAL_OPS; i++) {

      at Object.<anonymous> (tests/stress/memory-throughput.stress.test.ts:416:37)

FAIL STRESS tests/stress/cache-efficiency.stress.test.ts (141 MB heap size)
  Stress Test 5: Cache Efficiency & Invalidation
    ‚úï Baseline cache hit rate with 100k threshold
    ‚úï Improved cache hit rate with adaptive 30k threshold
    ‚úï Adaptive clearing shows 25%+ cache improvement
    ‚úï Discovers optimal clear threshold
    ‚úï Analyzes cache invalidation patterns
    ‚úï Maintains cache efficiency across 5 clears (1 ms)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Baseline cache hit rate with 100k threshold

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Baseline cache hit rate with 100k threshold

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Improved cache hit rate with adaptive 30k threshold

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Improved cache hit rate with adaptive 30k threshold

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Adaptive clearing shows 25%+ cache improvement

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Adaptive clearing shows 25%+ cache improvement

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Discovers optimal clear threshold

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Discovers optimal clear threshold

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Analyzes cache invalidation patterns

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Analyzes cache invalidation patterns

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Maintains cache efficiency across 5 clears

    ReferenceError: ContextSentinel is not defined

      23 |
      24 |   beforeEach(async () => {
    > 25 |     contextSentinel = new ContextSentinel();
         |     ^
      26 |     statsTracker = getGlobalContextTracker();
      27 |     await statsTracker.initialize();
      28 |     contextSentinel.startMonitoring();

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:25:5)

  ‚óè Stress Test 5: Cache Efficiency & Invalidation ‚Ä∫ Maintains cache efficiency across 5 clears

    TypeError: Cannot read properties of undefined (reading 'stopMonitoring')

      30 |
      31 |   afterEach(() => {
    > 32 |     contextSentinel.stopMonitoring();
         |                     ^
      33 |   });
      34 |
      35 |   /**

      at Object.<anonymous> (tests/stress/cache-efficiency.stress.test.ts:32:21)

PASS INTEGRATION tests/update/github-release-checker.test.ts (155 MB heap size)
  GitHubReleaseChecker
    Scenario 1: Get Latest Release
      ‚úì should fetch latest release successfully (1 ms)
      ‚úì should handle 404 error gracefully (8 ms)
      ‚úì should handle API errors
      ‚úì should use cache for repeated requests (1 ms)
      ‚úì should skip prerelease when includePrerelease=false
    Scenario 2: Check for Updates
      ‚úì should detect available update
      ‚úì should detect no update when already latest (1 ms)
      ‚úì should identify update type correctly (minor)
      ‚úì should identify update type correctly (patch)
      ‚úì should return no update on network error
    Scenario 3: Get All Releases
      ‚úì should fetch multiple releases (2 ms)
      ‚úì should respect limit parameter
    Scenario 4: Get Release by Tag
      ‚úì should fetch specific release by tag (1 ms)
      ‚úì should throw error when tag not found
    Scenario 5: Get Release by Version
      ‚úì should fetch release by version (without v prefix)
      ‚úì should return null when version not found (1 ms)
    Scenario 6: Get Releases Between Versions
      ‚úì should fetch releases between two versions
      ‚úì should return empty array when no releases in range
    Scenario 7: Cache Management
      ‚úì should clear cache
    Scenario 8: Parse Release Data
      ‚úì should parse release with assets
      ‚úì should handle release without body (1 ms)
      ‚úì should strip v prefix from version

FAIL INTEGRATION tests/integration/plan-command-e2e.test.ts (109 MB heap size)
  Plan Command E2E Integration
    Full Workflow: Authentication Feature
      ‚úï should complete full plan workflow for authentication (2929 ms)
    Full Workflow: CRUD Endpoint
      ‚úï should complete workflow for CRUD API (4 ms)
    Full Workflow: Custom Feature (No Template)
      ‚úï should handle custom feature without template match (3 ms)
    Explicit Template Selection
      ‚úì should use explicitly selected template (2 ms)
    Parallel Execution Detection
      ‚úï should detect parallel execution opportunities (1 ms)
    Confidence Scoring Integration
      ‚úì should calculate overall confidence from all sources (10 ms)
    Error Handling
      ‚úì should gracefully handle missing template directory (4 ms)
      ‚úì should handle RAG store failures gracefully (1 ms)

  ‚óè Plan Command E2E Integration ‚Ä∫ Full Workflow: Authentication Feature ‚Ä∫ should complete full plan workflow for authentication

    expect(received).toBe(expected) // Object.is equality

    Expected: true
    Received: false

      69 |
      70 |       // Should match auth-system template
    > 71 |       expect(templateMatch.use_template).toBe(true);
         |                                          ^
      72 |       expect(templateMatch.best_match?.template_name).toBe('auth-system');
      73 |       expect(templateMatch.best_match?.match_score).toBeGreaterThanOrEqual(70);
      74 |

      at Object.<anonymous> (tests/integration/plan-command-e2e.test.ts:71:42)

  ‚óè Plan Command E2E Integration ‚Ä∫ Full Workflow: CRUD Endpoint ‚Ä∫ should complete workflow for CRUD API

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test-e2e/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/integration/plan-command-e2e.test.ts:267:38)

  ‚óè Plan Command E2E Integration ‚Ä∫ Full Workflow: Custom Feature (No Template) ‚Ä∫ should handle custom feature without template match

    expect(received).toContain(expected) // indexOf

    Expected substring: "threshold"
    Received string:    "No template matches found. Using agent research for custom feature."

      295 |       expect(templateMatch.use_template).toBe(false);
      296 |       expect(templateMatch.best_match).toBeNull();
    > 297 |       expect(templateMatch.reason).toContain('threshold');
          |                                    ^
      298 |
      299 |       // Generate conservative todos
      300 |       const todoSpecs: TodoFileSpec[] = [

      at Object.<anonymous> (tests/integration/plan-command-e2e.test.ts:297:36)

  ‚óè Plan Command E2E Integration ‚Ä∫ Parallel Execution Detection ‚Ä∫ should detect parallel execution opportunities

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test-e2e/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/integration/plan-command-e2e.test.ts:354:38)

PASS INTEGRATION tests/update/version-diff.test.ts (119 MB heap size)
  VersionDiffGenerator
    Scenario 1: Generate Basic Version Diff
      ‚úì should generate diff between two versions (2 ms)
      ‚úì should throw error when release not found (10 ms)
      ‚úì should identify minor update type (1 ms)
      ‚úì should identify patch update type (1 ms)
    Scenario 2: Parse Changelog Categories
      ‚úì should parse breaking changes
      ‚úì should parse security fixes (1 ms)
      ‚úì should parse performance improvements
      ‚úì should parse conventional commit format
    Scenario 3: Generate Cumulative Diff
      ‚úì should aggregate changes from multiple releases (24 ms)
      ‚úì should throw when no releases found (1 ms)
    Scenario 4: Generate Summary
      ‚úì should generate user-friendly summary (1 ms)
      ‚úì should limit features/fixes to 5 in summary
    Scenario 5: Utility Methods
      ‚úì should detect when update requires user action (1 ms)
      ‚úì should detect when update has security fixes
      ‚úì should recommend "required" action for security fixes (1 ms)
      ‚úì should recommend "recommended" for breaking changes
      ‚úì should recommend "optional" for patch updates

FAIL UNIT tests/mcp/docs-index-management.test.ts (48.95 s, 120 MB heap size)
  DocsSearchEngine - Index Management
    Index Building
      ‚úì should build index on first use (3878 ms)
      ‚úì should not rebuild if index is fresh (4043 ms)
      ‚úì should build within reasonable time (4918 ms)
    Index Rebuilding
      ‚úì should force rebuild when requested (6923 ms)
      ‚úì should clear old index on rebuild (5823 ms)
    Index Freshness (TTL)
      ‚úï should detect stale index (2080 ms)
      ‚úì should rebuild stale index automatically (4228 ms)
      ‚úì should include TTL in metadata
    Concurrent Index Building
      ‚úì should handle concurrent build requests (1246 ms)
      ‚úì should not duplicate index entries from concurrent builds (2745 ms)
    Index Metadata
      ‚úì should provide accurate metadata before build (2 ms)
      ‚úì should provide accurate metadata after build (6228 ms)
      ‚úì should track document count accurately (1804 ms)
    Performance
      ‚úì should search efficiently with built index (1994 ms)
      ‚úì should handle multiple searches efficiently (2201 ms)

  ‚óè DocsSearchEngine - Index Management ‚Ä∫ Index Freshness (TTL) ‚Ä∫ should detect stale index

    expect(received).toBe(expected) // Object.is equality

    Expected: false
    Received: true

      91 |
      92 |       await engine.buildIndex();
    > 93 |       expect(engine.isIndexStale()).toBe(false);
         |                                     ^
      94 |
      95 |       // Wait for TTL to expire
      96 |       await new Promise(resolve => setTimeout(resolve, 150));

      at Object.<anonymous> (tests/mcp/docs-index-management.test.ts:93:37)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
FAIL INTEGRATION tests/integration/cross-agent-context.test.ts
  ‚óè Test suite failed to run

    Cannot find module '../../src/agents/enhanced-maria' from 'tests/integration/cross-agent-context.test.ts'

      4 |  */
      5 |
    > 6 | import { EnhancedMaria } from '../../src/agents/enhanced-maria';
        | ^
      7 | import { EnhancedJames } from '../../src/agents/enhanced-james';
      8 | import { EnhancedMarcus } from '../../src/agents/enhanced-marcus';
      9 | import { AlexBa } from '../../src/agents/alex-ba';

      at Resolver._throwModNotFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:427:11)
      at Object.<anonymous> (tests/integration/cross-agent-context.test.ts:6:1)

FAIL INTEGRATION tests/integration/test-mcp-integration.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/tests/integration/test-mcp-integration.ts:258
        const result = await testMCPAvailability(mcp);
                       ^^^^^

    SyntaxError: await is only valid in async functions and the top level bodies of modules

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)

FAIL STRESS tests/stress/long-conversation.stress.test.ts (5.374 s, 132 MB heap size)
  Stress Test 2: Long Conversation Handling
    ‚úï Maintains context through 5+ clears (500k tokens) (2655 ms)
    ‚úï Accumulates 100+ patterns across 500k tokens
    ‚úï Retains critical information across 5 clears
    ‚úï Clear events show consistent efficiency (2609 ms)
    ‚úï Handles 500+ memory operations efficiently (12 ms)

  ‚óè Stress Test 2: Long Conversation Handling ‚Ä∫ Maintains context through 5+ clears (500k tokens)

    expect(received).toBeGreaterThanOrEqual(expected)

    Expected: >= 5
    Received:    0

      85 |
      86 |     // Verify 5+ clears occurred (500k / 100k = 5)
    > 87 |     expect(clearEvents.length).toBeGreaterThanOrEqual(5);
         |                                ^
      88 |
      89 |     // Verify patterns persisted across clears
      90 |     const storedPatterns = await getAllStoredPatterns();

      at Object.<anonymous> (tests/stress/long-conversation.stress.test.ts:87:32)

  ‚óè Stress Test 2: Long Conversation Handling ‚Ä∫ Accumulates 100+ patterns across 500k tokens

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      123 |       // Each agent does 25k tokens of work
      124 |       for (const agentId of agents) {
    > 125 |         const memory = getAgentMemoryAPI(agentId as any);
          |                                         ^
      126 |
      127 |         // Simulate discovering new pattern
      128 |         await memory.storePattern({

      at Object.<anonymous> (tests/stress/long-conversation.stress.test.ts:125:41)

  ‚óè Stress Test 2: Long Conversation Handling ‚Ä∫ Retains critical information across 5 clears

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      179 |
      180 |     // Store critical information at start
    > 181 |     const alexMemory = getAgentMemoryAPI('alex-ba');
          |                                         ^
      182 |     for (const info of criticalInfo) {
      183 |       await alexMemory.storePattern({
      184 |         title: info.type,

      at Object.<anonymous> (tests/stress/long-conversation.stress.test.ts:181:41)

  ‚óè Stress Test 2: Long Conversation Handling ‚Ä∫ Clear events show consistent efficiency

    expect(received).toBeGreaterThan(expected)

    Expected: > 3000
    Received:   NaN

      264 |
      265 |     // Verify consistency
    > 266 |     expect(avgTokensSaved).toBeGreaterThan(3_000); // At least 3k per clear
          |                            ^
      267 |     expect(avgToolsCleared).toBeGreaterThan(5); // At least 5 tools per clear
      268 |
      269 |     // Verify efficiency doesn't degrade over time

      at Object.<anonymous> (tests/stress/long-conversation.stress.test.ts:266:28)

  ‚óè Stress Test 2: Long Conversation Handling ‚Ä∫ Handles 500+ memory operations efficiently

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      296 |     for (let i = 0; i < 500; i++) {
      297 |       const agentId = agents[i % agents.length];
    > 298 |       const memory = getAgentMemoryAPI(agentId as any);
          |                                       ^
      299 |
      300 |       // Measure operation latency
      301 |       const start = Date.now();

      at Object.<anonymous> (tests/stress/long-conversation.stress.test.ts:298:39)

FAIL STRESS tests/stress/multi-agent-isolation.stress.test.ts (152 MB heap size)
  Stress Test 3: Multi-Agent Context Isolation
    ‚úï 18 agents with independent context (180k tokens) (1 ms)
    ‚úï Zero context leakage between agents (1 ms)
    ‚úï No collisions with concurrent file access
    ‚úì Budget manager handles 18 agent allocations (1 ms)
    ‚úï Independent memory directories maintained
    ‚úï Performance under full agent load (1 ms)

  ‚óè Stress Test 3: Multi-Agent Context Isolation ‚Ä∫ 18 agents with independent context (180k tokens)

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      368 |
      369 |   // Simulate agent initialization
    > 370 |   const memory = getAgentMemoryAPI(agentId as any);
          |                                   ^
      371 |
      372 |   // Store initialization pattern
      373 |   await memory.storePattern({

      at startAgentContext (tests/stress/multi-agent-isolation.stress.test.ts:370:35)
      at tests/stress/multi-agent-isolation.stress.test.ts:58:27
          at Array.map (<anonymous>)
      at Object.<anonymous> (tests/stress/multi-agent-isolation.stress.test.ts:58:17)

  ‚óè Stress Test 3: Multi-Agent Context Isolation ‚Ä∫ Zero context leakage between agents

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      93 |
      94 |     for (const agentId of agents) {
    > 95 |       const memory = getAgentMemoryAPI(agentId);
         |                                       ^
      96 |       const patterns: string[] = [];
      97 |
      98 |       // Store 5 unique patterns per agent

      at Object.<anonymous> (tests/stress/multi-agent-isolation.stress.test.ts:95:39)

  ‚óè Stress Test 3: Multi-Agent Context Isolation ‚Ä∫ No collisions with concurrent file access

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      156 |     // All agents attempt to write to their own files simultaneously
      157 |     const writeOperations = agents.map(async (agentId, index) => {
    > 158 |       const memory = getAgentMemoryAPI(agentId as any);
          |                                       ^
      159 |
      160 |       return memory.storePattern({
      161 |         title: `Concurrent pattern ${index}`,

      at tests/stress/multi-agent-isolation.stress.test.ts:158:39
          at Array.map (<anonymous>)
      at Object.<anonymous> (tests/stress/multi-agent-isolation.stress.test.ts:157:36)

  ‚óè Stress Test 3: Multi-Agent Context Isolation ‚Ä∫ Independent memory directories maintained

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      260 |     // Store patterns and verify directory paths
      261 |     for (const agentId of agents) {
    > 262 |       const memory = getAgentMemoryAPI(agentId);
          |                                       ^
      263 |
      264 |       await memory.storePattern({
      265 |         title: 'Directory test pattern',

      at Object.<anonymous> (tests/stress/multi-agent-isolation.stress.test.ts:262:39)

  ‚óè Stress Test 3: Multi-Agent Context Isolation ‚Ä∫ Performance under full agent load

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      310 |
      311 |     const agentWork = allAgents.map(async (agentId) => {
    > 312 |       const memory = getAgentMemoryAPI(agentId as any);
          |                                       ^
      313 |
      314 |       // Each agent performs 10 operations
      315 |       for (let i = 0; i < 10; i++) {

      at tests/stress/multi-agent-isolation.stress.test.ts:312:39
          at Array.map (<anonymous>)
      at Object.<anonymous> (tests/stress/multi-agent-isolation.stress.test.ts:311:33)

FAIL INTEGRATION tests/integration/credential-onboarding.test.ts (141 MB heap size)
  Credential Onboarding Integration
    Full Onboarding Workflow
      ‚úï should complete full credential setup workflow (293 ms)
      ‚úï should support scoped credential execution (312 ms)
    Project Isolation
      ‚úï should isolate credentials between projects (644 ms)
    Team Workflow (Export/Import)
      ‚úï should export and import credentials with password (190 ms)
      ‚úì should fail import with wrong password (334 ms)
    Audit Logging
      ‚úï should log credential access events (168 ms)
      ‚úì should detect audit log integrity (1 ms)
    Error Handling
      ‚úì should handle missing credentials file gracefully
      ‚úì should handle corrupted credentials file
      ‚úï should handle permission errors gracefully (1 ms)

  ‚óè Credential Onboarding Integration ‚Ä∫ Full Onboarding Workflow ‚Ä∫ should complete full credential setup workflow

    TypeError: Cannot read properties of undefined (reading 'isFile')

      63 |       // Verify file exists
      64 |       const stats = await fs.stat(credentialsPath);
    > 65 |       expect(stats.isFile()).toBe(true);
         |                    ^
      66 |
      67 |       // Step 3: Load credentials into environment
      68 |       const loaded = await loader.loadCredentials({

      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:65:20)

  ‚óè Credential Onboarding Integration ‚Ä∫ Full Onboarding Workflow ‚Ä∫ should support scoped credential execution

    Failed to load credentials: Failed to load credentials: "undefined" is not valid JSON

      151 |       await this.auditLogger.logAccess(event);
      152 |
    > 153 |       throw new Error(`Failed to load credentials: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      154 |     }
      155 |   }
      156 |

      at CredentialLoader.loadCredentials (src/security/credential-loader.ts:153:13)
      at CredentialLoader.withCredentials (src/security/credential-loader.ts:214:7)
      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:111:7)

  ‚óè Credential Onboarding Integration ‚Ä∫ Project Isolation ‚Ä∫ should isolate credentials between projects

    TypeError: fs.rm is not a function

      185 |       } finally {
      186 |         // Cleanup
    > 187 |         await fs.rm(project1Dir, { recursive: true, force: true });
          |                  ^
      188 |         await fs.rm(project2Dir, { recursive: true, force: true });
      189 |       }
      190 |     });

      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:187:18)

  ‚óè Credential Onboarding Integration ‚Ä∫ Team Workflow (Export/Import) ‚Ä∫ should export and import credentials with password

    Failed to load credentials: "undefined" is not valid JSON

      291 |
      292 |       this.logger.error('Failed to load encrypted credentials', { error, filePath });
    > 293 |       throw new Error(`Failed to load credentials: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      294 |     }
      295 |   }
      296 |

      at CredentialEncryptor.decryptFromFile (src/security/credential-encryptor.ts:293:13)
      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:211:25)

  ‚óè Credential Onboarding Integration ‚Ä∫ Audit Logging ‚Ä∫ should log credential access events

    Failed to load credentials: Failed to load credentials: "undefined" is not valid JSON

      151 |       await this.auditLogger.logAccess(event);
      152 |
    > 153 |       throw new Error(`Failed to load credentials: ${error instanceof Error ? error.message : String(error)}`);
          |             ^
      154 |     }
      155 |   }
      156 |

      at CredentialLoader.loadCredentials (src/security/credential-loader.ts:153:13)
      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:280:7)

  ‚óè Credential Onboarding Integration ‚Ä∫ Error Handling ‚Ä∫ should handle permission errors gracefully

    TypeError: fs.chmod is not a function

      366 |
      367 |       await fs.writeFile(credentialsPath, 'test', 'utf8');
    > 368 |       await fs.chmod(credentialsPath, 0o000); // No permissions
          |                ^
      369 |
      370 |       const encryptor = getCredentialEncryptor();
      371 |       const context = { projectPath: testProjectDir, projectId };

      at Object.<anonymous> (tests/integration/credential-onboarding.test.ts:368:16)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "üîß Initializing GCP Firestore Vector Store (centering-vine-454613-b3)...".

      43 |   dimension: number;
      44 |   created: Date;
    > 45 | }
         |  ^
      46 |
      47 | export interface VectorSearchQuery {
      48 |   text: string;

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at GCPVectorStore.initialize (src/lib/gcp-vector-store.ts:45:21)
      at EnhancedVectorMemoryStore.initializeGCP (src/rag/enhanced-vector-memory-store.ts:130:60)
      at EnhancedVectorMemoryStore.initialize (src/rag/enhanced-vector-memory-store.ts:87:24)

FAIL INTEGRATION tests/integration/three-layer-context.test.ts (157 MB heap size)
  Three-Layer Context System
    Layer 1: User Context
      ‚úì should create user with default preferences (6 ms)
      ‚úì should update user preferences (15 ms)
      ‚úì should store and retrieve user agent memories (2 ms)
    Layer 2: Team Context
      ‚úì should create team with default conventions (2 ms)
      ‚úì should update team conventions (1 ms)
      ‚úì should add and remove team members (1 ms)
    Layer 3: Project Context
      ‚úì should store and retrieve project vision (2 ms)
      ‚úì should track project events (1 ms)
    Context Priority Resolution
      ‚úì should resolve context with user > team > project priority (2 ms)
      ‚úï should apply team conventions when user has no overrides (2 ms)
      ‚úì should use framework defaults when no user/team context (1 ms)
    Coding Style Detector
      ‚úì should analyze code and detect preferences (1 ms)
    User Agent Memory Store
      ‚úì should enforce privacy isolation (2 ms)
      ‚úì should support memory expiration (1104 ms)

  ‚óè Three-Layer Context System ‚Ä∫ Context Priority Resolution ‚Ä∫ should apply team conventions when user has no overrides

    expect(received).toBe(expected) // Object.is equality

    Expected: "never"
    Received: "auto"

      227 |
      228 |       // Team conventions should apply (since user didn't override)
    > 229 |       expect(resolved.codingPreferences.semicolons).toBe('never'); // From standard style
          |                                                     ^
      230 |       expect(resolved.resolution.teamOverrides.length).toBeGreaterThan(0);
      231 |     });
      232 |

      at Object.<anonymous> (tests/integration/three-layer-context.test.ts:229:53)

FAIL INTEGRATION tests/integration/rag-integration.test.ts
  ‚óè Test suite failed to run

    Configuration error:

    Could not locate module ../../src/agents/enhanced-maria.js mapped as:
    $1.

    Please check your configuration for these entries:
    {
      "moduleNameMapper": {
        "/^(\.{1,2}\/.*)\.js$/": "$1"
      },
      "resolver": undefined
    }

      13 |  */
      14 |
    > 15 | import { EnhancedMaria } from '../../src/agents/enhanced-maria.js';
         | ^
      16 | import { EnhancedJames } from '../../src/agents/enhanced-james.js';
      17 | import { EnhancedMarcus } from '../../src/agents/enhanced-marcus.js';
      18 | import { SarahPm } from '../../src/agents/sarah-pm.js';

      at createNoMappedModuleFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:759:17)
      at Object.<anonymous> (tests/integration/rag-integration.test.ts:15:1)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  

  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ AdaptiveContextManager increases threshold for high cache rate".

      27 |       return result.then(() => {
      28 |         testsPassed++;
    > 29 |         console.log(`‚úÖ ${name}`);
         |                 ^
      30 |       }).catch((error) => {
      31 |         testsFailed++;
      32 |         console.log(`‚ùå ${name}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at tests/stress/validate-enhancements.ts:29:17
      at runValidation (tests/stress/validate-enhancements.ts:122:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "
    üîç Testing SmartToolFilter...
    ".

      145 |
      146 |   // Test 3: SmartToolFilter
    > 147 |   console.log('\nüîç Testing SmartToolFilter...\n');
          |           ^
      148 |
      149 |   test('SmartToolFilter filters by priority', () => {
      150 |     const filter = new SmartToolFilter();

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:147:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[smart-filter] INFO: Filtering tool results {"totalResults":4,"currentTokens":160000,"emergency":false}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at SmartToolFilter.filterResults (src/memory/smart-tool-filter.ts:82:21)
      at tests/stress/validate-enhancements.ts:159:36
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:149:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[smart-filter] INFO: Filtering complete {"resultsKept":2,"resultsCleared":2,"tokensSaved":400,"savingsPercent":"21.1"}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at SmartToolFilter.filterResults (src/memory/smart-tool-filter.ts:152:21)
      at tests/stress/validate-enhancements.ts:159:36
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:149:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ SmartToolFilter filters by priority".

      35 |     } else {
      36 |       testsPassed++;
    > 37 |       console.log(`‚úÖ ${name}`);
         |               ^
      38 |     }
      39 |   } catch (error: any) {
      40 |     testsFailed++;

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at test (tests/stress/validate-enhancements.ts:37:15)
      at runValidation (tests/stress/validate-enhancements.ts:149:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[smart-filter] INFO: Filtering tool results {"totalResults":3,"currentTokens":175000,"emergency":true}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at SmartToolFilter.filterResults (src/memory/smart-tool-filter.ts:82:21)
      at tests/stress/validate-enhancements.ts:179:30
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:170:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[smart-filter] INFO: Filtering complete {"resultsKept":1,"resultsCleared":2,"tokensSaved":800,"savingsPercent":"44.4"}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at SmartToolFilter.filterResults (src/memory/smart-tool-filter.ts:152:21)
      at tests/stress/validate-enhancements.ts:179:30
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:170:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ SmartToolFilter is more aggressive in emergency".

      35 |     } else {
      36 |       testsPassed++;
    > 37 |       console.log(`‚úÖ ${name}`);
         |               ^
      38 |     }
      39 |   } catch (error: any) {
      40 |     testsFailed++;

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at test (tests/stress/validate-enhancements.ts:37:15)
      at runValidation (tests/stress/validate-enhancements.ts:170:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "
    üåä Testing ContextDriftDetector...
    ".

      189 |
      190 |   // Test 4: ContextDriftDetector
    > 191 |   console.log('\nüåä Testing ContextDriftDetector...\n');
          |           ^
      192 |
      193 |   await test('ContextDriftDetector initializes', async () => {
      194 |     const tracker = new ContextStatsTracker();

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:191:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Running drift detection {"currentTokens":50000,"messageCount":0}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:64:21)
      at tests/stress/validate-enhancements.ts:196:35
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:193:9)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Drift detection complete {"overallSeverity":"none","driftScore":0,"indicatorCount":0,"shouldClear":false}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:112:21)
      at tests/stress/validate-enhancements.ts:196:20
      at runValidation (tests/stress/validate-enhancements.ts:193:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ ContextDriftDetector initializes".

      27 |       return result.then(() => {
      28 |         testsPassed++;
    > 29 |         console.log(`‚úÖ ${name}`);
         |                 ^
      30 |       }).catch((error) => {
      31 |         testsFailed++;
      32 |         console.log(`‚ùå ${name}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at tests/stress/validate-enhancements.ts:29:17
      at runValidation (tests/stress/validate-enhancements.ts:193:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Running drift detection {"currentTokens":150000,"messageCount":250}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:64:21)
      at tests/stress/validate-enhancements.ts:212:35
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:203:9)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Drift detection complete {"overallSeverity":"low","driftScore":15,"indicatorCount":1,"shouldClear":false}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:112:21)
      at tests/stress/validate-enhancements.ts:212:20
      at runValidation (tests/stress/validate-enhancements.ts:203:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ ContextDriftDetector detects conversation depth drift".

      27 |       return result.then(() => {
      28 |         testsPassed++;
    > 29 |         console.log(`‚úÖ ${name}`);
         |                 ^
      30 |       }).catch((error) => {
      31 |         testsFailed++;
      32 |         console.log(`‚ùå ${name}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at tests/stress/validate-enhancements.ts:29:17
      at runValidation (tests/stress/validate-enhancements.ts:203:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Running drift detection {"currentTokens":100000,"messageCount":0}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:64:21)
      at tests/stress/validate-enhancements.ts:239:35
      at test (tests/stress/validate-enhancements.ts:25:20)
      at runValidation (tests/stress/validate-enhancements.ts:225:9)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[drift-detector] INFO: Drift detection complete {"overallSeverity":"low","driftScore":15,"indicatorCount":1,"shouldClear":false}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at ContextDriftDetector.detectDrift (src/memory/context-drift-detector.ts:112:21)
      at tests/stress/validate-enhancements.ts:239:20
      at runValidation (tests/stress/validate-enhancements.ts:225:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ ContextDriftDetector detects task switching".

      27 |       return result.then(() => {
      28 |         testsPassed++;
    > 29 |         console.log(`‚úÖ ${name}`);
         |                 ^
      30 |       }).catch((error) => {
      31 |         testsFailed++;
      32 |         console.log(`‚ùå ${name}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at tests/stress/validate-enhancements.ts:29:17
      at runValidation (tests/stress/validate-enhancements.ts:225:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "
    üî¢ Testing Utilities...
    ".

      246 |
      247 |   // Test 5: Token Estimation
    > 248 |   console.log('\nüî¢ Testing Utilities...\n');
          |           ^
      249 |
      250 |   test('estimateTokens calculates correctly', () => {
      251 |     const text = 'This is a test string with approximately 40 characters';

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:248:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚úÖ estimateTokens calculates correctly".

      35 |     } else {
      36 |       testsPassed++;
    > 37 |       console.log(`‚úÖ ${name}`);
         |               ^
      38 |     }
      39 |   } catch (error: any) {
      40 |     testsFailed++;

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at test (tests/stress/validate-enhancements.ts:37:15)
      at runValidation (tests/stress/validate-enhancements.ts:250:3)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ".

      259 |
      260 |   // Summary
    > 261 |   console.log('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
          |           ^
      262 |   console.log('  üìä Validation Summary');
      263 |   console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');
      264 |   console.log(`  Total Tests: ${testsRun}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:261:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "  üìä Validation Summary".

      260 |   // Summary
      261 |   console.log('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    > 262 |   console.log('  üìä Validation Summary');
          |           ^
      263 |   console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');
      264 |   console.log(`  Total Tests: ${testsRun}`);
      265 |   console.log(`  ‚úÖ Passed: ${testsPassed}`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:262:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    ".

      261 |   console.log('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      262 |   console.log('  üìä Validation Summary');
    > 263 |   console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');
          |           ^
      264 |   console.log(`  Total Tests: ${testsRun}`);
      265 |   console.log(`  ‚úÖ Passed: ${testsPassed}`);
      266 |   console.log(`  ‚ùå Failed: ${testsFailed}\n`);

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:263:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "  Total Tests: 12".

      262 |   console.log('  üìä Validation Summary');
      263 |   console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');
    > 264 |   console.log(`  Total Tests: ${testsRun}`);
          |           ^
      265 |   console.log(`  ‚úÖ Passed: ${testsPassed}`);
      266 |   console.log(`  ‚ùå Failed: ${testsFailed}\n`);
      267 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:264:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "  ‚úÖ Passed: 12".

      263 |   console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n');
      264 |   console.log(`  Total Tests: ${testsRun}`);
    > 265 |   console.log(`  ‚úÖ Passed: ${testsPassed}`);
          |           ^
      266 |   console.log(`  ‚ùå Failed: ${testsFailed}\n`);
      267 |
      268 |   if (testsFailed === 0) {

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:265:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "  ‚ùå Failed: 0
    ".

      264 |   console.log(`  Total Tests: ${testsRun}`);
      265 |   console.log(`  ‚úÖ Passed: ${testsPassed}`);
    > 266 |   console.log(`  ‚ùå Failed: ${testsFailed}\n`);
          |           ^
      267 |
      268 |   if (testsFailed === 0) {
      269 |     console.log('‚ú® All enhancements validated successfully!\n');

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:266:11)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "‚ú® All enhancements validated successfully!
    ".

      267 |
      268 |   if (testsFailed === 0) {
    > 269 |     console.log('‚ú® All enhancements validated successfully!\n');
          |             ^
      270 |     process.exit(0);
      271 |   } else {
      272 |     console.log('‚ö†Ô∏è  Some tests failed. Review errors above.\n');

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at runValidation (tests/stress/validate-enhancements.ts:269:13)

  ‚óè  process.exit called with "0"

      268 |   if (testsFailed === 0) {
      269 |     console.log('‚ú® All enhancements validated successfully!\n');
    > 270 |     process.exit(0);
          |             ^
      271 |   } else {
      272 |     console.log('‚ö†Ô∏è  Some tests failed. Review errors above.\n');
      273 |     process.exit(1);

      at runValidation (tests/stress/validate-enhancements.ts:270:13)
FAIL STRESS tests/stress/validate-enhancements.ts
  ‚óè Test suite failed to run

    A jest worker process (pid=3302) crashed for an unknown reason: exitCode=0

      at ChildProcessWorker._onExit (node_modules/.pnpm/jest-worker@29.7.0/node_modules/jest-worker/build/workers/ChildProcessWorker.js:370:23)

FAIL INTEGRATION tests/integration/skills-validation.test.ts (69 MB heap size)
  Skills Validation Suite
    Skill File Existence
      ‚úì should have SKILL.md for all 17 expected skills (4 ms)
      ‚úï should not have extra skill directories beyond 17 (6 ms)
    Skill Content Validation
      state-management
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section (1 ms)
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
      styling-architecture
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist (2 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
      testing-strategies
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation) (1 ms)
      micro-frontends
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úï should be at least 500 lines (comprehensive documentation)
      api-design
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation)
      auth-security
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation)
      microservices
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation)
      serverless
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section (1 ms)
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
      vector-databases
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section (1 ms)
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation)
      schema-optimization
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úï should be at least 500 lines (comprehensive documentation)
      rls-policies
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úï should be at least 500 lines (comprehensive documentation)
      edge-databases
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
      ml-pipelines
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section (1 ms)
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
      rag-optimization
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section (1 ms)
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation) (1 ms)
      model-deployment
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation)
      workflow-orchestration
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section
        ‚úì should have code examples
        ‚úï should have implementation checklist
        ‚úì should be at least 500 lines (comprehensive documentation) (1 ms)
      cross-domain-patterns
        ‚úì should have frontmatter metadata
        ‚úì should have When to Use section
        ‚úï should have Key Patterns section (1 ms)
        ‚úì should have code examples
        ‚úï should have implementation checklist (1 ms)
        ‚úì should be at least 500 lines (comprehensive documentation)
    Agent Integration Validation
      james-frontend.md
        ‚úì should have Enhanced Skills section (1 ms)
        ‚úì should reference state-management skill
        ‚úì should have trigger phrases for state-management
        ‚úì should reference styling-architecture skill
        ‚úì should have trigger phrases for styling-architecture
        ‚úì should reference testing-strategies skill
        ‚úì should have trigger phrases for testing-strategies (1 ms)
        ‚úì should reference micro-frontends skill
        ‚úì should have trigger phrases for micro-frontends
        ‚úì should reference cross-domain-patterns skill
        ‚úì should have trigger phrases for cross-domain-patterns
      marcus-backend.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference api-design skill
        ‚úì should have trigger phrases for api-design (1 ms)
        ‚úì should reference auth-security skill
        ‚úì should have trigger phrases for auth-security
        ‚úì should reference microservices skill
        ‚úì should have trigger phrases for microservices
        ‚úì should reference serverless skill
        ‚úì should have trigger phrases for serverless
        ‚úì should reference cross-domain-patterns skill
        ‚úì should have trigger phrases for cross-domain-patterns
      dana-database.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference vector-databases skill
        ‚úì should have trigger phrases for vector-databases
        ‚úì should reference schema-optimization skill
        ‚úì should have trigger phrases for schema-optimization
        ‚úì should reference rls-policies skill
        ‚úì should have trigger phrases for rls-policies (1 ms)
        ‚úì should reference edge-databases skill
        ‚úì should have trigger phrases for edge-databases (1 ms)
        ‚úì should reference cross-domain-patterns skill
        ‚úì should have trigger phrases for cross-domain-patterns
      maria-qa.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference testing-strategies skill
        ‚úì should have trigger phrases for testing-strategies
        ‚úì should reference quality-gates skill (1 ms)
        ‚úì should have trigger phrases for quality-gates
      dr-ai-ml.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference ml-pipelines skill
        ‚úì should have trigger phrases for ml-pipelines
        ‚úì should reference rag-optimization skill (1 ms)
        ‚úì should have trigger phrases for rag-optimization
        ‚úì should reference model-deployment skill
        ‚úì should have trigger phrases for model-deployment
      sarah-pm.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference workflow-orchestration skill
        ‚úì should have trigger phrases for workflow-orchestration
      alex-ba.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference api-design skill
        ‚úì should have trigger phrases for api-design (1 ms)
        ‚úì should reference auth-security skill
        ‚úì should have trigger phrases for auth-security
      oliver-mcp.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference rag-optimization skill
        ‚úì should have trigger phrases for rag-optimization
      victor-verifier.md
        ‚úì should have Enhanced Skills section
        ‚úì should reference testing-strategies skill
        ‚úì should have trigger phrases for testing-strategies
    Code Example Syntax Validation
      state-management code examples
        ‚úì should have valid TypeScript code blocks (2 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      styling-architecture code examples
        ‚úì should have valid TypeScript code blocks (2 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      testing-strategies code examples
        ‚úï should have valid TypeScript code blocks (2 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      micro-frontends code examples
        ‚úì should have valid TypeScript code blocks (4 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      api-design code examples
        ‚úì should have valid TypeScript code blocks (1 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      auth-security code examples
        ‚úì should have valid TypeScript code blocks (1 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      microservices code examples
        ‚úï should have valid TypeScript code blocks (3 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      serverless code examples
        ‚úì should have valid TypeScript code blocks (1 ms)
        ‚úì should have valid Python code blocks (if applicable) (1 ms)
        ‚úì should have valid SQL code blocks (if applicable)
      vector-databases code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable) (1 ms)
      schema-optimization code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable) (1 ms)
      rls-policies code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable)
        ‚úï should have valid SQL code blocks (if applicable) (1 ms)
      edge-databases code examples
        ‚úì should have valid TypeScript code blocks (2 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      ml-pipelines code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable) (1 ms)
        ‚úì should have valid SQL code blocks (if applicable)
      rag-optimization code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable) (1 ms)
        ‚úì should have valid SQL code blocks (if applicable)
      model-deployment code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      workflow-orchestration code examples
        ‚úì should have valid TypeScript code blocks
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
      cross-domain-patterns code examples
        ‚úì should have valid TypeScript code blocks (1 ms)
        ‚úì should have valid Python code blocks (if applicable)
        ‚úì should have valid SQL code blocks (if applicable)
    Cross-Reference Validation
      ‚úì should have all skills referenced by at least one agent
      ‚úì should have no broken skill references in agents
    Validation Report Cross-Check
      ‚úï should have SKILLS_VALIDATION_REPORT.md file
      ‚úï should have validation scores for all 17 skills
    Documentation Completeness
      ‚úì should have PARALLEL_IMPLEMENTATION_SUMMARY.md with all waves complete

  ‚óè Skills Validation Suite ‚Ä∫ Skill File Existence ‚Ä∫ should not have extra skill directories beyond 17

    expect(received).toEqual(expected) // deep equality

    - Expected  -  1
    + Received  + 32

    - Array []
    + Array [
    +   "webapp-testing",
    +   "visual-regression",
    +   "version-management",
    +   "theme-factory",
    +   "template-skill",
    +   "slack-gif-creator",
    +   "skill-creator",
    +   "rag-query",
    +   "rag-patterns",
    +   "quality-gates",
    +   "performance-optimization",
    +   "opera-orchestration",
    +   "mcp-builder",
    +   "library-guides",
    +   "internal-comms",
    +   "i18n",
    +   "health-monitoring",
    +   "document-skills",
    +   "design-tokens",
    +   "design-philosophy",
    +   "context-injection",
    +   "compounding-engineering",
    +   "component-patterns",
    +   "code-generators",
    +   "canvas-design",
    +   "brand-guidelines",
    +   "artifacts-builder",
    +   "animation-interaction",
    +   "algorithmic-art",
    +   "accessibility-audit",
    + ]

      75 |       const extraSkills = skillDirs.filter((s) => !EXPECTED_SKILLS.includes(s));
      76 |
    > 77 |       expect(extraSkills).toEqual([]);
         |                           ^
      78 |     });
      79 |   });
      80 |

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:77:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ state-management ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: state-management
    description: Modern state management patterns using Zustand (1KB lightweight), TanStack Query (server state), and Jotai (atomic state). Use when managing global state, server-state caching, or complex state logic. Reduces boilerplate by 60% vs Redux and re-renders by 80% through atomic state.
    ---¬∑
    # State Management¬∑
    ## Overview¬∑
    Modern React state management with minimal boilerplate using Zustand (client state), TanStack Query (server state), and Jotai (atomic state). Eliminates prop drilling, optimizes re-renders, and provides type-safe state management.¬∑
    **Goal**: Efficient state management with minimal boilerplate and maximum performance¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Managing global client state (user preferences, UI state, cart)
    - Fetching and caching server data (API responses, background sync)
    - Avoiding prop drilling in deep component trees
    - Optimizing re-renders (atomic state updates)
    - Migrating from Redux (60% less boilerplate)
    - Implementing optimistic updates
    - Managing derived/computed state¬∑
    **Triggers**: \"state management\", \"global state\", \"Zustand\", \"TanStack Query\", \"React Query\", \"Jotai\", \"Redux migration\"¬∑
    ---¬∑
    ## Quick Start: State Library Decision Tree¬∑
    ### When to Use Zustand vs TanStack Query vs Jotai¬∑
    **Zustand** (Client state, 1KB):
    - ‚úÖ Global UI state (theme, sidebar open/closed, modal state)
    - ‚úÖ Shopping cart, user preferences
    - ‚úÖ Simple API, minimal boilerplate
    - ‚úÖ Redux-like patterns without the complexity
    - ‚úÖ Middleware (persist, devtools, immer)¬∑
    **TanStack Query** (Server state, caching):
    - ‚úÖ Fetching data from APIs
    - ‚úÖ Automatic caching and background refetch
    - ‚úÖ Optimistic updates (instant UI feedback)
    - ‚úÖ Pagination, infinite scroll
    - ‚úÖ Stale-while-revalidate pattern¬∑
    **Jotai** (Atomic state, granular updates):
    - ‚úÖ Fine-grained reactivity (only re-render what changed)
    - ‚úÖ Derived state (computed values)
    - ‚úÖ Async atoms (fetch data in atoms)
    - ‚úÖ Minimal re-renders (80% reduction)
    - ‚úÖ Bottom-up state management¬∑
    **Use Multiple** when:
    - Zustand for UI state + TanStack Query for server data (recommended combo)
    - Jotai for granular state + TanStack Query for API calls¬∑
    ---¬∑
    ## Zustand Patterns¬∑
    ### 1. Basic Store¬∑
    ```typescript
    import { create } from 'zustand';¬∑
    interface CartStore {
      items: CartItem[];
      addItem: (item: CartItem) => void;
      removeItem: (id: string) => void;
      total: number;
    }¬∑
    const useCartStore = create<CartStore>((set, get) => ({
      items: [],
      addItem: (item) => set((state) => ({
        items: [...state.items, item]
      })),
      removeItem: (id) => set((state) => ({
        items: state.items.filter(item => item.id !== id)
      })),
      total: 0 // Will be computed
    }));¬∑
    // Usage in component
    function Cart() {
      const items = useCartStore((state) => state.items);
      const addItem = useCartStore((state) => state.addItem);¬∑
      return (
        <div>
          {items.map(item => <CartItem key={item.id} {...item} />)}
          <button onClick={() => addItem({ id: '1', name: 'Product' })}>
            Add Item
          </button>
        </div>
      );
    }
    ```¬∑
    ### 2. Computed/Derived State¬∑
    ```typescript
    const useCartStore = create<CartStore>((set, get) => ({
      items: [],
      addItem: (item) => set((state) => ({
        items: [...state.items, item]
      })),
      // Computed property (getter)
      get total() {
        return get().items.reduce((sum, item) => sum + item.price, 0);
      }
    }));¬∑
    // Usage
    function CartTotal() {
      const total = useCartStore((state) => state.total);
      return <div>Total: ${total}</div>;
    }
    ```¬∑
    ### 3. Middleware (Persist, Devtools, Immer)¬∑
    ```typescript
    import { create } from 'zustand';
    import { persist, devtools } from 'zustand/middleware';
    import { immer } from 'zustand/middleware/immer';¬∑
    const useStore = create<Store>()(
      devtools(
        persist(
          immer((set) => ({
            user: null,
            setUser: (user) => set((state) => {
              state.user = user; // Immer allows mutations
            })
          })),
          { name: 'user-storage' } // LocalStorage key
        )
      )
    );
    ```¬∑
    ### 4. Slices Pattern (Large Stores)¬∑
    ```typescript
    // userSlice.ts
    const createUserSlice = (set) => ({
      user: null,
      setUser: (user) => set({ user }),
      logout: () => set({ user: null })
    });¬∑
    // cartSlice.ts
    const createCartSlice = (set) => ({
      items: [],
      addItem: (item) => set((state) => ({ items: [...state.items, item] }))
    });¬∑
    // Combined store
    const useStore = create((set, get) => ({
      ...createUserSlice(set, get),
      ...createCartSlice(set, get)
    }));
    ```¬∑
    ---¬∑
    ## TanStack Query Patterns¬∑
    ### 1. Basic Query (Fetch Data)¬∑
    ```typescript
    import { useQuery } from '@tanstack/react-query';¬∑
    function UserProfile({ userId }: { userId: string }) {
      const { data, isLoading, error } = useQuery({
        queryKey: ['user', userId],
        queryFn: () => fetch(`/api/users/${userId}`).then(res => res.json()),
        staleTime: 5 * 60 * 1000, // 5 minutes
        gcTime: 10 * 60 * 1000    // 10 minutes (formerly cacheTime)
      });¬∑
      if (isLoading) return <Spinner />;
      if (error) return <div>Error: {error.message}</div>;¬∑
      return <div>{data.name}</div>;
    }
    ```¬∑
    ### 2. Mutations (Update Data)¬∑
    ```typescript
    import { useMutation, useQueryClient } from '@tanstack/react-query';¬∑
    function UpdateUserForm({ userId }: { userId: string }) {
      const queryClient = useQueryClient();¬∑
      const mutation = useMutation({
        mutationFn: (newUser: User) =>
          fetch(`/api/users/${userId}`, {
            method: 'PATCH',
            body: JSON.stringify(newUser)
          }),
        onSuccess: () => {
          // Invalidate and refetch
          queryClient.invalidateQueries({ queryKey: ['user', userId] });
        }
      });¬∑
      return (
        <button onClick={() => mutation.mutate({ name: 'New Name' })}>
          Update
        </button>
      );
    }
    ```¬∑
    ### 3. Optimistic Updates¬∑
    ```typescript
    const mutation = useMutation({
      mutationFn: updateTodo,
      onMutate: async (newTodo) => {
        // Cancel outgoing refetches
        await queryClient.cancelQueries({ queryKey: ['todos'] });¬∑
        // Snapshot previous value
        const previousTodos = queryClient.getQueryData(['todos']);¬∑
        // Optimistically update
        queryClient.setQueryData(['todos'], (old: Todo[]) => [...old, newTodo]);¬∑
        // Return context with snapshot
        return { previousTodos };
      },
      onError: (err, newTodo, context) => {
        // Rollback on error
        queryClient.setQueryData(['todos'], context?.previousTodos);
      },
      onSettled: () => {
        // Refetch after error or success
        queryClient.invalidateQueries({ queryKey: ['todos'] });
      }
    });
    ```¬∑
    ### 4. Pagination¬∑
    ```typescript
    function TodoList() {
      const [page, setPage] = useState(1);¬∑
      const { data, isLoading } = useQuery({
        queryKey: ['todos', page],
        queryFn: () => fetch(`/api/todos?page=${page}`).then(res => res.json()),
        placeholderData: keepPreviousData // Keep previous page while loading
      });¬∑
      return (
        <div>
          {data?.todos.map(todo => <TodoItem key={todo.id} {...todo} />)}
          <button onClick={() => setPage(p => Math.max(1, p - 1))}>Previous</button>
          <button onClick={() => setPage(p => p + 1)}>Next</button>
        </div>
      );
    }
    ```¬∑
    ### 5. Infinite Scroll¬∑
    ```typescript
    import { useInfiniteQuery } from '@tanstack/react-query';¬∑
    function InfiniteList() {
      const {
        data,
        fetchNextPage,
        hasNextPage,
        isFetchingNextPage
      } = useInfiniteQuery({
        queryKey: ['todos'],
        queryFn: ({ pageParam = 1 }) =>
          fetch(`/api/todos?page=${pageParam}`).then(res => res.json()),
        initialPageParam: 1,
        getNextPageParam: (lastPage, pages) =>
          lastPage.hasMore ? pages.length + 1 : undefined
      });¬∑
      return (
        <div>
          {data?.pages.map((page, i) => (
            <React.Fragment key={i}>
              {page.todos.map(todo => <TodoItem key={todo.id} {...todo} />)}
            </React.Fragment>
          ))}
          <button
            onClick={() => fetchNextPage()}
            disabled={!hasNextPage || isFetchingNextPage}
          >
            {isFetchingNextPage ? 'Loading...' : 'Load More'}
          </button>
        </div>
      );
    }
    ```¬∑
    ---¬∑
    ## Jotai Patterns¬∑
    ### 1. Primitive Atoms¬∑
    ```typescript
    import { atom, useAtom } from 'jotai';¬∑
    // Primitive atoms
    const countAtom = atom(0);
    const userAtom = atom<User | null>(null);¬∑
    function Counter() {
      const [count, setCount] = useAtom(countAtom);¬∑
      return (
        <div>
          <p>Count: {count}</p>
          <button onClick={() => setCount(c => c + 1)}>Increment</button>
        </div>
      );
    }
    ```¬∑
    ### 2. Derived Atoms (Read-Only)¬∑
    ```typescript
    const priceAtom = atom(10);
    const quantityAtom = atom(5);¬∑
    // Derived atom (computed)
    const totalAtom = atom((get) => {
      const price = get(priceAtom);
      const quantity = get(quantityAtom);
      return price * quantity;
    });¬∑
    function Total() {
      const [total] = useAtom(totalAtom);
      return <div>Total: ${total}</div>; // Automatically updates
    }
    ```¬∑
    ### 3. Async Atoms¬∑
    ```typescript
    const userIdAtom = atom('user-123');¬∑
    // Async atom (fetch data)
    const userAtom = atom(async (get) => {
      const userId = get(userIdAtom);
      const response = await fetch(`/api/users/${userId}`);
      return response.json();
    });¬∑
    function UserProfile() {
      const [user] = useAtom(userAtom);¬∑
      return <div>{user.name}</div>; // Suspense boundary handles loading
    }¬∑
    // Wrap in Suspense
    function App() {
      return (
        <Suspense fallback={<Spinner />}>
          <UserProfile />
        </Suspense>
      );
    }
    ```¬∑
    ### 4. Write-Only Atoms (Actions)¬∑
    ```typescript
    const todosAtom = atom<Todo[]>([]);¬∑
    // Write-only atom (action)
    const addTodoAtom = atom(
      null, // No read
      (get, set, newTodo: Todo) => {
        set(todosAtom, [...get(todosAtom), newTodo]);
      }
    );¬∑
    function AddTodo() {
      const [, addTodo] = useAtom(addTodoAtom);¬∑
      return (
        <button onClick={() => addTodo({ id: '1', text: 'New Todo' })}>
          Add Todo
        </button>
      );
    }
    ```¬∑
    ### 5. Atom Families (Dynamic Atoms)¬∑
    ```typescript
    import { atomFamily } from 'jotai/utils';¬∑
    // Create atoms dynamically based on ID
    const userAtomFamily = atomFamily((userId: string) =>
      atom(async () => {
        const response = await fetch(`/api/users/${userId}`);
        return response.json();
      })
    );¬∑
    function UserCard({ userId }: { userId: string }) {
      const [user] = useAtom(userAtomFamily(userId));
      return <div>{user.name}</div>;
    }
    ```¬∑
    ---¬∑
    ## Migration from Redux¬∑
    ### Redux to Zustand¬∑
    **Before (Redux)**:
    ```typescript
    // actions.ts
    export const increment = () => ({ type: 'INCREMENT' });
    export const decrement = () => ({ type: 'DECREMENT' });¬∑
    // reducer.ts
    const counterReducer = (state = { count: 0 }, action) => {
      switch (action.type) {
        case 'INCREMENT':
          return { count: state.count + 1 };
        case 'DECREMENT':
          return { count: state.count - 1 };
        default:
          return state;
      }
    };¬∑
    // store.ts
    const store = createStore(counterReducer);¬∑
    // Usage
    dispatch(increment());
    ```¬∑
    **After (Zustand)**:
    ```typescript
    const useStore = create((set) => ({
      count: 0,
      increment: () => set((state) => ({ count: state.count + 1 })),
      decrement: () => set((state) => ({ count: state.count - 1 }))
    }));¬∑
    // Usage
    const increment = useStore((state) => state.increment);
    increment(); // Direct call, no dispatch
    ```¬∑
    **60% less boilerplate** (no actions, reducers, dispatch, connect, mapStateToProps)¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Selector Optimization (Prevent Re-Renders)¬∑
    ```typescript
    // ‚ùå Bad - Re-renders on any state change
    const { items, total } = useStore();¬∑
    // ‚úÖ Good - Only re-renders when `total` changes
    const total = useStore((state) => state.total);
    ```¬∑
    ### 2. Shallow Comparison¬∑
    ```typescript
    import { shallow } from 'zustand/shallow';¬∑
    // Re-renders only if items array changes (shallow comparison)
    const items = useStore((state) => state.items, shallow);
    ```¬∑
    ### 3. TanStack Query - Stale Time¬∑
    ```typescript
    // Avoid unnecessary refetches
    const { data } = useQuery({
      queryKey: ['user'],
      queryFn: fetchUser,
      staleTime: 5 * 60 * 1000, // Consider fresh for 5 minutes
      gcTime: 10 * 60 * 1000    // Cache for 10 minutes
    });
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migration-helper.js` - Redux to Zustand migration script¬∑
    ### references/
    - `references/zustand-patterns.md` - Store setup, middleware, slices
    - `references/tanstack-query-patterns.md` - Queries, mutations, caching
    - `references/jotai-patterns.md` - Atoms, derived state, async
    - `references/redux-migration.md` - Step-by-step Redux ‚Üí Zustand migration¬∑
    ### assets/
    - `assets/store-templates/` - Zustand/Jotai/TanStack Query starter templates¬∑
    ## Related Skills¬∑
    - `testing-strategies` - Testing state management with Vitest
    - `performance-optimization` - Re-render optimization, profiling
    - `api-design` - Backend API integration with TanStack Query
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ state-management ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: state-management
    description: Modern state management patterns using Zustand (1KB lightweight), TanStack Query (server state), and Jotai (atomic state). Use when managing global state, server-state caching, or complex state logic. Reduces boilerplate by 60% vs Redux and re-renders by 80% through atomic state.
    ---¬∑
    # State Management¬∑
    ## Overview¬∑
    Modern React state management with minimal boilerplate using Zustand (client state), TanStack Query (server state), and Jotai (atomic state). Eliminates prop drilling, optimizes re-renders, and provides type-safe state management.¬∑
    **Goal**: Efficient state management with minimal boilerplate and maximum performance¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Managing global client state (user preferences, UI state, cart)
    - Fetching and caching server data (API responses, background sync)
    - Avoiding prop drilling in deep component trees
    - Optimizing re-renders (atomic state updates)
    - Migrating from Redux (60% less boilerplate)
    - Implementing optimistic updates
    - Managing derived/computed state¬∑
    **Triggers**: \"state management\", \"global state\", \"Zustand\", \"TanStack Query\", \"React Query\", \"Jotai\", \"Redux migration\"¬∑
    ---¬∑
    ## Quick Start: State Library Decision Tree¬∑
    ### When to Use Zustand vs TanStack Query vs Jotai¬∑
    **Zustand** (Client state, 1KB):
    - ‚úÖ Global UI state (theme, sidebar open/closed, modal state)
    - ‚úÖ Shopping cart, user preferences
    - ‚úÖ Simple API, minimal boilerplate
    - ‚úÖ Redux-like patterns without the complexity
    - ‚úÖ Middleware (persist, devtools, immer)¬∑
    **TanStack Query** (Server state, caching):
    - ‚úÖ Fetching data from APIs
    - ‚úÖ Automatic caching and background refetch
    - ‚úÖ Optimistic updates (instant UI feedback)
    - ‚úÖ Pagination, infinite scroll
    - ‚úÖ Stale-while-revalidate pattern¬∑
    **Jotai** (Atomic state, granular updates):
    - ‚úÖ Fine-grained reactivity (only re-render what changed)
    - ‚úÖ Derived state (computed values)
    - ‚úÖ Async atoms (fetch data in atoms)
    - ‚úÖ Minimal re-renders (80% reduction)
    - ‚úÖ Bottom-up state management¬∑
    **Use Multiple** when:
    - Zustand for UI state + TanStack Query for server data (recommended combo)
    - Jotai for granular state + TanStack Query for API calls¬∑
    ---¬∑
    ## Zustand Patterns¬∑
    ### 1. Basic Store¬∑
    ```typescript
    import { create } from 'zustand';¬∑
    interface CartStore {
      items: CartItem[];
      addItem: (item: CartItem) => void;
      removeItem: (id: string) => void;
      total: number;
    }¬∑
    const useCartStore = create<CartStore>((set, get) => ({
      items: [],
      addItem: (item) => set((state) => ({
        items: [...state.items, item]
      })),
      removeItem: (id) => set((state) => ({
        items: state.items.filter(item => item.id !== id)
      })),
      total: 0 // Will be computed
    }));¬∑
    // Usage in component
    function Cart() {
      const items = useCartStore((state) => state.items);
      const addItem = useCartStore((state) => state.addItem);¬∑
      return (
        <div>
          {items.map(item => <CartItem key={item.id} {...item} />)}
          <button onClick={() => addItem({ id: '1', name: 'Product' })}>
            Add Item
          </button>
        </div>
      );
    }
    ```¬∑
    ### 2. Computed/Derived State¬∑
    ```typescript
    const useCartStore = create<CartStore>((set, get) => ({
      items: [],
      addItem: (item) => set((state) => ({
        items: [...state.items, item]
      })),
      // Computed property (getter)
      get total() {
        return get().items.reduce((sum, item) => sum + item.price, 0);
      }
    }));¬∑
    // Usage
    function CartTotal() {
      const total = useCartStore((state) => state.total);
      return <div>Total: ${total}</div>;
    }
    ```¬∑
    ### 3. Middleware (Persist, Devtools, Immer)¬∑
    ```typescript
    import { create } from 'zustand';
    import { persist, devtools } from 'zustand/middleware';
    import { immer } from 'zustand/middleware/immer';¬∑
    const useStore = create<Store>()(
      devtools(
        persist(
          immer((set) => ({
            user: null,
            setUser: (user) => set((state) => {
              state.user = user; // Immer allows mutations
            })
          })),
          { name: 'user-storage' } // LocalStorage key
        )
      )
    );
    ```¬∑
    ### 4. Slices Pattern (Large Stores)¬∑
    ```typescript
    // userSlice.ts
    const createUserSlice = (set) => ({
      user: null,
      setUser: (user) => set({ user }),
      logout: () => set({ user: null })
    });¬∑
    // cartSlice.ts
    const createCartSlice = (set) => ({
      items: [],
      addItem: (item) => set((state) => ({ items: [...state.items, item] }))
    });¬∑
    // Combined store
    const useStore = create((set, get) => ({
      ...createUserSlice(set, get),
      ...createCartSlice(set, get)
    }));
    ```¬∑
    ---¬∑
    ## TanStack Query Patterns¬∑
    ### 1. Basic Query (Fetch Data)¬∑
    ```typescript
    import { useQuery } from '@tanstack/react-query';¬∑
    function UserProfile({ userId }: { userId: string }) {
      const { data, isLoading, error } = useQuery({
        queryKey: ['user', userId],
        queryFn: () => fetch(`/api/users/${userId}`).then(res => res.json()),
        staleTime: 5 * 60 * 1000, // 5 minutes
        gcTime: 10 * 60 * 1000    // 10 minutes (formerly cacheTime)
      });¬∑
      if (isLoading) return <Spinner />;
      if (error) return <div>Error: {error.message}</div>;¬∑
      return <div>{data.name}</div>;
    }
    ```¬∑
    ### 2. Mutations (Update Data)¬∑
    ```typescript
    import { useMutation, useQueryClient } from '@tanstack/react-query';¬∑
    function UpdateUserForm({ userId }: { userId: string }) {
      const queryClient = useQueryClient();¬∑
      const mutation = useMutation({
        mutationFn: (newUser: User) =>
          fetch(`/api/users/${userId}`, {
            method: 'PATCH',
            body: JSON.stringify(newUser)
          }),
        onSuccess: () => {
          // Invalidate and refetch
          queryClient.invalidateQueries({ queryKey: ['user', userId] });
        }
      });¬∑
      return (
        <button onClick={() => mutation.mutate({ name: 'New Name' })}>
          Update
        </button>
      );
    }
    ```¬∑
    ### 3. Optimistic Updates¬∑
    ```typescript
    const mutation = useMutation({
      mutationFn: updateTodo,
      onMutate: async (newTodo) => {
        // Cancel outgoing refetches
        await queryClient.cancelQueries({ queryKey: ['todos'] });¬∑
        // Snapshot previous value
        const previousTodos = queryClient.getQueryData(['todos']);¬∑
        // Optimistically update
        queryClient.setQueryData(['todos'], (old: Todo[]) => [...old, newTodo]);¬∑
        // Return context with snapshot
        return { previousTodos };
      },
      onError: (err, newTodo, context) => {
        // Rollback on error
        queryClient.setQueryData(['todos'], context?.previousTodos);
      },
      onSettled: () => {
        // Refetch after error or success
        queryClient.invalidateQueries({ queryKey: ['todos'] });
      }
    });
    ```¬∑
    ### 4. Pagination¬∑
    ```typescript
    function TodoList() {
      const [page, setPage] = useState(1);¬∑
      const { data, isLoading } = useQuery({
        queryKey: ['todos', page],
        queryFn: () => fetch(`/api/todos?page=${page}`).then(res => res.json()),
        placeholderData: keepPreviousData // Keep previous page while loading
      });¬∑
      return (
        <div>
          {data?.todos.map(todo => <TodoItem key={todo.id} {...todo} />)}
          <button onClick={() => setPage(p => Math.max(1, p - 1))}>Previous</button>
          <button onClick={() => setPage(p => p + 1)}>Next</button>
        </div>
      );
    }
    ```¬∑
    ### 5. Infinite Scroll¬∑
    ```typescript
    import { useInfiniteQuery } from '@tanstack/react-query';¬∑
    function InfiniteList() {
      const {
        data,
        fetchNextPage,
        hasNextPage,
        isFetchingNextPage
      } = useInfiniteQuery({
        queryKey: ['todos'],
        queryFn: ({ pageParam = 1 }) =>
          fetch(`/api/todos?page=${pageParam}`).then(res => res.json()),
        initialPageParam: 1,
        getNextPageParam: (lastPage, pages) =>
          lastPage.hasMore ? pages.length + 1 : undefined
      });¬∑
      return (
        <div>
          {data?.pages.map((page, i) => (
            <React.Fragment key={i}>
              {page.todos.map(todo => <TodoItem key={todo.id} {...todo} />)}
            </React.Fragment>
          ))}
          <button
            onClick={() => fetchNextPage()}
            disabled={!hasNextPage || isFetchingNextPage}
          >
            {isFetchingNextPage ? 'Loading...' : 'Load More'}
          </button>
        </div>
      );
    }
    ```¬∑
    ---¬∑
    ## Jotai Patterns¬∑
    ### 1. Primitive Atoms¬∑
    ```typescript
    import { atom, useAtom } from 'jotai';¬∑
    // Primitive atoms
    const countAtom = atom(0);
    const userAtom = atom<User | null>(null);¬∑
    function Counter() {
      const [count, setCount] = useAtom(countAtom);¬∑
      return (
        <div>
          <p>Count: {count}</p>
          <button onClick={() => setCount(c => c + 1)}>Increment</button>
        </div>
      );
    }
    ```¬∑
    ### 2. Derived Atoms (Read-Only)¬∑
    ```typescript
    const priceAtom = atom(10);
    const quantityAtom = atom(5);¬∑
    // Derived atom (computed)
    const totalAtom = atom((get) => {
      const price = get(priceAtom);
      const quantity = get(quantityAtom);
      return price * quantity;
    });¬∑
    function Total() {
      const [total] = useAtom(totalAtom);
      return <div>Total: ${total}</div>; // Automatically updates
    }
    ```¬∑
    ### 3. Async Atoms¬∑
    ```typescript
    const userIdAtom = atom('user-123');¬∑
    // Async atom (fetch data)
    const userAtom = atom(async (get) => {
      const userId = get(userIdAtom);
      const response = await fetch(`/api/users/${userId}`);
      return response.json();
    });¬∑
    function UserProfile() {
      const [user] = useAtom(userAtom);¬∑
      return <div>{user.name}</div>; // Suspense boundary handles loading
    }¬∑
    // Wrap in Suspense
    function App() {
      return (
        <Suspense fallback={<Spinner />}>
          <UserProfile />
        </Suspense>
      );
    }
    ```¬∑
    ### 4. Write-Only Atoms (Actions)¬∑
    ```typescript
    const todosAtom = atom<Todo[]>([]);¬∑
    // Write-only atom (action)
    const addTodoAtom = atom(
      null, // No read
      (get, set, newTodo: Todo) => {
        set(todosAtom, [...get(todosAtom), newTodo]);
      }
    );¬∑
    function AddTodo() {
      const [, addTodo] = useAtom(addTodoAtom);¬∑
      return (
        <button onClick={() => addTodo({ id: '1', text: 'New Todo' })}>
          Add Todo
        </button>
      );
    }
    ```¬∑
    ### 5. Atom Families (Dynamic Atoms)¬∑
    ```typescript
    import { atomFamily } from 'jotai/utils';¬∑
    // Create atoms dynamically based on ID
    const userAtomFamily = atomFamily((userId: string) =>
      atom(async () => {
        const response = await fetch(`/api/users/${userId}`);
        return response.json();
      })
    );¬∑
    function UserCard({ userId }: { userId: string }) {
      const [user] = useAtom(userAtomFamily(userId));
      return <div>{user.name}</div>;
    }
    ```¬∑
    ---¬∑
    ## Migration from Redux¬∑
    ### Redux to Zustand¬∑
    **Before (Redux)**:
    ```typescript
    // actions.ts
    export const increment = () => ({ type: 'INCREMENT' });
    export const decrement = () => ({ type: 'DECREMENT' });¬∑
    // reducer.ts
    const counterReducer = (state = { count: 0 }, action) => {
      switch (action.type) {
        case 'INCREMENT':
          return { count: state.count + 1 };
        case 'DECREMENT':
          return { count: state.count - 1 };
        default:
          return state;
      }
    };¬∑
    // store.ts
    const store = createStore(counterReducer);¬∑
    // Usage
    dispatch(increment());
    ```¬∑
    **After (Zustand)**:
    ```typescript
    const useStore = create((set) => ({
      count: 0,
      increment: () => set((state) => ({ count: state.count + 1 })),
      decrement: () => set((state) => ({ count: state.count - 1 }))
    }));¬∑
    // Usage
    const increment = useStore((state) => state.increment);
    increment(); // Direct call, no dispatch
    ```¬∑
    **60% less boilerplate** (no actions, reducers, dispatch, connect, mapStateToProps)¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Selector Optimization (Prevent Re-Renders)¬∑
    ```typescript
    // ‚ùå Bad - Re-renders on any state change
    const { items, total } = useStore();¬∑
    // ‚úÖ Good - Only re-renders when `total` changes
    const total = useStore((state) => state.total);
    ```¬∑
    ### 2. Shallow Comparison¬∑
    ```typescript
    import { shallow } from 'zustand/shallow';¬∑
    // Re-renders only if items array changes (shallow comparison)
    const items = useStore((state) => state.items, shallow);
    ```¬∑
    ### 3. TanStack Query - Stale Time¬∑
    ```typescript
    // Avoid unnecessary refetches
    const { data } = useQuery({
      queryKey: ['user'],
      queryFn: fetchUser,
      staleTime: 5 * 60 * 1000, // Consider fresh for 5 minutes
      gcTime: 10 * 60 * 1000    // Cache for 10 minutes
    });
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migration-helper.js` - Redux to Zustand migration script¬∑
    ### references/
    - `references/zustand-patterns.md` - Store setup, middleware, slices
    - `references/tanstack-query-patterns.md` - Queries, mutations, caching
    - `references/jotai-patterns.md` - Atoms, derived state, async
    - `references/redux-migration.md` - Step-by-step Redux ‚Üí Zustand migration¬∑
    ### assets/
    - `assets/store-templates/` - Zustand/Jotai/TanStack Query starter templates¬∑
    ## Related Skills¬∑
    - `testing-strategies` - Testing state management with Vitest
    - `performance-optimization` - Re-render optimization, profiling
    - `api-design` - Backend API integration with TanStack Query
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ styling-architecture ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: styling-architecture
    description: Modern CSS-in-JS and styling architectures using Panda CSS (zero-runtime), Vanilla Extract (type-safe), and CVA (component variants). Use when implementing design systems, theming, or optimizing CSS bundle size. Reduces runtime overhead by 100% (zero-runtime) and provides full TypeScript safety.
    ---¬∑
    # Styling Architecture¬∑
    ## Overview¬∑
    Modern styling architectures with zero-runtime CSS-in-JS (Panda CSS), type-safe styling (Vanilla Extract), and component variant systems (CVA). Eliminates runtime overhead while maintaining developer experience and type safety.¬∑
    **Goal**: Type-safe, performant styling with design token integration and minimal bundle size¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing design systems with type-safe tokens
    - Migrating from runtime CSS-in-JS (styled-components, Emotion)
    - Optimizing CSS bundle size and runtime performance
    - Creating themeable component libraries
    - Building variant-based component APIs
    - Implementing responsive design patterns
    - Reducing CSS specificity conflicts¬∑
    **Triggers**: \"styling system\", \"CSS-in-JS\", \"Panda CSS\", \"Vanilla Extract\", \"design tokens\", \"theming\", \"component variants\"¬∑
    ---¬∑
    ## Quick Start: Styling Library Decision Tree¬∑
    ### When to Use Panda CSS vs Vanilla Extract vs CVA¬∑
    **Panda CSS** (Zero-runtime, utility-first):
    - ‚úÖ Zero runtime overhead (styles extracted at build time)
    - ‚úÖ Utility-first with type-safe props
    - ‚úÖ Automatic atomic CSS generation
    - ‚úÖ Design token integration (colors, spacing, typography)
    - ‚úÖ Responsive variants (`{ base: '16px', md: '18px', lg: '20px' }`)
    - ‚úÖ Best for: New projects, performance-critical apps¬∑
    **Vanilla Extract** (Zero-runtime, CSS Modules++):
    - ‚úÖ Zero runtime overhead (compiles to CSS Modules)
    - ‚úÖ Full TypeScript safety (types for all CSS properties)
    - ‚úÖ Scoped styles (no global namespace pollution)
    - ‚úÖ Theme contracts (typed theme variables)
    - ‚úÖ CSS utility integration (Tailwind, Sprinkles)
    - ‚úÖ Best for: Component libraries, design systems¬∑
    **CVA (Class Variance Authority)** (Variant API):
    - ‚úÖ Component variant API (size, color, intent)
    - ‚úÖ Compound variants (combine multiple variants)
    - ‚úÖ Default variants
    - ‚úÖ Works with any CSS solution (Tailwind, Panda, Vanilla Extract)
    - ‚úÖ Best for: UI component libraries (buttons, cards, badges)¬∑
    **Use Multiple** when:
    - Panda CSS for app styling + CVA for component variants
    - Vanilla Extract for component library + CVA for variant API¬∑
    ---¬∑
    ## Panda CSS Patterns¬∑
    ### 1. Basic Styling¬∑
    ```typescript
    import { css } from '../styled-system/css';¬∑
    function Button({ children }) {
      return (
        <button className={css({
          bg: 'blue.500',
          color: 'white',
          px: 4,
          py: 2,
          rounded: 'md',
          _hover: { bg: 'blue.600' },
          _active: { bg: 'blue.700' }
        })}>
          {children}
        </button>
      );
    }
    ```¬∑
    ### 2. Responsive Design¬∑
    ```typescript
    import { css } from '../styled-system/css';¬∑
    function ResponsiveCard() {
      return (
        <div className={css({
          // Mobile-first responsive design
          fontSize: { base: '14px', md: '16px', lg: '18px' },
          padding: { base: 4, md: 6, lg: 8 },
          display: { base: 'block', md: 'flex' },
          gap: { md: 4, lg: 6 }
        })}>
          Content
        </div>
      );
    }
    ```¬∑
    ### 3. Design Tokens¬∑
    ```typescript
    // panda.config.ts
    import { defineConfig } from '@pandacss/dev';¬∑
    export default defineConfig({
      theme: {
        extend: {
          tokens: {
            colors: {
              primary: { value: '#3b82f6' },
              secondary: { value: '#8b5cf6' },
              danger: { value: '#ef4444' }
            },
            spacing: {
              xs: { value: '0.25rem' },
              sm: { value: '0.5rem' },
              md: { value: '1rem' },
              lg: { value: '1.5rem' },
              xl: { value: '2rem' }
            },
            fonts: {
              heading: { value: 'Inter, sans-serif' },
              body: { value: 'system-ui, sans-serif' }
            }
          }
        }
      }
    });¬∑
    // Usage with full type safety
    import { css } from '../styled-system/css';¬∑
    const heading = css({
      color: 'primary',
      fontFamily: 'heading',
      fontSize: '2xl',
      mb: 'lg'
    });
    ```¬∑
    ### 4. Recipes (Reusable Styles)¬∑
    ```typescript
    // recipes/button.ts
    import { cva } from '../styled-system/css';¬∑
    export const buttonRecipe = cva({
      base: {
        display: 'inline-flex',
        alignItems: 'center',
        justifyContent: 'center',
        rounded: 'md',
        fontWeight: 'medium',
        transition: 'all 0.2s'
      },
      variants: {
        visual: {
          solid: { bg: 'blue.500', color: 'white', _hover: { bg: 'blue.600' } },
          outline: { border: '1px solid', borderColor: 'blue.500', color: 'blue.500' },
          ghost: { bg: 'transparent', color: 'blue.500', _hover: { bg: 'blue.50' } }
        },
        size: {
          sm: { px: 3, py: 1.5, fontSize: 'sm' },
          md: { px: 4, py: 2, fontSize: 'md' },
          lg: { px: 6, py: 3, fontSize: 'lg' }
        }
      },
      defaultVariants: {
        visual: 'solid',
        size: 'md'
      }
    });¬∑
    // Usage
    function Button({ visual, size, children }) {
      return <button className={buttonRecipe({ visual, size })}>{children}</button>;
    }
    ```¬∑
    ### 5. Patterns (Layout Helpers)¬∑
    ```typescript
    import { stack, hstack, vstack } from '../styled-system/patterns';¬∑
    function LayoutExample() {
      return (
        <div className={vstack({ gap: 4, align: 'stretch' })}>
          <header className={hstack({ justify: 'between', p: 4 })}>
            <h1>Title</h1>
            <button>Action</button>
          </header>
          <main className={stack({ gap: 6, p: 6 })}>
            Content
          </main>
        </div>
      );
    }
    ```¬∑
    ---¬∑
    ## Vanilla Extract Patterns¬∑
    ### 1. Basic Styles¬∑
    ```typescript
    // button.css.ts
    import { style } from '@vanilla-extract/css';¬∑
    export const button = style({
      backgroundColor: '#3b82f6',
      color: 'white',
      padding: '8px 16px',
      borderRadius: '6px',
      border: 'none',
      cursor: 'pointer',
      ':hover': {
        backgroundColor: '#2563eb'
      }
    });¬∑
    // Button.tsx
    import * as styles from './button.css';¬∑
    export function Button({ children }) {
      return <button className={styles.button}>{children}</button>;
    }
    ```¬∑
    ### 2. Theme Contracts (Typed Themes)¬∑
    ```typescript
    // theme.css.ts
    import { createThemeContract, createTheme } from '@vanilla-extract/css';¬∑
    // Define theme structure with type safety
    export const vars = createThemeContract({
      color: {
        primary: null,
        secondary: null,
        background: null,
        text: null
      },
      space: {
        small: null,
        medium: null,
        large: null
      },
      font: {
        body: null,
        heading: null
      }
    });¬∑
    // Light theme
    export const lightTheme = createTheme(vars, {
      color: {
        primary: '#3b82f6',
        secondary: '#8b5cf6',
        background: '#ffffff',
        text: '#1f2937'
      },
      space: {
        small: '8px',
        medium: '16px',
        large: '24px'
      },
      font: {
        body: 'system-ui, sans-serif',
        heading: 'Inter, sans-serif'
      }
    });¬∑
    // Dark theme
    export const darkTheme = createTheme(vars, {
      color: {
        primary: '#60a5fa',
        secondary: '#a78bfa',
        background: '#111827',
        text: '#f3f4f6'
      },
      space: {
        small: '8px',
        medium: '16px',
        large: '24px'
      },
      font: {
        body: 'system-ui, sans-serif',
        heading: 'Inter, sans-serif'
      }
    });¬∑
    // Usage
    import { style } from '@vanilla-extract/css';
    import { vars } from './theme.css';¬∑
    export const card = style({
      backgroundColor: vars.color.background,
      color: vars.color.text,
      padding: vars.space.medium,
      borderRadius: '8px'
    });
    ```¬∑
    ### 3. Sprinkles (Utility System)¬∑
    ```typescript
    // sprinkles.css.ts
    import { defineProperties, createSprinkles } from '@vanilla-extract/sprinkles';¬∑
    const responsiveProperties = defineProperties({
      conditions: {
        mobile: {},
        tablet: { '@media': 'screen and (min-width: 768px)' },
        desktop: { '@media': 'screen and (min-width: 1024px)' }
      },
      defaultCondition: 'mobile',
      properties: {
        display: ['none', 'flex', 'block', 'inline'],
        flexDirection: ['row', 'column'],
        justifyContent: ['flex-start', 'center', 'flex-end', 'space-between'],
        alignItems: ['flex-start', 'center', 'flex-end', 'stretch'],
        paddingTop: ['4px', '8px', '16px', '24px', '32px'],
        paddingBottom: ['4px', '8px', '16px', '24px', '32px'],
        paddingLeft: ['4px', '8px', '16px', '24px', '32px'],
        paddingRight: ['4px', '8px', '16px', '24px', '32px']
      },
      shorthands: {
        padding: ['paddingTop', 'paddingBottom', 'paddingLeft', 'paddingRight'],
        paddingX: ['paddingLeft', 'paddingRight'],
        paddingY: ['paddingTop', 'paddingBottom']
      }
    });¬∑
    export const sprinkles = createSprinkles(responsiveProperties);
    export type Sprinkles = Parameters<typeof sprinkles>[0];¬∑
    // Usage
    function Card() {
      return (
        <div className={sprinkles({
          display: 'flex',
          flexDirection: { mobile: 'column', tablet: 'row' },
          padding: { mobile: '8px', tablet: '16px', desktop: '24px' },
          justifyContent: 'space-between'
        })}>
          Content
        </div>
      );
    }
    ```¬∑
    ### 4. Style Variants¬∑
    ```typescript
    // button.css.ts
    import { styleVariants } from '@vanilla-extract/css';¬∑
    const base = style({
      padding: '8px 16px',
      borderRadius: '6px',
      border: 'none',
      cursor: 'pointer'
    });¬∑
    export const buttonVariants = styleVariants({
      primary: [base, {
        backgroundColor: '#3b82f6',
        color: 'white'
      }],
      secondary: [base, {
        backgroundColor: '#8b5cf6',
        color: 'white'
      }],
      outline: [base, {
        backgroundColor: 'transparent',
        border: '1px solid #3b82f6',
        color: '#3b82f6'
      }]
    });¬∑
    // Usage
    import { buttonVariants } from './button.css';¬∑
    function Button({ variant = 'primary', children }) {
      return <button className={buttonVariants[variant]}>{children}</button>;
    }
    ```¬∑
    ---¬∑
    ## CVA (Class Variance Authority) Patterns¬∑
    ### 1. Basic Variants¬∑
    ```typescript
    import { cva } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded font-medium', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white hover:bg-blue-600',
          secondary: 'bg-gray-200 text-gray-900 hover:bg-gray-300',
          danger: 'bg-red-500 text-white hover:bg-red-600'
        },
        size: {
          small: 'text-sm px-3 py-1.5',
          medium: 'text-base px-4 py-2',
          large: 'text-lg px-6 py-3'
        }
      },
      defaultVariants: {
        intent: 'primary',
        size: 'medium'
      }
    });¬∑
    // Usage
    function Button({ intent, size, children }) {
      return <button className={button({ intent, size })}>{children}</button>;
    }¬∑
    // Examples:
    <Button intent=\"primary\" size=\"small\">Small Primary</Button>
    <Button intent=\"danger\" size=\"large\">Large Danger</Button>
    <Button>Medium Primary (defaults)</Button>
    ```¬∑
    ### 2. Compound Variants¬∑
    ```typescript
    import { cva } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white',
          secondary: 'bg-gray-200 text-gray-900'
        },
        outlined: {
          true: 'bg-transparent border-2'
        }
      },
      compoundVariants: [
        {
          intent: 'primary',
          outlined: true,
          className: 'border-blue-500 text-blue-500 hover:bg-blue-50'
        },
        {
          intent: 'secondary',
          outlined: true,
          className: 'border-gray-300 text-gray-700 hover:bg-gray-50'
        }
      ]
    });¬∑
    // Usage
    <Button intent=\"primary\" outlined>Outlined Primary</Button>
    ```¬∑
    ### 3. TypeScript Integration¬∑
    ```typescript
    import { cva, type VariantProps } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white',
          secondary: 'bg-gray-200 text-gray-900',
          danger: 'bg-red-500 text-white'
        },
        size: {
          small: 'text-sm px-3 py-1.5',
          medium: 'text-base px-4 py-2',
          large: 'text-lg px-6 py-3'
        }
      },
      defaultVariants: {
        intent: 'primary',
        size: 'medium'
      }
    });¬∑
    // Extract types from CVA definition
    type ButtonProps = VariantProps<typeof button> & {
      children: React.ReactNode;
    };¬∑
    function Button({ intent, size, children }: ButtonProps) {
      return <button className={button({ intent, size })}>{children}</button>;
    }¬∑
    // Full type safety:
    <Button intent=\"primary\" size=\"small\">Typed</Button>
    // @ts-expect-error - \"invalid\" is not a valid intent
    <Button intent=\"invalid\">Error</Button>
    ```¬∑
    ---¬∑
    ## Migration Patterns¬∑
    ### From styled-components to Panda CSS¬∑
    **Before (styled-components)**:
    ```typescript
    import styled from 'styled-components';¬∑
    const Button = styled.button`
      background-color: ${props => props.primary ? '#3b82f6' : '#8b5cf6'};
      color: white;
      padding: 8px 16px;
      border-radius: 6px;¬∑
      &:hover {
        background-color: ${props => props.primary ? '#2563eb' : '#7c3aed'};
      }
    `;¬∑
    // Runtime: Styles generated on mount (~2-5ms overhead per component)
    ```¬∑
    **After (Panda CSS)**:
    ```typescript
    import { css, cva } from '../styled-system/css';¬∑
    const button = cva({
      base: {
        color: 'white',
        px: 4,
        py: 2,
        rounded: 'md'
      },
      variants: {
        variant: {
          primary: { bg: 'blue.500', _hover: { bg: 'blue.600' } },
          secondary: { bg: 'purple.500', _hover: { bg: 'purple.600' } }
        }
      }
    });¬∑
    function Button({ variant = 'primary', children }) {
      return <button className={button({ variant })}>{children}</button>;
    }¬∑
    // Zero runtime: All styles extracted at build time
    ```¬∑
    **100% runtime overhead eliminated** (0ms vs 2-5ms per component)¬∑
    ### From Emotion to Vanilla Extract¬∑
    **Before (Emotion)**:
    ```typescript
    import { css } from '@emotion/react';¬∑
    function Card() {
      return (
        <div css={css`
          background-color: white;
          padding: 16px;
          border-radius: 8px;
          box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        `}>
          Content
        </div>
      );
    }
    ```¬∑
    **After (Vanilla Extract)**:
    ```typescript
    // card.css.ts
    import { style } from '@vanilla-extract/css';¬∑
    export const card = style({
      backgroundColor: 'white',
      padding: '16px',
      borderRadius: '8px',
      boxShadow: '0 2px 4px rgba(0,0,0,0.1)'
    });¬∑
    // Card.tsx
    import * as styles from './card.css';¬∑
    export function Card() {
      return <div className={styles.card}>Content</div>;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Zero-Runtime CSS¬∑
    ```typescript
    // ‚úÖ Good - Zero runtime (Panda CSS)
    import { css } from '../styled-system/css';¬∑
    const button = css({ bg: 'blue.500', px: 4, py: 2 });¬∑
    // Compiled to static CSS at build time:
    // .css-button { background: #3b82f6; padding-left: 1rem; padding-right: 1rem; }
    ```¬∑
    ```typescript
    // ‚ùå Bad - Runtime overhead (styled-components)
    import styled from 'styled-components';¬∑
    const Button = styled.button`
      background: #3b82f6;
      padding: 1rem;
    `;¬∑
    // Styles generated on mount (~2-5ms overhead + CSS injection)
    ```¬∑
    ### 2. Atomic CSS¬∑
    ```typescript
    // Panda CSS automatically generates atomic classes
    import { css } from '../styled-system/css';¬∑
    const card1 = css({ bg: 'white', p: 4, rounded: 'md' });
    const card2 = css({ bg: 'white', p: 4, rounded: 'lg' });¬∑
    // Compiled to:
    // .bg-white { background: white; }
    // .p-4 { padding: 1rem; }
    // .rounded-md { border-radius: 0.375rem; }
    // .rounded-lg { border-radius: 0.5rem; }¬∑
    // CSS reused across components ‚Üí smaller bundle size
    ```¬∑
    ### 3. Tree-Shaking¬∑
    ```typescript
    // Only import what you use
    import { css } from '../styled-system/css';
    import { hstack } from '../styled-system/patterns';¬∑
    // Unused patterns/recipes automatically tree-shaken
    // Final bundle only includes css() and hstack()
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migrate-to-panda.js` - styled-components ‚Üí Panda CSS migration script
    - `generate-design-tokens.js` - Figma ‚Üí Panda tokens script¬∑
    ### references/
    - `references/panda-patterns.md` - Recipes, patterns, responsive design
    - `references/vanilla-extract-patterns.md` - Themes, sprinkles, style variants
    - `references/cva-patterns.md` - Component variants, compound variants
    - `references/zero-runtime-migration.md` - styled-components/Emotion ‚Üí Panda/Vanilla Extract¬∑
    ### assets/
    - `assets/design-tokens/` - Theme token examples
    - `assets/component-variants/` - CVA variant templates¬∑
    ## Related Skills¬∑
    - `design-tokens` - Design token automation with Figma sync
    - `component-patterns` - Component composition and API design
    - `performance-optimization` - CSS bundle size optimization
    - `testing-strategies` - Visual regression testing for styles
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ styling-architecture ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: styling-architecture
    description: Modern CSS-in-JS and styling architectures using Panda CSS (zero-runtime), Vanilla Extract (type-safe), and CVA (component variants). Use when implementing design systems, theming, or optimizing CSS bundle size. Reduces runtime overhead by 100% (zero-runtime) and provides full TypeScript safety.
    ---¬∑
    # Styling Architecture¬∑
    ## Overview¬∑
    Modern styling architectures with zero-runtime CSS-in-JS (Panda CSS), type-safe styling (Vanilla Extract), and component variant systems (CVA). Eliminates runtime overhead while maintaining developer experience and type safety.¬∑
    **Goal**: Type-safe, performant styling with design token integration and minimal bundle size¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing design systems with type-safe tokens
    - Migrating from runtime CSS-in-JS (styled-components, Emotion)
    - Optimizing CSS bundle size and runtime performance
    - Creating themeable component libraries
    - Building variant-based component APIs
    - Implementing responsive design patterns
    - Reducing CSS specificity conflicts¬∑
    **Triggers**: \"styling system\", \"CSS-in-JS\", \"Panda CSS\", \"Vanilla Extract\", \"design tokens\", \"theming\", \"component variants\"¬∑
    ---¬∑
    ## Quick Start: Styling Library Decision Tree¬∑
    ### When to Use Panda CSS vs Vanilla Extract vs CVA¬∑
    **Panda CSS** (Zero-runtime, utility-first):
    - ‚úÖ Zero runtime overhead (styles extracted at build time)
    - ‚úÖ Utility-first with type-safe props
    - ‚úÖ Automatic atomic CSS generation
    - ‚úÖ Design token integration (colors, spacing, typography)
    - ‚úÖ Responsive variants (`{ base: '16px', md: '18px', lg: '20px' }`)
    - ‚úÖ Best for: New projects, performance-critical apps¬∑
    **Vanilla Extract** (Zero-runtime, CSS Modules++):
    - ‚úÖ Zero runtime overhead (compiles to CSS Modules)
    - ‚úÖ Full TypeScript safety (types for all CSS properties)
    - ‚úÖ Scoped styles (no global namespace pollution)
    - ‚úÖ Theme contracts (typed theme variables)
    - ‚úÖ CSS utility integration (Tailwind, Sprinkles)
    - ‚úÖ Best for: Component libraries, design systems¬∑
    **CVA (Class Variance Authority)** (Variant API):
    - ‚úÖ Component variant API (size, color, intent)
    - ‚úÖ Compound variants (combine multiple variants)
    - ‚úÖ Default variants
    - ‚úÖ Works with any CSS solution (Tailwind, Panda, Vanilla Extract)
    - ‚úÖ Best for: UI component libraries (buttons, cards, badges)¬∑
    **Use Multiple** when:
    - Panda CSS for app styling + CVA for component variants
    - Vanilla Extract for component library + CVA for variant API¬∑
    ---¬∑
    ## Panda CSS Patterns¬∑
    ### 1. Basic Styling¬∑
    ```typescript
    import { css } from '../styled-system/css';¬∑
    function Button({ children }) {
      return (
        <button className={css({
          bg: 'blue.500',
          color: 'white',
          px: 4,
          py: 2,
          rounded: 'md',
          _hover: { bg: 'blue.600' },
          _active: { bg: 'blue.700' }
        })}>
          {children}
        </button>
      );
    }
    ```¬∑
    ### 2. Responsive Design¬∑
    ```typescript
    import { css } from '../styled-system/css';¬∑
    function ResponsiveCard() {
      return (
        <div className={css({
          // Mobile-first responsive design
          fontSize: { base: '14px', md: '16px', lg: '18px' },
          padding: { base: 4, md: 6, lg: 8 },
          display: { base: 'block', md: 'flex' },
          gap: { md: 4, lg: 6 }
        })}>
          Content
        </div>
      );
    }
    ```¬∑
    ### 3. Design Tokens¬∑
    ```typescript
    // panda.config.ts
    import { defineConfig } from '@pandacss/dev';¬∑
    export default defineConfig({
      theme: {
        extend: {
          tokens: {
            colors: {
              primary: { value: '#3b82f6' },
              secondary: { value: '#8b5cf6' },
              danger: { value: '#ef4444' }
            },
            spacing: {
              xs: { value: '0.25rem' },
              sm: { value: '0.5rem' },
              md: { value: '1rem' },
              lg: { value: '1.5rem' },
              xl: { value: '2rem' }
            },
            fonts: {
              heading: { value: 'Inter, sans-serif' },
              body: { value: 'system-ui, sans-serif' }
            }
          }
        }
      }
    });¬∑
    // Usage with full type safety
    import { css } from '../styled-system/css';¬∑
    const heading = css({
      color: 'primary',
      fontFamily: 'heading',
      fontSize: '2xl',
      mb: 'lg'
    });
    ```¬∑
    ### 4. Recipes (Reusable Styles)¬∑
    ```typescript
    // recipes/button.ts
    import { cva } from '../styled-system/css';¬∑
    export const buttonRecipe = cva({
      base: {
        display: 'inline-flex',
        alignItems: 'center',
        justifyContent: 'center',
        rounded: 'md',
        fontWeight: 'medium',
        transition: 'all 0.2s'
      },
      variants: {
        visual: {
          solid: { bg: 'blue.500', color: 'white', _hover: { bg: 'blue.600' } },
          outline: { border: '1px solid', borderColor: 'blue.500', color: 'blue.500' },
          ghost: { bg: 'transparent', color: 'blue.500', _hover: { bg: 'blue.50' } }
        },
        size: {
          sm: { px: 3, py: 1.5, fontSize: 'sm' },
          md: { px: 4, py: 2, fontSize: 'md' },
          lg: { px: 6, py: 3, fontSize: 'lg' }
        }
      },
      defaultVariants: {
        visual: 'solid',
        size: 'md'
      }
    });¬∑
    // Usage
    function Button({ visual, size, children }) {
      return <button className={buttonRecipe({ visual, size })}>{children}</button>;
    }
    ```¬∑
    ### 5. Patterns (Layout Helpers)¬∑
    ```typescript
    import { stack, hstack, vstack } from '../styled-system/patterns';¬∑
    function LayoutExample() {
      return (
        <div className={vstack({ gap: 4, align: 'stretch' })}>
          <header className={hstack({ justify: 'between', p: 4 })}>
            <h1>Title</h1>
            <button>Action</button>
          </header>
          <main className={stack({ gap: 6, p: 6 })}>
            Content
          </main>
        </div>
      );
    }
    ```¬∑
    ---¬∑
    ## Vanilla Extract Patterns¬∑
    ### 1. Basic Styles¬∑
    ```typescript
    // button.css.ts
    import { style } from '@vanilla-extract/css';¬∑
    export const button = style({
      backgroundColor: '#3b82f6',
      color: 'white',
      padding: '8px 16px',
      borderRadius: '6px',
      border: 'none',
      cursor: 'pointer',
      ':hover': {
        backgroundColor: '#2563eb'
      }
    });¬∑
    // Button.tsx
    import * as styles from './button.css';¬∑
    export function Button({ children }) {
      return <button className={styles.button}>{children}</button>;
    }
    ```¬∑
    ### 2. Theme Contracts (Typed Themes)¬∑
    ```typescript
    // theme.css.ts
    import { createThemeContract, createTheme } from '@vanilla-extract/css';¬∑
    // Define theme structure with type safety
    export const vars = createThemeContract({
      color: {
        primary: null,
        secondary: null,
        background: null,
        text: null
      },
      space: {
        small: null,
        medium: null,
        large: null
      },
      font: {
        body: null,
        heading: null
      }
    });¬∑
    // Light theme
    export const lightTheme = createTheme(vars, {
      color: {
        primary: '#3b82f6',
        secondary: '#8b5cf6',
        background: '#ffffff',
        text: '#1f2937'
      },
      space: {
        small: '8px',
        medium: '16px',
        large: '24px'
      },
      font: {
        body: 'system-ui, sans-serif',
        heading: 'Inter, sans-serif'
      }
    });¬∑
    // Dark theme
    export const darkTheme = createTheme(vars, {
      color: {
        primary: '#60a5fa',
        secondary: '#a78bfa',
        background: '#111827',
        text: '#f3f4f6'
      },
      space: {
        small: '8px',
        medium: '16px',
        large: '24px'
      },
      font: {
        body: 'system-ui, sans-serif',
        heading: 'Inter, sans-serif'
      }
    });¬∑
    // Usage
    import { style } from '@vanilla-extract/css';
    import { vars } from './theme.css';¬∑
    export const card = style({
      backgroundColor: vars.color.background,
      color: vars.color.text,
      padding: vars.space.medium,
      borderRadius: '8px'
    });
    ```¬∑
    ### 3. Sprinkles (Utility System)¬∑
    ```typescript
    // sprinkles.css.ts
    import { defineProperties, createSprinkles } from '@vanilla-extract/sprinkles';¬∑
    const responsiveProperties = defineProperties({
      conditions: {
        mobile: {},
        tablet: { '@media': 'screen and (min-width: 768px)' },
        desktop: { '@media': 'screen and (min-width: 1024px)' }
      },
      defaultCondition: 'mobile',
      properties: {
        display: ['none', 'flex', 'block', 'inline'],
        flexDirection: ['row', 'column'],
        justifyContent: ['flex-start', 'center', 'flex-end', 'space-between'],
        alignItems: ['flex-start', 'center', 'flex-end', 'stretch'],
        paddingTop: ['4px', '8px', '16px', '24px', '32px'],
        paddingBottom: ['4px', '8px', '16px', '24px', '32px'],
        paddingLeft: ['4px', '8px', '16px', '24px', '32px'],
        paddingRight: ['4px', '8px', '16px', '24px', '32px']
      },
      shorthands: {
        padding: ['paddingTop', 'paddingBottom', 'paddingLeft', 'paddingRight'],
        paddingX: ['paddingLeft', 'paddingRight'],
        paddingY: ['paddingTop', 'paddingBottom']
      }
    });¬∑
    export const sprinkles = createSprinkles(responsiveProperties);
    export type Sprinkles = Parameters<typeof sprinkles>[0];¬∑
    // Usage
    function Card() {
      return (
        <div className={sprinkles({
          display: 'flex',
          flexDirection: { mobile: 'column', tablet: 'row' },
          padding: { mobile: '8px', tablet: '16px', desktop: '24px' },
          justifyContent: 'space-between'
        })}>
          Content
        </div>
      );
    }
    ```¬∑
    ### 4. Style Variants¬∑
    ```typescript
    // button.css.ts
    import { styleVariants } from '@vanilla-extract/css';¬∑
    const base = style({
      padding: '8px 16px',
      borderRadius: '6px',
      border: 'none',
      cursor: 'pointer'
    });¬∑
    export const buttonVariants = styleVariants({
      primary: [base, {
        backgroundColor: '#3b82f6',
        color: 'white'
      }],
      secondary: [base, {
        backgroundColor: '#8b5cf6',
        color: 'white'
      }],
      outline: [base, {
        backgroundColor: 'transparent',
        border: '1px solid #3b82f6',
        color: '#3b82f6'
      }]
    });¬∑
    // Usage
    import { buttonVariants } from './button.css';¬∑
    function Button({ variant = 'primary', children }) {
      return <button className={buttonVariants[variant]}>{children}</button>;
    }
    ```¬∑
    ---¬∑
    ## CVA (Class Variance Authority) Patterns¬∑
    ### 1. Basic Variants¬∑
    ```typescript
    import { cva } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded font-medium', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white hover:bg-blue-600',
          secondary: 'bg-gray-200 text-gray-900 hover:bg-gray-300',
          danger: 'bg-red-500 text-white hover:bg-red-600'
        },
        size: {
          small: 'text-sm px-3 py-1.5',
          medium: 'text-base px-4 py-2',
          large: 'text-lg px-6 py-3'
        }
      },
      defaultVariants: {
        intent: 'primary',
        size: 'medium'
      }
    });¬∑
    // Usage
    function Button({ intent, size, children }) {
      return <button className={button({ intent, size })}>{children}</button>;
    }¬∑
    // Examples:
    <Button intent=\"primary\" size=\"small\">Small Primary</Button>
    <Button intent=\"danger\" size=\"large\">Large Danger</Button>
    <Button>Medium Primary (defaults)</Button>
    ```¬∑
    ### 2. Compound Variants¬∑
    ```typescript
    import { cva } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white',
          secondary: 'bg-gray-200 text-gray-900'
        },
        outlined: {
          true: 'bg-transparent border-2'
        }
      },
      compoundVariants: [
        {
          intent: 'primary',
          outlined: true,
          className: 'border-blue-500 text-blue-500 hover:bg-blue-50'
        },
        {
          intent: 'secondary',
          outlined: true,
          className: 'border-gray-300 text-gray-700 hover:bg-gray-50'
        }
      ]
    });¬∑
    // Usage
    <Button intent=\"primary\" outlined>Outlined Primary</Button>
    ```¬∑
    ### 3. TypeScript Integration¬∑
    ```typescript
    import { cva, type VariantProps } from 'class-variance-authority';¬∑
    const button = cva('px-4 py-2 rounded', {
      variants: {
        intent: {
          primary: 'bg-blue-500 text-white',
          secondary: 'bg-gray-200 text-gray-900',
          danger: 'bg-red-500 text-white'
        },
        size: {
          small: 'text-sm px-3 py-1.5',
          medium: 'text-base px-4 py-2',
          large: 'text-lg px-6 py-3'
        }
      },
      defaultVariants: {
        intent: 'primary',
        size: 'medium'
      }
    });¬∑
    // Extract types from CVA definition
    type ButtonProps = VariantProps<typeof button> & {
      children: React.ReactNode;
    };¬∑
    function Button({ intent, size, children }: ButtonProps) {
      return <button className={button({ intent, size })}>{children}</button>;
    }¬∑
    // Full type safety:
    <Button intent=\"primary\" size=\"small\">Typed</Button>
    // @ts-expect-error - \"invalid\" is not a valid intent
    <Button intent=\"invalid\">Error</Button>
    ```¬∑
    ---¬∑
    ## Migration Patterns¬∑
    ### From styled-components to Panda CSS¬∑
    **Before (styled-components)**:
    ```typescript
    import styled from 'styled-components';¬∑
    const Button = styled.button`
      background-color: ${props => props.primary ? '#3b82f6' : '#8b5cf6'};
      color: white;
      padding: 8px 16px;
      border-radius: 6px;¬∑
      &:hover {
        background-color: ${props => props.primary ? '#2563eb' : '#7c3aed'};
      }
    `;¬∑
    // Runtime: Styles generated on mount (~2-5ms overhead per component)
    ```¬∑
    **After (Panda CSS)**:
    ```typescript
    import { css, cva } from '../styled-system/css';¬∑
    const button = cva({
      base: {
        color: 'white',
        px: 4,
        py: 2,
        rounded: 'md'
      },
      variants: {
        variant: {
          primary: { bg: 'blue.500', _hover: { bg: 'blue.600' } },
          secondary: { bg: 'purple.500', _hover: { bg: 'purple.600' } }
        }
      }
    });¬∑
    function Button({ variant = 'primary', children }) {
      return <button className={button({ variant })}>{children}</button>;
    }¬∑
    // Zero runtime: All styles extracted at build time
    ```¬∑
    **100% runtime overhead eliminated** (0ms vs 2-5ms per component)¬∑
    ### From Emotion to Vanilla Extract¬∑
    **Before (Emotion)**:
    ```typescript
    import { css } from '@emotion/react';¬∑
    function Card() {
      return (
        <div css={css`
          background-color: white;
          padding: 16px;
          border-radius: 8px;
          box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        `}>
          Content
        </div>
      );
    }
    ```¬∑
    **After (Vanilla Extract)**:
    ```typescript
    // card.css.ts
    import { style } from '@vanilla-extract/css';¬∑
    export const card = style({
      backgroundColor: 'white',
      padding: '16px',
      borderRadius: '8px',
      boxShadow: '0 2px 4px rgba(0,0,0,0.1)'
    });¬∑
    // Card.tsx
    import * as styles from './card.css';¬∑
    export function Card() {
      return <div className={styles.card}>Content</div>;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Zero-Runtime CSS¬∑
    ```typescript
    // ‚úÖ Good - Zero runtime (Panda CSS)
    import { css } from '../styled-system/css';¬∑
    const button = css({ bg: 'blue.500', px: 4, py: 2 });¬∑
    // Compiled to static CSS at build time:
    // .css-button { background: #3b82f6; padding-left: 1rem; padding-right: 1rem; }
    ```¬∑
    ```typescript
    // ‚ùå Bad - Runtime overhead (styled-components)
    import styled from 'styled-components';¬∑
    const Button = styled.button`
      background: #3b82f6;
      padding: 1rem;
    `;¬∑
    // Styles generated on mount (~2-5ms overhead + CSS injection)
    ```¬∑
    ### 2. Atomic CSS¬∑
    ```typescript
    // Panda CSS automatically generates atomic classes
    import { css } from '../styled-system/css';¬∑
    const card1 = css({ bg: 'white', p: 4, rounded: 'md' });
    const card2 = css({ bg: 'white', p: 4, rounded: 'lg' });¬∑
    // Compiled to:
    // .bg-white { background: white; }
    // .p-4 { padding: 1rem; }
    // .rounded-md { border-radius: 0.375rem; }
    // .rounded-lg { border-radius: 0.5rem; }¬∑
    // CSS reused across components ‚Üí smaller bundle size
    ```¬∑
    ### 3. Tree-Shaking¬∑
    ```typescript
    // Only import what you use
    import { css } from '../styled-system/css';
    import { hstack } from '../styled-system/patterns';¬∑
    // Unused patterns/recipes automatically tree-shaken
    // Final bundle only includes css() and hstack()
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migrate-to-panda.js` - styled-components ‚Üí Panda CSS migration script
    - `generate-design-tokens.js` - Figma ‚Üí Panda tokens script¬∑
    ### references/
    - `references/panda-patterns.md` - Recipes, patterns, responsive design
    - `references/vanilla-extract-patterns.md` - Themes, sprinkles, style variants
    - `references/cva-patterns.md` - Component variants, compound variants
    - `references/zero-runtime-migration.md` - styled-components/Emotion ‚Üí Panda/Vanilla Extract¬∑
    ### assets/
    - `assets/design-tokens/` - Theme token examples
    - `assets/component-variants/` - CVA variant templates¬∑
    ## Related Skills¬∑
    - `design-tokens` - Design token automation with Figma sync
    - `component-patterns` - Component composition and API design
    - `performance-optimization` - CSS bundle size optimization
    - `testing-strategies` - Visual regression testing for styles
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ testing-strategies ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: testing-strategies
    description: Modern testing strategies using Vitest (5-20x faster than Jest), Playwright (E2E with auto-wait), and MSW (API mocking). Use when implementing unit tests, integration tests, E2E tests, or API mocking. Achieves 80%+ code coverage with minimal test maintenance. Enforces quality gates before deployment.
    ---¬∑
    # Testing Strategies¬∑
    ## Overview¬∑
    Comprehensive testing strategies covering unit tests (Vitest), end-to-end tests (Playwright), and API mocking (MSW). Provides fast feedback loops, reliable tests, and high code coverage with minimal maintenance overhead.¬∑
    **Goal**: 80%+ code coverage with fast, reliable, maintainable tests¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Setting up testing infrastructure (Vitest, Playwright, MSW)
    - Writing unit tests for components and utilities
    - Implementing E2E tests for critical user flows
    - Mocking API calls for reliable tests
    - Debugging flaky tests
    - Optimizing test performance
    - Setting up CI/CD quality gates
    - Migrating from Jest to Vitest¬∑
    **Triggers**: \"testing\", \"test coverage\", \"Vitest\", \"Playwright\", \"E2E tests\", \"API mocking\", \"MSW\", \"test flakiness\"¬∑
    ---¬∑
    ## Quick Start: Testing Framework Decision Tree¬∑
    ### When to Use Vitest vs Jest vs Playwright vs Cypress¬∑
    **Vitest** (Unit/Integration Testing):
    - ‚úÖ 5-20x faster than Jest (native ESM, Vite-powered)
    - ‚úÖ Compatible with Jest API (easy migration)
    - ‚úÖ Built-in TypeScript support
    - ‚úÖ Watch mode with HMR-like speed
    - ‚úÖ Native code coverage (c8/v8)
    - ‚úÖ Best for: New projects, Vite/React/Vue apps, unit/integration tests¬∑
    **Jest** (Unit/Integration Testing):
    - ‚úÖ Industry standard (mature ecosystem)
    - ‚úÖ Extensive plugin ecosystem
    - ‚úÖ Works with any bundler
    - ‚úÖ Snapshot testing
    - ‚úÖ Best for: Existing Jest projects, non-Vite projects, when ecosystem matters¬∑
    **Playwright** (E2E Testing):
    - ‚úÖ Auto-wait (no manual waits needed)
    - ‚úÖ Multi-browser (Chromium, Firefox, WebKit)
    - ‚úÖ Network interception
    - ‚úÖ Parallel execution
    - ‚úÖ Video/screenshot on failure
    - ‚úÖ Best for: E2E tests, cross-browser testing, reliable automation¬∑
    **Cypress** (E2E Testing):
    - ‚úÖ Developer-friendly API
    - ‚úÖ Time-travel debugging
    - ‚úÖ Real-time reloads
    - ‚úÖ Built-in retries
    - ‚úÖ Best for: Developer experience, visual testing, debugging¬∑
    **MSW (API Mocking)**:
    - ‚úÖ Service Worker-based (no axios/fetch mocking)
    - ‚úÖ Works in browser and Node.js
    - ‚úÖ Network-level interception
    - ‚úÖ Reusable across unit/integration/E2E tests
    - ‚úÖ Best for: API mocking, consistent test data, offline development¬∑
    ---¬∑
    ## Vitest Patterns (Unit/Integration Tests)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // vitest.config.ts
    import { defineConfig } from 'vitest/config';
    import react from '@vitejs/plugin-react';¬∑
    export default defineConfig({
      plugins: [react()],
      test: {
        globals: true, // Use global test functions (describe, it, expect)
        environment: 'jsdom', // Simulate browser environment
        setupFiles: './src/test/setup.ts',
        coverage: {
          provider: 'v8',
          reporter: ['text', 'json', 'html'],
          exclude: [
            'node_modules/',
            'src/test/',
            '**/*.d.ts',
            '**/*.config.*',
            '**/mockData/*'
          ]
        }
      }
    });
    ```¬∑
    ```typescript
    // src/test/setup.ts
    import { expect, afterEach } from 'vitest';
    import { cleanup } from '@testing-library/react';
    import * as matchers from '@testing-library/jest-dom/matchers';¬∑
    // Extend Vitest's expect with jest-dom matchers
    expect.extend(matchers);¬∑
    // Cleanup after each test
    afterEach(() => {
      cleanup();
    });
    ```¬∑
    ### 2. Component Testing (React)¬∑
    ```typescript
    // Button.test.tsx
    import { render, screen, fireEvent } from '@testing-library/react';
    import { describe, it, expect, vi } from 'vitest';
    import Button from './Button';¬∑
    describe('Button', () => {
      it('renders with text', () => {
        render(<Button>Click me</Button>);
        expect(screen.getByText('Click me')).toBeInTheDocument();
      });¬∑
      it('calls onClick when clicked', () => {
        const handleClick = vi.fn();
        render(<Button onClick={handleClick}>Click me</Button>);¬∑
        fireEvent.click(screen.getByText('Click me'));¬∑
        expect(handleClick).toHaveBeenCalledTimes(1);
      });¬∑
      it('applies correct variant styles', () => {
        const { container } = render(<Button variant=\"primary\">Primary</Button>);
        const button = container.querySelector('button');¬∑
        expect(button).toHaveClass('btn-primary');
      });¬∑
      it('disables button when disabled prop is true', () => {
        render(<Button disabled>Disabled</Button>);
        const button = screen.getByRole('button');¬∑
        expect(button).toBeDisabled();
      });
    });
    ```¬∑
    ### 3. Async Testing¬∑
    ```typescript
    // UserProfile.test.tsx
    import { render, screen, waitFor } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import UserProfile from './UserProfile';¬∑
    describe('UserProfile', () => {
      it('loads and displays user data', async () => {
        render(<UserProfile userId=\"123\" />);¬∑
        // Initially shows loading state
        expect(screen.getByText('Loading...')).toBeInTheDocument();¬∑
        // Wait for data to load
        await waitFor(() => {
          expect(screen.getByText('John Doe')).toBeInTheDocument();
        });¬∑
        // Verify all data is displayed
        expect(screen.getByText('john@example.com')).toBeInTheDocument();
      });¬∑
      it('shows error message on fetch failure', async () => {
        // Mock failed API call
        global.fetch = vi.fn(() =>
          Promise.reject(new Error('Failed to fetch'))
        );¬∑
        render(<UserProfile userId=\"123\" />);¬∑
        await waitFor(() => {
          expect(screen.getByText(/error/i)).toBeInTheDocument();
        });
      });
    });
    ```¬∑
    ### 4. Mocking (Spies, Stubs, Mocks)¬∑
    ```typescript
    import { vi, describe, it, expect, beforeEach } from 'vitest';¬∑
    // Mock entire module
    vi.mock('./api', () => ({
      fetchUser: vi.fn(() => Promise.resolve({ id: 1, name: 'John' })),
      createUser: vi.fn()
    }));¬∑
    // Mock specific functions
    describe('UserService', () => {
      beforeEach(() => {
        vi.clearAllMocks(); // Reset mocks before each test
      });¬∑
      it('fetches user data', async () => {
        const { fetchUser } = await import('./api');¬∑
        const user = await fetchUser('123');¬∑
        expect(fetchUser).toHaveBeenCalledWith('123');
        expect(user).toEqual({ id: 1, name: 'John' });
      });¬∑
      it('handles API errors', async () => {
        const { fetchUser } = await import('./api');
        fetchUser.mockRejectedValueOnce(new Error('Network error'));¬∑
        await expect(fetchUser('123')).rejects.toThrow('Network error');
      });
    });¬∑
    // Spy on existing function
    describe('Analytics', () => {
      it('tracks page views', () => {
        const trackSpy = vi.spyOn(analytics, 'track');¬∑
        analytics.pageView('/home');¬∑
        expect(trackSpy).toHaveBeenCalledWith('pageview', { path: '/home' });¬∑
        trackSpy.mockRestore(); // Restore original implementation
      });
    });
    ```¬∑
    ### 5. Snapshot Testing¬∑
    ```typescript
    import { render } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import Card from './Card';¬∑
    describe('Card snapshots', () => {
      it('matches snapshot for default variant', () => {
        const { container } = render(
          <Card title=\"Test Card\" description=\"Test description\" />
        );¬∑
        expect(container.firstChild).toMatchSnapshot();
      });¬∑
      it('matches inline snapshot for primary variant', () => {
        const { container } = render(
          <Card variant=\"primary\" title=\"Primary Card\" />
        );¬∑
        expect(container.firstChild).toMatchInlineSnapshot(`
          <div class=\"card card-primary\">
            <h3 class=\"card-title\">Primary Card</h3>
          </div>
        `);
      });
    });
    ```¬∑
    ---¬∑
    ## Playwright Patterns (E2E Tests)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // playwright.config.ts
    import { defineConfig, devices } from '@playwright/test';¬∑
    export default defineConfig({
      testDir: './e2e',
      fullyParallel: true,
      forbidOnly: !!process.env.CI,
      retries: process.env.CI ? 2 : 0,
      workers: process.env.CI ? 1 : undefined,
      reporter: 'html',
      use: {
        baseURL: 'http://localhost:3000',
        trace: 'on-first-retry', // Collect trace on retry
        screenshot: 'only-on-failure'
      },
      projects: [
        {
          name: 'chromium',
          use: { ...devices['Desktop Chrome'] }
        },
        {
          name: 'firefox',
          use: { ...devices['Desktop Firefox'] }
        },
        {
          name: 'webkit',
          use: { ...devices['Desktop Safari'] }
        },
        {
          name: 'Mobile Chrome',
          use: { ...devices['Pixel 5'] }
        }
      ],
      webServer: {
        command: 'npm run dev',
        url: 'http://localhost:3000',
        reuseExistingServer: !process.env.CI
      }
    });
    ```¬∑
    ### 2. Basic E2E Test¬∑
    ```typescript
    // e2e/auth.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    test.describe('Authentication', () => {
      test('user can login', async ({ page }) => {
        // Navigate to login page
        await page.goto('/login');¬∑
        // Fill form (auto-waits for elements)
        await page.fill('[name=\"email\"]', 'user@example.com');
        await page.fill('[name=\"password\"]', 'password123');¬∑
        // Click button
        await page.click('button[type=\"submit\"]');¬∑
        // Assert redirect to dashboard (auto-waits for navigation)
        await expect(page).toHaveURL('/dashboard');¬∑
        // Assert user is logged in
        await expect(page.locator('text=Welcome back')).toBeVisible();
      });¬∑
      test('shows error for invalid credentials', async ({ page }) => {
        await page.goto('/login');¬∑
        await page.fill('[name=\"email\"]', 'wrong@example.com');
        await page.fill('[name=\"password\"]', 'wrongpass');
        await page.click('button[type=\"submit\"]');¬∑
        // Assert error message appears
        await expect(page.locator('text=Invalid credentials')).toBeVisible();¬∑
        // Assert stays on login page
        await expect(page).toHaveURL('/login');
      });
    });
    ```¬∑
    ### 3. Page Object Model (POM)¬∑
    ```typescript
    // e2e/pages/LoginPage.ts
    import { Page, Locator } from '@playwright/test';¬∑
    export class LoginPage {
      readonly page: Page;
      readonly emailInput: Locator;
      readonly passwordInput: Locator;
      readonly submitButton: Locator;
      readonly errorMessage: Locator;¬∑
      constructor(page: Page) {
        this.page = page;
        this.emailInput = page.locator('[name=\"email\"]');
        this.passwordInput = page.locator('[name=\"password\"]');
        this.submitButton = page.locator('button[type=\"submit\"]');
        this.errorMessage = page.locator('.error-message');
      }¬∑
      async goto() {
        await this.page.goto('/login');
      }¬∑
      async login(email: string, password: string) {
        await this.emailInput.fill(email);
        await this.passwordInput.fill(password);
        await this.submitButton.click();
      }
    }¬∑
    // Usage in test
    import { test, expect } from '@playwright/test';
    import { LoginPage } from './pages/LoginPage';¬∑
    test('login with POM', async ({ page }) => {
      const loginPage = new LoginPage(page);¬∑
      await loginPage.goto();
      await loginPage.login('user@example.com', 'password123');¬∑
      await expect(page).toHaveURL('/dashboard');
    });
    ```¬∑
    ### 4. API Mocking with Playwright¬∑
    ```typescript
    // e2e/api-mocking.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    test('mocks API response', async ({ page }) => {
      // Intercept API call and return mock data
      await page.route('**/api/users', (route) => {
        route.fulfill({
          status: 200,
          contentType: 'application/json',
          body: JSON.stringify([
            { id: 1, name: 'John Doe', email: 'john@example.com' },
            { id: 2, name: 'Jane Smith', email: 'jane@example.com' }
          ])
        });
      });¬∑
      await page.goto('/users');¬∑
      // Verify mock data is displayed
      await expect(page.locator('text=John Doe')).toBeVisible();
      await expect(page.locator('text=Jane Smith')).toBeVisible();
    });¬∑
    test('simulates API error', async ({ page }) => {
      await page.route('**/api/users', (route) => {
        route.fulfill({
          status: 500,
          contentType: 'application/json',
          body: JSON.stringify({ error: 'Internal Server Error' })
        });
      });¬∑
      await page.goto('/users');¬∑
      await expect(page.locator('text=Failed to load users')).toBeVisible();
    });
    ```¬∑
    ### 5. Authentication State Management¬∑
    ```typescript
    // e2e/auth.setup.ts
    import { test as setup } from '@playwright/test';¬∑
    const authFile = 'playwright/.auth/user.json';¬∑
    setup('authenticate', async ({ page }) => {
      await page.goto('/login');
      await page.fill('[name=\"email\"]', 'user@example.com');
      await page.fill('[name=\"password\"]', 'password123');
      await page.click('button[type=\"submit\"]');¬∑
      await page.waitForURL('/dashboard');¬∑
      // Save auth state to file
      await page.context().storageState({ path: authFile });
    });¬∑
    // e2e/dashboard.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    // Reuse authenticated state
    test.use({ storageState: 'playwright/.auth/user.json' });¬∑
    test('view dashboard as logged in user', async ({ page }) => {
      await page.goto('/dashboard');¬∑
      // Already authenticated, no login required
      await expect(page.locator('text=Welcome back')).toBeVisible();
    });
    ```¬∑
    ---¬∑
    ## MSW Patterns (API Mocking)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // src/mocks/handlers.ts
    import { http, HttpResponse } from 'msw';¬∑
    export const handlers = [
      // GET request
      http.get('/api/users', () => {
        return HttpResponse.json([
          { id: 1, name: 'John Doe', email: 'john@example.com' },
          { id: 2, name: 'Jane Smith', email: 'jane@example.com' }
        ]);
      }),¬∑
      // POST request
      http.post('/api/users', async ({ request }) => {
        const newUser = await request.json();¬∑
        return HttpResponse.json(
          { id: 3, ...newUser },
          { status: 201 }
        );
      }),¬∑
      // Dynamic route params
      http.get('/api/users/:id', ({ params }) => {
        const { id } = params;¬∑
        return HttpResponse.json({
          id: Number(id),
          name: 'John Doe',
          email: 'john@example.com'
        });
      }),¬∑
      // Simulate error
      http.get('/api/error', () => {
        return HttpResponse.json(
          { error: 'Internal Server Error' },
          { status: 500 }
        );
      })
    ];
    ```¬∑
    ```typescript
    // src/mocks/server.ts (for Node.js/Vitest)
    import { setupServer } from 'msw/node';
    import { handlers } from './handlers';¬∑
    export const server = setupServer(...handlers);
    ```¬∑
    ```typescript
    // src/mocks/browser.ts (for browser/Playwright)
    import { setupWorker } from 'msw/browser';
    import { handlers } from './handlers';¬∑
    export const worker = setupWorker(...handlers);
    ```¬∑
    ### 2. Integration with Vitest¬∑
    ```typescript
    // src/test/setup.ts
    import { beforeAll, afterEach, afterAll } from 'vitest';
    import { server } from '../mocks/server';¬∑
    // Start server before all tests
    beforeAll(() => server.listen());¬∑
    // Reset handlers after each test
    afterEach(() => server.resetHandlers());¬∑
    // Stop server after all tests
    afterAll(() => server.close());
    ```¬∑
    ```typescript
    // UserList.test.tsx
    import { render, screen, waitFor } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import { server } from '../mocks/server';
    import { http, HttpResponse } from 'msw';
    import UserList from './UserList';¬∑
    describe('UserList', () => {
      it('displays users from API', async () => {
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText('John Doe')).toBeInTheDocument();
          expect(screen.getByText('Jane Smith')).toBeInTheDocument();
        });
      });¬∑
      it('handles empty list', async () => {
        // Override handler for this test
        server.use(
          http.get('/api/users', () => {
            return HttpResponse.json([]);
          })
        );¬∑
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText('No users found')).toBeInTheDocument();
        });
      });¬∑
      it('handles API error', async () => {
        server.use(
          http.get('/api/users', () => {
            return HttpResponse.json(
              { error: 'Failed to fetch' },
              { status: 500 }
            );
          })
        );¬∑
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText(/error/i)).toBeInTheDocument();
        });
      });
    });
    ```¬∑
    ### 3. Advanced Mocking Patterns¬∑
    ```typescript
    // Delay response (simulate slow network)
    http.get('/api/users', async () => {
      await delay(2000); // 2 second delay
      return HttpResponse.json([...]);
    });¬∑
    // Conditional responses
    http.get('/api/users', ({ request }) => {
      const url = new URL(request.url);
      const role = url.searchParams.get('role');¬∑
      if (role === 'admin') {
        return HttpResponse.json([{ id: 1, name: 'Admin User' }]);
      }¬∑
      return HttpResponse.json([{ id: 2, name: 'Regular User' }]);
    });¬∑
    // Stateful mocking
    let users = [
      { id: 1, name: 'John Doe' },
      { id: 2, name: 'Jane Smith' }
    ];¬∑
    http.get('/api/users', () => {
      return HttpResponse.json(users);
    });¬∑
    http.post('/api/users', async ({ request }) => {
      const newUser = await request.json();
      const user = { id: users.length + 1, ...newUser };
      users.push(user);
      return HttpResponse.json(user, { status: 201 });
    });¬∑
    http.delete('/api/users/:id', ({ params }) => {
      users = users.filter(u => u.id !== Number(params.id));
      return new HttpResponse(null, { status: 204 });
    });
    ```¬∑
    ---¬∑
    ## Test Coverage & Quality Gates¬∑
    ### 1. Coverage Configuration¬∑
    ```typescript
    // vitest.config.ts
    export default defineConfig({
      test: {
        coverage: {
          provider: 'v8',
          reporter: ['text', 'json', 'html', 'lcov'],
          include: ['src/**/*.{ts,tsx}'],
          exclude: [
            'node_modules/',
            'src/test/',
            '**/*.d.ts',
            '**/*.config.*',
            '**/*.test.{ts,tsx}',
            '**/mockData/*'
          ],
          thresholds: {
            lines: 80,
            functions: 80,
            branches: 80,
            statements: 80
          }
        }
      }
    });
    ```¬∑
    ### 2. CI/CD Quality Gates¬∑
    ```yaml
    # .github/workflows/test.yml
    name: Test¬∑
    on: [push, pull_request]¬∑
    jobs:
      test:
        runs-on: ubuntu-latest
        steps:
          - uses: actions/checkout@v3
          - uses: actions/setup-node@v3
            with:
              node-version: '18'¬∑
          - run: npm ci¬∑
          # Run unit tests with coverage
          - run: npm run test:coverage¬∑
          # Fail if coverage below threshold
          - name: Check coverage threshold
            run: |
              COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')
              if (( $(echo \"$COVERAGE < 80\" | bc -l) )); then
                echo \"Coverage $COVERAGE% is below 80% threshold\"
                exit 1
              fi¬∑
          # Run E2E tests
          - run: npx playwright install --with-deps
          - run: npm run test:e2e¬∑
          # Upload coverage report
          - uses: codecov/codecov-action@v3
            with:
              files: ./coverage/lcov.info
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Parallel Test Execution¬∑
    ```typescript
    // vitest.config.ts
    export default defineConfig({
      test: {
        // Run tests in parallel (default)
        threads: true,¬∑
        // Max number of threads
        maxThreads: 8,¬∑
        // Isolate test environment for each file
        isolate: true
      }
    });
    ```¬∑
    ```typescript
    // playwright.config.ts
    export default defineConfig({
      // Run tests in parallel
      fullyParallel: true,¬∑
      // Number of workers
      workers: process.env.CI ? 1 : undefined, // CI: 1, local: CPU cores¬∑
      // Timeout
      timeout: 30000
    });
    ```¬∑
    ### 2. Test Sharding (CI Optimization)¬∑
    ```yaml
    # .github/workflows/test.yml
    strategy:
      matrix:
        shard: [1, 2, 3, 4]
    steps:
      - run: npx playwright test --shard=${{ matrix.shard }}/4
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migrate-jest-to-vitest.js` - Automated Jest ‚Üí Vitest migration
    - `generate-test-stubs.js` - Generate test file boilerplate¬∑
    ### references/
    - `references/vitest-patterns.md` - Vitest API examples and best practices
    - `references/playwright-selectors.md` - Playwright selector strategies
    - `references/msw-patterns.md` - MSW handler patterns and recipes
    - `references/coverage-thresholds.md` - Industry-standard coverage targets¬∑
    ### assets/
    - `assets/test-templates/` - Test file templates (component, hook, utility)
    - `assets/ci-workflows/` - GitHub Actions/GitLab CI test workflows¬∑
    ## Related Skills¬∑
    - `component-patterns` - Component testing strategies
    - `api-design` - API contract testing
    - `performance-optimization` - Performance testing with Lighthouse CI
    - `accessibility-audit` - Accessibility testing with axe-core
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ testing-strategies ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: testing-strategies
    description: Modern testing strategies using Vitest (5-20x faster than Jest), Playwright (E2E with auto-wait), and MSW (API mocking). Use when implementing unit tests, integration tests, E2E tests, or API mocking. Achieves 80%+ code coverage with minimal test maintenance. Enforces quality gates before deployment.
    ---¬∑
    # Testing Strategies¬∑
    ## Overview¬∑
    Comprehensive testing strategies covering unit tests (Vitest), end-to-end tests (Playwright), and API mocking (MSW). Provides fast feedback loops, reliable tests, and high code coverage with minimal maintenance overhead.¬∑
    **Goal**: 80%+ code coverage with fast, reliable, maintainable tests¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Setting up testing infrastructure (Vitest, Playwright, MSW)
    - Writing unit tests for components and utilities
    - Implementing E2E tests for critical user flows
    - Mocking API calls for reliable tests
    - Debugging flaky tests
    - Optimizing test performance
    - Setting up CI/CD quality gates
    - Migrating from Jest to Vitest¬∑
    **Triggers**: \"testing\", \"test coverage\", \"Vitest\", \"Playwright\", \"E2E tests\", \"API mocking\", \"MSW\", \"test flakiness\"¬∑
    ---¬∑
    ## Quick Start: Testing Framework Decision Tree¬∑
    ### When to Use Vitest vs Jest vs Playwright vs Cypress¬∑
    **Vitest** (Unit/Integration Testing):
    - ‚úÖ 5-20x faster than Jest (native ESM, Vite-powered)
    - ‚úÖ Compatible with Jest API (easy migration)
    - ‚úÖ Built-in TypeScript support
    - ‚úÖ Watch mode with HMR-like speed
    - ‚úÖ Native code coverage (c8/v8)
    - ‚úÖ Best for: New projects, Vite/React/Vue apps, unit/integration tests¬∑
    **Jest** (Unit/Integration Testing):
    - ‚úÖ Industry standard (mature ecosystem)
    - ‚úÖ Extensive plugin ecosystem
    - ‚úÖ Works with any bundler
    - ‚úÖ Snapshot testing
    - ‚úÖ Best for: Existing Jest projects, non-Vite projects, when ecosystem matters¬∑
    **Playwright** (E2E Testing):
    - ‚úÖ Auto-wait (no manual waits needed)
    - ‚úÖ Multi-browser (Chromium, Firefox, WebKit)
    - ‚úÖ Network interception
    - ‚úÖ Parallel execution
    - ‚úÖ Video/screenshot on failure
    - ‚úÖ Best for: E2E tests, cross-browser testing, reliable automation¬∑
    **Cypress** (E2E Testing):
    - ‚úÖ Developer-friendly API
    - ‚úÖ Time-travel debugging
    - ‚úÖ Real-time reloads
    - ‚úÖ Built-in retries
    - ‚úÖ Best for: Developer experience, visual testing, debugging¬∑
    **MSW (API Mocking)**:
    - ‚úÖ Service Worker-based (no axios/fetch mocking)
    - ‚úÖ Works in browser and Node.js
    - ‚úÖ Network-level interception
    - ‚úÖ Reusable across unit/integration/E2E tests
    - ‚úÖ Best for: API mocking, consistent test data, offline development¬∑
    ---¬∑
    ## Vitest Patterns (Unit/Integration Tests)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // vitest.config.ts
    import { defineConfig } from 'vitest/config';
    import react from '@vitejs/plugin-react';¬∑
    export default defineConfig({
      plugins: [react()],
      test: {
        globals: true, // Use global test functions (describe, it, expect)
        environment: 'jsdom', // Simulate browser environment
        setupFiles: './src/test/setup.ts',
        coverage: {
          provider: 'v8',
          reporter: ['text', 'json', 'html'],
          exclude: [
            'node_modules/',
            'src/test/',
            '**/*.d.ts',
            '**/*.config.*',
            '**/mockData/*'
          ]
        }
      }
    });
    ```¬∑
    ```typescript
    // src/test/setup.ts
    import { expect, afterEach } from 'vitest';
    import { cleanup } from '@testing-library/react';
    import * as matchers from '@testing-library/jest-dom/matchers';¬∑
    // Extend Vitest's expect with jest-dom matchers
    expect.extend(matchers);¬∑
    // Cleanup after each test
    afterEach(() => {
      cleanup();
    });
    ```¬∑
    ### 2. Component Testing (React)¬∑
    ```typescript
    // Button.test.tsx
    import { render, screen, fireEvent } from '@testing-library/react';
    import { describe, it, expect, vi } from 'vitest';
    import Button from './Button';¬∑
    describe('Button', () => {
      it('renders with text', () => {
        render(<Button>Click me</Button>);
        expect(screen.getByText('Click me')).toBeInTheDocument();
      });¬∑
      it('calls onClick when clicked', () => {
        const handleClick = vi.fn();
        render(<Button onClick={handleClick}>Click me</Button>);¬∑
        fireEvent.click(screen.getByText('Click me'));¬∑
        expect(handleClick).toHaveBeenCalledTimes(1);
      });¬∑
      it('applies correct variant styles', () => {
        const { container } = render(<Button variant=\"primary\">Primary</Button>);
        const button = container.querySelector('button');¬∑
        expect(button).toHaveClass('btn-primary');
      });¬∑
      it('disables button when disabled prop is true', () => {
        render(<Button disabled>Disabled</Button>);
        const button = screen.getByRole('button');¬∑
        expect(button).toBeDisabled();
      });
    });
    ```¬∑
    ### 3. Async Testing¬∑
    ```typescript
    // UserProfile.test.tsx
    import { render, screen, waitFor } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import UserProfile from './UserProfile';¬∑
    describe('UserProfile', () => {
      it('loads and displays user data', async () => {
        render(<UserProfile userId=\"123\" />);¬∑
        // Initially shows loading state
        expect(screen.getByText('Loading...')).toBeInTheDocument();¬∑
        // Wait for data to load
        await waitFor(() => {
          expect(screen.getByText('John Doe')).toBeInTheDocument();
        });¬∑
        // Verify all data is displayed
        expect(screen.getByText('john@example.com')).toBeInTheDocument();
      });¬∑
      it('shows error message on fetch failure', async () => {
        // Mock failed API call
        global.fetch = vi.fn(() =>
          Promise.reject(new Error('Failed to fetch'))
        );¬∑
        render(<UserProfile userId=\"123\" />);¬∑
        await waitFor(() => {
          expect(screen.getByText(/error/i)).toBeInTheDocument();
        });
      });
    });
    ```¬∑
    ### 4. Mocking (Spies, Stubs, Mocks)¬∑
    ```typescript
    import { vi, describe, it, expect, beforeEach } from 'vitest';¬∑
    // Mock entire module
    vi.mock('./api', () => ({
      fetchUser: vi.fn(() => Promise.resolve({ id: 1, name: 'John' })),
      createUser: vi.fn()
    }));¬∑
    // Mock specific functions
    describe('UserService', () => {
      beforeEach(() => {
        vi.clearAllMocks(); // Reset mocks before each test
      });¬∑
      it('fetches user data', async () => {
        const { fetchUser } = await import('./api');¬∑
        const user = await fetchUser('123');¬∑
        expect(fetchUser).toHaveBeenCalledWith('123');
        expect(user).toEqual({ id: 1, name: 'John' });
      });¬∑
      it('handles API errors', async () => {
        const { fetchUser } = await import('./api');
        fetchUser.mockRejectedValueOnce(new Error('Network error'));¬∑
        await expect(fetchUser('123')).rejects.toThrow('Network error');
      });
    });¬∑
    // Spy on existing function
    describe('Analytics', () => {
      it('tracks page views', () => {
        const trackSpy = vi.spyOn(analytics, 'track');¬∑
        analytics.pageView('/home');¬∑
        expect(trackSpy).toHaveBeenCalledWith('pageview', { path: '/home' });¬∑
        trackSpy.mockRestore(); // Restore original implementation
      });
    });
    ```¬∑
    ### 5. Snapshot Testing¬∑
    ```typescript
    import { render } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import Card from './Card';¬∑
    describe('Card snapshots', () => {
      it('matches snapshot for default variant', () => {
        const { container } = render(
          <Card title=\"Test Card\" description=\"Test description\" />
        );¬∑
        expect(container.firstChild).toMatchSnapshot();
      });¬∑
      it('matches inline snapshot for primary variant', () => {
        const { container } = render(
          <Card variant=\"primary\" title=\"Primary Card\" />
        );¬∑
        expect(container.firstChild).toMatchInlineSnapshot(`
          <div class=\"card card-primary\">
            <h3 class=\"card-title\">Primary Card</h3>
          </div>
        `);
      });
    });
    ```¬∑
    ---¬∑
    ## Playwright Patterns (E2E Tests)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // playwright.config.ts
    import { defineConfig, devices } from '@playwright/test';¬∑
    export default defineConfig({
      testDir: './e2e',
      fullyParallel: true,
      forbidOnly: !!process.env.CI,
      retries: process.env.CI ? 2 : 0,
      workers: process.env.CI ? 1 : undefined,
      reporter: 'html',
      use: {
        baseURL: 'http://localhost:3000',
        trace: 'on-first-retry', // Collect trace on retry
        screenshot: 'only-on-failure'
      },
      projects: [
        {
          name: 'chromium',
          use: { ...devices['Desktop Chrome'] }
        },
        {
          name: 'firefox',
          use: { ...devices['Desktop Firefox'] }
        },
        {
          name: 'webkit',
          use: { ...devices['Desktop Safari'] }
        },
        {
          name: 'Mobile Chrome',
          use: { ...devices['Pixel 5'] }
        }
      ],
      webServer: {
        command: 'npm run dev',
        url: 'http://localhost:3000',
        reuseExistingServer: !process.env.CI
      }
    });
    ```¬∑
    ### 2. Basic E2E Test¬∑
    ```typescript
    // e2e/auth.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    test.describe('Authentication', () => {
      test('user can login', async ({ page }) => {
        // Navigate to login page
        await page.goto('/login');¬∑
        // Fill form (auto-waits for elements)
        await page.fill('[name=\"email\"]', 'user@example.com');
        await page.fill('[name=\"password\"]', 'password123');¬∑
        // Click button
        await page.click('button[type=\"submit\"]');¬∑
        // Assert redirect to dashboard (auto-waits for navigation)
        await expect(page).toHaveURL('/dashboard');¬∑
        // Assert user is logged in
        await expect(page.locator('text=Welcome back')).toBeVisible();
      });¬∑
      test('shows error for invalid credentials', async ({ page }) => {
        await page.goto('/login');¬∑
        await page.fill('[name=\"email\"]', 'wrong@example.com');
        await page.fill('[name=\"password\"]', 'wrongpass');
        await page.click('button[type=\"submit\"]');¬∑
        // Assert error message appears
        await expect(page.locator('text=Invalid credentials')).toBeVisible();¬∑
        // Assert stays on login page
        await expect(page).toHaveURL('/login');
      });
    });
    ```¬∑
    ### 3. Page Object Model (POM)¬∑
    ```typescript
    // e2e/pages/LoginPage.ts
    import { Page, Locator } from '@playwright/test';¬∑
    export class LoginPage {
      readonly page: Page;
      readonly emailInput: Locator;
      readonly passwordInput: Locator;
      readonly submitButton: Locator;
      readonly errorMessage: Locator;¬∑
      constructor(page: Page) {
        this.page = page;
        this.emailInput = page.locator('[name=\"email\"]');
        this.passwordInput = page.locator('[name=\"password\"]');
        this.submitButton = page.locator('button[type=\"submit\"]');
        this.errorMessage = page.locator('.error-message');
      }¬∑
      async goto() {
        await this.page.goto('/login');
      }¬∑
      async login(email: string, password: string) {
        await this.emailInput.fill(email);
        await this.passwordInput.fill(password);
        await this.submitButton.click();
      }
    }¬∑
    // Usage in test
    import { test, expect } from '@playwright/test';
    import { LoginPage } from './pages/LoginPage';¬∑
    test('login with POM', async ({ page }) => {
      const loginPage = new LoginPage(page);¬∑
      await loginPage.goto();
      await loginPage.login('user@example.com', 'password123');¬∑
      await expect(page).toHaveURL('/dashboard');
    });
    ```¬∑
    ### 4. API Mocking with Playwright¬∑
    ```typescript
    // e2e/api-mocking.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    test('mocks API response', async ({ page }) => {
      // Intercept API call and return mock data
      await page.route('**/api/users', (route) => {
        route.fulfill({
          status: 200,
          contentType: 'application/json',
          body: JSON.stringify([
            { id: 1, name: 'John Doe', email: 'john@example.com' },
            { id: 2, name: 'Jane Smith', email: 'jane@example.com' }
          ])
        });
      });¬∑
      await page.goto('/users');¬∑
      // Verify mock data is displayed
      await expect(page.locator('text=John Doe')).toBeVisible();
      await expect(page.locator('text=Jane Smith')).toBeVisible();
    });¬∑
    test('simulates API error', async ({ page }) => {
      await page.route('**/api/users', (route) => {
        route.fulfill({
          status: 500,
          contentType: 'application/json',
          body: JSON.stringify({ error: 'Internal Server Error' })
        });
      });¬∑
      await page.goto('/users');¬∑
      await expect(page.locator('text=Failed to load users')).toBeVisible();
    });
    ```¬∑
    ### 5. Authentication State Management¬∑
    ```typescript
    // e2e/auth.setup.ts
    import { test as setup } from '@playwright/test';¬∑
    const authFile = 'playwright/.auth/user.json';¬∑
    setup('authenticate', async ({ page }) => {
      await page.goto('/login');
      await page.fill('[name=\"email\"]', 'user@example.com');
      await page.fill('[name=\"password\"]', 'password123');
      await page.click('button[type=\"submit\"]');¬∑
      await page.waitForURL('/dashboard');¬∑
      // Save auth state to file
      await page.context().storageState({ path: authFile });
    });¬∑
    // e2e/dashboard.spec.ts
    import { test, expect } from '@playwright/test';¬∑
    // Reuse authenticated state
    test.use({ storageState: 'playwright/.auth/user.json' });¬∑
    test('view dashboard as logged in user', async ({ page }) => {
      await page.goto('/dashboard');¬∑
      // Already authenticated, no login required
      await expect(page.locator('text=Welcome back')).toBeVisible();
    });
    ```¬∑
    ---¬∑
    ## MSW Patterns (API Mocking)¬∑
    ### 1. Basic Setup¬∑
    ```typescript
    // src/mocks/handlers.ts
    import { http, HttpResponse } from 'msw';¬∑
    export const handlers = [
      // GET request
      http.get('/api/users', () => {
        return HttpResponse.json([
          { id: 1, name: 'John Doe', email: 'john@example.com' },
          { id: 2, name: 'Jane Smith', email: 'jane@example.com' }
        ]);
      }),¬∑
      // POST request
      http.post('/api/users', async ({ request }) => {
        const newUser = await request.json();¬∑
        return HttpResponse.json(
          { id: 3, ...newUser },
          { status: 201 }
        );
      }),¬∑
      // Dynamic route params
      http.get('/api/users/:id', ({ params }) => {
        const { id } = params;¬∑
        return HttpResponse.json({
          id: Number(id),
          name: 'John Doe',
          email: 'john@example.com'
        });
      }),¬∑
      // Simulate error
      http.get('/api/error', () => {
        return HttpResponse.json(
          { error: 'Internal Server Error' },
          { status: 500 }
        );
      })
    ];
    ```¬∑
    ```typescript
    // src/mocks/server.ts (for Node.js/Vitest)
    import { setupServer } from 'msw/node';
    import { handlers } from './handlers';¬∑
    export const server = setupServer(...handlers);
    ```¬∑
    ```typescript
    // src/mocks/browser.ts (for browser/Playwright)
    import { setupWorker } from 'msw/browser';
    import { handlers } from './handlers';¬∑
    export const worker = setupWorker(...handlers);
    ```¬∑
    ### 2. Integration with Vitest¬∑
    ```typescript
    // src/test/setup.ts
    import { beforeAll, afterEach, afterAll } from 'vitest';
    import { server } from '../mocks/server';¬∑
    // Start server before all tests
    beforeAll(() => server.listen());¬∑
    // Reset handlers after each test
    afterEach(() => server.resetHandlers());¬∑
    // Stop server after all tests
    afterAll(() => server.close());
    ```¬∑
    ```typescript
    // UserList.test.tsx
    import { render, screen, waitFor } from '@testing-library/react';
    import { describe, it, expect } from 'vitest';
    import { server } from '../mocks/server';
    import { http, HttpResponse } from 'msw';
    import UserList from './UserList';¬∑
    describe('UserList', () => {
      it('displays users from API', async () => {
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText('John Doe')).toBeInTheDocument();
          expect(screen.getByText('Jane Smith')).toBeInTheDocument();
        });
      });¬∑
      it('handles empty list', async () => {
        // Override handler for this test
        server.use(
          http.get('/api/users', () => {
            return HttpResponse.json([]);
          })
        );¬∑
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText('No users found')).toBeInTheDocument();
        });
      });¬∑
      it('handles API error', async () => {
        server.use(
          http.get('/api/users', () => {
            return HttpResponse.json(
              { error: 'Failed to fetch' },
              { status: 500 }
            );
          })
        );¬∑
        render(<UserList />);¬∑
        await waitFor(() => {
          expect(screen.getByText(/error/i)).toBeInTheDocument();
        });
      });
    });
    ```¬∑
    ### 3. Advanced Mocking Patterns¬∑
    ```typescript
    // Delay response (simulate slow network)
    http.get('/api/users', async () => {
      await delay(2000); // 2 second delay
      return HttpResponse.json([...]);
    });¬∑
    // Conditional responses
    http.get('/api/users', ({ request }) => {
      const url = new URL(request.url);
      const role = url.searchParams.get('role');¬∑
      if (role === 'admin') {
        return HttpResponse.json([{ id: 1, name: 'Admin User' }]);
      }¬∑
      return HttpResponse.json([{ id: 2, name: 'Regular User' }]);
    });¬∑
    // Stateful mocking
    let users = [
      { id: 1, name: 'John Doe' },
      { id: 2, name: 'Jane Smith' }
    ];¬∑
    http.get('/api/users', () => {
      return HttpResponse.json(users);
    });¬∑
    http.post('/api/users', async ({ request }) => {
      const newUser = await request.json();
      const user = { id: users.length + 1, ...newUser };
      users.push(user);
      return HttpResponse.json(user, { status: 201 });
    });¬∑
    http.delete('/api/users/:id', ({ params }) => {
      users = users.filter(u => u.id !== Number(params.id));
      return new HttpResponse(null, { status: 204 });
    });
    ```¬∑
    ---¬∑
    ## Test Coverage & Quality Gates¬∑
    ### 1. Coverage Configuration¬∑
    ```typescript
    // vitest.config.ts
    export default defineConfig({
      test: {
        coverage: {
          provider: 'v8',
          reporter: ['text', 'json', 'html', 'lcov'],
          include: ['src/**/*.{ts,tsx}'],
          exclude: [
            'node_modules/',
            'src/test/',
            '**/*.d.ts',
            '**/*.config.*',
            '**/*.test.{ts,tsx}',
            '**/mockData/*'
          ],
          thresholds: {
            lines: 80,
            functions: 80,
            branches: 80,
            statements: 80
          }
        }
      }
    });
    ```¬∑
    ### 2. CI/CD Quality Gates¬∑
    ```yaml
    # .github/workflows/test.yml
    name: Test¬∑
    on: [push, pull_request]¬∑
    jobs:
      test:
        runs-on: ubuntu-latest
        steps:
          - uses: actions/checkout@v3
          - uses: actions/setup-node@v3
            with:
              node-version: '18'¬∑
          - run: npm ci¬∑
          # Run unit tests with coverage
          - run: npm run test:coverage¬∑
          # Fail if coverage below threshold
          - name: Check coverage threshold
            run: |
              COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')
              if (( $(echo \"$COVERAGE < 80\" | bc -l) )); then
                echo \"Coverage $COVERAGE% is below 80% threshold\"
                exit 1
              fi¬∑
          # Run E2E tests
          - run: npx playwright install --with-deps
          - run: npm run test:e2e¬∑
          # Upload coverage report
          - uses: codecov/codecov-action@v3
            with:
              files: ./coverage/lcov.info
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Parallel Test Execution¬∑
    ```typescript
    // vitest.config.ts
    export default defineConfig({
      test: {
        // Run tests in parallel (default)
        threads: true,¬∑
        // Max number of threads
        maxThreads: 8,¬∑
        // Isolate test environment for each file
        isolate: true
      }
    });
    ```¬∑
    ```typescript
    // playwright.config.ts
    export default defineConfig({
      // Run tests in parallel
      fullyParallel: true,¬∑
      // Number of workers
      workers: process.env.CI ? 1 : undefined, // CI: 1, local: CPU cores¬∑
      // Timeout
      timeout: 30000
    });
    ```¬∑
    ### 2. Test Sharding (CI Optimization)¬∑
    ```yaml
    # .github/workflows/test.yml
    strategy:
      matrix:
        shard: [1, 2, 3, 4]
    steps:
      - run: npx playwright test --shard=${{ matrix.shard }}/4
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `migrate-jest-to-vitest.js` - Automated Jest ‚Üí Vitest migration
    - `generate-test-stubs.js` - Generate test file boilerplate¬∑
    ### references/
    - `references/vitest-patterns.md` - Vitest API examples and best practices
    - `references/playwright-selectors.md` - Playwright selector strategies
    - `references/msw-patterns.md` - MSW handler patterns and recipes
    - `references/coverage-thresholds.md` - Industry-standard coverage targets¬∑
    ### assets/
    - `assets/test-templates/` - Test file templates (component, hook, utility)
    - `assets/ci-workflows/` - GitHub Actions/GitLab CI test workflows¬∑
    ## Related Skills¬∑
    - `component-patterns` - Component testing strategies
    - `api-design` - API contract testing
    - `performance-optimization` - Performance testing with Lighthouse CI
    - `accessibility-audit` - Accessibility testing with axe-core
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ micro-frontends ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: micro-frontends
    description: Micro-frontend architecture using Module Federation (Webpack/Rspack) and single-spa. Use when building large-scale applications with independent teams, enabling independent deployments and technology flexibility. Reduces deployment coupling and enables team autonomy.
    ---¬∑
    # Micro-Frontends¬∑
    ## Overview¬∑
    Micro-frontend architecture patterns using Module Federation and single-spa for building large-scale applications with independent teams. Enables independent deployments, technology flexibility, and team autonomy while maintaining a cohesive user experience.¬∑
    **Goal**: Independent frontend deployments with shared runtime integration¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Large teams need independent deployments
    - Multiple framework versions needed (React 17 + React 18)
    - Gradual migration from legacy code
    - Team autonomy required
    - Independent feature development
    - Shared component libraries across apps
    - Different release cycles per team¬∑
    **Triggers**: \"micro-frontends\", \"Module Federation\", \"single-spa\", \"independent deployments\", \"monorepo alternatives\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Module Federation vs single-spa vs Monorepo¬∑
    **Module Federation** (Runtime Integration):
    - ‚úÖ Share code at runtime (no duplication)
    - ‚úÖ Independent deployments
    - ‚úÖ Version compatibility (load multiple React versions)
    - ‚úÖ Dynamic imports (load on demand)
    - ‚úÖ Best for: Webpack/Rspack apps, shared libraries, independent teams¬∑
    **single-spa** (Framework-Agnostic):
    - ‚úÖ Mix frameworks (React + Vue + Angular)
    - ‚úÖ Gradual migration
    - ‚úÖ Lifecycle management
    - ‚úÖ Framework independence
    - ‚úÖ Best for: Legacy migration, polyglot frontends¬∑
    **Monorepo** (Build-Time Integration):
    - ‚úÖ Shared TypeScript types
    - ‚úÖ Atomic commits across apps
    - ‚úÖ Easier refactoring
    - ‚úÖ Coordinated releases
    - ‚úÖ Best for: Single team, coordinated releases¬∑
    ---¬∑
    ## Module Federation Patterns¬∑
    ### 1. Basic Setup (Host + Remote)¬∑
    ```javascript
    // Remote app (products): webpack.config.js
    const { ModuleFederationPlugin } = require('webpack').container;¬∑
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'products',
          filename: 'remoteEntry.js',
          exposes: {
            './ProductList': './src/components/ProductList',
            './ProductDetail': './src/components/ProductDetail'
          },
          shared: {
            react: { singleton: true, requiredVersion: '^18.0.0' },
            'react-dom': { singleton: true, requiredVersion: '^18.0.0' }
          }
        })
      ]
    };¬∑
    // Host app (shell): webpack.config.js
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'shell',
          remotes: {
            products: 'products@http://localhost:3001/remoteEntry.js'
          },
          shared: {
            react: { singleton: true, requiredVersion: '^18.0.0' },
            'react-dom': { singleton: true, requiredVersion: '^18.0.0' }
          }
        })
      ]
    };¬∑
    // Host app: Use remote component
    import React, { lazy, Suspense } from 'react';¬∑
    const ProductList = lazy(() => import('products/ProductList'));¬∑
    function App() {
      return (
        <Suspense fallback={<div>Loading...</div>}>
          <ProductList />
        </Suspense>
      );
    }
    ```¬∑
    ### 2. Dynamic Remote Loading¬∑
    ```typescript
    // Load remote at runtime (URL from environment/API)
    async function loadRemote(url: string, module: string) {
      await __webpack_init_sharing__('default');¬∑
      const container = await import(/* webpackIgnore: true */ url);
      await container.init(__webpack_share_scopes__.default);¬∑
      const factory = await container.get(module);
      return factory();
    }¬∑
    // Usage: Load remote dynamically
    const ProductList = await loadRemote(
      'http://cdn.example.com/products/remoteEntry.js',
      './ProductList'
    );
    ```¬∑
    ### 3. Shared State Management¬∑
    ```typescript
    // Shared store in host
    // Host: Expose shared store
    const { ModuleFederationPlugin } = require('webpack').container;¬∑
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'shell',
          exposes: {
            './store': './src/store'
          },
          shared: {
            zustand: { singleton: true }
          }
        })
      ]
    };¬∑
    // Remote: Import shared store
    import { useStore } from 'shell/store';¬∑
    function ProductList() {
      const user = useStore(state => state.user);
      return <div>Welcome {user.name}</div>;
    }
    ```¬∑
    ---¬∑
    ## single-spa Patterns¬∑
    ### 1. Root Config¬∑
    ```typescript
    // root-config.ts
    import { registerApplication, start } from 'single-spa';¬∑
    // Register micro-frontends
    registerApplication({
      name: '@org/navbar',
      app: () => import('@org/navbar'),
      activeWhen: '/' // Always active
    });¬∑
    registerApplication({
      name: '@org/products',
      app: () => import('@org/products'),
      activeWhen: '/products'
    });¬∑
    registerApplication({
      name: '@org/checkout',
      app: () => import('@org/checkout'),
      activeWhen: '/checkout'
    });¬∑
    start();
    ```¬∑
    ### 2. React Micro-Frontend¬∑
    ```typescript
    // products/src/root.component.tsx
    import React from 'react';
    import ReactDOM from 'react-dom';
    import singleSpaReact from 'single-spa-react';
    import App from './App';¬∑
    const lifecycles = singleSpaReact({
      React,
      ReactDOM,
      rootComponent: App,
      errorBoundary(err, info, props) {
        return <div>Error loading products</div>;
      }
    });¬∑
    export const { bootstrap, mount, unmount } = lifecycles;
    ```¬∑
    ### 3. Framework Migration¬∑
    ```typescript
    // Gradual migration: Angular to React
    registerApplication({
      name: '@org/legacy-angular',
      app: () => import('@org/legacy-angular'), // Angular app
      activeWhen: '/admin'
    });¬∑
    registerApplication({
      name: '@org/new-react',
      app: () => import('@org/new-react'), // React app
      activeWhen: ['/dashboard', '/settings']
    });¬∑
    // Both can coexist and share routing
    ```¬∑
    ---¬∑
    ## Communication Patterns¬∑
    ### 1. CustomEvents (Decoupled)¬∑
    ```typescript
    // Remote: Emit event
    function ProductList() {
      const handleClick = (product) => {
        window.dispatchEvent(new CustomEvent('product:selected', {
          detail: { productId: product.id }
        }));
      };¬∑
      return <ProductCard onClick={handleClick} />;
    }¬∑
    // Host: Listen for event
    useEffect(() => {
      const handler = (e) => {
        console.log('Product selected:', e.detail.productId);
        navigate(`/product/${e.detail.productId}`);
      };¬∑
      window.addEventListener('product:selected', handler);
      return () => window.removeEventListener('product:selected', handler);
    }, []);
    ```¬∑
    ### 2. Shared EventBus¬∑
    ```typescript
    // Shared event bus (exposed by host)
    // host/src/eventBus.ts
    import { EventEmitter } from 'events';¬∑
    export const eventBus = new EventEmitter();¬∑
    // Remote: Use event bus
    import { eventBus } from 'shell/eventBus';¬∑
    eventBus.emit('cart:add', { productId: '123', quantity: 1 });¬∑
    // Host: Listen
    eventBus.on('cart:add', (data) => {
      updateCart(data);
    });
    ```¬∑
    ### 3. Shared Store (Zustand/Redux)¬∑
    ```typescript
    // Host exposes store
    export const useCartStore = create((set) => ({
      items: [],
      addItem: (item) => set((state) => ({ items: [...state.items, item] }))
    }));¬∑
    // Remote imports and uses
    import { useCartStore } from 'shell/store';¬∑
    function AddToCart({ product }) {
      const addItem = useCartStore(state => state.addItem);¬∑
      return <button onClick={() => addItem(product)}>Add to Cart</button>;
    }
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. Independent Deployments¬∑
    ```yaml
    # products/.github/workflows/deploy.yml
    name: Deploy Products
    on:
      push:
        branches: [main]¬∑
    jobs:
      deploy:
        runs-on: ubuntu-latest
        steps:
          - run: npm run build
          - run: aws s3 sync ./dist s3://cdn.example.com/products/
          - run: aws cloudfront create-invalidation
    ```¬∑
    ### 2. Import Map (Runtime Configuration)¬∑
    ```html
    <!-- index.html -->
    <script type=\"importmap\">
    {
      \"imports\": {
        \"products\": \"https://cdn.example.com/products/v1.2.3/remoteEntry.js\",
        \"checkout\": \"https://cdn.example.com/checkout/v2.1.0/remoteEntry.js\"
      }
    }
    </script>
    ```¬∑
    ### 3. Versioning Strategy¬∑
    ```typescript
    // Semantic versioning for remotes
    const remotes = {
      products: 'products@https://cdn.example.com/products/latest/remoteEntry.js',
      checkout: 'checkout@https://cdn.example.com/checkout/v2/remoteEntry.js'
    };¬∑
    // Blue-green deployment: Switch versions instantly
    const remotes = {
      products: process.env.PRODUCTS_VERSION === 'blue'
        ? 'products@https://cdn.example.com/products/blue/remoteEntry.js'
        : 'products@https://cdn.example.com/products/green/remoteEntry.js'
    };
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Lazy Loading¬∑
    ```typescript
    // Load remotes only when needed
    const ProductDetail = lazy(() => import('products/ProductDetail'));¬∑
    function App() {
      return (
        <Routes>
          <Route path=\"/product/:id\" element={
            <Suspense fallback={<Skeleton />}>
              <ProductDetail />
            </Suspense>
          } />
        </Routes>
      );
    }
    ```¬∑
    ### 2. Shared Dependencies¬∑
    ```javascript
    // Share common libraries (load once)
    shared: {
      react: { singleton: true, eager: true },
      'react-dom': { singleton: true, eager: true },
      'react-router-dom': { singleton: true },
      lodash: { singleton: false } // Allow duplicates if versions differ
    }
    ```¬∑
    ### 3. Preloading¬∑
    ```html
    <!-- Preload critical remotes -->
    <link rel=\"preload\" href=\"https://cdn.example.com/products/remoteEntry.js\" as=\"script\">
    <link rel=\"prefetch\" href=\"https://cdn.example.com/checkout/remoteEntry.js\" as=\"script\">
    ```¬∑
    ---¬∑
    ## Testing Strategies¬∑
    ### 1. Component Testing (Isolated)¬∑
    ```typescript
    // Test remote component in isolation
    import { render } from '@testing-library/react';
    import ProductList from './ProductList';¬∑
    test('renders products', () => {
      const { getByText } = render(<ProductList />);
      expect(getByText('Product 1')).toBeInTheDocument();
    });
    ```¬∑
    ### 2. Integration Testing¬∑
    ```typescript
    // Test host + remote integration
    import { mount } from 'cypress';¬∑
    cy.visit('/products');
    cy.wait('@loadRemote'); // Wait for remote to load
    cy.get('[data-testid=\"product-card\"]').should('exist');
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `create-micro-frontend.js` - Scaffold new micro-frontend
    - `analyze-bundle.js` - Analyze shared dependencies¬∑
    ### references/
    - `references/module-federation.md` - Module Federation patterns
    - `references/single-spa.md` - single-spa lifecycle and routing
    - `references/communication-patterns.md` - Inter-app communication
    - `references/deployment-strategies.md` - CI/CD for micro-frontends¬∑
    ### assets/
    - `assets/templates/` - Micro-frontend boilerplate templates¬∑
    ## Related Skills¬∑
    - `state-management` - Shared store patterns
    - `testing-strategies` - Testing micro-frontends
    - `api-design` - Backend-for-frontend (BFF) pattern
    - `microservices` - Backend microservices architecture
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ micro-frontends ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: micro-frontends
    description: Micro-frontend architecture using Module Federation (Webpack/Rspack) and single-spa. Use when building large-scale applications with independent teams, enabling independent deployments and technology flexibility. Reduces deployment coupling and enables team autonomy.
    ---¬∑
    # Micro-Frontends¬∑
    ## Overview¬∑
    Micro-frontend architecture patterns using Module Federation and single-spa for building large-scale applications with independent teams. Enables independent deployments, technology flexibility, and team autonomy while maintaining a cohesive user experience.¬∑
    **Goal**: Independent frontend deployments with shared runtime integration¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Large teams need independent deployments
    - Multiple framework versions needed (React 17 + React 18)
    - Gradual migration from legacy code
    - Team autonomy required
    - Independent feature development
    - Shared component libraries across apps
    - Different release cycles per team¬∑
    **Triggers**: \"micro-frontends\", \"Module Federation\", \"single-spa\", \"independent deployments\", \"monorepo alternatives\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Module Federation vs single-spa vs Monorepo¬∑
    **Module Federation** (Runtime Integration):
    - ‚úÖ Share code at runtime (no duplication)
    - ‚úÖ Independent deployments
    - ‚úÖ Version compatibility (load multiple React versions)
    - ‚úÖ Dynamic imports (load on demand)
    - ‚úÖ Best for: Webpack/Rspack apps, shared libraries, independent teams¬∑
    **single-spa** (Framework-Agnostic):
    - ‚úÖ Mix frameworks (React + Vue + Angular)
    - ‚úÖ Gradual migration
    - ‚úÖ Lifecycle management
    - ‚úÖ Framework independence
    - ‚úÖ Best for: Legacy migration, polyglot frontends¬∑
    **Monorepo** (Build-Time Integration):
    - ‚úÖ Shared TypeScript types
    - ‚úÖ Atomic commits across apps
    - ‚úÖ Easier refactoring
    - ‚úÖ Coordinated releases
    - ‚úÖ Best for: Single team, coordinated releases¬∑
    ---¬∑
    ## Module Federation Patterns¬∑
    ### 1. Basic Setup (Host + Remote)¬∑
    ```javascript
    // Remote app (products): webpack.config.js
    const { ModuleFederationPlugin } = require('webpack').container;¬∑
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'products',
          filename: 'remoteEntry.js',
          exposes: {
            './ProductList': './src/components/ProductList',
            './ProductDetail': './src/components/ProductDetail'
          },
          shared: {
            react: { singleton: true, requiredVersion: '^18.0.0' },
            'react-dom': { singleton: true, requiredVersion: '^18.0.0' }
          }
        })
      ]
    };¬∑
    // Host app (shell): webpack.config.js
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'shell',
          remotes: {
            products: 'products@http://localhost:3001/remoteEntry.js'
          },
          shared: {
            react: { singleton: true, requiredVersion: '^18.0.0' },
            'react-dom': { singleton: true, requiredVersion: '^18.0.0' }
          }
        })
      ]
    };¬∑
    // Host app: Use remote component
    import React, { lazy, Suspense } from 'react';¬∑
    const ProductList = lazy(() => import('products/ProductList'));¬∑
    function App() {
      return (
        <Suspense fallback={<div>Loading...</div>}>
          <ProductList />
        </Suspense>
      );
    }
    ```¬∑
    ### 2. Dynamic Remote Loading¬∑
    ```typescript
    // Load remote at runtime (URL from environment/API)
    async function loadRemote(url: string, module: string) {
      await __webpack_init_sharing__('default');¬∑
      const container = await import(/* webpackIgnore: true */ url);
      await container.init(__webpack_share_scopes__.default);¬∑
      const factory = await container.get(module);
      return factory();
    }¬∑
    // Usage: Load remote dynamically
    const ProductList = await loadRemote(
      'http://cdn.example.com/products/remoteEntry.js',
      './ProductList'
    );
    ```¬∑
    ### 3. Shared State Management¬∑
    ```typescript
    // Shared store in host
    // Host: Expose shared store
    const { ModuleFederationPlugin } = require('webpack').container;¬∑
    module.exports = {
      plugins: [
        new ModuleFederationPlugin({
          name: 'shell',
          exposes: {
            './store': './src/store'
          },
          shared: {
            zustand: { singleton: true }
          }
        })
      ]
    };¬∑
    // Remote: Import shared store
    import { useStore } from 'shell/store';¬∑
    function ProductList() {
      const user = useStore(state => state.user);
      return <div>Welcome {user.name}</div>;
    }
    ```¬∑
    ---¬∑
    ## single-spa Patterns¬∑
    ### 1. Root Config¬∑
    ```typescript
    // root-config.ts
    import { registerApplication, start } from 'single-spa';¬∑
    // Register micro-frontends
    registerApplication({
      name: '@org/navbar',
      app: () => import('@org/navbar'),
      activeWhen: '/' // Always active
    });¬∑
    registerApplication({
      name: '@org/products',
      app: () => import('@org/products'),
      activeWhen: '/products'
    });¬∑
    registerApplication({
      name: '@org/checkout',
      app: () => import('@org/checkout'),
      activeWhen: '/checkout'
    });¬∑
    start();
    ```¬∑
    ### 2. React Micro-Frontend¬∑
    ```typescript
    // products/src/root.component.tsx
    import React from 'react';
    import ReactDOM from 'react-dom';
    import singleSpaReact from 'single-spa-react';
    import App from './App';¬∑
    const lifecycles = singleSpaReact({
      React,
      ReactDOM,
      rootComponent: App,
      errorBoundary(err, info, props) {
        return <div>Error loading products</div>;
      }
    });¬∑
    export const { bootstrap, mount, unmount } = lifecycles;
    ```¬∑
    ### 3. Framework Migration¬∑
    ```typescript
    // Gradual migration: Angular to React
    registerApplication({
      name: '@org/legacy-angular',
      app: () => import('@org/legacy-angular'), // Angular app
      activeWhen: '/admin'
    });¬∑
    registerApplication({
      name: '@org/new-react',
      app: () => import('@org/new-react'), // React app
      activeWhen: ['/dashboard', '/settings']
    });¬∑
    // Both can coexist and share routing
    ```¬∑
    ---¬∑
    ## Communication Patterns¬∑
    ### 1. CustomEvents (Decoupled)¬∑
    ```typescript
    // Remote: Emit event
    function ProductList() {
      const handleClick = (product) => {
        window.dispatchEvent(new CustomEvent('product:selected', {
          detail: { productId: product.id }
        }));
      };¬∑
      return <ProductCard onClick={handleClick} />;
    }¬∑
    // Host: Listen for event
    useEffect(() => {
      const handler = (e) => {
        console.log('Product selected:', e.detail.productId);
        navigate(`/product/${e.detail.productId}`);
      };¬∑
      window.addEventListener('product:selected', handler);
      return () => window.removeEventListener('product:selected', handler);
    }, []);
    ```¬∑
    ### 2. Shared EventBus¬∑
    ```typescript
    // Shared event bus (exposed by host)
    // host/src/eventBus.ts
    import { EventEmitter } from 'events';¬∑
    export const eventBus = new EventEmitter();¬∑
    // Remote: Use event bus
    import { eventBus } from 'shell/eventBus';¬∑
    eventBus.emit('cart:add', { productId: '123', quantity: 1 });¬∑
    // Host: Listen
    eventBus.on('cart:add', (data) => {
      updateCart(data);
    });
    ```¬∑
    ### 3. Shared Store (Zustand/Redux)¬∑
    ```typescript
    // Host exposes store
    export const useCartStore = create((set) => ({
      items: [],
      addItem: (item) => set((state) => ({ items: [...state.items, item] }))
    }));¬∑
    // Remote imports and uses
    import { useCartStore } from 'shell/store';¬∑
    function AddToCart({ product }) {
      const addItem = useCartStore(state => state.addItem);¬∑
      return <button onClick={() => addItem(product)}>Add to Cart</button>;
    }
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. Independent Deployments¬∑
    ```yaml
    # products/.github/workflows/deploy.yml
    name: Deploy Products
    on:
      push:
        branches: [main]¬∑
    jobs:
      deploy:
        runs-on: ubuntu-latest
        steps:
          - run: npm run build
          - run: aws s3 sync ./dist s3://cdn.example.com/products/
          - run: aws cloudfront create-invalidation
    ```¬∑
    ### 2. Import Map (Runtime Configuration)¬∑
    ```html
    <!-- index.html -->
    <script type=\"importmap\">
    {
      \"imports\": {
        \"products\": \"https://cdn.example.com/products/v1.2.3/remoteEntry.js\",
        \"checkout\": \"https://cdn.example.com/checkout/v2.1.0/remoteEntry.js\"
      }
    }
    </script>
    ```¬∑
    ### 3. Versioning Strategy¬∑
    ```typescript
    // Semantic versioning for remotes
    const remotes = {
      products: 'products@https://cdn.example.com/products/latest/remoteEntry.js',
      checkout: 'checkout@https://cdn.example.com/checkout/v2/remoteEntry.js'
    };¬∑
    // Blue-green deployment: Switch versions instantly
    const remotes = {
      products: process.env.PRODUCTS_VERSION === 'blue'
        ? 'products@https://cdn.example.com/products/blue/remoteEntry.js'
        : 'products@https://cdn.example.com/products/green/remoteEntry.js'
    };
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Lazy Loading¬∑
    ```typescript
    // Load remotes only when needed
    const ProductDetail = lazy(() => import('products/ProductDetail'));¬∑
    function App() {
      return (
        <Routes>
          <Route path=\"/product/:id\" element={
            <Suspense fallback={<Skeleton />}>
              <ProductDetail />
            </Suspense>
          } />
        </Routes>
      );
    }
    ```¬∑
    ### 2. Shared Dependencies¬∑
    ```javascript
    // Share common libraries (load once)
    shared: {
      react: { singleton: true, eager: true },
      'react-dom': { singleton: true, eager: true },
      'react-router-dom': { singleton: true },
      lodash: { singleton: false } // Allow duplicates if versions differ
    }
    ```¬∑
    ### 3. Preloading¬∑
    ```html
    <!-- Preload critical remotes -->
    <link rel=\"preload\" href=\"https://cdn.example.com/products/remoteEntry.js\" as=\"script\">
    <link rel=\"prefetch\" href=\"https://cdn.example.com/checkout/remoteEntry.js\" as=\"script\">
    ```¬∑
    ---¬∑
    ## Testing Strategies¬∑
    ### 1. Component Testing (Isolated)¬∑
    ```typescript
    // Test remote component in isolation
    import { render } from '@testing-library/react';
    import ProductList from './ProductList';¬∑
    test('renders products', () => {
      const { getByText } = render(<ProductList />);
      expect(getByText('Product 1')).toBeInTheDocument();
    });
    ```¬∑
    ### 2. Integration Testing¬∑
    ```typescript
    // Test host + remote integration
    import { mount } from 'cypress';¬∑
    cy.visit('/products');
    cy.wait('@loadRemote'); // Wait for remote to load
    cy.get('[data-testid=\"product-card\"]').should('exist');
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `create-micro-frontend.js` - Scaffold new micro-frontend
    - `analyze-bundle.js` - Analyze shared dependencies¬∑
    ### references/
    - `references/module-federation.md` - Module Federation patterns
    - `references/single-spa.md` - single-spa lifecycle and routing
    - `references/communication-patterns.md` - Inter-app communication
    - `references/deployment-strategies.md` - CI/CD for micro-frontends¬∑
    ### assets/
    - `assets/templates/` - Micro-frontend boilerplate templates¬∑
    ## Related Skills¬∑
    - `state-management` - Shared store patterns
    - `testing-strategies` - Testing micro-frontends
    - `api-design` - Backend-for-frontend (BFF) pattern
    - `microservices` - Backend microservices architecture
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ micro-frontends ‚Ä∫ should be at least 500 lines (comprehensive documentation)

    expect(received).toBeGreaterThanOrEqual(expected)

    Expected: >= 500
    Received:    450

      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {
      115 |           const lineCount = content.split('\n').length;
    > 116 |           expect(lineCount).toBeGreaterThanOrEqual(500);
          |                             ^
      117 |         });
      118 |       });
      119 |     });

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:116:29)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ api-design ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: api-design
    description: Modern API design patterns for REST, GraphQL, and tRPC. Use when designing APIs, implementing endpoints, versioning, or optimizing API performance. Covers resource naming, HTTP methods, status codes, GraphQL schema design, and type-safe RPC with tRPC. Reduces API design time by 50% through proven patterns.
    ---¬∑
    # API Design¬∑
    ## Overview¬∑
    Modern API design patterns covering RESTful APIs, GraphQL, and tRPC (type-safe RPC). Provides battle-tested patterns for resource naming, versioning, error handling, and performance optimization.¬∑
    **Goal**: Design consistent, scalable, and developer-friendly APIs following industry best practices¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Designing new API endpoints (REST, GraphQL, tRPC)
    - Implementing resource CRUD operations
    - Setting up API versioning strategies
    - Handling errors and validation
    - Optimizing API performance (caching, pagination)
    - Creating API documentation (OpenAPI/Swagger)
    - Migrating between API paradigms¬∑
    **Triggers**: \"API design\", \"REST endpoint\", \"GraphQL schema\", \"tRPC\", \"API versioning\", \"endpoint naming\", \"HTTP methods\"¬∑
    ---¬∑
    ## Quick Start: API Paradigm Decision Tree¬∑
    ### When to Use REST vs GraphQL vs tRPC¬∑
    **REST** (Resource-oriented, HTTP-based):
    - ‚úÖ Simple CRUD operations
    - ‚úÖ Public APIs with broad client support
    - ‚úÖ Caching with HTTP semantics (ETags, Cache-Control)
    - ‚úÖ Stateless operations
    - ‚úÖ Well-understood by most developers
    - ‚úÖ Best for: Public APIs, microservices, traditional web apps¬∑
    **GraphQL** (Query language, flexible data fetching):
    - ‚úÖ Complex data relationships
    - ‚úÖ Multiple resources in single request
    - ‚úÖ Frontend-driven data requirements
    - ‚úÖ Real-time subscriptions
    - ‚úÖ Strongly typed schema
    - ‚úÖ Best for: Complex frontends, mobile apps, data aggregation¬∑
    **tRPC** (Type-safe RPC, TypeScript-first):
    - ‚úÖ Full-stack TypeScript projects
    - ‚úÖ End-to-end type safety
    - ‚úÖ No code generation needed
    - ‚úÖ Automatic API client generation
    - ‚úÖ React Query integration
    - ‚úÖ Best for: TypeScript monorepos, internal APIs, Next.js apps¬∑
    **Use Multiple** when:
    - REST for public API + tRPC for internal admin API
    - GraphQL for frontend + REST for third-party integrations¬∑
    ---¬∑
    ## REST API Patterns¬∑
    ### 1. Resource Naming¬∑
    ```http
    # ‚úÖ Good - Plural nouns, hierarchical
    GET    /api/v1/users              # List users
    POST   /api/v1/users              # Create user
    GET    /api/v1/users/:id          # Get user
    PATCH  /api/v1/users/:id          # Update user (partial)
    PUT    /api/v1/users/:id          # Replace user (full)
    DELETE /api/v1/users/:id          # Delete user¬∑
    # Nested resources (1-2 levels max)
    GET    /api/v1/users/:id/posts    # Get user's posts
    POST   /api/v1/users/:id/posts    # Create post for user¬∑
    # ‚ùå Bad - Verbs, singular, inconsistent
    GET    /api/v1/getUser/:id        # Don't use verbs
    GET    /api/v1/user               # Use plural
    GET    /api/v1/users-list         # No hyphens in resource names
    ```¬∑
    ### 2. HTTP Methods & Status Codes¬∑
    ```typescript
    // Express.js example
    import { Router } from 'express';¬∑
    const router = Router();¬∑
    // GET - Retrieve resource(s)
    router.get('/users', async (req, res) => {
      const users = await db.user.findMany();
      res.status(200).json(users); // 200 OK
    });¬∑
    // POST - Create resource
    router.post('/users', async (req, res) => {
      const user = await db.user.create({ data: req.body });
      res.status(201).json(user); // 201 Created
    });¬∑
    // PATCH - Partial update
    router.patch('/users/:id', async (req, res) => {
      const user = await db.user.update({
        where: { id: req.params.id },
        data: req.body
      });
      res.status(200).json(user); // 200 OK
    });¬∑
    // DELETE - Remove resource
    router.delete('/users/:id', async (req, res) => {
      await db.user.delete({ where: { id: req.params.id } });
      res.status(204).send(); // 204 No Content
    });¬∑
    // Common status codes:
    // 200 OK - Success
    // 201 Created - Resource created
    // 204 No Content - Success, no response body
    // 400 Bad Request - Invalid input
    // 401 Unauthorized - Missing/invalid auth
    // 403 Forbidden - Authenticated but no permission
    // 404 Not Found - Resource doesn't exist
    // 409 Conflict - Resource conflict (duplicate)
    // 422 Unprocessable Entity - Validation error
    // 500 Internal Server Error - Server error
    ```¬∑
    ### 3. Pagination¬∑
    ```typescript
    // Offset pagination (simple, page-based)
    router.get('/users', async (req, res) => {
      const { page = 1, limit = 20 } = req.query;
      const skip = (page - 1) * limit;¬∑
      const [users, total] = await Promise.all([
        db.user.findMany({ skip, take: limit }),
        db.user.count()
      ]);¬∑
      res.json({
        data: users,
        meta: {
          page: parseInt(page),
          limit: parseInt(limit),
          total,
          total_pages: Math.ceil(total / limit)
        }
      });
    });¬∑
    // Cursor pagination (better for large datasets, real-time data)
    router.get('/users', async (req, res) => {
      const { cursor, limit = 20 } = req.query;¬∑
      const users = await db.user.findMany({
        take: limit + 1, // Fetch one extra to check if there's a next page
        cursor: cursor ? { id: cursor } : undefined,
        orderBy: { id: 'asc' }
      });¬∑
      const hasMore = users.length > limit;
      const data = hasMore ? users.slice(0, -1) : users;
      const nextCursor = hasMore ? data[data.length - 1].id : null;¬∑
      res.json({
        data,
        meta: {
          next_cursor: nextCursor,
          has_more: hasMore
        }
      });
    });
    ```¬∑
    ### 4. Filtering & Sorting¬∑
    ```typescript
    // Query parameters for filtering
    router.get('/users', async (req, res) => {
      const { status, role, sort = '-created_at', search } = req.query;¬∑
      const where = {};
      if (status) where.status = status;
      if (role) where.role = role;
      if (search) where.name = { contains: search, mode: 'insensitive' };¬∑
      // Sort: \"-created_at\" = descending, \"created_at\" = ascending
      const [sortField, sortOrder] = sort.startsWith('-')
        ? [sort.slice(1), 'desc']
        : [sort, 'asc'];¬∑
      const users = await db.user.findMany({
        where,
        orderBy: { [sortField]: sortOrder }
      });¬∑
      res.json(users);
    });¬∑
    // Example requests:
    // GET /users?status=active&role=admin&sort=-created_at
    // GET /users?search=john&sort=name
    ```¬∑
    ### 5. Error Handling¬∑
    ```typescript
    // Consistent error response format
    interface ApiError {
      error: {
        code: string;
        message: string;
        details?: any;
      };
    }¬∑
    // Error middleware
    app.use((err, req, res, next) => {
      console.error(err);¬∑
      // Validation error (Zod, Joi, etc.)
      if (err.name === 'ZodError') {
        return res.status(422).json({
          error: {
            code: 'VALIDATION_ERROR',
            message: 'Invalid input',
            details: err.errors
          }
        });
      }¬∑
      // Not found
      if (err.name === 'NotFoundError') {
        return res.status(404).json({
          error: {
            code: 'NOT_FOUND',
            message: err.message
          }
        });
      }¬∑
      // Default error
      res.status(500).json({
        error: {
          code: 'INTERNAL_ERROR',
          message: 'An unexpected error occurred'
        }
      });
    });
    ```¬∑
    ### 6. API Versioning¬∑
    ```typescript
    // URL versioning (recommended for REST)
    app.use('/api/v1', v1Routes);
    app.use('/api/v2', v2Routes);¬∑
    // Header versioning (alternative)
    app.use((req, res, next) => {
      const version = req.headers['api-version'] || '1';
      if (version === '1') return v1Routes(req, res, next);
      if (version === '2') return v2Routes(req, res, next);
      res.status(400).json({ error: 'Invalid API version' });
    });¬∑
    // Migration strategy:
    // 1. Deprecate v1 endpoint, add warning header
    // 2. Run both v1 and v2 in parallel (6-12 months)
    // 3. Monitor v1 usage, communicate sunset date
    // 4. Remove v1 after adoption threshold (e.g., <5% traffic)
    ```¬∑
    ---¬∑
    ## GraphQL Patterns¬∑
    ### 1. Schema Design¬∑
    ```graphql
    # Type definitions
    type User {
      id: ID!
      name: String!
      email: String!
      role: Role!
      posts: [Post!]!
      createdAt: DateTime!
      updatedAt: DateTime!
    }¬∑
    type Post {
      id: ID!
      title: String!
      content: String!
      author: User!
      published: Boolean!
      tags: [String!]!
      createdAt: DateTime!
    }¬∑
    enum Role {
      USER
      ADMIN
      MODERATOR
    }¬∑
    # Queries
    type Query {
      # Get single resource
      user(id: ID!): User
      post(id: ID!): Post¬∑
      # List resources with pagination
      users(
        filter: UserFilter
        sort: UserSort
        page: Int = 1
        limit: Int = 20
      ): UserConnection!¬∑
      posts(
        filter: PostFilter
        sort: PostSort
        cursor: String
        limit: Int = 20
      ): PostConnection!
    }¬∑
    # Mutations
    type Mutation {
      createUser(input: CreateUserInput!): User!
      updateUser(id: ID!, input: UpdateUserInput!): User!
      deleteUser(id: ID!): Boolean!¬∑
      createPost(input: CreatePostInput!): Post!
      publishPost(id: ID!): Post!
    }¬∑
    # Subscriptions (real-time)
    type Subscription {
      postCreated: Post!
      userOnline(userId: ID!): User!
    }¬∑
    # Input types
    input CreateUserInput {
      name: String!
      email: String!
      role: Role = USER
    }¬∑
    input UpdateUserInput {
      name: String
      email: String
      role: Role
    }¬∑
    input UserFilter {
      role: Role
      search: String
      createdAfter: DateTime
    }¬∑
    # Connection types (pagination)
    type UserConnection {
      edges: [UserEdge!]!
      pageInfo: PageInfo!
      totalCount: Int!
    }¬∑
    type UserEdge {
      node: User!
      cursor: String!
    }¬∑
    type PageInfo {
      hasNextPage: Boolean!
      hasPreviousPage: Boolean!
      startCursor: String
      endCursor: String
    }
    ```¬∑
    ### 2. Resolvers¬∑
    ```typescript
    import { GraphQLContext } from './context';¬∑
    const resolvers = {
      Query: {
        user: async (_parent, { id }, context: GraphQLContext) => {
          return context.db.user.findUnique({ where: { id } });
        },¬∑
        users: async (_parent, { filter, page = 1, limit = 20 }, context: GraphQLContext) => {
          const skip = (page - 1) * limit;¬∑
          const where = {};
          if (filter?.role) where.role = filter.role;
          if (filter?.search) where.name = { contains: filter.search };¬∑
          const [users, total] = await Promise.all([
            context.db.user.findMany({ where, skip, take: limit }),
            context.db.user.count({ where })
          ]);¬∑
          return {
            edges: users.map(user => ({ node: user, cursor: user.id })),
            pageInfo: {
              hasNextPage: skip + users.length < total,
              hasPreviousPage: page > 1
            },
            totalCount: total
          };
        }
      },¬∑
      Mutation: {
        createUser: async (_parent, { input }, context: GraphQLContext) => {
          // Authorization check
          if (!context.user) throw new Error('Unauthorized');¬∑
          // Validation
          if (!input.email.includes('@')) {
            throw new Error('Invalid email');
          }¬∑
          return context.db.user.create({ data: input });
        },¬∑
        updateUser: async (_parent, { id, input }, context: GraphQLContext) => {
          // Authorization check
          if (!context.user || context.user.id !== id) {
            throw new Error('Forbidden');
          }¬∑
          return context.db.user.update({
            where: { id },
            data: input
          });
        }
      },¬∑
      // Field resolvers (relationships)
      User: {
        posts: async (user, _args, context: GraphQLContext) => {
          return context.db.post.findMany({
            where: { authorId: user.id }
          });
        }
      },¬∑
      Post: {
        author: async (post, _args, context: GraphQLContext) => {
          return context.db.user.findUnique({
            where: { id: post.authorId }
          });
        }
      }
    };
    ```¬∑
    ### 3. DataLoader (N+1 Prevention)¬∑
    ```typescript
    import DataLoader from 'dataloader';¬∑
    // Create loaders to batch database queries
    export function createLoaders(db: PrismaClient) {
      return {
        userLoader: new DataLoader(async (ids: string[]) => {
          const users = await db.user.findMany({
            where: { id: { in: ids } }
          });
          // Return in same order as input
          return ids.map(id => users.find(user => user.id === id));
        }),¬∑
        postsByAuthorLoader: new DataLoader(async (authorIds: string[]) => {
          const posts = await db.post.findMany({
            where: { authorId: { in: authorIds } }
          });
          // Group by authorId
          return authorIds.map(id => posts.filter(post => post.authorId === id));
        })
      };
    }¬∑
    // Usage in resolver
    const resolvers = {
      User: {
        posts: async (user, _args, context: GraphQLContext) => {
          // Batches queries automatically
          return context.loaders.postsByAuthorLoader.load(user.id);
        }
      }
    };¬∑
    // Without DataLoader: N+1 queries (1 + N)
    // With DataLoader: 2 queries (1 for users, 1 batched query for all posts)
    ```¬∑
    ---¬∑
    ## tRPC Patterns¬∑
    ### 1. Router Definition¬∑
    ```typescript
    // server/routers/user.ts
    import { z } from 'zod';
    import { router, publicProcedure, protectedProcedure } from '../trpc';¬∑
    export const userRouter = router({
      // Query (GET-like)
      getById: publicProcedure
        .input(z.object({ id: z.string() }))
        .query(async ({ input, ctx }) => {
          return ctx.db.user.findUnique({ where: { id: input.id } });
        }),¬∑
      // List with pagination
      list: publicProcedure
        .input(z.object({
          page: z.number().default(1),
          limit: z.number().default(20),
          role: z.enum(['USER', 'ADMIN']).optional()
        }))
        .query(async ({ input, ctx }) => {
          const { page, limit, role } = input;
          const skip = (page - 1) * limit;¬∑
          const where = role ? { role } : {};¬∑
          const [users, total] = await Promise.all([
            ctx.db.user.findMany({ where, skip, take: limit }),
            ctx.db.user.count({ where })
          ]);¬∑
          return {
            users,
            meta: {
              page,
              limit,
              total,
              total_pages: Math.ceil(total / limit)
            }
          };
        }),¬∑
      // Mutation (POST/PUT/DELETE-like)
      create: protectedProcedure
        .input(z.object({
          name: z.string().min(1),
          email: z.string().email(),
          role: z.enum(['USER', 'ADMIN']).default('USER')
        }))
        .mutation(async ({ input, ctx }) => {
          return ctx.db.user.create({ data: input });
        }),¬∑
      update: protectedProcedure
        .input(z.object({
          id: z.string(),
          name: z.string().optional(),
          email: z.string().email().optional()
        }))
        .mutation(async ({ input, ctx }) => {
          const { id, ...data } = input;¬∑
          // Authorization check
          if (ctx.user.id !== id && ctx.user.role !== 'ADMIN') {
            throw new TRPCError({ code: 'FORBIDDEN' });
          }¬∑
          return ctx.db.user.update({ where: { id }, data });
        }),¬∑
      delete: protectedProcedure
        .input(z.object({ id: z.string() }))
        .mutation(async ({ input, ctx }) => {
          // Only admins can delete
          if (ctx.user.role !== 'ADMIN') {
            throw new TRPCError({ code: 'FORBIDDEN' });
          }¬∑
          return ctx.db.user.delete({ where: { id: input.id } });
        })
    });
    ```¬∑
    ### 2. Root Router¬∑
    ```typescript
    // server/routers/_app.ts
    import { router } from '../trpc';
    import { userRouter } from './user';
    import { postRouter } from './post';¬∑
    export const appRouter = router({
      user: userRouter,
      post: postRouter
    });¬∑
    // Export type for client
    export type AppRouter = typeof appRouter;
    ```¬∑
    ### 3. Client Usage (React)¬∑
    ```typescript
    // client/trpc.ts
    import { createTRPCReact } from '@trpc/react-query';
    import type { AppRouter } from '../server/routers/_app';¬∑
    export const trpc = createTRPCReact<AppRouter>();¬∑
    // components/UserList.tsx
    import { trpc } from '../client/trpc';¬∑
    function UserList() {
      // Full type safety - TypeScript knows the return type!
      const { data, isLoading } = trpc.user.list.useQuery({
        page: 1,
        limit: 20,
        role: 'ADMIN' // TypeScript error if invalid role
      });¬∑
      const createUser = trpc.user.create.useMutation({
        onSuccess: () => {
          // Invalidate and refetch
          trpc.useContext().user.list.invalidate();
        }
      });¬∑
      if (isLoading) return <div>Loading...</div>;¬∑
      return (
        <div>
          {data?.users.map(user => (
            <div key={user.id}>{user.name}</div>
          ))}¬∑
          <button onClick={() => createUser.mutate({
            name: 'John Doe',
            email: 'john@example.com',
            role: 'USER'
          })}>
            Create User
          </button>
        </div>
      );
    }
    ```¬∑
    ### 4. Subscriptions (Real-Time)¬∑
    ```typescript
    // server/routers/user.ts
    export const userRouter = router({
      onUserCreated: publicProcedure
        .subscription(async ({ ctx }) => {
          // Return an observable
          return observable<User>((emit) => {
            const listener = (user: User) => emit.next(user);¬∑
            // Subscribe to event emitter
            ctx.eventEmitter.on('userCreated', listener);¬∑
            // Cleanup
            return () => {
              ctx.eventEmitter.off('userCreated', listener);
            };
          });
        })
    });¬∑
    // client/UserSubscription.tsx
    function UserSubscription() {
      trpc.user.onUserCreated.useSubscription(undefined, {
        onData: (user) => {
          console.log('New user created:', user);
          // Show notification, update UI, etc.
        }
      });¬∑
      return <div>Listening for new users...</div>;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Response Caching¬∑
    ```typescript
    // HTTP caching (REST)
    import { Router } from 'express';¬∑
    router.get('/users/:id', async (req, res) => {
      const user = await db.user.findUnique({ where: { id: req.params.id } });¬∑
      // Cache for 5 minutes
      res.set('Cache-Control', 'public, max-age=300');¬∑
      // ETag for conditional requests
      const etag = `\"${user.updated_at.getTime()}\"`;
      res.set('ETag', etag);¬∑
      // Return 304 Not Modified if ETag matches
      if (req.headers['if-none-match'] === etag) {
        return res.status(304).end();
      }¬∑
      res.json(user);
    });
    ```¬∑
    ### 2. Database Query Optimization¬∑
    ```typescript
    // ‚ùå Bad - N+1 queries
    const users = await db.user.findMany();
    for (const user of users) {
      user.posts = await db.post.findMany({ where: { authorId: user.id } });
    }¬∑
    // ‚úÖ Good - Single query with include
    const users = await db.user.findMany({
      include: { posts: true }
    });¬∑
    // ‚úÖ Good - Select only needed fields
    const users = await db.user.findMany({
      select: {
        id: true,
        name: true,
        email: true
        // Don't fetch unnecessary fields
      }
    });
    ```¬∑
    ### 3. Rate Limiting¬∑
    ```typescript
    import rateLimit from 'express-rate-limit';¬∑
    // Apply to all requests
    const limiter = rateLimit({
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 100, // Limit each IP to 100 requests per windowMs
      message: 'Too many requests from this IP, please try again later'
    });¬∑
    app.use('/api/', limiter);¬∑
    // Stricter limit for auth endpoints
    const authLimiter = rateLimit({
      windowMs: 15 * 60 * 1000,
      max: 5, // Only 5 login attempts per 15 minutes
      skipSuccessfulRequests: true
    });¬∑
    app.post('/api/auth/login', authLimiter, loginHandler);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-openapi.js` - Generate OpenAPI/Swagger docs from code
    - `validate-api-design.js` - Lint API design (naming, status codes)¬∑
    ### references/
    - `references/rest-conventions.md` - REST API naming and HTTP method guidelines
    - `references/graphql-best-practices.md` - GraphQL schema design patterns
    - `references/trpc-patterns.md` - tRPC router organization and error handling
    - `references/api-security.md` - CORS, rate limiting, authentication¬∑
    ### assets/
    - `assets/openapi-templates/` - OpenAPI 3.0 specification templates
    - `assets/postman-collections/` - Example Postman collections¬∑
    ## Related Skills¬∑
    - `auth-security` - OAuth2, JWT, API authentication
    - `schema-optimization` - Database query optimization
    - `testing-strategies` - API testing with Supertest/Playwright
    - `microservices` - API gateway patterns, service mesh
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ api-design ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: api-design
    description: Modern API design patterns for REST, GraphQL, and tRPC. Use when designing APIs, implementing endpoints, versioning, or optimizing API performance. Covers resource naming, HTTP methods, status codes, GraphQL schema design, and type-safe RPC with tRPC. Reduces API design time by 50% through proven patterns.
    ---¬∑
    # API Design¬∑
    ## Overview¬∑
    Modern API design patterns covering RESTful APIs, GraphQL, and tRPC (type-safe RPC). Provides battle-tested patterns for resource naming, versioning, error handling, and performance optimization.¬∑
    **Goal**: Design consistent, scalable, and developer-friendly APIs following industry best practices¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Designing new API endpoints (REST, GraphQL, tRPC)
    - Implementing resource CRUD operations
    - Setting up API versioning strategies
    - Handling errors and validation
    - Optimizing API performance (caching, pagination)
    - Creating API documentation (OpenAPI/Swagger)
    - Migrating between API paradigms¬∑
    **Triggers**: \"API design\", \"REST endpoint\", \"GraphQL schema\", \"tRPC\", \"API versioning\", \"endpoint naming\", \"HTTP methods\"¬∑
    ---¬∑
    ## Quick Start: API Paradigm Decision Tree¬∑
    ### When to Use REST vs GraphQL vs tRPC¬∑
    **REST** (Resource-oriented, HTTP-based):
    - ‚úÖ Simple CRUD operations
    - ‚úÖ Public APIs with broad client support
    - ‚úÖ Caching with HTTP semantics (ETags, Cache-Control)
    - ‚úÖ Stateless operations
    - ‚úÖ Well-understood by most developers
    - ‚úÖ Best for: Public APIs, microservices, traditional web apps¬∑
    **GraphQL** (Query language, flexible data fetching):
    - ‚úÖ Complex data relationships
    - ‚úÖ Multiple resources in single request
    - ‚úÖ Frontend-driven data requirements
    - ‚úÖ Real-time subscriptions
    - ‚úÖ Strongly typed schema
    - ‚úÖ Best for: Complex frontends, mobile apps, data aggregation¬∑
    **tRPC** (Type-safe RPC, TypeScript-first):
    - ‚úÖ Full-stack TypeScript projects
    - ‚úÖ End-to-end type safety
    - ‚úÖ No code generation needed
    - ‚úÖ Automatic API client generation
    - ‚úÖ React Query integration
    - ‚úÖ Best for: TypeScript monorepos, internal APIs, Next.js apps¬∑
    **Use Multiple** when:
    - REST for public API + tRPC for internal admin API
    - GraphQL for frontend + REST for third-party integrations¬∑
    ---¬∑
    ## REST API Patterns¬∑
    ### 1. Resource Naming¬∑
    ```http
    # ‚úÖ Good - Plural nouns, hierarchical
    GET    /api/v1/users              # List users
    POST   /api/v1/users              # Create user
    GET    /api/v1/users/:id          # Get user
    PATCH  /api/v1/users/:id          # Update user (partial)
    PUT    /api/v1/users/:id          # Replace user (full)
    DELETE /api/v1/users/:id          # Delete user¬∑
    # Nested resources (1-2 levels max)
    GET    /api/v1/users/:id/posts    # Get user's posts
    POST   /api/v1/users/:id/posts    # Create post for user¬∑
    # ‚ùå Bad - Verbs, singular, inconsistent
    GET    /api/v1/getUser/:id        # Don't use verbs
    GET    /api/v1/user               # Use plural
    GET    /api/v1/users-list         # No hyphens in resource names
    ```¬∑
    ### 2. HTTP Methods & Status Codes¬∑
    ```typescript
    // Express.js example
    import { Router } from 'express';¬∑
    const router = Router();¬∑
    // GET - Retrieve resource(s)
    router.get('/users', async (req, res) => {
      const users = await db.user.findMany();
      res.status(200).json(users); // 200 OK
    });¬∑
    // POST - Create resource
    router.post('/users', async (req, res) => {
      const user = await db.user.create({ data: req.body });
      res.status(201).json(user); // 201 Created
    });¬∑
    // PATCH - Partial update
    router.patch('/users/:id', async (req, res) => {
      const user = await db.user.update({
        where: { id: req.params.id },
        data: req.body
      });
      res.status(200).json(user); // 200 OK
    });¬∑
    // DELETE - Remove resource
    router.delete('/users/:id', async (req, res) => {
      await db.user.delete({ where: { id: req.params.id } });
      res.status(204).send(); // 204 No Content
    });¬∑
    // Common status codes:
    // 200 OK - Success
    // 201 Created - Resource created
    // 204 No Content - Success, no response body
    // 400 Bad Request - Invalid input
    // 401 Unauthorized - Missing/invalid auth
    // 403 Forbidden - Authenticated but no permission
    // 404 Not Found - Resource doesn't exist
    // 409 Conflict - Resource conflict (duplicate)
    // 422 Unprocessable Entity - Validation error
    // 500 Internal Server Error - Server error
    ```¬∑
    ### 3. Pagination¬∑
    ```typescript
    // Offset pagination (simple, page-based)
    router.get('/users', async (req, res) => {
      const { page = 1, limit = 20 } = req.query;
      const skip = (page - 1) * limit;¬∑
      const [users, total] = await Promise.all([
        db.user.findMany({ skip, take: limit }),
        db.user.count()
      ]);¬∑
      res.json({
        data: users,
        meta: {
          page: parseInt(page),
          limit: parseInt(limit),
          total,
          total_pages: Math.ceil(total / limit)
        }
      });
    });¬∑
    // Cursor pagination (better for large datasets, real-time data)
    router.get('/users', async (req, res) => {
      const { cursor, limit = 20 } = req.query;¬∑
      const users = await db.user.findMany({
        take: limit + 1, // Fetch one extra to check if there's a next page
        cursor: cursor ? { id: cursor } : undefined,
        orderBy: { id: 'asc' }
      });¬∑
      const hasMore = users.length > limit;
      const data = hasMore ? users.slice(0, -1) : users;
      const nextCursor = hasMore ? data[data.length - 1].id : null;¬∑
      res.json({
        data,
        meta: {
          next_cursor: nextCursor,
          has_more: hasMore
        }
      });
    });
    ```¬∑
    ### 4. Filtering & Sorting¬∑
    ```typescript
    // Query parameters for filtering
    router.get('/users', async (req, res) => {
      const { status, role, sort = '-created_at', search } = req.query;¬∑
      const where = {};
      if (status) where.status = status;
      if (role) where.role = role;
      if (search) where.name = { contains: search, mode: 'insensitive' };¬∑
      // Sort: \"-created_at\" = descending, \"created_at\" = ascending
      const [sortField, sortOrder] = sort.startsWith('-')
        ? [sort.slice(1), 'desc']
        : [sort, 'asc'];¬∑
      const users = await db.user.findMany({
        where,
        orderBy: { [sortField]: sortOrder }
      });¬∑
      res.json(users);
    });¬∑
    // Example requests:
    // GET /users?status=active&role=admin&sort=-created_at
    // GET /users?search=john&sort=name
    ```¬∑
    ### 5. Error Handling¬∑
    ```typescript
    // Consistent error response format
    interface ApiError {
      error: {
        code: string;
        message: string;
        details?: any;
      };
    }¬∑
    // Error middleware
    app.use((err, req, res, next) => {
      console.error(err);¬∑
      // Validation error (Zod, Joi, etc.)
      if (err.name === 'ZodError') {
        return res.status(422).json({
          error: {
            code: 'VALIDATION_ERROR',
            message: 'Invalid input',
            details: err.errors
          }
        });
      }¬∑
      // Not found
      if (err.name === 'NotFoundError') {
        return res.status(404).json({
          error: {
            code: 'NOT_FOUND',
            message: err.message
          }
        });
      }¬∑
      // Default error
      res.status(500).json({
        error: {
          code: 'INTERNAL_ERROR',
          message: 'An unexpected error occurred'
        }
      });
    });
    ```¬∑
    ### 6. API Versioning¬∑
    ```typescript
    // URL versioning (recommended for REST)
    app.use('/api/v1', v1Routes);
    app.use('/api/v2', v2Routes);¬∑
    // Header versioning (alternative)
    app.use((req, res, next) => {
      const version = req.headers['api-version'] || '1';
      if (version === '1') return v1Routes(req, res, next);
      if (version === '2') return v2Routes(req, res, next);
      res.status(400).json({ error: 'Invalid API version' });
    });¬∑
    // Migration strategy:
    // 1. Deprecate v1 endpoint, add warning header
    // 2. Run both v1 and v2 in parallel (6-12 months)
    // 3. Monitor v1 usage, communicate sunset date
    // 4. Remove v1 after adoption threshold (e.g., <5% traffic)
    ```¬∑
    ---¬∑
    ## GraphQL Patterns¬∑
    ### 1. Schema Design¬∑
    ```graphql
    # Type definitions
    type User {
      id: ID!
      name: String!
      email: String!
      role: Role!
      posts: [Post!]!
      createdAt: DateTime!
      updatedAt: DateTime!
    }¬∑
    type Post {
      id: ID!
      title: String!
      content: String!
      author: User!
      published: Boolean!
      tags: [String!]!
      createdAt: DateTime!
    }¬∑
    enum Role {
      USER
      ADMIN
      MODERATOR
    }¬∑
    # Queries
    type Query {
      # Get single resource
      user(id: ID!): User
      post(id: ID!): Post¬∑
      # List resources with pagination
      users(
        filter: UserFilter
        sort: UserSort
        page: Int = 1
        limit: Int = 20
      ): UserConnection!¬∑
      posts(
        filter: PostFilter
        sort: PostSort
        cursor: String
        limit: Int = 20
      ): PostConnection!
    }¬∑
    # Mutations
    type Mutation {
      createUser(input: CreateUserInput!): User!
      updateUser(id: ID!, input: UpdateUserInput!): User!
      deleteUser(id: ID!): Boolean!¬∑
      createPost(input: CreatePostInput!): Post!
      publishPost(id: ID!): Post!
    }¬∑
    # Subscriptions (real-time)
    type Subscription {
      postCreated: Post!
      userOnline(userId: ID!): User!
    }¬∑
    # Input types
    input CreateUserInput {
      name: String!
      email: String!
      role: Role = USER
    }¬∑
    input UpdateUserInput {
      name: String
      email: String
      role: Role
    }¬∑
    input UserFilter {
      role: Role
      search: String
      createdAfter: DateTime
    }¬∑
    # Connection types (pagination)
    type UserConnection {
      edges: [UserEdge!]!
      pageInfo: PageInfo!
      totalCount: Int!
    }¬∑
    type UserEdge {
      node: User!
      cursor: String!
    }¬∑
    type PageInfo {
      hasNextPage: Boolean!
      hasPreviousPage: Boolean!
      startCursor: String
      endCursor: String
    }
    ```¬∑
    ### 2. Resolvers¬∑
    ```typescript
    import { GraphQLContext } from './context';¬∑
    const resolvers = {
      Query: {
        user: async (_parent, { id }, context: GraphQLContext) => {
          return context.db.user.findUnique({ where: { id } });
        },¬∑
        users: async (_parent, { filter, page = 1, limit = 20 }, context: GraphQLContext) => {
          const skip = (page - 1) * limit;¬∑
          const where = {};
          if (filter?.role) where.role = filter.role;
          if (filter?.search) where.name = { contains: filter.search };¬∑
          const [users, total] = await Promise.all([
            context.db.user.findMany({ where, skip, take: limit }),
            context.db.user.count({ where })
          ]);¬∑
          return {
            edges: users.map(user => ({ node: user, cursor: user.id })),
            pageInfo: {
              hasNextPage: skip + users.length < total,
              hasPreviousPage: page > 1
            },
            totalCount: total
          };
        }
      },¬∑
      Mutation: {
        createUser: async (_parent, { input }, context: GraphQLContext) => {
          // Authorization check
          if (!context.user) throw new Error('Unauthorized');¬∑
          // Validation
          if (!input.email.includes('@')) {
            throw new Error('Invalid email');
          }¬∑
          return context.db.user.create({ data: input });
        },¬∑
        updateUser: async (_parent, { id, input }, context: GraphQLContext) => {
          // Authorization check
          if (!context.user || context.user.id !== id) {
            throw new Error('Forbidden');
          }¬∑
          return context.db.user.update({
            where: { id },
            data: input
          });
        }
      },¬∑
      // Field resolvers (relationships)
      User: {
        posts: async (user, _args, context: GraphQLContext) => {
          return context.db.post.findMany({
            where: { authorId: user.id }
          });
        }
      },¬∑
      Post: {
        author: async (post, _args, context: GraphQLContext) => {
          return context.db.user.findUnique({
            where: { id: post.authorId }
          });
        }
      }
    };
    ```¬∑
    ### 3. DataLoader (N+1 Prevention)¬∑
    ```typescript
    import DataLoader from 'dataloader';¬∑
    // Create loaders to batch database queries
    export function createLoaders(db: PrismaClient) {
      return {
        userLoader: new DataLoader(async (ids: string[]) => {
          const users = await db.user.findMany({
            where: { id: { in: ids } }
          });
          // Return in same order as input
          return ids.map(id => users.find(user => user.id === id));
        }),¬∑
        postsByAuthorLoader: new DataLoader(async (authorIds: string[]) => {
          const posts = await db.post.findMany({
            where: { authorId: { in: authorIds } }
          });
          // Group by authorId
          return authorIds.map(id => posts.filter(post => post.authorId === id));
        })
      };
    }¬∑
    // Usage in resolver
    const resolvers = {
      User: {
        posts: async (user, _args, context: GraphQLContext) => {
          // Batches queries automatically
          return context.loaders.postsByAuthorLoader.load(user.id);
        }
      }
    };¬∑
    // Without DataLoader: N+1 queries (1 + N)
    // With DataLoader: 2 queries (1 for users, 1 batched query for all posts)
    ```¬∑
    ---¬∑
    ## tRPC Patterns¬∑
    ### 1. Router Definition¬∑
    ```typescript
    // server/routers/user.ts
    import { z } from 'zod';
    import { router, publicProcedure, protectedProcedure } from '../trpc';¬∑
    export const userRouter = router({
      // Query (GET-like)
      getById: publicProcedure
        .input(z.object({ id: z.string() }))
        .query(async ({ input, ctx }) => {
          return ctx.db.user.findUnique({ where: { id: input.id } });
        }),¬∑
      // List with pagination
      list: publicProcedure
        .input(z.object({
          page: z.number().default(1),
          limit: z.number().default(20),
          role: z.enum(['USER', 'ADMIN']).optional()
        }))
        .query(async ({ input, ctx }) => {
          const { page, limit, role } = input;
          const skip = (page - 1) * limit;¬∑
          const where = role ? { role } : {};¬∑
          const [users, total] = await Promise.all([
            ctx.db.user.findMany({ where, skip, take: limit }),
            ctx.db.user.count({ where })
          ]);¬∑
          return {
            users,
            meta: {
              page,
              limit,
              total,
              total_pages: Math.ceil(total / limit)
            }
          };
        }),¬∑
      // Mutation (POST/PUT/DELETE-like)
      create: protectedProcedure
        .input(z.object({
          name: z.string().min(1),
          email: z.string().email(),
          role: z.enum(['USER', 'ADMIN']).default('USER')
        }))
        .mutation(async ({ input, ctx }) => {
          return ctx.db.user.create({ data: input });
        }),¬∑
      update: protectedProcedure
        .input(z.object({
          id: z.string(),
          name: z.string().optional(),
          email: z.string().email().optional()
        }))
        .mutation(async ({ input, ctx }) => {
          const { id, ...data } = input;¬∑
          // Authorization check
          if (ctx.user.id !== id && ctx.user.role !== 'ADMIN') {
            throw new TRPCError({ code: 'FORBIDDEN' });
          }¬∑
          return ctx.db.user.update({ where: { id }, data });
        }),¬∑
      delete: protectedProcedure
        .input(z.object({ id: z.string() }))
        .mutation(async ({ input, ctx }) => {
          // Only admins can delete
          if (ctx.user.role !== 'ADMIN') {
            throw new TRPCError({ code: 'FORBIDDEN' });
          }¬∑
          return ctx.db.user.delete({ where: { id: input.id } });
        })
    });
    ```¬∑
    ### 2. Root Router¬∑
    ```typescript
    // server/routers/_app.ts
    import { router } from '../trpc';
    import { userRouter } from './user';
    import { postRouter } from './post';¬∑
    export const appRouter = router({
      user: userRouter,
      post: postRouter
    });¬∑
    // Export type for client
    export type AppRouter = typeof appRouter;
    ```¬∑
    ### 3. Client Usage (React)¬∑
    ```typescript
    // client/trpc.ts
    import { createTRPCReact } from '@trpc/react-query';
    import type { AppRouter } from '../server/routers/_app';¬∑
    export const trpc = createTRPCReact<AppRouter>();¬∑
    // components/UserList.tsx
    import { trpc } from '../client/trpc';¬∑
    function UserList() {
      // Full type safety - TypeScript knows the return type!
      const { data, isLoading } = trpc.user.list.useQuery({
        page: 1,
        limit: 20,
        role: 'ADMIN' // TypeScript error if invalid role
      });¬∑
      const createUser = trpc.user.create.useMutation({
        onSuccess: () => {
          // Invalidate and refetch
          trpc.useContext().user.list.invalidate();
        }
      });¬∑
      if (isLoading) return <div>Loading...</div>;¬∑
      return (
        <div>
          {data?.users.map(user => (
            <div key={user.id}>{user.name}</div>
          ))}¬∑
          <button onClick={() => createUser.mutate({
            name: 'John Doe',
            email: 'john@example.com',
            role: 'USER'
          })}>
            Create User
          </button>
        </div>
      );
    }
    ```¬∑
    ### 4. Subscriptions (Real-Time)¬∑
    ```typescript
    // server/routers/user.ts
    export const userRouter = router({
      onUserCreated: publicProcedure
        .subscription(async ({ ctx }) => {
          // Return an observable
          return observable<User>((emit) => {
            const listener = (user: User) => emit.next(user);¬∑
            // Subscribe to event emitter
            ctx.eventEmitter.on('userCreated', listener);¬∑
            // Cleanup
            return () => {
              ctx.eventEmitter.off('userCreated', listener);
            };
          });
        })
    });¬∑
    // client/UserSubscription.tsx
    function UserSubscription() {
      trpc.user.onUserCreated.useSubscription(undefined, {
        onData: (user) => {
          console.log('New user created:', user);
          // Show notification, update UI, etc.
        }
      });¬∑
      return <div>Listening for new users...</div>;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Response Caching¬∑
    ```typescript
    // HTTP caching (REST)
    import { Router } from 'express';¬∑
    router.get('/users/:id', async (req, res) => {
      const user = await db.user.findUnique({ where: { id: req.params.id } });¬∑
      // Cache for 5 minutes
      res.set('Cache-Control', 'public, max-age=300');¬∑
      // ETag for conditional requests
      const etag = `\"${user.updated_at.getTime()}\"`;
      res.set('ETag', etag);¬∑
      // Return 304 Not Modified if ETag matches
      if (req.headers['if-none-match'] === etag) {
        return res.status(304).end();
      }¬∑
      res.json(user);
    });
    ```¬∑
    ### 2. Database Query Optimization¬∑
    ```typescript
    // ‚ùå Bad - N+1 queries
    const users = await db.user.findMany();
    for (const user of users) {
      user.posts = await db.post.findMany({ where: { authorId: user.id } });
    }¬∑
    // ‚úÖ Good - Single query with include
    const users = await db.user.findMany({
      include: { posts: true }
    });¬∑
    // ‚úÖ Good - Select only needed fields
    const users = await db.user.findMany({
      select: {
        id: true,
        name: true,
        email: true
        // Don't fetch unnecessary fields
      }
    });
    ```¬∑
    ### 3. Rate Limiting¬∑
    ```typescript
    import rateLimit from 'express-rate-limit';¬∑
    // Apply to all requests
    const limiter = rateLimit({
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 100, // Limit each IP to 100 requests per windowMs
      message: 'Too many requests from this IP, please try again later'
    });¬∑
    app.use('/api/', limiter);¬∑
    // Stricter limit for auth endpoints
    const authLimiter = rateLimit({
      windowMs: 15 * 60 * 1000,
      max: 5, // Only 5 login attempts per 15 minutes
      skipSuccessfulRequests: true
    });¬∑
    app.post('/api/auth/login', authLimiter, loginHandler);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-openapi.js` - Generate OpenAPI/Swagger docs from code
    - `validate-api-design.js` - Lint API design (naming, status codes)¬∑
    ### references/
    - `references/rest-conventions.md` - REST API naming and HTTP method guidelines
    - `references/graphql-best-practices.md` - GraphQL schema design patterns
    - `references/trpc-patterns.md` - tRPC router organization and error handling
    - `references/api-security.md` - CORS, rate limiting, authentication¬∑
    ### assets/
    - `assets/openapi-templates/` - OpenAPI 3.0 specification templates
    - `assets/postman-collections/` - Example Postman collections¬∑
    ## Related Skills¬∑
    - `auth-security` - OAuth2, JWT, API authentication
    - `schema-optimization` - Database query optimization
    - `testing-strategies` - API testing with Supertest/Playwright
    - `microservices` - API gateway patterns, service mesh
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ auth-security ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: auth-security
    description: Authentication and security patterns using OAuth2/PKCE, JWT (short-lived tokens), OWASP Top 10 mitigation, and rate limiting. Use when implementing auth systems, securing APIs, or addressing security vulnerabilities. Provides defense-in-depth security with industry best practices.
    ---¬∑
    # Authentication & Security¬∑
    ## Overview¬∑
    Comprehensive authentication and security patterns covering OAuth2/PKCE, JWT token management, OWASP Top 10 vulnerabilities, rate limiting, and security headers. Provides defense-in-depth approach to application security.¬∑
    **Goal**: Secure authentication with protection against common vulnerabilities (OWASP Top 10)¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing authentication (OAuth2, JWT, sessions)
    - Securing API endpoints
    - Addressing security vulnerabilities (OWASP Top 10)
    - Implementing rate limiting and DDOS protection
    - Setting up security headers (CSP, HSTS, etc.)
    - Conducting security audits
    - Implementing RBAC (Role-Based Access Control)
    - Migrating from session-based to token-based auth¬∑
    **Triggers**: \"authentication\", \"OAuth2\", \"JWT\", \"security\", \"OWASP\", \"rate limiting\", \"RBAC\", \"security headers\"¬∑
    ---¬∑
    ## Quick Start: Auth Strategy Decision Tree¬∑
    ### When to Use OAuth2 vs JWT vs Sessions¬∑
    **OAuth2/PKCE** (Authorization Framework):
    - ‚úÖ Third-party login (Google, GitHub, etc.)
    - ‚úÖ Mobile apps (PKCE flow for security)
    - ‚úÖ Single Sign-On (SSO)
    - ‚úÖ Delegated authorization
    - ‚úÖ Best for: Social login, multi-app ecosystems, mobile apps¬∑
    **JWT** (Stateless Tokens):
    - ‚úÖ Stateless authentication (no server sessions)
    - ‚úÖ Microservices (token passed between services)
    - ‚úÖ API authentication
    - ‚úÖ Scalability (no session store needed)
    - ‚úÖ Best for: APIs, microservices, mobile backends¬∑
    **Sessions** (Server-side Storage):
    - ‚úÖ Traditional web apps
    - ‚úÖ Easy revocation (server controls sessions)
    - ‚úÖ Smaller payload (only session ID in cookie)
    - ‚úÖ Sensitive data stays server-side
    - ‚úÖ Best for: Traditional MVC apps, high-security requirements¬∑
    **Hybrid** (JWT + Refresh Token):
    - ‚úÖ Short-lived access tokens (15min JWT)
    - ‚úÖ Long-lived refresh tokens (7-30 days, database-backed)
    - ‚úÖ Balance security and UX
    - ‚úÖ Best for: Production apps, balance between stateless and revocability¬∑
    ---¬∑
    ## OAuth2/PKCE Patterns¬∑
    ### 1. Authorization Code Flow with PKCE¬∑
    ```typescript
    // Step 1: Generate PKCE challenge
    import crypto from 'crypto';¬∑
    function generatePKCE() {
      // Code verifier: random string (43-128 characters)
      const codeVerifier = crypto.randomBytes(32).toString('base64url');¬∑
      // Code challenge: SHA256 hash of verifier
      const codeChallenge = crypto
        .createHash('sha256')
        .update(codeVerifier)
        .digest('base64url');¬∑
      return { codeVerifier, codeChallenge };
    }¬∑
    // Step 2: Redirect to authorization URL
    app.get('/auth/google', (req, res) => {
      const { codeVerifier, codeChallenge } = generatePKCE();¬∑
      // Store code_verifier in session (needed for token exchange)
      req.session.codeVerifier = codeVerifier;¬∑
      const authUrl = new URL('https://accounts.google.com/o/oauth2/v2/auth');
      authUrl.searchParams.set('client_id', process.env.GOOGLE_CLIENT_ID!);
      authUrl.searchParams.set('redirect_uri', 'http://localhost:3000/auth/callback');
      authUrl.searchParams.set('response_type', 'code');
      authUrl.searchParams.set('scope', 'openid profile email');
      authUrl.searchParams.set('code_challenge', codeChallenge);
      authUrl.searchParams.set('code_challenge_method', 'S256');¬∑
      res.redirect(authUrl.toString());
    });¬∑
    // Step 3: Handle callback and exchange code for token
    app.get('/auth/callback', async (req, res) => {
      const { code } = req.query;
      const codeVerifier = req.session.codeVerifier;¬∑
      const tokenResponse = await fetch('https://oauth2.googleapis.com/token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          client_id: process.env.GOOGLE_CLIENT_ID,
          code,
          code_verifier: codeVerifier,
          grant_type: 'authorization_code',
          redirect_uri: 'http://localhost:3000/auth/callback'
        })
      });¬∑
      const tokens = await tokenResponse.json();
      const { access_token, id_token, refresh_token } = tokens;¬∑
      // Decode ID token to get user info
      const userInfo = JSON.parse(
        Buffer.from(id_token.split('.')[1], 'base64').toString()
      );¬∑
      req.session.user = userInfo;
      res.redirect('/dashboard');
    });
    ```¬∑
    ---¬∑
    ## JWT Patterns¬∑
    ### 1. JWT Generation & Validation¬∑
    ```typescript
    import jwt from 'jsonwebtoken';¬∑
    const ACCESS_TOKEN_SECRET = process.env.ACCESS_TOKEN_SECRET!;
    const REFRESH_TOKEN_SECRET = process.env.REFRESH_TOKEN_SECRET!;¬∑
    // Generate JWT tokens
    function generateTokens(userId: string) {
      // Access token: short-lived (15 minutes)
      const accessToken = jwt.sign(
        { userId, type: 'access' },
        ACCESS_TOKEN_SECRET,
        { expiresIn: '15m' }
      );¬∑
      // Refresh token: long-lived (7 days), stored in DB
      const refreshToken = jwt.sign(
        { userId, type: 'refresh' },
        REFRESH_TOKEN_SECRET,
        { expiresIn: '7d' }
      );¬∑
      return { accessToken, refreshToken };
    }¬∑
    // Verify JWT
    function verifyAccessToken(token: string) {
      try {
        const payload = jwt.verify(token, ACCESS_TOKEN_SECRET) as { userId: string };
        return payload;
      } catch (error) {
        if (error instanceof jwt.TokenExpiredError) {
          throw new Error('Token expired');
        }
        throw new Error('Invalid token');
      }
    }¬∑
    // Middleware to protect routes
    function authenticateJWT(req, res, next) {
      const authHeader = req.headers.authorization;¬∑
      if (!authHeader?.startsWith('Bearer ')) {
        return res.status(401).json({ error: 'Missing token' });
      }¬∑
      const token = authHeader.substring(7);¬∑
      try {
        const payload = verifyAccessToken(token);
        req.user = payload;
        next();
      } catch (error) {
        return res.status(401).json({ error: error.message });
      }
    }¬∑
    // Usage
    app.get('/api/protected', authenticateJWT, (req, res) => {
      res.json({ message: 'Protected data', userId: req.user.userId });
    });
    ```¬∑
    ### 2. Refresh Token Flow¬∑
    ```typescript
    // Store refresh tokens in database
    interface RefreshToken {
      userId: string;
      token: string;
      expiresAt: Date;
      createdAt: Date;
    }¬∑
    // Login endpoint: generate both tokens
    app.post('/auth/login', async (req, res) => {
      const { email, password } = req.body;¬∑
      // Verify credentials
      const user = await db.user.findUnique({ where: { email } });
      const valid = await bcrypt.compare(password, user.passwordHash);¬∑
      if (!valid) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }¬∑
      // Generate tokens
      const { accessToken, refreshToken } = generateTokens(user.id);¬∑
      // Store refresh token in database
      await db.refreshToken.create({
        data: {
          userId: user.id,
          token: refreshToken,
          expiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000) // 7 days
        }
      });¬∑
      res.json({ accessToken, refreshToken });
    });¬∑
    // Refresh endpoint: exchange refresh token for new access token
    app.post('/auth/refresh', async (req, res) => {
      const { refreshToken } = req.body;¬∑
      // Verify refresh token
      let payload;
      try {
        payload = jwt.verify(refreshToken, REFRESH_TOKEN_SECRET) as { userId: string };
      } catch (error) {
        return res.status(401).json({ error: 'Invalid refresh token' });
      }¬∑
      // Check if refresh token exists in database
      const storedToken = await db.refreshToken.findFirst({
        where: {
          userId: payload.userId,
          token: refreshToken,
          expiresAt: { gt: new Date() }
        }
      });¬∑
      if (!storedToken) {
        return res.status(401).json({ error: 'Refresh token revoked or expired' });
      }¬∑
      // Generate new access token
      const accessToken = jwt.sign(
        { userId: payload.userId, type: 'access' },
        ACCESS_TOKEN_SECRET,
        { expiresIn: '15m' }
      );¬∑
      res.json({ accessToken });
    });¬∑
    // Logout endpoint: revoke refresh token
    app.post('/auth/logout', authenticateJWT, async (req, res) => {
      const { refreshToken } = req.body;¬∑
      await db.refreshToken.deleteMany({
        where: {
          userId: req.user.userId,
          token: refreshToken
        }
      });¬∑
      res.json({ message: 'Logged out' });
    });
    ```¬∑
    ---¬∑
    ## OWASP Top 10 Mitigation¬∑
    ### 1. Injection (SQL, NoSQL, Command)¬∑
    ```typescript
    // ‚ùå Bad - SQL Injection vulnerable
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.query(`SELECT * FROM users WHERE name = '${search}'`);
      res.json(users);
    });¬∑
    // ‚úÖ Good - Parameterized queries
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.query('SELECT * FROM users WHERE name = $1', [search]);
      res.json(users);
    });¬∑
    // ‚úÖ Good - ORM (Prisma)
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.user.findMany({
        where: { name: search }
      });
      res.json(users);
    });
    ```¬∑
    ### 2. Broken Authentication¬∑
    ```typescript
    // ‚úÖ Password hashing with bcrypt
    import bcrypt from 'bcrypt';¬∑
    const SALT_ROUNDS = 12; // Computational cost (higher = slower but more secure)¬∑
    // Hash password before storing
    async function hashPassword(password: string): Promise<string> {
      return bcrypt.hash(password, SALT_ROUNDS);
    }¬∑
    // Verify password
    async function verifyPassword(password: string, hash: string): Promise<boolean> {
      return bcrypt.compare(password, hash);
    }¬∑
    // Rate limit login attempts
    import rateLimit from 'express-rate-limit';¬∑
    const loginLimiter = rateLimit({
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 5, // 5 attempts per window
      message: 'Too many login attempts, please try again later'
    });¬∑
    app.post('/auth/login', loginLimiter, async (req, res) => {
      // Login logic
    });
    ```¬∑
    ### 3. Sensitive Data Exposure¬∑
    ```typescript
    // ‚úÖ Security headers
    import helmet from 'helmet';¬∑
    app.use(helmet()); // Sets multiple security headers¬∑
    // Specific headers:
    app.use(helmet.contentSecurityPolicy({
      directives: {
        defaultSrc: [\"'self'\"],
        scriptSrc: [\"'self'\", \"'unsafe-inline'\"],
        styleSrc: [\"'self'\", \"'unsafe-inline'\"],
        imgSrc: [\"'self'\", 'data:', 'https:']
      }
    }));¬∑
    app.use(helmet.hsts({
      maxAge: 31536000, // 1 year
      includeSubDomains: true,
      preload: true
    }));¬∑
    // ‚úÖ Encrypt sensitive data at rest
    import crypto from 'crypto';¬∑
    const algorithm = 'aes-256-gcm';
    const key = Buffer.from(process.env.ENCRYPTION_KEY!, 'hex'); // 32 bytes¬∑
    function encrypt(text: string): string {
      const iv = crypto.randomBytes(16);
      const cipher = crypto.createCipheriv(algorithm, key, iv);¬∑
      let encrypted = cipher.update(text, 'utf8', 'hex');
      encrypted += cipher.final('hex');¬∑
      const authTag = cipher.getAuthTag();¬∑
      return `${iv.toString('hex')}:${authTag.toString('hex')}:${encrypted}`;
    }¬∑
    function decrypt(encrypted: string): string {
      const [ivHex, authTagHex, encryptedText] = encrypted.split(':');¬∑
      const iv = Buffer.from(ivHex, 'hex');
      const authTag = Buffer.from(authTagHex, 'hex');¬∑
      const decipher = crypto.createDecipheriv(algorithm, key, iv);
      decipher.setAuthTag(authTag);¬∑
      let decrypted = decipher.update(encryptedText, 'hex', 'utf8');
      decrypted += decipher.final('utf8');¬∑
      return decrypted;
    }
    ```¬∑
    ### 4. XML External Entities (XXE)¬∑
    ```typescript
    // ‚úÖ Disable external entities in XML parsing
    import { DOMParser } from 'xmldom';¬∑
    const parser = new DOMParser({
      // Disable external entity resolution
      locator: {},
      errorHandler: {
        warning: () => {},
        error: () => {},
        fatalError: (error) => { throw error; }
      }
    });¬∑
    // Parse XML safely
    function parseXML(xmlString: string) {
      // Remove DOCTYPE declarations (prevents XXE)
      const sanitized = xmlString.replace(/<!DOCTYPE[^>]*>/gi, '');
      return parser.parseFromString(sanitized, 'text/xml');
    }
    ```¬∑
    ### 5. Broken Access Control¬∑
    ```typescript
    // ‚úÖ RBAC (Role-Based Access Control)
    enum Role {
      USER = 'USER',
      ADMIN = 'ADMIN',
      MODERATOR = 'MODERATOR'
    }¬∑
    function requireRole(...allowedRoles: Role[]) {
      return (req, res, next) => {
        if (!req.user) {
          return res.status(401).json({ error: 'Unauthorized' });
        }¬∑
        if (!allowedRoles.includes(req.user.role)) {
          return res.status(403).json({ error: 'Forbidden' });
        }¬∑
        next();
      };
    }¬∑
    // Usage
    app.delete('/api/users/:id', authenticateJWT, requireRole(Role.ADMIN), async (req, res) => {
      // Only admins can delete users
      await db.user.delete({ where: { id: req.params.id } });
      res.json({ message: 'User deleted' });
    });¬∑
    // ‚úÖ Resource ownership check
    app.patch('/api/posts/:id', authenticateJWT, async (req, res) => {
      const post = await db.post.findUnique({ where: { id: req.params.id } });¬∑
      // Check ownership
      if (post.authorId !== req.user.userId && req.user.role !== Role.ADMIN) {
        return res.status(403).json({ error: 'Forbidden' });
      }¬∑
      const updated = await db.post.update({
        where: { id: req.params.id },
        data: req.body
      });¬∑
      res.json(updated);
    });
    ```¬∑
    ### 6. Security Misconfiguration¬∑
    ```typescript
    // ‚úÖ Environment-specific configuration
    const config = {
      development: {
        cors: { origin: '*' },
        logging: 'debug',
        rateLimit: { max: 1000 }
      },
      production: {
        cors: { origin: process.env.ALLOWED_ORIGINS!.split(',') },
        logging: 'error',
        rateLimit: { max: 100 }
      }
    };¬∑
    const env = process.env.NODE_ENV || 'development';
    app.use(cors(config[env].cors));
    ```¬∑
    ### 7. Cross-Site Scripting (XSS)¬∑
    ```typescript
    // ‚úÖ Input sanitization
    import DOMPurify from 'isomorphic-dompurify';¬∑
    app.post('/api/posts', authenticateJWT, async (req, res) => {
      const { title, content } = req.body;¬∑
      // Sanitize HTML content
      const sanitizedContent = DOMPurify.sanitize(content, {
        ALLOWED_TAGS: ['p', 'br', 'strong', 'em', 'a'],
        ALLOWED_ATTR: ['href']
      });¬∑
      const post = await db.post.create({
        data: {
          title,
          content: sanitizedContent,
          authorId: req.user.userId
        }
      });¬∑
      res.json(post);
    });¬∑
    // ‚úÖ CSP header (prevents inline scripts)
    app.use(helmet.contentSecurityPolicy({
      directives: {
        defaultSrc: [\"'self'\"],
        scriptSrc: [\"'self'\"], // No 'unsafe-inline'
        objectSrc: [\"'none'\"]
      }
    }));
    ```¬∑
    ### 8. Insecure Deserialization¬∑
    ```typescript
    // ‚ùå Bad - eval() is dangerous
    app.post('/api/execute', (req, res) => {
      const result = eval(req.body.code); // NEVER DO THIS
      res.json({ result });
    });¬∑
    // ‚úÖ Good - Use JSON.parse with validation
    import { z } from 'zod';¬∑
    const userSchema = z.object({
      name: z.string().min(1).max(100),
      email: z.string().email(),
      age: z.number().int().positive()
    });¬∑
    app.post('/api/users', async (req, res) => {
      try {
        const validated = userSchema.parse(req.body);
        const user = await db.user.create({ data: validated });
        res.json(user);
      } catch (error) {
        res.status(400).json({ error: 'Validation failed', details: error.errors });
      }
    });
    ```¬∑
    ---¬∑
    ## Rate Limiting & DDOS Protection¬∑
    ### 1. Express Rate Limiting¬∑
    ```typescript
    import rateLimit from 'express-rate-limit';
    import RedisStore from 'rate-limit-redis';
    import Redis from 'ioredis';¬∑
    const redis = new Redis();¬∑
    // Global rate limit
    const globalLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:global:'
      }),
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 100, // 100 requests per window
      message: 'Too many requests, please try again later'
    });¬∑
    app.use('/api/', globalLimiter);¬∑
    // Stricter limit for auth endpoints
    const authLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:auth:'
      }),
      windowMs: 15 * 60 * 1000,
      max: 5,
      skipSuccessfulRequests: true // Only count failed attempts
    });¬∑
    app.post('/auth/login', authLimiter, loginHandler);¬∑
    // Per-user rate limit
    const userLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:user:'
      }),
      windowMs: 60 * 1000, // 1 minute
      max: 60, // 60 requests per minute per user
      keyGenerator: (req) => req.user?.userId || req.ip
    });¬∑
    app.use('/api/', authenticateJWT, userLimiter);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `security-audit.js` - Run automated security audit (npm audit + OWASP ZAP)
    - `generate-secrets.js` - Generate secure random secrets for JWT/encryption¬∑
    ### references/
    - `references/owasp-top-10.md` - OWASP Top 10 vulnerabilities with examples
    - `references/oauth2-flows.md` - OAuth2 flow diagrams and implementations
    - `references/jwt-best-practices.md` - JWT security patterns and anti-patterns
    - `references/security-headers.md` - Complete security headers reference¬∑
    ### assets/
    - `assets/security-checklists/` - Pre-deployment security checklists
    - `assets/zap-configs/` - OWASP ZAP scan configurations¬∑
    ## Related Skills¬∑
    - `api-design` - API authentication patterns
    - `schema-optimization` - Database security (RLS policies)
    - `testing-strategies` - Security testing with Playwright
    - `rls-policies` - Row-level security in PostgreSQL
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ auth-security ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: auth-security
    description: Authentication and security patterns using OAuth2/PKCE, JWT (short-lived tokens), OWASP Top 10 mitigation, and rate limiting. Use when implementing auth systems, securing APIs, or addressing security vulnerabilities. Provides defense-in-depth security with industry best practices.
    ---¬∑
    # Authentication & Security¬∑
    ## Overview¬∑
    Comprehensive authentication and security patterns covering OAuth2/PKCE, JWT token management, OWASP Top 10 vulnerabilities, rate limiting, and security headers. Provides defense-in-depth approach to application security.¬∑
    **Goal**: Secure authentication with protection against common vulnerabilities (OWASP Top 10)¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing authentication (OAuth2, JWT, sessions)
    - Securing API endpoints
    - Addressing security vulnerabilities (OWASP Top 10)
    - Implementing rate limiting and DDOS protection
    - Setting up security headers (CSP, HSTS, etc.)
    - Conducting security audits
    - Implementing RBAC (Role-Based Access Control)
    - Migrating from session-based to token-based auth¬∑
    **Triggers**: \"authentication\", \"OAuth2\", \"JWT\", \"security\", \"OWASP\", \"rate limiting\", \"RBAC\", \"security headers\"¬∑
    ---¬∑
    ## Quick Start: Auth Strategy Decision Tree¬∑
    ### When to Use OAuth2 vs JWT vs Sessions¬∑
    **OAuth2/PKCE** (Authorization Framework):
    - ‚úÖ Third-party login (Google, GitHub, etc.)
    - ‚úÖ Mobile apps (PKCE flow for security)
    - ‚úÖ Single Sign-On (SSO)
    - ‚úÖ Delegated authorization
    - ‚úÖ Best for: Social login, multi-app ecosystems, mobile apps¬∑
    **JWT** (Stateless Tokens):
    - ‚úÖ Stateless authentication (no server sessions)
    - ‚úÖ Microservices (token passed between services)
    - ‚úÖ API authentication
    - ‚úÖ Scalability (no session store needed)
    - ‚úÖ Best for: APIs, microservices, mobile backends¬∑
    **Sessions** (Server-side Storage):
    - ‚úÖ Traditional web apps
    - ‚úÖ Easy revocation (server controls sessions)
    - ‚úÖ Smaller payload (only session ID in cookie)
    - ‚úÖ Sensitive data stays server-side
    - ‚úÖ Best for: Traditional MVC apps, high-security requirements¬∑
    **Hybrid** (JWT + Refresh Token):
    - ‚úÖ Short-lived access tokens (15min JWT)
    - ‚úÖ Long-lived refresh tokens (7-30 days, database-backed)
    - ‚úÖ Balance security and UX
    - ‚úÖ Best for: Production apps, balance between stateless and revocability¬∑
    ---¬∑
    ## OAuth2/PKCE Patterns¬∑
    ### 1. Authorization Code Flow with PKCE¬∑
    ```typescript
    // Step 1: Generate PKCE challenge
    import crypto from 'crypto';¬∑
    function generatePKCE() {
      // Code verifier: random string (43-128 characters)
      const codeVerifier = crypto.randomBytes(32).toString('base64url');¬∑
      // Code challenge: SHA256 hash of verifier
      const codeChallenge = crypto
        .createHash('sha256')
        .update(codeVerifier)
        .digest('base64url');¬∑
      return { codeVerifier, codeChallenge };
    }¬∑
    // Step 2: Redirect to authorization URL
    app.get('/auth/google', (req, res) => {
      const { codeVerifier, codeChallenge } = generatePKCE();¬∑
      // Store code_verifier in session (needed for token exchange)
      req.session.codeVerifier = codeVerifier;¬∑
      const authUrl = new URL('https://accounts.google.com/o/oauth2/v2/auth');
      authUrl.searchParams.set('client_id', process.env.GOOGLE_CLIENT_ID!);
      authUrl.searchParams.set('redirect_uri', 'http://localhost:3000/auth/callback');
      authUrl.searchParams.set('response_type', 'code');
      authUrl.searchParams.set('scope', 'openid profile email');
      authUrl.searchParams.set('code_challenge', codeChallenge);
      authUrl.searchParams.set('code_challenge_method', 'S256');¬∑
      res.redirect(authUrl.toString());
    });¬∑
    // Step 3: Handle callback and exchange code for token
    app.get('/auth/callback', async (req, res) => {
      const { code } = req.query;
      const codeVerifier = req.session.codeVerifier;¬∑
      const tokenResponse = await fetch('https://oauth2.googleapis.com/token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          client_id: process.env.GOOGLE_CLIENT_ID,
          code,
          code_verifier: codeVerifier,
          grant_type: 'authorization_code',
          redirect_uri: 'http://localhost:3000/auth/callback'
        })
      });¬∑
      const tokens = await tokenResponse.json();
      const { access_token, id_token, refresh_token } = tokens;¬∑
      // Decode ID token to get user info
      const userInfo = JSON.parse(
        Buffer.from(id_token.split('.')[1], 'base64').toString()
      );¬∑
      req.session.user = userInfo;
      res.redirect('/dashboard');
    });
    ```¬∑
    ---¬∑
    ## JWT Patterns¬∑
    ### 1. JWT Generation & Validation¬∑
    ```typescript
    import jwt from 'jsonwebtoken';¬∑
    const ACCESS_TOKEN_SECRET = process.env.ACCESS_TOKEN_SECRET!;
    const REFRESH_TOKEN_SECRET = process.env.REFRESH_TOKEN_SECRET!;¬∑
    // Generate JWT tokens
    function generateTokens(userId: string) {
      // Access token: short-lived (15 minutes)
      const accessToken = jwt.sign(
        { userId, type: 'access' },
        ACCESS_TOKEN_SECRET,
        { expiresIn: '15m' }
      );¬∑
      // Refresh token: long-lived (7 days), stored in DB
      const refreshToken = jwt.sign(
        { userId, type: 'refresh' },
        REFRESH_TOKEN_SECRET,
        { expiresIn: '7d' }
      );¬∑
      return { accessToken, refreshToken };
    }¬∑
    // Verify JWT
    function verifyAccessToken(token: string) {
      try {
        const payload = jwt.verify(token, ACCESS_TOKEN_SECRET) as { userId: string };
        return payload;
      } catch (error) {
        if (error instanceof jwt.TokenExpiredError) {
          throw new Error('Token expired');
        }
        throw new Error('Invalid token');
      }
    }¬∑
    // Middleware to protect routes
    function authenticateJWT(req, res, next) {
      const authHeader = req.headers.authorization;¬∑
      if (!authHeader?.startsWith('Bearer ')) {
        return res.status(401).json({ error: 'Missing token' });
      }¬∑
      const token = authHeader.substring(7);¬∑
      try {
        const payload = verifyAccessToken(token);
        req.user = payload;
        next();
      } catch (error) {
        return res.status(401).json({ error: error.message });
      }
    }¬∑
    // Usage
    app.get('/api/protected', authenticateJWT, (req, res) => {
      res.json({ message: 'Protected data', userId: req.user.userId });
    });
    ```¬∑
    ### 2. Refresh Token Flow¬∑
    ```typescript
    // Store refresh tokens in database
    interface RefreshToken {
      userId: string;
      token: string;
      expiresAt: Date;
      createdAt: Date;
    }¬∑
    // Login endpoint: generate both tokens
    app.post('/auth/login', async (req, res) => {
      const { email, password } = req.body;¬∑
      // Verify credentials
      const user = await db.user.findUnique({ where: { email } });
      const valid = await bcrypt.compare(password, user.passwordHash);¬∑
      if (!valid) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }¬∑
      // Generate tokens
      const { accessToken, refreshToken } = generateTokens(user.id);¬∑
      // Store refresh token in database
      await db.refreshToken.create({
        data: {
          userId: user.id,
          token: refreshToken,
          expiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000) // 7 days
        }
      });¬∑
      res.json({ accessToken, refreshToken });
    });¬∑
    // Refresh endpoint: exchange refresh token for new access token
    app.post('/auth/refresh', async (req, res) => {
      const { refreshToken } = req.body;¬∑
      // Verify refresh token
      let payload;
      try {
        payload = jwt.verify(refreshToken, REFRESH_TOKEN_SECRET) as { userId: string };
      } catch (error) {
        return res.status(401).json({ error: 'Invalid refresh token' });
      }¬∑
      // Check if refresh token exists in database
      const storedToken = await db.refreshToken.findFirst({
        where: {
          userId: payload.userId,
          token: refreshToken,
          expiresAt: { gt: new Date() }
        }
      });¬∑
      if (!storedToken) {
        return res.status(401).json({ error: 'Refresh token revoked or expired' });
      }¬∑
      // Generate new access token
      const accessToken = jwt.sign(
        { userId: payload.userId, type: 'access' },
        ACCESS_TOKEN_SECRET,
        { expiresIn: '15m' }
      );¬∑
      res.json({ accessToken });
    });¬∑
    // Logout endpoint: revoke refresh token
    app.post('/auth/logout', authenticateJWT, async (req, res) => {
      const { refreshToken } = req.body;¬∑
      await db.refreshToken.deleteMany({
        where: {
          userId: req.user.userId,
          token: refreshToken
        }
      });¬∑
      res.json({ message: 'Logged out' });
    });
    ```¬∑
    ---¬∑
    ## OWASP Top 10 Mitigation¬∑
    ### 1. Injection (SQL, NoSQL, Command)¬∑
    ```typescript
    // ‚ùå Bad - SQL Injection vulnerable
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.query(`SELECT * FROM users WHERE name = '${search}'`);
      res.json(users);
    });¬∑
    // ‚úÖ Good - Parameterized queries
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.query('SELECT * FROM users WHERE name = $1', [search]);
      res.json(users);
    });¬∑
    // ‚úÖ Good - ORM (Prisma)
    app.get('/users', async (req, res) => {
      const { search } = req.query;
      const users = await db.user.findMany({
        where: { name: search }
      });
      res.json(users);
    });
    ```¬∑
    ### 2. Broken Authentication¬∑
    ```typescript
    // ‚úÖ Password hashing with bcrypt
    import bcrypt from 'bcrypt';¬∑
    const SALT_ROUNDS = 12; // Computational cost (higher = slower but more secure)¬∑
    // Hash password before storing
    async function hashPassword(password: string): Promise<string> {
      return bcrypt.hash(password, SALT_ROUNDS);
    }¬∑
    // Verify password
    async function verifyPassword(password: string, hash: string): Promise<boolean> {
      return bcrypt.compare(password, hash);
    }¬∑
    // Rate limit login attempts
    import rateLimit from 'express-rate-limit';¬∑
    const loginLimiter = rateLimit({
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 5, // 5 attempts per window
      message: 'Too many login attempts, please try again later'
    });¬∑
    app.post('/auth/login', loginLimiter, async (req, res) => {
      // Login logic
    });
    ```¬∑
    ### 3. Sensitive Data Exposure¬∑
    ```typescript
    // ‚úÖ Security headers
    import helmet from 'helmet';¬∑
    app.use(helmet()); // Sets multiple security headers¬∑
    // Specific headers:
    app.use(helmet.contentSecurityPolicy({
      directives: {
        defaultSrc: [\"'self'\"],
        scriptSrc: [\"'self'\", \"'unsafe-inline'\"],
        styleSrc: [\"'self'\", \"'unsafe-inline'\"],
        imgSrc: [\"'self'\", 'data:', 'https:']
      }
    }));¬∑
    app.use(helmet.hsts({
      maxAge: 31536000, // 1 year
      includeSubDomains: true,
      preload: true
    }));¬∑
    // ‚úÖ Encrypt sensitive data at rest
    import crypto from 'crypto';¬∑
    const algorithm = 'aes-256-gcm';
    const key = Buffer.from(process.env.ENCRYPTION_KEY!, 'hex'); // 32 bytes¬∑
    function encrypt(text: string): string {
      const iv = crypto.randomBytes(16);
      const cipher = crypto.createCipheriv(algorithm, key, iv);¬∑
      let encrypted = cipher.update(text, 'utf8', 'hex');
      encrypted += cipher.final('hex');¬∑
      const authTag = cipher.getAuthTag();¬∑
      return `${iv.toString('hex')}:${authTag.toString('hex')}:${encrypted}`;
    }¬∑
    function decrypt(encrypted: string): string {
      const [ivHex, authTagHex, encryptedText] = encrypted.split(':');¬∑
      const iv = Buffer.from(ivHex, 'hex');
      const authTag = Buffer.from(authTagHex, 'hex');¬∑
      const decipher = crypto.createDecipheriv(algorithm, key, iv);
      decipher.setAuthTag(authTag);¬∑
      let decrypted = decipher.update(encryptedText, 'hex', 'utf8');
      decrypted += decipher.final('utf8');¬∑
      return decrypted;
    }
    ```¬∑
    ### 4. XML External Entities (XXE)¬∑
    ```typescript
    // ‚úÖ Disable external entities in XML parsing
    import { DOMParser } from 'xmldom';¬∑
    const parser = new DOMParser({
      // Disable external entity resolution
      locator: {},
      errorHandler: {
        warning: () => {},
        error: () => {},
        fatalError: (error) => { throw error; }
      }
    });¬∑
    // Parse XML safely
    function parseXML(xmlString: string) {
      // Remove DOCTYPE declarations (prevents XXE)
      const sanitized = xmlString.replace(/<!DOCTYPE[^>]*>/gi, '');
      return parser.parseFromString(sanitized, 'text/xml');
    }
    ```¬∑
    ### 5. Broken Access Control¬∑
    ```typescript
    // ‚úÖ RBAC (Role-Based Access Control)
    enum Role {
      USER = 'USER',
      ADMIN = 'ADMIN',
      MODERATOR = 'MODERATOR'
    }¬∑
    function requireRole(...allowedRoles: Role[]) {
      return (req, res, next) => {
        if (!req.user) {
          return res.status(401).json({ error: 'Unauthorized' });
        }¬∑
        if (!allowedRoles.includes(req.user.role)) {
          return res.status(403).json({ error: 'Forbidden' });
        }¬∑
        next();
      };
    }¬∑
    // Usage
    app.delete('/api/users/:id', authenticateJWT, requireRole(Role.ADMIN), async (req, res) => {
      // Only admins can delete users
      await db.user.delete({ where: { id: req.params.id } });
      res.json({ message: 'User deleted' });
    });¬∑
    // ‚úÖ Resource ownership check
    app.patch('/api/posts/:id', authenticateJWT, async (req, res) => {
      const post = await db.post.findUnique({ where: { id: req.params.id } });¬∑
      // Check ownership
      if (post.authorId !== req.user.userId && req.user.role !== Role.ADMIN) {
        return res.status(403).json({ error: 'Forbidden' });
      }¬∑
      const updated = await db.post.update({
        where: { id: req.params.id },
        data: req.body
      });¬∑
      res.json(updated);
    });
    ```¬∑
    ### 6. Security Misconfiguration¬∑
    ```typescript
    // ‚úÖ Environment-specific configuration
    const config = {
      development: {
        cors: { origin: '*' },
        logging: 'debug',
        rateLimit: { max: 1000 }
      },
      production: {
        cors: { origin: process.env.ALLOWED_ORIGINS!.split(',') },
        logging: 'error',
        rateLimit: { max: 100 }
      }
    };¬∑
    const env = process.env.NODE_ENV || 'development';
    app.use(cors(config[env].cors));
    ```¬∑
    ### 7. Cross-Site Scripting (XSS)¬∑
    ```typescript
    // ‚úÖ Input sanitization
    import DOMPurify from 'isomorphic-dompurify';¬∑
    app.post('/api/posts', authenticateJWT, async (req, res) => {
      const { title, content } = req.body;¬∑
      // Sanitize HTML content
      const sanitizedContent = DOMPurify.sanitize(content, {
        ALLOWED_TAGS: ['p', 'br', 'strong', 'em', 'a'],
        ALLOWED_ATTR: ['href']
      });¬∑
      const post = await db.post.create({
        data: {
          title,
          content: sanitizedContent,
          authorId: req.user.userId
        }
      });¬∑
      res.json(post);
    });¬∑
    // ‚úÖ CSP header (prevents inline scripts)
    app.use(helmet.contentSecurityPolicy({
      directives: {
        defaultSrc: [\"'self'\"],
        scriptSrc: [\"'self'\"], // No 'unsafe-inline'
        objectSrc: [\"'none'\"]
      }
    }));
    ```¬∑
    ### 8. Insecure Deserialization¬∑
    ```typescript
    // ‚ùå Bad - eval() is dangerous
    app.post('/api/execute', (req, res) => {
      const result = eval(req.body.code); // NEVER DO THIS
      res.json({ result });
    });¬∑
    // ‚úÖ Good - Use JSON.parse with validation
    import { z } from 'zod';¬∑
    const userSchema = z.object({
      name: z.string().min(1).max(100),
      email: z.string().email(),
      age: z.number().int().positive()
    });¬∑
    app.post('/api/users', async (req, res) => {
      try {
        const validated = userSchema.parse(req.body);
        const user = await db.user.create({ data: validated });
        res.json(user);
      } catch (error) {
        res.status(400).json({ error: 'Validation failed', details: error.errors });
      }
    });
    ```¬∑
    ---¬∑
    ## Rate Limiting & DDOS Protection¬∑
    ### 1. Express Rate Limiting¬∑
    ```typescript
    import rateLimit from 'express-rate-limit';
    import RedisStore from 'rate-limit-redis';
    import Redis from 'ioredis';¬∑
    const redis = new Redis();¬∑
    // Global rate limit
    const globalLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:global:'
      }),
      windowMs: 15 * 60 * 1000, // 15 minutes
      max: 100, // 100 requests per window
      message: 'Too many requests, please try again later'
    });¬∑
    app.use('/api/', globalLimiter);¬∑
    // Stricter limit for auth endpoints
    const authLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:auth:'
      }),
      windowMs: 15 * 60 * 1000,
      max: 5,
      skipSuccessfulRequests: true // Only count failed attempts
    });¬∑
    app.post('/auth/login', authLimiter, loginHandler);¬∑
    // Per-user rate limit
    const userLimiter = rateLimit({
      store: new RedisStore({
        client: redis,
        prefix: 'rl:user:'
      }),
      windowMs: 60 * 1000, // 1 minute
      max: 60, // 60 requests per minute per user
      keyGenerator: (req) => req.user?.userId || req.ip
    });¬∑
    app.use('/api/', authenticateJWT, userLimiter);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `security-audit.js` - Run automated security audit (npm audit + OWASP ZAP)
    - `generate-secrets.js` - Generate secure random secrets for JWT/encryption¬∑
    ### references/
    - `references/owasp-top-10.md` - OWASP Top 10 vulnerabilities with examples
    - `references/oauth2-flows.md` - OAuth2 flow diagrams and implementations
    - `references/jwt-best-practices.md` - JWT security patterns and anti-patterns
    - `references/security-headers.md` - Complete security headers reference¬∑
    ### assets/
    - `assets/security-checklists/` - Pre-deployment security checklists
    - `assets/zap-configs/` - OWASP ZAP scan configurations¬∑
    ## Related Skills¬∑
    - `api-design` - API authentication patterns
    - `schema-optimization` - Database security (RLS policies)
    - `testing-strategies` - Security testing with Playwright
    - `rls-policies` - Row-level security in PostgreSQL
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ microservices ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: microservices
    description: Microservices architecture patterns using service mesh (Istio/Linkerd), API gateways (Kong/APISIX), and event-driven communication (Kafka/RabbitMQ). Use when building distributed systems requiring independent scaling, polyglot persistence, and team autonomy. Enables fault isolation and technology diversity.
    ---¬∑
    # Microservices Architecture¬∑
    ## Overview¬∑
    Microservices architecture patterns for building scalable, distributed systems with independent services, API gateways, service mesh, and event-driven communication. Enables independent deployments, technology flexibility, and fault isolation while maintaining system coherence.¬∑
    **Goal**: Independent service deployments with reliable inter-service communication¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Large teams need independent service ownership
    - Different services require different technologies
    - Independent scaling requirements per service
    - Fault isolation critical for availability
    - Gradual migration from monolith needed
    - High traffic requiring horizontal scaling
    - Different data storage needs per service
    - Team autonomy and DevOps culture established¬∑
    **Triggers**: \"microservices\", \"service mesh\", \"API gateway\", \"event-driven\", \"distributed systems\", \"service discovery\", \"circuit breaker\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Microservices vs Monolith vs Serverless¬∑
    **Microservices**:
    - ‚úÖ Independent scaling per service
    - ‚úÖ Technology diversity (polyglot)
    - ‚úÖ Fault isolation (one service fails, others continue)
    - ‚úÖ Team autonomy (own entire service lifecycle)
    - ‚úÖ Large teams (10+ engineers)
    - ‚úÖ Best for: High-traffic apps, complex domains, large teams¬∑
    **Monolith**:
    - ‚úÖ Simpler deployment (one artifact)
    - ‚úÖ Easier debugging (single process)
    - ‚úÖ Lower latency (no network calls)
    - ‚úÖ Simpler testing (no distributed complexity)
    - ‚úÖ Best for: Small teams (<10), early-stage startups, simple domains¬∑
    **Serverless**:
    - ‚úÖ Zero infrastructure management
    - ‚úÖ Auto-scaling (pay per request)
    - ‚úÖ Low operational overhead
    - ‚úÖ Best for: Event-driven workloads, sporadic traffic, lightweight APIs¬∑
    **Hybrid** (Microservices + Serverless):
    - ‚úÖ Core services as microservices
    - ‚úÖ Background jobs as serverless functions
    - ‚úÖ Best for: Production systems with mixed workloads¬∑
    ---¬∑
    ## Service Communication Patterns¬∑
    ### 1. Synchronous (REST/gRPC)¬∑
    ```typescript
    // REST API call between services
    // Order service ‚Üí Inventory service
    import axios from 'axios';¬∑
    class OrderService {
      async createOrder(items: OrderItem[]) {
        // Check inventory availability
        const inventoryResponse = await axios.post(
          'http://inventory-service:3001/api/check',
          { items },
          { timeout: 5000 }  // Timeout protection
        );¬∑
        if (!inventoryResponse.data.available) {
          throw new Error('Items not available');
        }¬∑
        // Create order
        const order = await this.db.orders.create({ items });
        return order;
      }
    }
    ```¬∑
    ```protobuf
    // gRPC for high-performance inter-service calls
    // inventory.proto
    syntax = \"proto3\";¬∑
    service InventoryService {
      rpc CheckAvailability (CheckRequest) returns (CheckResponse);
    }¬∑
    message CheckRequest {
      repeated string product_ids = 1;
    }¬∑
    message CheckResponse {
      bool available = 1;
      repeated string unavailable_items = 2;
    }
    ```¬∑
    ```typescript
    // gRPC client
    import { InventoryServiceClient } from './proto/inventory_grpc_pb';
    import { CheckRequest } from './proto/inventory_pb';¬∑
    const client = new InventoryServiceClient(
      'inventory-service:50051',
      grpc.credentials.createInsecure()
    );¬∑
    const request = new CheckRequest();
    request.setProductIdsList(['prod-1', 'prod-2']);¬∑
    client.checkAvailability(request, (err, response) => {
      if (err) throw err;
      console.log('Available:', response.getAvailable());
    });
    ```¬∑
    ### 2. Asynchronous (Event-Driven)¬∑
    ```typescript
    // Kafka producer (Order service)
    import { Kafka } from 'kafkajs';¬∑
    const kafka = new Kafka({
      clientId: 'order-service',
      brokers: ['kafka:9092']
    });¬∑
    const producer = kafka.producer();¬∑
    async function publishOrderCreated(order: Order) {
      await producer.connect();¬∑
      await producer.send({
        topic: 'order.created',
        messages: [
          {
            key: order.id,
            value: JSON.stringify({
              order_id: order.id,
              user_id: order.user_id,
              items: order.items,
              total: order.total,
              timestamp: new Date().toISOString()
            })
          }
        ]
      });¬∑
      await producer.disconnect();
    }
    ```¬∑
    ```typescript
    // Kafka consumer (Notification service)
    const consumer = kafka.consumer({ groupId: 'notification-service' });¬∑
    async function startConsumer() {
      await consumer.connect();
      await consumer.subscribe({ topic: 'order.created', fromBeginning: false });¬∑
      await consumer.run({
        eachMessage: async ({ topic, partition, message }) => {
          const order = JSON.parse(message.value.toString());¬∑
          // Send notification
          await sendEmail(order.user_id, {
            subject: 'Order Confirmed',
            body: `Your order ${order.order_id} has been confirmed.`
          });
        }
      });
    }
    ```¬∑
    ### 3. Request-Reply Pattern¬∑
    ```typescript
    // RabbitMQ RPC pattern
    import amqp from 'amqplib';¬∑
    class RPCClient {
      private connection: amqp.Connection;
      private channel: amqp.Channel;
      private replyQueue: string;¬∑
      async call(queue: string, message: any): Promise<any> {
        const correlationId = generateUUID();¬∑
        return new Promise((resolve) => {
          // Listen for reply
          this.channel.consume(this.replyQueue, (msg) => {
            if (msg.properties.correlationId === correlationId) {
              resolve(JSON.parse(msg.content.toString()));
              this.channel.ack(msg);
            }
          }, { noAck: false });¬∑
          // Send request
          this.channel.sendToQueue(queue, Buffer.from(JSON.stringify(message)), {
            correlationId,
            replyTo: this.replyQueue
          });
        });
      }
    }¬∑
    // Usage
    const client = new RPCClient();
    const result = await client.call('inventory.check', { items: ['item-1'] });
    ```¬∑
    ---¬∑
    ## Service Mesh (Istio/Linkerd)¬∑
    ### 1. Istio Setup¬∑
    ```yaml
    # Install Istio
    kubectl apply -f https://istio.io/latest/istio-operator.yaml¬∑
    # Enable sidecar injection for namespace
    kubectl label namespace default istio-injection=enabled¬∑
    # Deploy service with Istio sidecar
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service
    spec:
      replicas: 3
      template:
        metadata:
          labels:
            app: order-service
            version: v1
        spec:
          containers:
          - name: order-service
            image: order-service:latest
            ports:
            - containerPort: 3000
    ```¬∑
    ### 2. Traffic Management¬∑
    ```yaml
    # Virtual Service - Route traffic based on headers
    apiVersion: networking.istio.io/v1beta1
    kind: VirtualService
    metadata:
      name: order-service
    spec:
      hosts:
      - order-service
      http:
      - match:
        - headers:
            version:
              exact: \"v2\"
        route:
        - destination:
            host: order-service
            subset: v2
      - route:
        - destination:
            host: order-service
            subset: v1
          weight: 90
        - destination:
            host: order-service
            subset: v2
          weight: 10  # Canary deployment: 10% to v2
    ```¬∑
    ### 3. Circuit Breaker¬∑
    ```yaml
    # Destination Rule - Circuit breaker for resilience
    apiVersion: networking.istio.io/v1beta1
    kind: DestinationRule
    metadata:
      name: inventory-service
    spec:
      host: inventory-service
      trafficPolicy:
        connectionPool:
          tcp:
            maxConnections: 100
          http:
            http1MaxPendingRequests: 50
            http2MaxRequests: 100
            maxRequestsPerConnection: 2
        outlierDetection:
          consecutiveErrors: 5
          interval: 30s
          baseEjectionTime: 30s
          maxEjectionPercent: 50
          minHealthPercent: 40
    ```¬∑
    ### 4. Observability (Distributed Tracing)¬∑
    ```typescript
    // Automatic distributed tracing via Istio sidecars
    // No code changes needed - Istio injects trace headers¬∑
    // View traces in Jaeger
    kubectl port-forward -n istio-system svc/jaeger-query 16686:16686¬∑
    // Manual instrumentation (optional)
    import { trace, context } from '@opentelemetry/api';¬∑
    const tracer = trace.getTracer('order-service');¬∑
    async function createOrder(items: OrderItem[]) {
      const span = tracer.startSpan('createOrder');¬∑
      try {
        // Span automatically propagated to downstream services
        const order = await orderRepository.create(items);
        span.setAttributes({ orderId: order.id });
        return order;
      } finally {
        span.end();
      }
    }
    ```¬∑
    ---¬∑
    ## API Gateway Patterns¬∑
    ### 1. Kong Gateway¬∑
    ```yaml
    # Kong ingress for API gateway
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: api-gateway
      annotations:
        konghq.com/strip-path: \"true\"
        konghq.com/plugins: rate-limiting, jwt, cors
    spec:
      ingressClassName: kong
      rules:
      - host: api.example.com
        http:
          paths:
          - path: /orders
            pathType: Prefix
            backend:
              service:
                name: order-service
                port:
                  number: 3000
          - path: /inventory
            pathType: Prefix
            backend:
              service:
                name: inventory-service
                port:
                  number: 3001
    ```¬∑
    ```yaml
    # Kong Plugin - Rate limiting
    apiVersion: configuration.konghq.com/v1
    kind: KongPlugin
    metadata:
      name: rate-limiting
    plugin: rate-limiting
    config:
      minute: 100
      policy: local
      limit_by: consumer
    ```¬∑
    ```yaml
    # Kong Plugin - JWT authentication
    apiVersion: configuration.konghq.com/v1
    kind: KongPlugin
    metadata:
      name: jwt
    plugin: jwt
    config:
      uri_param_names:
        - jwt
      claims_to_verify:
        - exp
    ```¬∑
    ### 2. APISIX Gateway¬∑
    ```yaml
    # APISIX route configuration
    routes:
      - id: order-route
        uri: /api/orders/*
        upstream:
          type: roundrobin
          nodes:
            \"order-service:3000\": 1
        plugins:
          limit-req:
            rate: 100
            burst: 50
            rejected_code: 429
          jwt-auth: {}
          prometheus: {}¬∑
      - id: inventory-route
        uri: /api/inventory/*
        upstream:
          type: roundrobin
          nodes:
            \"inventory-service-v1:3001\": 90
            \"inventory-service-v2:3001\": 10  # Canary
        plugins:
          limit-req:
            rate: 200
            burst: 100
    ```¬∑
    ### 3. GraphQL Federation (Apollo Gateway)¬∑
    ```typescript
    // Apollo Gateway - Federated GraphQL across microservices
    import { ApolloGateway, IntrospectAndCompose } from '@apollo/gateway';
    import { ApolloServer } from 'apollo-server';¬∑
    const gateway = new ApolloGateway({
      supergraphSdl: new IntrospectAndCompose({
        subgraphs: [
          { name: 'orders', url: 'http://order-service:4000/graphql' },
          { name: 'inventory', url: 'http://inventory-service:4001/graphql' },
          { name: 'users', url: 'http://user-service:4002/graphql' }
        ]
      })
    });¬∑
    const server = new ApolloServer({
      gateway,
      subscriptions: false
    });¬∑
    server.listen(4000);
    ```¬∑
    ```typescript
    // Order service - Federated schema
    import { buildSubgraphSchema } from '@apollo/subgraph';
    import { gql } from 'apollo-server';¬∑
    const typeDefs = gql`
      extend type User @key(fields: \"id\") {
        id: ID! @external
        orders: [Order!]!
      }¬∑
      type Order @key(fields: \"id\") {
        id: ID!
        user: User!
        items: [OrderItem!]!
        total: Float!
      }¬∑
      type Query {
        order(id: ID!): Order
      }
    `;¬∑
    const resolvers = {
      User: {
        orders(user) {
          return getOrdersByUserId(user.id);
        }
      }
    };¬∑
    export const schema = buildSubgraphSchema({ typeDefs, resolvers });
    ```¬∑
    ---¬∑
    ## Service Discovery¬∑
    ### 1. Kubernetes Service Discovery¬∑
    ```typescript
    // Automatic service discovery via Kubernetes DNS
    // No library needed - use service names directly¬∑
    const INVENTORY_SERVICE_URL = 'http://inventory-service:3001';
    const ORDER_SERVICE_URL = 'http://order-service:3000';¬∑
    // Kubernetes DNS resolves service-name.namespace.svc.cluster.local
    const response = await axios.get(`${INVENTORY_SERVICE_URL}/api/check`);
    ```¬∑
    ### 2. Consul Service Registry¬∑
    ```typescript
    // Consul service registration
    import Consul from 'consul';¬∑
    const consul = new Consul({ host: 'consul-server', port: 8500 });¬∑
    // Register service on startup
    await consul.agent.service.register({
      id: 'order-service-1',
      name: 'order-service',
      address: process.env.HOST_IP,
      port: 3000,
      check: {
        http: 'http://localhost:3000/health',
        interval: '10s',
        timeout: '5s'
      }
    });¬∑
    // Discover services
    const services = await consul.health.service('inventory-service');
    const healthyService = services[0];
    const url = `http://${healthyService.Service.Address}:${healthyService.Service.Port}`;
    ```¬∑
    ### 3. Load Balancing (Client-Side)¬∑
    ```typescript
    // Client-side load balancing with retry
    import axios from 'axios';¬∑
    class ServiceClient {
      private serviceUrls: string[] = [
        'http://inventory-service-1:3001',
        'http://inventory-service-2:3001',
        'http://inventory-service-3:3001'
      ];
      private currentIndex = 0;¬∑
      async call(path: string, data?: any): Promise<any> {
        let lastError: Error;¬∑
        // Try all instances with round-robin
        for (let i = 0; i < this.serviceUrls.length; i++) {
          const url = this.serviceUrls[this.currentIndex];
          this.currentIndex = (this.currentIndex + 1) % this.serviceUrls.length;¬∑
          try {
            const response = await axios.post(`${url}${path}`, data, {
              timeout: 5000
            });
            return response.data;
          } catch (error) {
            lastError = error;
            console.warn(`Failed to call ${url}, trying next instance`);
          }
        }¬∑
        throw lastError;
      }
    }
    ```¬∑
    ---¬∑
    ## Resilience Patterns¬∑
    ### 1. Circuit Breaker (Opossum)¬∑
    ```typescript
    import CircuitBreaker from 'opossum';
    import axios from 'axios';¬∑
    // Wrap service call with circuit breaker
    const breaker = new CircuitBreaker(
      async (items: string[]) => {
        const response = await axios.post('http://inventory-service:3001/check', {
          items
        });
        return response.data;
      },
      {
        timeout: 3000,          // Timeout after 3s
        errorThresholdPercentage: 50,  // Open after 50% failures
        resetTimeout: 30000     // Try again after 30s
      }
    );¬∑
    // Fallback when circuit is open
    breaker.fallback(() => {
      return { available: false, reason: 'Service temporarily unavailable' };
    });¬∑
    // Event listeners
    breaker.on('open', () => console.log('Circuit opened'));
    breaker.on('halfOpen', () => console.log('Circuit half-open, testing'));
    breaker.on('close', () => console.log('Circuit closed'));¬∑
    // Usage
    const result = await breaker.fire(['item-1', 'item-2']);
    ```¬∑
    ### 2. Retry with Exponential Backoff¬∑
    ```typescript
    import { retry } from 'ts-retry-promise';¬∑
    async function callInventoryService(items: string[]) {
      return retry(
        async () => {
          const response = await axios.post('http://inventory-service:3001/check', {
            items
          });
          return response.data;
        },
        {
          retries: 3,
          delay: 1000,        // Start with 1s delay
          backoff: 'EXPONENTIAL',  // 1s, 2s, 4s
          timeout: 10000,     // Total timeout 10s
          logger: (msg) => console.log(`Retry: ${msg}`)
        }
      );
    }
    ```¬∑
    ### 3. Bulkhead Pattern¬∑
    ```typescript
    // Isolate resources to prevent cascading failures
    import Bottleneck from 'bottleneck';¬∑
    // Limit concurrent calls to inventory service
    const inventoryLimiter = new Bottleneck({
      maxConcurrent: 10,  // Max 10 concurrent requests
      minTime: 100        // Min 100ms between requests
    });¬∑
    // Separate limiter for payment service
    const paymentLimiter = new Bottleneck({
      maxConcurrent: 5,   // Payment is critical - stricter limit
      minTime: 200
    });¬∑
    // Usage
    const inventoryResult = await inventoryLimiter.schedule(() =>
      axios.post('http://inventory-service:3001/check', { items })
    );¬∑
    const paymentResult = await paymentLimiter.schedule(() =>
      axios.post('http://payment-service:3002/charge', { amount })
    );
    ```¬∑
    ---¬∑
    ## Data Management Patterns¬∑
    ### 1. Database per Service¬∑
    ```typescript
    // Order service - PostgreSQL
    import { Pool } from 'pg';¬∑
    const orderDb = new Pool({
      host: 'order-db',
      database: 'orders',
      user: 'order_service',
      password: process.env.ORDER_DB_PASSWORD
    });¬∑
    // Inventory service - MongoDB
    import { MongoClient } from 'mongodb';¬∑
    const inventoryDb = await MongoClient.connect('mongodb://inventory-db:27017', {
      auth: { username: 'inventory_service', password: process.env.INVENTORY_DB_PASSWORD }
    });¬∑
    // User service - Redis (cache) + PostgreSQL
    import Redis from 'ioredis';¬∑
    const userCache = new Redis({ host: 'user-cache', port: 6379 });
    const userDb = new Pool({ host: 'user-db', database: 'users' });
    ```¬∑
    ### 2. Saga Pattern (Distributed Transactions)¬∑
    ```typescript
    // Choreography-based saga (event-driven)
    // Order service
    async function createOrder(items: OrderItem[], userId: string) {
      const order = await orderDb.orders.create({
        user_id: userId,
        items,
        status: 'pending',
        total: calculateTotal(items)
      });¬∑
      // Publish event
      await kafka.send({
        topic: 'order.created',
        messages: [{ value: JSON.stringify(order) }]
      });¬∑
      return order;
    }¬∑
    // Inventory service - listens to order.created
    async function handleOrderCreated(order: Order) {
      try {
        await reserveInventory(order.items);¬∑
        // Success - publish event
        await kafka.send({
          topic: 'inventory.reserved',
          messages: [{ value: JSON.stringify({ order_id: order.id }) }]
        });
      } catch (error) {
        // Failure - publish compensating event
        await kafka.send({
          topic: 'inventory.reservation.failed',
          messages: [{ value: JSON.stringify({ order_id: order.id }) }]
        });
      }
    }¬∑
    // Order service - listens to inventory.reservation.failed
    async function handleInventoryFailed(data: { order_id: string }) {
      await orderDb.orders.update({
        where: { id: data.order_id },
        data: { status: 'failed' }
      });
    }
    ```¬∑
    ### 3. CQRS (Command Query Responsibility Segregation)¬∑
    ```typescript
    // Write model (Command) - Order service
    class OrderCommandService {
      async createOrder(command: CreateOrderCommand) {
        // Validate and create order
        const order = await this.orderDb.orders.create(command);¬∑
        // Publish event for read model
        await this.eventBus.publish('order.created', order);¬∑
        return order;
      }
    }¬∑
    // Read model (Query) - Separate database optimized for queries
    class OrderQueryService {
      async getOrderHistory(userId: string) {
        // Query from denormalized read model
        return this.readDb.query(`
          SELECT o.*, u.name as user_name, array_agg(i.product_name) as items
          FROM orders_view o
          JOIN users_view u ON o.user_id = u.id
          JOIN order_items_view i ON o.id = i.order_id
          WHERE o.user_id = $1
          GROUP BY o.id, u.name
        `, [userId]);
      }
    }¬∑
    // Event handler - Updates read model
    async function handleOrderCreated(order: Order) {
      // Denormalize data for fast queries
      await readDb.orders_view.upsert({
        id: order.id,
        user_id: order.user_id,
        total: order.total,
        created_at: order.created_at
      });¬∑
      for (const item of order.items) {
        await readDb.order_items_view.create({
          order_id: order.id,
          product_name: item.name,
          quantity: item.quantity
        });
      }
    }
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. Blue-Green Deployment¬∑
    ```yaml
    # Blue deployment (current production)
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service-blue
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: order-service
          version: blue
      template:
        spec:
          containers:
          - name: order-service
            image: order-service:v1.5¬∑
    ---
    # Green deployment (new version)
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service-green
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: order-service
          version: green
      template:
        spec:
          containers:
          - name: order-service
            image: order-service:v1.6¬∑
    ---
    # Service switches between blue/green
    apiVersion: v1
    kind: Service
    metadata:
      name: order-service
    spec:
      selector:
        app: order-service
        version: blue  # Change to \"green\" for cutover
      ports:
      - port: 3000
    ```¬∑
    ### 2. Canary Deployment (Istio)¬∑
    ```yaml
    # Virtual Service - 90% v1, 10% v2
    apiVersion: networking.istio.io/v1beta1
    kind: VirtualService
    metadata:
      name: order-service
    spec:
      hosts:
      - order-service
      http:
      - route:
        - destination:
            host: order-service
            subset: v1
          weight: 90
        - destination:
            host: order-service
            subset: v2
          weight: 10  # Canary: 10% traffic to v2¬∑
    ---
    # Monitor metrics, gradually increase v2 weight:
    # 10% ‚Üí 25% ‚Üí 50% ‚Üí 100%
    ```¬∑
    ---¬∑
    ## Observability¬∑
    ### 1. Logging (Structured)¬∑
    ```typescript
    import winston from 'winston';¬∑
    const logger = winston.createLogger({
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.json()
      ),
      defaultMeta: {
        service: 'order-service',
        environment: process.env.NODE_ENV
      },
      transports: [
        new winston.transports.Console(),
        new winston.transports.File({ filename: 'logs/orders.log' })
      ]
    });¬∑
    // Usage with correlation ID for distributed tracing
    logger.info('Order created', {
      order_id: order.id,
      user_id: order.user_id,
      correlation_id: req.headers['x-correlation-id'],
      total: order.total
    });
    ```¬∑
    ### 2. Metrics (Prometheus)¬∑
    ```typescript
    import client from 'prom-client';¬∑
    // Define metrics
    const httpRequestDuration = new client.Histogram({
      name: 'http_request_duration_seconds',
      help: 'Duration of HTTP requests in seconds',
      labelNames: ['method', 'route', 'status_code']
    });¬∑
    const ordersCreated = new client.Counter({
      name: 'orders_created_total',
      help: 'Total number of orders created'
    });¬∑
    // Middleware
    app.use((req, res, next) => {
      const end = httpRequestDuration.startTimer();
      res.on('finish', () => {
        end({ method: req.method, route: req.route?.path, status_code: res.statusCode });
      });
      next();
    });¬∑
    // Expose metrics endpoint
    app.get('/metrics', async (req, res) => {
      res.set('Content-Type', client.register.contentType);
      res.end(await client.register.metrics());
    });
    ```¬∑
    ### 3. Health Checks¬∑
    ```typescript
    // Kubernetes liveness + readiness probes
    app.get('/health', async (req, res) => {
      // Liveness: Is the app running?
      res.status(200).json({ status: 'ok' });
    });¬∑
    app.get('/ready', async (req, res) => {
      // Readiness: Can the app serve traffic?
      try {
        await db.query('SELECT 1');  // Check database
        await kafka.admin().listTopics();  // Check Kafka
        res.status(200).json({ status: 'ready' });
      } catch (error) {
        res.status(503).json({ status: 'not ready', error: error.message });
      }
    });
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `create-microservice.sh` - Scaffold new microservice with boilerplate
    - `deploy-canary.sh` - Automated canary deployment script¬∑
    ### references/
    - `references/service-mesh.md` - Istio/Linkerd comparison and setup
    - `references/event-driven.md` - Kafka/RabbitMQ patterns and best practices
    - `references/api-gateway.md` - Kong/APISIX configuration guides
    - `references/observability.md` - Distributed tracing, logging, metrics¬∑
    ### assets/
    - `assets/k8s-manifests/` - Kubernetes deployment templates
    - `assets/docker-compose/` - Local development docker-compose files¬∑
    ## Related Skills¬∑
    - `api-design` - REST/GraphQL/gRPC API design
    - `micro-frontends` - Frontend microservices architecture
    - `serverless` - Serverless functions as lightweight services
    - `edge-databases` - Distributed data patterns for microservices
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ microservices ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: microservices
    description: Microservices architecture patterns using service mesh (Istio/Linkerd), API gateways (Kong/APISIX), and event-driven communication (Kafka/RabbitMQ). Use when building distributed systems requiring independent scaling, polyglot persistence, and team autonomy. Enables fault isolation and technology diversity.
    ---¬∑
    # Microservices Architecture¬∑
    ## Overview¬∑
    Microservices architecture patterns for building scalable, distributed systems with independent services, API gateways, service mesh, and event-driven communication. Enables independent deployments, technology flexibility, and fault isolation while maintaining system coherence.¬∑
    **Goal**: Independent service deployments with reliable inter-service communication¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Large teams need independent service ownership
    - Different services require different technologies
    - Independent scaling requirements per service
    - Fault isolation critical for availability
    - Gradual migration from monolith needed
    - High traffic requiring horizontal scaling
    - Different data storage needs per service
    - Team autonomy and DevOps culture established¬∑
    **Triggers**: \"microservices\", \"service mesh\", \"API gateway\", \"event-driven\", \"distributed systems\", \"service discovery\", \"circuit breaker\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Microservices vs Monolith vs Serverless¬∑
    **Microservices**:
    - ‚úÖ Independent scaling per service
    - ‚úÖ Technology diversity (polyglot)
    - ‚úÖ Fault isolation (one service fails, others continue)
    - ‚úÖ Team autonomy (own entire service lifecycle)
    - ‚úÖ Large teams (10+ engineers)
    - ‚úÖ Best for: High-traffic apps, complex domains, large teams¬∑
    **Monolith**:
    - ‚úÖ Simpler deployment (one artifact)
    - ‚úÖ Easier debugging (single process)
    - ‚úÖ Lower latency (no network calls)
    - ‚úÖ Simpler testing (no distributed complexity)
    - ‚úÖ Best for: Small teams (<10), early-stage startups, simple domains¬∑
    **Serverless**:
    - ‚úÖ Zero infrastructure management
    - ‚úÖ Auto-scaling (pay per request)
    - ‚úÖ Low operational overhead
    - ‚úÖ Best for: Event-driven workloads, sporadic traffic, lightweight APIs¬∑
    **Hybrid** (Microservices + Serverless):
    - ‚úÖ Core services as microservices
    - ‚úÖ Background jobs as serverless functions
    - ‚úÖ Best for: Production systems with mixed workloads¬∑
    ---¬∑
    ## Service Communication Patterns¬∑
    ### 1. Synchronous (REST/gRPC)¬∑
    ```typescript
    // REST API call between services
    // Order service ‚Üí Inventory service
    import axios from 'axios';¬∑
    class OrderService {
      async createOrder(items: OrderItem[]) {
        // Check inventory availability
        const inventoryResponse = await axios.post(
          'http://inventory-service:3001/api/check',
          { items },
          { timeout: 5000 }  // Timeout protection
        );¬∑
        if (!inventoryResponse.data.available) {
          throw new Error('Items not available');
        }¬∑
        // Create order
        const order = await this.db.orders.create({ items });
        return order;
      }
    }
    ```¬∑
    ```protobuf
    // gRPC for high-performance inter-service calls
    // inventory.proto
    syntax = \"proto3\";¬∑
    service InventoryService {
      rpc CheckAvailability (CheckRequest) returns (CheckResponse);
    }¬∑
    message CheckRequest {
      repeated string product_ids = 1;
    }¬∑
    message CheckResponse {
      bool available = 1;
      repeated string unavailable_items = 2;
    }
    ```¬∑
    ```typescript
    // gRPC client
    import { InventoryServiceClient } from './proto/inventory_grpc_pb';
    import { CheckRequest } from './proto/inventory_pb';¬∑
    const client = new InventoryServiceClient(
      'inventory-service:50051',
      grpc.credentials.createInsecure()
    );¬∑
    const request = new CheckRequest();
    request.setProductIdsList(['prod-1', 'prod-2']);¬∑
    client.checkAvailability(request, (err, response) => {
      if (err) throw err;
      console.log('Available:', response.getAvailable());
    });
    ```¬∑
    ### 2. Asynchronous (Event-Driven)¬∑
    ```typescript
    // Kafka producer (Order service)
    import { Kafka } from 'kafkajs';¬∑
    const kafka = new Kafka({
      clientId: 'order-service',
      brokers: ['kafka:9092']
    });¬∑
    const producer = kafka.producer();¬∑
    async function publishOrderCreated(order: Order) {
      await producer.connect();¬∑
      await producer.send({
        topic: 'order.created',
        messages: [
          {
            key: order.id,
            value: JSON.stringify({
              order_id: order.id,
              user_id: order.user_id,
              items: order.items,
              total: order.total,
              timestamp: new Date().toISOString()
            })
          }
        ]
      });¬∑
      await producer.disconnect();
    }
    ```¬∑
    ```typescript
    // Kafka consumer (Notification service)
    const consumer = kafka.consumer({ groupId: 'notification-service' });¬∑
    async function startConsumer() {
      await consumer.connect();
      await consumer.subscribe({ topic: 'order.created', fromBeginning: false });¬∑
      await consumer.run({
        eachMessage: async ({ topic, partition, message }) => {
          const order = JSON.parse(message.value.toString());¬∑
          // Send notification
          await sendEmail(order.user_id, {
            subject: 'Order Confirmed',
            body: `Your order ${order.order_id} has been confirmed.`
          });
        }
      });
    }
    ```¬∑
    ### 3. Request-Reply Pattern¬∑
    ```typescript
    // RabbitMQ RPC pattern
    import amqp from 'amqplib';¬∑
    class RPCClient {
      private connection: amqp.Connection;
      private channel: amqp.Channel;
      private replyQueue: string;¬∑
      async call(queue: string, message: any): Promise<any> {
        const correlationId = generateUUID();¬∑
        return new Promise((resolve) => {
          // Listen for reply
          this.channel.consume(this.replyQueue, (msg) => {
            if (msg.properties.correlationId === correlationId) {
              resolve(JSON.parse(msg.content.toString()));
              this.channel.ack(msg);
            }
          }, { noAck: false });¬∑
          // Send request
          this.channel.sendToQueue(queue, Buffer.from(JSON.stringify(message)), {
            correlationId,
            replyTo: this.replyQueue
          });
        });
      }
    }¬∑
    // Usage
    const client = new RPCClient();
    const result = await client.call('inventory.check', { items: ['item-1'] });
    ```¬∑
    ---¬∑
    ## Service Mesh (Istio/Linkerd)¬∑
    ### 1. Istio Setup¬∑
    ```yaml
    # Install Istio
    kubectl apply -f https://istio.io/latest/istio-operator.yaml¬∑
    # Enable sidecar injection for namespace
    kubectl label namespace default istio-injection=enabled¬∑
    # Deploy service with Istio sidecar
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service
    spec:
      replicas: 3
      template:
        metadata:
          labels:
            app: order-service
            version: v1
        spec:
          containers:
          - name: order-service
            image: order-service:latest
            ports:
            - containerPort: 3000
    ```¬∑
    ### 2. Traffic Management¬∑
    ```yaml
    # Virtual Service - Route traffic based on headers
    apiVersion: networking.istio.io/v1beta1
    kind: VirtualService
    metadata:
      name: order-service
    spec:
      hosts:
      - order-service
      http:
      - match:
        - headers:
            version:
              exact: \"v2\"
        route:
        - destination:
            host: order-service
            subset: v2
      - route:
        - destination:
            host: order-service
            subset: v1
          weight: 90
        - destination:
            host: order-service
            subset: v2
          weight: 10  # Canary deployment: 10% to v2
    ```¬∑
    ### 3. Circuit Breaker¬∑
    ```yaml
    # Destination Rule - Circuit breaker for resilience
    apiVersion: networking.istio.io/v1beta1
    kind: DestinationRule
    metadata:
      name: inventory-service
    spec:
      host: inventory-service
      trafficPolicy:
        connectionPool:
          tcp:
            maxConnections: 100
          http:
            http1MaxPendingRequests: 50
            http2MaxRequests: 100
            maxRequestsPerConnection: 2
        outlierDetection:
          consecutiveErrors: 5
          interval: 30s
          baseEjectionTime: 30s
          maxEjectionPercent: 50
          minHealthPercent: 40
    ```¬∑
    ### 4. Observability (Distributed Tracing)¬∑
    ```typescript
    // Automatic distributed tracing via Istio sidecars
    // No code changes needed - Istio injects trace headers¬∑
    // View traces in Jaeger
    kubectl port-forward -n istio-system svc/jaeger-query 16686:16686¬∑
    // Manual instrumentation (optional)
    import { trace, context } from '@opentelemetry/api';¬∑
    const tracer = trace.getTracer('order-service');¬∑
    async function createOrder(items: OrderItem[]) {
      const span = tracer.startSpan('createOrder');¬∑
      try {
        // Span automatically propagated to downstream services
        const order = await orderRepository.create(items);
        span.setAttributes({ orderId: order.id });
        return order;
      } finally {
        span.end();
      }
    }
    ```¬∑
    ---¬∑
    ## API Gateway Patterns¬∑
    ### 1. Kong Gateway¬∑
    ```yaml
    # Kong ingress for API gateway
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: api-gateway
      annotations:
        konghq.com/strip-path: \"true\"
        konghq.com/plugins: rate-limiting, jwt, cors
    spec:
      ingressClassName: kong
      rules:
      - host: api.example.com
        http:
          paths:
          - path: /orders
            pathType: Prefix
            backend:
              service:
                name: order-service
                port:
                  number: 3000
          - path: /inventory
            pathType: Prefix
            backend:
              service:
                name: inventory-service
                port:
                  number: 3001
    ```¬∑
    ```yaml
    # Kong Plugin - Rate limiting
    apiVersion: configuration.konghq.com/v1
    kind: KongPlugin
    metadata:
      name: rate-limiting
    plugin: rate-limiting
    config:
      minute: 100
      policy: local
      limit_by: consumer
    ```¬∑
    ```yaml
    # Kong Plugin - JWT authentication
    apiVersion: configuration.konghq.com/v1
    kind: KongPlugin
    metadata:
      name: jwt
    plugin: jwt
    config:
      uri_param_names:
        - jwt
      claims_to_verify:
        - exp
    ```¬∑
    ### 2. APISIX Gateway¬∑
    ```yaml
    # APISIX route configuration
    routes:
      - id: order-route
        uri: /api/orders/*
        upstream:
          type: roundrobin
          nodes:
            \"order-service:3000\": 1
        plugins:
          limit-req:
            rate: 100
            burst: 50
            rejected_code: 429
          jwt-auth: {}
          prometheus: {}¬∑
      - id: inventory-route
        uri: /api/inventory/*
        upstream:
          type: roundrobin
          nodes:
            \"inventory-service-v1:3001\": 90
            \"inventory-service-v2:3001\": 10  # Canary
        plugins:
          limit-req:
            rate: 200
            burst: 100
    ```¬∑
    ### 3. GraphQL Federation (Apollo Gateway)¬∑
    ```typescript
    // Apollo Gateway - Federated GraphQL across microservices
    import { ApolloGateway, IntrospectAndCompose } from '@apollo/gateway';
    import { ApolloServer } from 'apollo-server';¬∑
    const gateway = new ApolloGateway({
      supergraphSdl: new IntrospectAndCompose({
        subgraphs: [
          { name: 'orders', url: 'http://order-service:4000/graphql' },
          { name: 'inventory', url: 'http://inventory-service:4001/graphql' },
          { name: 'users', url: 'http://user-service:4002/graphql' }
        ]
      })
    });¬∑
    const server = new ApolloServer({
      gateway,
      subscriptions: false
    });¬∑
    server.listen(4000);
    ```¬∑
    ```typescript
    // Order service - Federated schema
    import { buildSubgraphSchema } from '@apollo/subgraph';
    import { gql } from 'apollo-server';¬∑
    const typeDefs = gql`
      extend type User @key(fields: \"id\") {
        id: ID! @external
        orders: [Order!]!
      }¬∑
      type Order @key(fields: \"id\") {
        id: ID!
        user: User!
        items: [OrderItem!]!
        total: Float!
      }¬∑
      type Query {
        order(id: ID!): Order
      }
    `;¬∑
    const resolvers = {
      User: {
        orders(user) {
          return getOrdersByUserId(user.id);
        }
      }
    };¬∑
    export const schema = buildSubgraphSchema({ typeDefs, resolvers });
    ```¬∑
    ---¬∑
    ## Service Discovery¬∑
    ### 1. Kubernetes Service Discovery¬∑
    ```typescript
    // Automatic service discovery via Kubernetes DNS
    // No library needed - use service names directly¬∑
    const INVENTORY_SERVICE_URL = 'http://inventory-service:3001';
    const ORDER_SERVICE_URL = 'http://order-service:3000';¬∑
    // Kubernetes DNS resolves service-name.namespace.svc.cluster.local
    const response = await axios.get(`${INVENTORY_SERVICE_URL}/api/check`);
    ```¬∑
    ### 2. Consul Service Registry¬∑
    ```typescript
    // Consul service registration
    import Consul from 'consul';¬∑
    const consul = new Consul({ host: 'consul-server', port: 8500 });¬∑
    // Register service on startup
    await consul.agent.service.register({
      id: 'order-service-1',
      name: 'order-service',
      address: process.env.HOST_IP,
      port: 3000,
      check: {
        http: 'http://localhost:3000/health',
        interval: '10s',
        timeout: '5s'
      }
    });¬∑
    // Discover services
    const services = await consul.health.service('inventory-service');
    const healthyService = services[0];
    const url = `http://${healthyService.Service.Address}:${healthyService.Service.Port}`;
    ```¬∑
    ### 3. Load Balancing (Client-Side)¬∑
    ```typescript
    // Client-side load balancing with retry
    import axios from 'axios';¬∑
    class ServiceClient {
      private serviceUrls: string[] = [
        'http://inventory-service-1:3001',
        'http://inventory-service-2:3001',
        'http://inventory-service-3:3001'
      ];
      private currentIndex = 0;¬∑
      async call(path: string, data?: any): Promise<any> {
        let lastError: Error;¬∑
        // Try all instances with round-robin
        for (let i = 0; i < this.serviceUrls.length; i++) {
          const url = this.serviceUrls[this.currentIndex];
          this.currentIndex = (this.currentIndex + 1) % this.serviceUrls.length;¬∑
          try {
            const response = await axios.post(`${url}${path}`, data, {
              timeout: 5000
            });
            return response.data;
          } catch (error) {
            lastError = error;
            console.warn(`Failed to call ${url}, trying next instance`);
          }
        }¬∑
        throw lastError;
      }
    }
    ```¬∑
    ---¬∑
    ## Resilience Patterns¬∑
    ### 1. Circuit Breaker (Opossum)¬∑
    ```typescript
    import CircuitBreaker from 'opossum';
    import axios from 'axios';¬∑
    // Wrap service call with circuit breaker
    const breaker = new CircuitBreaker(
      async (items: string[]) => {
        const response = await axios.post('http://inventory-service:3001/check', {
          items
        });
        return response.data;
      },
      {
        timeout: 3000,          // Timeout after 3s
        errorThresholdPercentage: 50,  // Open after 50% failures
        resetTimeout: 30000     // Try again after 30s
      }
    );¬∑
    // Fallback when circuit is open
    breaker.fallback(() => {
      return { available: false, reason: 'Service temporarily unavailable' };
    });¬∑
    // Event listeners
    breaker.on('open', () => console.log('Circuit opened'));
    breaker.on('halfOpen', () => console.log('Circuit half-open, testing'));
    breaker.on('close', () => console.log('Circuit closed'));¬∑
    // Usage
    const result = await breaker.fire(['item-1', 'item-2']);
    ```¬∑
    ### 2. Retry with Exponential Backoff¬∑
    ```typescript
    import { retry } from 'ts-retry-promise';¬∑
    async function callInventoryService(items: string[]) {
      return retry(
        async () => {
          const response = await axios.post('http://inventory-service:3001/check', {
            items
          });
          return response.data;
        },
        {
          retries: 3,
          delay: 1000,        // Start with 1s delay
          backoff: 'EXPONENTIAL',  // 1s, 2s, 4s
          timeout: 10000,     // Total timeout 10s
          logger: (msg) => console.log(`Retry: ${msg}`)
        }
      );
    }
    ```¬∑
    ### 3. Bulkhead Pattern¬∑
    ```typescript
    // Isolate resources to prevent cascading failures
    import Bottleneck from 'bottleneck';¬∑
    // Limit concurrent calls to inventory service
    const inventoryLimiter = new Bottleneck({
      maxConcurrent: 10,  // Max 10 concurrent requests
      minTime: 100        // Min 100ms between requests
    });¬∑
    // Separate limiter for payment service
    const paymentLimiter = new Bottleneck({
      maxConcurrent: 5,   // Payment is critical - stricter limit
      minTime: 200
    });¬∑
    // Usage
    const inventoryResult = await inventoryLimiter.schedule(() =>
      axios.post('http://inventory-service:3001/check', { items })
    );¬∑
    const paymentResult = await paymentLimiter.schedule(() =>
      axios.post('http://payment-service:3002/charge', { amount })
    );
    ```¬∑
    ---¬∑
    ## Data Management Patterns¬∑
    ### 1. Database per Service¬∑
    ```typescript
    // Order service - PostgreSQL
    import { Pool } from 'pg';¬∑
    const orderDb = new Pool({
      host: 'order-db',
      database: 'orders',
      user: 'order_service',
      password: process.env.ORDER_DB_PASSWORD
    });¬∑
    // Inventory service - MongoDB
    import { MongoClient } from 'mongodb';¬∑
    const inventoryDb = await MongoClient.connect('mongodb://inventory-db:27017', {
      auth: { username: 'inventory_service', password: process.env.INVENTORY_DB_PASSWORD }
    });¬∑
    // User service - Redis (cache) + PostgreSQL
    import Redis from 'ioredis';¬∑
    const userCache = new Redis({ host: 'user-cache', port: 6379 });
    const userDb = new Pool({ host: 'user-db', database: 'users' });
    ```¬∑
    ### 2. Saga Pattern (Distributed Transactions)¬∑
    ```typescript
    // Choreography-based saga (event-driven)
    // Order service
    async function createOrder(items: OrderItem[], userId: string) {
      const order = await orderDb.orders.create({
        user_id: userId,
        items,
        status: 'pending',
        total: calculateTotal(items)
      });¬∑
      // Publish event
      await kafka.send({
        topic: 'order.created',
        messages: [{ value: JSON.stringify(order) }]
      });¬∑
      return order;
    }¬∑
    // Inventory service - listens to order.created
    async function handleOrderCreated(order: Order) {
      try {
        await reserveInventory(order.items);¬∑
        // Success - publish event
        await kafka.send({
          topic: 'inventory.reserved',
          messages: [{ value: JSON.stringify({ order_id: order.id }) }]
        });
      } catch (error) {
        // Failure - publish compensating event
        await kafka.send({
          topic: 'inventory.reservation.failed',
          messages: [{ value: JSON.stringify({ order_id: order.id }) }]
        });
      }
    }¬∑
    // Order service - listens to inventory.reservation.failed
    async function handleInventoryFailed(data: { order_id: string }) {
      await orderDb.orders.update({
        where: { id: data.order_id },
        data: { status: 'failed' }
      });
    }
    ```¬∑
    ### 3. CQRS (Command Query Responsibility Segregation)¬∑
    ```typescript
    // Write model (Command) - Order service
    class OrderCommandService {
      async createOrder(command: CreateOrderCommand) {
        // Validate and create order
        const order = await this.orderDb.orders.create(command);¬∑
        // Publish event for read model
        await this.eventBus.publish('order.created', order);¬∑
        return order;
      }
    }¬∑
    // Read model (Query) - Separate database optimized for queries
    class OrderQueryService {
      async getOrderHistory(userId: string) {
        // Query from denormalized read model
        return this.readDb.query(`
          SELECT o.*, u.name as user_name, array_agg(i.product_name) as items
          FROM orders_view o
          JOIN users_view u ON o.user_id = u.id
          JOIN order_items_view i ON o.id = i.order_id
          WHERE o.user_id = $1
          GROUP BY o.id, u.name
        `, [userId]);
      }
    }¬∑
    // Event handler - Updates read model
    async function handleOrderCreated(order: Order) {
      // Denormalize data for fast queries
      await readDb.orders_view.upsert({
        id: order.id,
        user_id: order.user_id,
        total: order.total,
        created_at: order.created_at
      });¬∑
      for (const item of order.items) {
        await readDb.order_items_view.create({
          order_id: order.id,
          product_name: item.name,
          quantity: item.quantity
        });
      }
    }
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. Blue-Green Deployment¬∑
    ```yaml
    # Blue deployment (current production)
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service-blue
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: order-service
          version: blue
      template:
        spec:
          containers:
          - name: order-service
            image: order-service:v1.5¬∑
    ---
    # Green deployment (new version)
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: order-service-green
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: order-service
          version: green
      template:
        spec:
          containers:
          - name: order-service
            image: order-service:v1.6¬∑
    ---
    # Service switches between blue/green
    apiVersion: v1
    kind: Service
    metadata:
      name: order-service
    spec:
      selector:
        app: order-service
        version: blue  # Change to \"green\" for cutover
      ports:
      - port: 3000
    ```¬∑
    ### 2. Canary Deployment (Istio)¬∑
    ```yaml
    # Virtual Service - 90% v1, 10% v2
    apiVersion: networking.istio.io/v1beta1
    kind: VirtualService
    metadata:
      name: order-service
    spec:
      hosts:
      - order-service
      http:
      - route:
        - destination:
            host: order-service
            subset: v1
          weight: 90
        - destination:
            host: order-service
            subset: v2
          weight: 10  # Canary: 10% traffic to v2¬∑
    ---
    # Monitor metrics, gradually increase v2 weight:
    # 10% ‚Üí 25% ‚Üí 50% ‚Üí 100%
    ```¬∑
    ---¬∑
    ## Observability¬∑
    ### 1. Logging (Structured)¬∑
    ```typescript
    import winston from 'winston';¬∑
    const logger = winston.createLogger({
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.json()
      ),
      defaultMeta: {
        service: 'order-service',
        environment: process.env.NODE_ENV
      },
      transports: [
        new winston.transports.Console(),
        new winston.transports.File({ filename: 'logs/orders.log' })
      ]
    });¬∑
    // Usage with correlation ID for distributed tracing
    logger.info('Order created', {
      order_id: order.id,
      user_id: order.user_id,
      correlation_id: req.headers['x-correlation-id'],
      total: order.total
    });
    ```¬∑
    ### 2. Metrics (Prometheus)¬∑
    ```typescript
    import client from 'prom-client';¬∑
    // Define metrics
    const httpRequestDuration = new client.Histogram({
      name: 'http_request_duration_seconds',
      help: 'Duration of HTTP requests in seconds',
      labelNames: ['method', 'route', 'status_code']
    });¬∑
    const ordersCreated = new client.Counter({
      name: 'orders_created_total',
      help: 'Total number of orders created'
    });¬∑
    // Middleware
    app.use((req, res, next) => {
      const end = httpRequestDuration.startTimer();
      res.on('finish', () => {
        end({ method: req.method, route: req.route?.path, status_code: res.statusCode });
      });
      next();
    });¬∑
    // Expose metrics endpoint
    app.get('/metrics', async (req, res) => {
      res.set('Content-Type', client.register.contentType);
      res.end(await client.register.metrics());
    });
    ```¬∑
    ### 3. Health Checks¬∑
    ```typescript
    // Kubernetes liveness + readiness probes
    app.get('/health', async (req, res) => {
      // Liveness: Is the app running?
      res.status(200).json({ status: 'ok' });
    });¬∑
    app.get('/ready', async (req, res) => {
      // Readiness: Can the app serve traffic?
      try {
        await db.query('SELECT 1');  // Check database
        await kafka.admin().listTopics();  // Check Kafka
        res.status(200).json({ status: 'ready' });
      } catch (error) {
        res.status(503).json({ status: 'not ready', error: error.message });
      }
    });
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `create-microservice.sh` - Scaffold new microservice with boilerplate
    - `deploy-canary.sh` - Automated canary deployment script¬∑
    ### references/
    - `references/service-mesh.md` - Istio/Linkerd comparison and setup
    - `references/event-driven.md` - Kafka/RabbitMQ patterns and best practices
    - `references/api-gateway.md` - Kong/APISIX configuration guides
    - `references/observability.md` - Distributed tracing, logging, metrics¬∑
    ### assets/
    - `assets/k8s-manifests/` - Kubernetes deployment templates
    - `assets/docker-compose/` - Local development docker-compose files¬∑
    ## Related Skills¬∑
    - `api-design` - REST/GraphQL/gRPC API design
    - `micro-frontends` - Frontend microservices architecture
    - `serverless` - Serverless functions as lightweight services
    - `edge-databases` - Distributed data patterns for microservices
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ serverless ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: serverless
    description: Serverless computing patterns using AWS Lambda, Vercel Edge Functions, and Cloudflare Workers. Use when building event-driven, auto-scaling applications with zero infrastructure management. Optimizes for cold start performance, memory/cost efficiency, and edge deployment. Best for APIs, background jobs, and edge computing.
    ---¬∑
    # Serverless Computing¬∑
    ## Overview¬∑
    Serverless computing patterns for building auto-scaling, event-driven applications without managing infrastructure. Covers AWS Lambda, Vercel Edge Functions, Cloudflare Workers, cold start optimization, and edge deployment strategies.¬∑
    **Goal**: Deploy scalable applications with zero infrastructure management and pay-per-use pricing¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building APIs with sporadic traffic patterns
    - Running background jobs and scheduled tasks
    - Processing event-driven workloads (file uploads, webhooks)
    - Deploying edge functions for low-latency responses
    - Prototyping quickly without infrastructure setup
    - Optimizing costs (pay only for actual execution time)
    - Auto-scaling from zero to millions of requests
    - Integrating with cloud services (S3, DynamoDB, etc.)¬∑
    **Triggers**: \"serverless\", \"lambda\", \"edge functions\", \"cold start\", \"function-as-a-service\", \"FaaS\", \"auto-scaling\"¬∑
    ---¬∑
    ## Quick Start: Platform Decision Tree¬∑
    ### When to Use Each Platform¬∑
    **AWS Lambda**:
    - ‚úÖ Complex integrations (100+ AWS services)
    - ‚úÖ Long-running functions (up to 15 minutes)
    - ‚úÖ Large memory requirements (up to 10GB)
    - ‚úÖ VPC access for private resources
    - ‚úÖ Best for: Enterprise apps, data processing, batch jobs¬∑
    **Vercel Edge Functions**:
    - ‚úÖ Next.js integration (middleware, API routes)
    - ‚úÖ Global edge deployment (low latency)
    - ‚úÖ Streaming responses (SSE, WebSockets)
    - ‚úÖ Zero cold starts (edge runtime)
    - ‚úÖ Best for: API routes, user-facing apps, real-time features¬∑
    **Cloudflare Workers**:
    - ‚úÖ Ultra-low latency (<50ms globally)
    - ‚úÖ Zero cold starts (V8 isolates)
    - ‚úÖ Unlimited scalability
    - ‚úÖ KV storage integration
    - ‚úÖ Best for: CDN logic, edge APIs, A/B testing¬∑
    **Google Cloud Functions**:
    - ‚úÖ GCP integration (BigQuery, Pub/Sub)
    - ‚úÖ Cloud Run integration (containers)
    - ‚úÖ Best for: Google Cloud ecosystem¬∑
    ---¬∑
    ## AWS Lambda Patterns¬∑
    ### 1. Basic Lambda Function¬∑
    ```typescript
    // handler.ts - Simple Lambda handler
    import { APIGatewayProxyEvent, APIGatewayProxyResult } from 'aws-lambda';¬∑
    export const handler = async (
      event: APIGatewayProxyEvent
    ): Promise<APIGatewayProxyResult> => {
      console.log('Event:', JSON.stringify(event, null, 2));¬∑
      const body = event.body ? JSON.parse(event.body) : {};¬∑
      return {
        statusCode: 200,
        headers: {
          'Content-Type': 'application/json',
          'Access-Control-Allow-Origin': '*'
        },
        body: JSON.stringify({
          message: 'Success',
          input: body
        })
      };
    };
    ```¬∑
    ### 2. Lambda with Database Connection¬∑
    ```typescript
    // Cold start optimization - connection reuse
    import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
    import { DynamoDBDocumentClient, PutCommand, GetCommand } from '@aws-sdk/lib-dynamodb';¬∑
    // Initialize outside handler - reused across invocations
    const client = new DynamoDBClient({ region: 'us-east-1' });
    const docClient = DynamoDBDocumentClient.from(client);¬∑
    export const handler = async (event: APIGatewayProxyEvent) => {
      const { userId, data } = JSON.parse(event.body || '{}');¬∑
      // Write to DynamoDB
      await docClient.send(new PutCommand({
        TableName: 'Users',
        Item: {
          userId,
          data,
          createdAt: new Date().toISOString()
        }
      }));¬∑
      return {
        statusCode: 201,
        body: JSON.stringify({ success: true })
      };
    };
    ```¬∑
    ### 3. S3 Event Trigger¬∑
    ```typescript
    // Triggered when file uploaded to S3
    import { S3Event } from 'aws-lambda';
    import { S3Client, GetObjectCommand } from '@aws-sdk/client-s3';¬∑
    const s3Client = new S3Client({ region: 'us-east-1' });¬∑
    export const handler = async (event: S3Event) => {
      for (const record of event.Records) {
        const bucket = record.s3.bucket.name;
        const key = decodeURIComponent(record.s3.object.key.replace(/\\+/g, ' '));¬∑
        console.log(`Processing file: ${bucket}/${key}`);¬∑
        // Get file from S3
        const response = await s3Client.send(new GetObjectCommand({
          Bucket: bucket,
          Key: key
        }));¬∑
        const fileContent = await response.Body?.transformToString();¬∑
        // Process file (resize image, parse CSV, etc.)
        await processFile(fileContent);
      }
    };
    ```¬∑
    ### 4. Scheduled Lambda (Cron)¬∑
    ```typescript
    // CloudWatch Events trigger - runs on schedule
    import { ScheduledEvent } from 'aws-lambda';
    import { SESClient, SendEmailCommand } from '@aws-sdk/client-ses';¬∑
    const sesClient = new SESClient({ region: 'us-east-1' });¬∑
    export const handler = async (event: ScheduledEvent) => {
      console.log(`Scheduled task triggered at: ${event.time}`);¬∑
      // Send daily report
      await sesClient.send(new SendEmailCommand({
        Source: 'reports@example.com',
        Destination: { ToAddresses: ['admin@example.com'] },
        Message: {
          Subject: { Data: 'Daily Report' },
          Body: {
            Text: { Data: `Report for ${new Date().toISOString()}` }
          }
        }
      }));¬∑
      return { statusCode: 200 };
    };
    ```¬∑
    ### 5. Lambda Layers (Shared Dependencies)¬∑
    ```bash
    # Create layer with shared dependencies
    mkdir -p layer/nodejs
    cd layer/nodejs
    npm install pg redis¬∑
    cd ..
    zip -r layer.zip nodejs/¬∑
    # Deploy layer
    aws lambda publish-layer-version \\
      --layer-name shared-deps \\
      --zip-file fileb://layer.zip \\
      --compatible-runtimes nodejs20.x
    ```¬∑
    ```typescript
    // Use layer in Lambda function
    // layers: [arn:aws:lambda:us-east-1:123456789:layer:shared-deps:1]¬∑
    import { Pool } from 'pg';  // From layer¬∑
    const pool = new Pool({
      host: process.env.DB_HOST,
      database: process.env.DB_NAME,
      user: process.env.DB_USER,
      password: process.env.DB_PASSWORD
    });¬∑
    export const handler = async (event) => {
      const result = await pool.query('SELECT * FROM users WHERE id = $1', [event.userId]);
      return { statusCode: 200, body: JSON.stringify(result.rows[0]) };
    };
    ```¬∑
    ---¬∑
    ## Vercel Edge Functions¬∑
    ### 1. Basic Edge Function¬∑
    ```typescript
    // app/api/hello/route.ts - Next.js Edge API Route
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const name = searchParams.get('name') || 'World';¬∑
      return new Response(JSON.stringify({ message: `Hello, ${name}!` }), {
        headers: { 'content-type': 'application/json' }
      });
    }
    ```¬∑
    ### 2. Middleware (Authentication)¬∑
    ```typescript
    // middleware.ts - Runs on all requests at the edge
    import { NextResponse } from 'next/server';
    import type { NextRequest } from 'next/server';¬∑
    export function middleware(request: NextRequest) {
      const token = request.cookies.get('auth-token')?.value;¬∑
      // Protected routes
      if (request.nextUrl.pathname.startsWith('/dashboard')) {
        if (!token) {
          return NextResponse.redirect(new URL('/login', request.url));
        }¬∑
        // Verify JWT at the edge (fast!)
        try {
          const payload = verifyJWT(token);
          const response = NextResponse.next();
          response.headers.set('x-user-id', payload.userId);
          return response;
        } catch {
          return NextResponse.redirect(new URL('/login', request.url));
        }
      }¬∑
      return NextResponse.next();
    }¬∑
    export const config = {
      matcher: ['/dashboard/:path*', '/api/:path*']
    };
    ```¬∑
    ### 3. Edge API with Database¬∑
    ```typescript
    // app/api/users/route.ts - Edge function with Vercel Postgres
    export const runtime = 'edge';¬∑
    import { sql } from '@vercel/postgres';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const userId = searchParams.get('id');¬∑
      const { rows } = await sql`
        SELECT id, name, email FROM users WHERE id = ${userId}
      `;¬∑
      return Response.json(rows[0] || { error: 'Not found' });
    }¬∑
    export async function POST(request: Request) {
      const { name, email } = await request.json();¬∑
      const { rows } = await sql`
        INSERT INTO users (name, email) VALUES (${name}, ${email})
        RETURNING id, name, email
      `;¬∑
      return Response.json(rows[0], { status: 201 });
    }
    ```¬∑
    ### 4. Streaming Response (SSE)¬∑
    ```typescript
    // app/api/stream/route.ts - Server-Sent Events at the edge
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const encoder = new TextEncoder();¬∑
      const stream = new ReadableStream({
        async start(controller) {
          for (let i = 0; i < 10; i++) {
            const message = `data: ${JSON.stringify({ count: i, time: Date.now() })}\\n\\n`;
            controller.enqueue(encoder.encode(message));
            await new Promise(resolve => setTimeout(resolve, 1000));
          }
          controller.close();
        }
      });¬∑
      return new Response(stream, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive'
        }
      });
    }
    ```¬∑
    ### 5. Geolocation-Based Response¬∑
    ```typescript
    // app/api/geo/route.ts - Edge function with geolocation
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      // Vercel Edge provides geolocation headers
      const geo = {
        city: request.headers.get('x-vercel-ip-city'),
        country: request.headers.get('x-vercel-ip-country'),
        region: request.headers.get('x-vercel-ip-country-region'),
        latitude: request.headers.get('x-vercel-ip-latitude'),
        longitude: request.headers.get('x-vercel-ip-longitude')
      };¬∑
      // Customize response based on location
      const currency = geo.country === 'US' ? 'USD' : 'EUR';
      const language = geo.country === 'US' ? 'en-US' : 'en-GB';¬∑
      return Response.json({
        geo,
        currency,
        language
      });
    }
    ```¬∑
    ---¬∑
    ## Cloudflare Workers¬∑
    ### 1. Basic Worker¬∑
    ```typescript
    // index.ts - Cloudflare Worker
    export default {
      async fetch(request: Request): Promise<Response> {
        const url = new URL(request.url);¬∑
        if (url.pathname === '/api/hello') {
          return new Response(JSON.stringify({ message: 'Hello from the edge!' }), {
            headers: { 'content-type': 'application/json' }
          });
        }¬∑
        return new Response('Not found', { status: 404 });
      }
    };
    ```¬∑
    ### 2. Worker with KV Storage¬∑
    ```typescript
    // Worker with Cloudflare KV (key-value store)
    interface Env {
      MY_KV: KVNamespace;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const url = new URL(request.url);
        const key = url.searchParams.get('key');¬∑
        if (request.method === 'GET' && key) {
          const value = await env.MY_KV.get(key);
          return Response.json({ key, value });
        }¬∑
        if (request.method === 'POST') {
          const { key, value } = await request.json();
          await env.MY_KV.put(key, value, { expirationTtl: 3600 }); // 1 hour TTL
          return Response.json({ success: true });
        }¬∑
        return new Response('Method not allowed', { status: 405 });
      }
    };
    ```¬∑
    ### 3. Worker with Durable Objects (Stateful)¬∑
    ```typescript
    // Durable Object - WebSocket chat room
    export class ChatRoom {
      state: DurableObjectState;
      sessions: Set<WebSocket>;¬∑
      constructor(state: DurableObjectState) {
        this.state = state;
        this.sessions = new Set();
      }¬∑
      async fetch(request: Request): Promise<Response> {
        const upgradeHeader = request.headers.get('Upgrade');¬∑
        if (upgradeHeader === 'websocket') {
          const [client, server] = Object.values(new WebSocketPair());¬∑
          this.sessions.add(server);
          server.accept();¬∑
          server.addEventListener('message', (event) => {
            // Broadcast to all connected clients
            for (const session of this.sessions) {
              session.send(event.data);
            }
          });¬∑
          server.addEventListener('close', () => {
            this.sessions.delete(server);
          });¬∑
          return new Response(null, { status: 101, webSocket: client });
        }¬∑
        return new Response('Expected WebSocket', { status: 400 });
      }
    }¬∑
    // Worker that uses Durable Object
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const url = new URL(request.url);
        const roomName = url.pathname.slice(1);¬∑
        const id = env.CHAT_ROOM.idFromName(roomName);
        const room = env.CHAT_ROOM.get(id);¬∑
        return room.fetch(request);
      }
    };
    ```¬∑
    ### 4. Worker with Caching¬∑
    ```typescript
    // Edge caching with Cache API
    export default {
      async fetch(request: Request): Promise<Response> {
        const cache = caches.default;
        const cacheKey = new Request(request.url, request);¬∑
        // Try to get from cache
        let response = await cache.match(cacheKey);¬∑
        if (!response) {
          // Cache miss - fetch from origin
          console.log('Cache miss, fetching from origin');
          response = await fetch(request);¬∑
          // Clone response before caching (response can only be read once)
          const clonedResponse = response.clone();¬∑
          // Cache for 1 hour
          const headers = new Headers(clonedResponse.headers);
          headers.set('Cache-Control', 'public, max-age=3600');¬∑
          const cachedResponse = new Response(clonedResponse.body, {
            status: clonedResponse.status,
            statusText: clonedResponse.statusText,
            headers
          });¬∑
          // Don't await - cache in background
          cache.put(cacheKey, cachedResponse);
        } else {
          console.log('Cache hit');
        }¬∑
        return response;
      }
    };
    ```¬∑
    ---¬∑
    ## Cold Start Optimization¬∑
    ### 1. Lambda Cold Start Mitigation¬∑
    ```typescript
    // Minimize dependencies - use AWS SDK v3 (modular)
    import { DynamoDBClient } from '@aws-sdk/client-dynamodb';  // Only what you need¬∑
    // NOT: import AWS from 'aws-sdk';  // Loads entire SDK (slow!)¬∑
    // Initialize connections outside handler
    const dynamoDb = new DynamoDBClient({ region: 'us-east-1' });¬∑
    // Lazy load heavy dependencies
    let heavyLib: any;¬∑
    export const handler = async (event: APIGatewayProxyEvent) => {
      // Only load if needed
      if (event.path === '/heavy') {
        if (!heavyLib) {
          heavyLib = await import('./heavy-library');
        }
        return heavyLib.process(event);
      }¬∑
      // Fast path - no heavy imports
      return { statusCode: 200, body: JSON.stringify({ message: 'Fast!' }) };
    };
    ```¬∑
    ### 2. Provisioned Concurrency¬∑
    ```yaml
    # serverless.yml - AWS Lambda with provisioned concurrency
    functions:
      api:
        handler: handler.main
        provisionedConcurrency: 5  # Keep 5 instances warm
        reservedConcurrency: 100   # Max 100 concurrent executions
        events:
          - http:
              path: /api/{proxy+}
              method: ANY
    ```¬∑
    ### 3. Lambda SnapStart (Java/.NET)¬∑
    ```yaml
    # For Java/Spring Boot Lambda
    functions:
      springApi:
        handler: org.springframework.cloud.function.adapter.aws.FunctionInvoker
        runtime: java17
        snapStart: true  # Reduces cold start from 10s to 1s
        memorySize: 2048
    ```¬∑
    ### 4. Warming Strategy¬∑
    ```typescript
    // Scheduled event to keep Lambda warm
    export const warmer = async (event: any) => {
      if (event.source === 'aws.events') {
        console.log('Warmer ping - keeping function warm');
        return { statusCode: 200, body: 'Warm' };
      }¬∑
      // Actual handler logic
      return await handleRequest(event);
    };
    ```¬∑
    ```yaml
    # serverless.yml - Warming schedule
    functions:
      api:
        handler: handler.warmer
        events:
          - http: ANY /api/{proxy+}
          - schedule:
              rate: rate(5 minutes)  # Ping every 5 minutes
              input:
                source: aws.events
    ```¬∑
    ---¬∑
    ## Cost Optimization¬∑
    ### 1. Right-Sizing Memory¬∑
    ```typescript
    // Lambda pricing: Memory √ó Duration
    // More memory = faster execution = potentially cheaper!¬∑
    // Example: Process 1000 items
    // 128 MB: 5000ms = $0.000000208 √ó 128 √ó 5 = $0.000133
    // 1024 MB: 625ms = $0.000001667 √ó 1024 √ó 0.625 = $0.000107 (cheaper!)¬∑
    // Run benchmarks to find optimal memory
    import { PerformanceObserver, performance } from 'perf_hooks';¬∑
    export const handler = async (event: any) => {
      const start = performance.now();¬∑
      // Your logic here
      await processItems(event.items);¬∑
      const duration = performance.now() - start;
      const memoryMB = parseInt(process.env.AWS_LAMBDA_FUNCTION_MEMORY_SIZE || '128');¬∑
      console.log(JSON.stringify({
        memoryMB,
        durationMs: duration,
        cost: calculateCost(memoryMB, duration)
      }));
    };¬∑
    function calculateCost(memoryMB: number, durationMs: number): number {
      const gbSeconds = (memoryMB / 1024) * (durationMs / 1000);
      return gbSeconds * 0.0000166667;  // AWS pricing per GB-second
    }
    ```¬∑
    ### 2. Caching Responses¬∑
    ```typescript
    // Edge function with aggressive caching
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const data = await fetchExpensiveData();¬∑
      return new Response(JSON.stringify(data), {
        headers: {
          'Content-Type': 'application/json',
          'Cache-Control': 'public, s-maxage=3600, stale-while-revalidate=86400'
          // Cache for 1 hour, serve stale for 24 hours
        }
      });
    }
    ```¬∑
    ### 3. Batch Processing¬∑
    ```typescript
    // Process items in batches to reduce invocations
    import { SQSEvent } from 'aws-lambda';¬∑
    export const handler = async (event: SQSEvent) => {
      // Process all messages in one invocation (up to 10)
      const promises = event.Records.map(async (record) => {
        const data = JSON.parse(record.body);
        return processItem(data);
      });¬∑
      await Promise.all(promises);¬∑
      // Return success for all messages
      return { batchItemFailures: [] };
    };
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. AWS SAM Template¬∑
    ```yaml
    # template.yaml - AWS SAM (Serverless Application Model)
    AWSTemplateFormatVersion: '2010-09-09'
    Transform: AWS::Serverless-2016-10-31¬∑
    Globals:
      Function:
        Runtime: nodejs20.x
        Timeout: 30
        MemorySize: 256
        Environment:
          Variables:
            TABLE_NAME: !Ref UsersTable¬∑
    Resources:
      ApiFunction:
        Type: AWS::Serverless::Function
        Properties:
          Handler: dist/handler.main
          Events:
            Api:
              Type: Api
              Properties:
                Path: /api/{proxy+}
                Method: ANY
          Policies:
            - DynamoDBCrudPolicy:
                TableName: !Ref UsersTable¬∑
      UsersTable:
        Type: AWS::Serverless::SimpleTable
        Properties:
          PrimaryKey:
            Name: userId
            Type: String
    ```¬∑
    ### 2. Serverless Framework¬∑
    ```yaml
    # serverless.yml
    service: my-api¬∑
    provider:
      name: aws
      runtime: nodejs20.x
      region: us-east-1
      environment:
        TABLE_NAME: ${self:service}-users-${sls:stage}¬∑
    functions:
      api:
        handler: dist/handler.main
        events:
          - httpApi:
              path: /api/{proxy+}
              method: '*'
        iamRoleStatements:
          - Effect: Allow
            Action:
              - dynamodb:*
            Resource: !GetAtt UsersTable.Arn¬∑
    resources:
      Resources:
        UsersTable:
          Type: AWS::DynamoDB::Table
          Properties:
            BillingMode: PAY_PER_REQUEST
            AttributeDefinitions:
              - AttributeName: userId
                AttributeType: S
            KeySchema:
              - AttributeName: userId
                KeyType: HASH
    ```¬∑
    ### 3. Vercel Deployment¬∑
    ```json
    // vercel.json
    {
      \"functions\": {
        \"app/api/**/*.ts\": {
          \"runtime\": \"edge\",
          \"regions\": [\"iad1\", \"sfo1\", \"fra1\"],
          \"maxDuration\": 10
        }
      },
      \"env\": {
        \"DATABASE_URL\": \"@database-url\"
      }
    }
    ```¬∑
    ---¬∑
    ## Monitoring & Debugging¬∑
    ### 1. Structured Logging¬∑
    ```typescript
    import { APIGatewayProxyEvent, Context } from 'aws-lambda';¬∑
    // Structured logs for CloudWatch Logs Insights
    export const handler = async (event: APIGatewayProxyEvent, context: Context) => {
      const logger = {
        info: (message: string, meta?: any) => console.log(JSON.stringify({
          level: 'info',
          message,
          requestId: context.requestId,
          functionName: context.functionName,
          ...meta
        })),
        error: (message: string, error?: Error) => console.error(JSON.stringify({
          level: 'error',
          message,
          requestId: context.requestId,
          error: error?.message,
          stack: error?.stack
        }))
      };¬∑
      try {
        logger.info('Processing request', { path: event.path });
        const result = await processRequest(event);
        logger.info('Request completed', { duration: context.getRemainingTimeInMillis() });
        return result;
      } catch (error) {
        logger.error('Request failed', error as Error);
        throw error;
      }
    };
    ```¬∑
    ### 2. X-Ray Tracing¬∑
    ```typescript
    // Enable AWS X-Ray for distributed tracing
    import AWSXRay from 'aws-xray-sdk-core';
    import AWS from 'aws-sdk';¬∑
    const dynamodb = AWSXRay.captureAWSClient(new AWS.DynamoDB.DocumentClient());¬∑
    export const handler = async (event: any) => {
      const segment = AWSXRay.getSegment();
      const subsegment = segment?.addNewSubsegment('process-items');¬∑
      try {
        // Traced DynamoDB call
        const result = await dynamodb.get({
          TableName: 'Users',
          Key: { userId: event.userId }
        }).promise();¬∑
        subsegment?.close();
        return result;
      } catch (error) {
        subsegment?.addError(error as Error);
        subsegment?.close();
        throw error;
      }
    };
    ```¬∑
    ### 3. CloudWatch Metrics¬∑
    ```typescript
    import { CloudWatch } from '@aws-sdk/client-cloudwatch';¬∑
    const cloudwatch = new CloudWatch({ region: 'us-east-1' });¬∑
    export const handler = async (event: any) => {
      const start = Date.now();¬∑
      try {
        const result = await processRequest(event);¬∑
        // Custom metric
        await cloudwatch.putMetricData({
          Namespace: 'MyApp/Lambda',
          MetricData: [{
            MetricName: 'ProcessingDuration',
            Value: Date.now() - start,
            Unit: 'Milliseconds',
            Dimensions: [
              { Name: 'FunctionName', Value: process.env.AWS_LAMBDA_FUNCTION_NAME! }
            ]
          }]
        });¬∑
        return result;
      } catch (error) {
        // Error metric
        await cloudwatch.putMetricData({
          Namespace: 'MyApp/Lambda',
          MetricData: [{
            MetricName: 'Errors',
            Value: 1,
            Unit: 'Count'
          }]
        });¬∑
        throw error;
      }
    };
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `deploy-lambda.sh` - Deploy Lambda with SAM/Serverless Framework
    - `test-edge-function.sh` - Local testing for edge functions¬∑
    ### references/
    - `references/lambda-best-practices.md` - AWS Lambda optimization guide
    - `references/edge-runtime.md` - Vercel/Cloudflare edge runtime comparison
    - `references/serverless-pricing.md` - Cost comparison and optimization¬∑
    ### assets/
    - `assets/sam-templates/` - AWS SAM template examples
    - `assets/serverless-configs/` - Serverless Framework configurations¬∑
    ## Related Skills¬∑
    - `microservices` - Microservices vs serverless trade-offs
    - `edge-databases` - Edge computing with distributed databases
    - `api-design` - API design patterns for serverless functions
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ serverless ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: serverless
    description: Serverless computing patterns using AWS Lambda, Vercel Edge Functions, and Cloudflare Workers. Use when building event-driven, auto-scaling applications with zero infrastructure management. Optimizes for cold start performance, memory/cost efficiency, and edge deployment. Best for APIs, background jobs, and edge computing.
    ---¬∑
    # Serverless Computing¬∑
    ## Overview¬∑
    Serverless computing patterns for building auto-scaling, event-driven applications without managing infrastructure. Covers AWS Lambda, Vercel Edge Functions, Cloudflare Workers, cold start optimization, and edge deployment strategies.¬∑
    **Goal**: Deploy scalable applications with zero infrastructure management and pay-per-use pricing¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building APIs with sporadic traffic patterns
    - Running background jobs and scheduled tasks
    - Processing event-driven workloads (file uploads, webhooks)
    - Deploying edge functions for low-latency responses
    - Prototyping quickly without infrastructure setup
    - Optimizing costs (pay only for actual execution time)
    - Auto-scaling from zero to millions of requests
    - Integrating with cloud services (S3, DynamoDB, etc.)¬∑
    **Triggers**: \"serverless\", \"lambda\", \"edge functions\", \"cold start\", \"function-as-a-service\", \"FaaS\", \"auto-scaling\"¬∑
    ---¬∑
    ## Quick Start: Platform Decision Tree¬∑
    ### When to Use Each Platform¬∑
    **AWS Lambda**:
    - ‚úÖ Complex integrations (100+ AWS services)
    - ‚úÖ Long-running functions (up to 15 minutes)
    - ‚úÖ Large memory requirements (up to 10GB)
    - ‚úÖ VPC access for private resources
    - ‚úÖ Best for: Enterprise apps, data processing, batch jobs¬∑
    **Vercel Edge Functions**:
    - ‚úÖ Next.js integration (middleware, API routes)
    - ‚úÖ Global edge deployment (low latency)
    - ‚úÖ Streaming responses (SSE, WebSockets)
    - ‚úÖ Zero cold starts (edge runtime)
    - ‚úÖ Best for: API routes, user-facing apps, real-time features¬∑
    **Cloudflare Workers**:
    - ‚úÖ Ultra-low latency (<50ms globally)
    - ‚úÖ Zero cold starts (V8 isolates)
    - ‚úÖ Unlimited scalability
    - ‚úÖ KV storage integration
    - ‚úÖ Best for: CDN logic, edge APIs, A/B testing¬∑
    **Google Cloud Functions**:
    - ‚úÖ GCP integration (BigQuery, Pub/Sub)
    - ‚úÖ Cloud Run integration (containers)
    - ‚úÖ Best for: Google Cloud ecosystem¬∑
    ---¬∑
    ## AWS Lambda Patterns¬∑
    ### 1. Basic Lambda Function¬∑
    ```typescript
    // handler.ts - Simple Lambda handler
    import { APIGatewayProxyEvent, APIGatewayProxyResult } from 'aws-lambda';¬∑
    export const handler = async (
      event: APIGatewayProxyEvent
    ): Promise<APIGatewayProxyResult> => {
      console.log('Event:', JSON.stringify(event, null, 2));¬∑
      const body = event.body ? JSON.parse(event.body) : {};¬∑
      return {
        statusCode: 200,
        headers: {
          'Content-Type': 'application/json',
          'Access-Control-Allow-Origin': '*'
        },
        body: JSON.stringify({
          message: 'Success',
          input: body
        })
      };
    };
    ```¬∑
    ### 2. Lambda with Database Connection¬∑
    ```typescript
    // Cold start optimization - connection reuse
    import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
    import { DynamoDBDocumentClient, PutCommand, GetCommand } from '@aws-sdk/lib-dynamodb';¬∑
    // Initialize outside handler - reused across invocations
    const client = new DynamoDBClient({ region: 'us-east-1' });
    const docClient = DynamoDBDocumentClient.from(client);¬∑
    export const handler = async (event: APIGatewayProxyEvent) => {
      const { userId, data } = JSON.parse(event.body || '{}');¬∑
      // Write to DynamoDB
      await docClient.send(new PutCommand({
        TableName: 'Users',
        Item: {
          userId,
          data,
          createdAt: new Date().toISOString()
        }
      }));¬∑
      return {
        statusCode: 201,
        body: JSON.stringify({ success: true })
      };
    };
    ```¬∑
    ### 3. S3 Event Trigger¬∑
    ```typescript
    // Triggered when file uploaded to S3
    import { S3Event } from 'aws-lambda';
    import { S3Client, GetObjectCommand } from '@aws-sdk/client-s3';¬∑
    const s3Client = new S3Client({ region: 'us-east-1' });¬∑
    export const handler = async (event: S3Event) => {
      for (const record of event.Records) {
        const bucket = record.s3.bucket.name;
        const key = decodeURIComponent(record.s3.object.key.replace(/\\+/g, ' '));¬∑
        console.log(`Processing file: ${bucket}/${key}`);¬∑
        // Get file from S3
        const response = await s3Client.send(new GetObjectCommand({
          Bucket: bucket,
          Key: key
        }));¬∑
        const fileContent = await response.Body?.transformToString();¬∑
        // Process file (resize image, parse CSV, etc.)
        await processFile(fileContent);
      }
    };
    ```¬∑
    ### 4. Scheduled Lambda (Cron)¬∑
    ```typescript
    // CloudWatch Events trigger - runs on schedule
    import { ScheduledEvent } from 'aws-lambda';
    import { SESClient, SendEmailCommand } from '@aws-sdk/client-ses';¬∑
    const sesClient = new SESClient({ region: 'us-east-1' });¬∑
    export const handler = async (event: ScheduledEvent) => {
      console.log(`Scheduled task triggered at: ${event.time}`);¬∑
      // Send daily report
      await sesClient.send(new SendEmailCommand({
        Source: 'reports@example.com',
        Destination: { ToAddresses: ['admin@example.com'] },
        Message: {
          Subject: { Data: 'Daily Report' },
          Body: {
            Text: { Data: `Report for ${new Date().toISOString()}` }
          }
        }
      }));¬∑
      return { statusCode: 200 };
    };
    ```¬∑
    ### 5. Lambda Layers (Shared Dependencies)¬∑
    ```bash
    # Create layer with shared dependencies
    mkdir -p layer/nodejs
    cd layer/nodejs
    npm install pg redis¬∑
    cd ..
    zip -r layer.zip nodejs/¬∑
    # Deploy layer
    aws lambda publish-layer-version \\
      --layer-name shared-deps \\
      --zip-file fileb://layer.zip \\
      --compatible-runtimes nodejs20.x
    ```¬∑
    ```typescript
    // Use layer in Lambda function
    // layers: [arn:aws:lambda:us-east-1:123456789:layer:shared-deps:1]¬∑
    import { Pool } from 'pg';  // From layer¬∑
    const pool = new Pool({
      host: process.env.DB_HOST,
      database: process.env.DB_NAME,
      user: process.env.DB_USER,
      password: process.env.DB_PASSWORD
    });¬∑
    export const handler = async (event) => {
      const result = await pool.query('SELECT * FROM users WHERE id = $1', [event.userId]);
      return { statusCode: 200, body: JSON.stringify(result.rows[0]) };
    };
    ```¬∑
    ---¬∑
    ## Vercel Edge Functions¬∑
    ### 1. Basic Edge Function¬∑
    ```typescript
    // app/api/hello/route.ts - Next.js Edge API Route
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const name = searchParams.get('name') || 'World';¬∑
      return new Response(JSON.stringify({ message: `Hello, ${name}!` }), {
        headers: { 'content-type': 'application/json' }
      });
    }
    ```¬∑
    ### 2. Middleware (Authentication)¬∑
    ```typescript
    // middleware.ts - Runs on all requests at the edge
    import { NextResponse } from 'next/server';
    import type { NextRequest } from 'next/server';¬∑
    export function middleware(request: NextRequest) {
      const token = request.cookies.get('auth-token')?.value;¬∑
      // Protected routes
      if (request.nextUrl.pathname.startsWith('/dashboard')) {
        if (!token) {
          return NextResponse.redirect(new URL('/login', request.url));
        }¬∑
        // Verify JWT at the edge (fast!)
        try {
          const payload = verifyJWT(token);
          const response = NextResponse.next();
          response.headers.set('x-user-id', payload.userId);
          return response;
        } catch {
          return NextResponse.redirect(new URL('/login', request.url));
        }
      }¬∑
      return NextResponse.next();
    }¬∑
    export const config = {
      matcher: ['/dashboard/:path*', '/api/:path*']
    };
    ```¬∑
    ### 3. Edge API with Database¬∑
    ```typescript
    // app/api/users/route.ts - Edge function with Vercel Postgres
    export const runtime = 'edge';¬∑
    import { sql } from '@vercel/postgres';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const userId = searchParams.get('id');¬∑
      const { rows } = await sql`
        SELECT id, name, email FROM users WHERE id = ${userId}
      `;¬∑
      return Response.json(rows[0] || { error: 'Not found' });
    }¬∑
    export async function POST(request: Request) {
      const { name, email } = await request.json();¬∑
      const { rows } = await sql`
        INSERT INTO users (name, email) VALUES (${name}, ${email})
        RETURNING id, name, email
      `;¬∑
      return Response.json(rows[0], { status: 201 });
    }
    ```¬∑
    ### 4. Streaming Response (SSE)¬∑
    ```typescript
    // app/api/stream/route.ts - Server-Sent Events at the edge
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const encoder = new TextEncoder();¬∑
      const stream = new ReadableStream({
        async start(controller) {
          for (let i = 0; i < 10; i++) {
            const message = `data: ${JSON.stringify({ count: i, time: Date.now() })}\\n\\n`;
            controller.enqueue(encoder.encode(message));
            await new Promise(resolve => setTimeout(resolve, 1000));
          }
          controller.close();
        }
      });¬∑
      return new Response(stream, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive'
        }
      });
    }
    ```¬∑
    ### 5. Geolocation-Based Response¬∑
    ```typescript
    // app/api/geo/route.ts - Edge function with geolocation
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      // Vercel Edge provides geolocation headers
      const geo = {
        city: request.headers.get('x-vercel-ip-city'),
        country: request.headers.get('x-vercel-ip-country'),
        region: request.headers.get('x-vercel-ip-country-region'),
        latitude: request.headers.get('x-vercel-ip-latitude'),
        longitude: request.headers.get('x-vercel-ip-longitude')
      };¬∑
      // Customize response based on location
      const currency = geo.country === 'US' ? 'USD' : 'EUR';
      const language = geo.country === 'US' ? 'en-US' : 'en-GB';¬∑
      return Response.json({
        geo,
        currency,
        language
      });
    }
    ```¬∑
    ---¬∑
    ## Cloudflare Workers¬∑
    ### 1. Basic Worker¬∑
    ```typescript
    // index.ts - Cloudflare Worker
    export default {
      async fetch(request: Request): Promise<Response> {
        const url = new URL(request.url);¬∑
        if (url.pathname === '/api/hello') {
          return new Response(JSON.stringify({ message: 'Hello from the edge!' }), {
            headers: { 'content-type': 'application/json' }
          });
        }¬∑
        return new Response('Not found', { status: 404 });
      }
    };
    ```¬∑
    ### 2. Worker with KV Storage¬∑
    ```typescript
    // Worker with Cloudflare KV (key-value store)
    interface Env {
      MY_KV: KVNamespace;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const url = new URL(request.url);
        const key = url.searchParams.get('key');¬∑
        if (request.method === 'GET' && key) {
          const value = await env.MY_KV.get(key);
          return Response.json({ key, value });
        }¬∑
        if (request.method === 'POST') {
          const { key, value } = await request.json();
          await env.MY_KV.put(key, value, { expirationTtl: 3600 }); // 1 hour TTL
          return Response.json({ success: true });
        }¬∑
        return new Response('Method not allowed', { status: 405 });
      }
    };
    ```¬∑
    ### 3. Worker with Durable Objects (Stateful)¬∑
    ```typescript
    // Durable Object - WebSocket chat room
    export class ChatRoom {
      state: DurableObjectState;
      sessions: Set<WebSocket>;¬∑
      constructor(state: DurableObjectState) {
        this.state = state;
        this.sessions = new Set();
      }¬∑
      async fetch(request: Request): Promise<Response> {
        const upgradeHeader = request.headers.get('Upgrade');¬∑
        if (upgradeHeader === 'websocket') {
          const [client, server] = Object.values(new WebSocketPair());¬∑
          this.sessions.add(server);
          server.accept();¬∑
          server.addEventListener('message', (event) => {
            // Broadcast to all connected clients
            for (const session of this.sessions) {
              session.send(event.data);
            }
          });¬∑
          server.addEventListener('close', () => {
            this.sessions.delete(server);
          });¬∑
          return new Response(null, { status: 101, webSocket: client });
        }¬∑
        return new Response('Expected WebSocket', { status: 400 });
      }
    }¬∑
    // Worker that uses Durable Object
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const url = new URL(request.url);
        const roomName = url.pathname.slice(1);¬∑
        const id = env.CHAT_ROOM.idFromName(roomName);
        const room = env.CHAT_ROOM.get(id);¬∑
        return room.fetch(request);
      }
    };
    ```¬∑
    ### 4. Worker with Caching¬∑
    ```typescript
    // Edge caching with Cache API
    export default {
      async fetch(request: Request): Promise<Response> {
        const cache = caches.default;
        const cacheKey = new Request(request.url, request);¬∑
        // Try to get from cache
        let response = await cache.match(cacheKey);¬∑
        if (!response) {
          // Cache miss - fetch from origin
          console.log('Cache miss, fetching from origin');
          response = await fetch(request);¬∑
          // Clone response before caching (response can only be read once)
          const clonedResponse = response.clone();¬∑
          // Cache for 1 hour
          const headers = new Headers(clonedResponse.headers);
          headers.set('Cache-Control', 'public, max-age=3600');¬∑
          const cachedResponse = new Response(clonedResponse.body, {
            status: clonedResponse.status,
            statusText: clonedResponse.statusText,
            headers
          });¬∑
          // Don't await - cache in background
          cache.put(cacheKey, cachedResponse);
        } else {
          console.log('Cache hit');
        }¬∑
        return response;
      }
    };
    ```¬∑
    ---¬∑
    ## Cold Start Optimization¬∑
    ### 1. Lambda Cold Start Mitigation¬∑
    ```typescript
    // Minimize dependencies - use AWS SDK v3 (modular)
    import { DynamoDBClient } from '@aws-sdk/client-dynamodb';  // Only what you need¬∑
    // NOT: import AWS from 'aws-sdk';  // Loads entire SDK (slow!)¬∑
    // Initialize connections outside handler
    const dynamoDb = new DynamoDBClient({ region: 'us-east-1' });¬∑
    // Lazy load heavy dependencies
    let heavyLib: any;¬∑
    export const handler = async (event: APIGatewayProxyEvent) => {
      // Only load if needed
      if (event.path === '/heavy') {
        if (!heavyLib) {
          heavyLib = await import('./heavy-library');
        }
        return heavyLib.process(event);
      }¬∑
      // Fast path - no heavy imports
      return { statusCode: 200, body: JSON.stringify({ message: 'Fast!' }) };
    };
    ```¬∑
    ### 2. Provisioned Concurrency¬∑
    ```yaml
    # serverless.yml - AWS Lambda with provisioned concurrency
    functions:
      api:
        handler: handler.main
        provisionedConcurrency: 5  # Keep 5 instances warm
        reservedConcurrency: 100   # Max 100 concurrent executions
        events:
          - http:
              path: /api/{proxy+}
              method: ANY
    ```¬∑
    ### 3. Lambda SnapStart (Java/.NET)¬∑
    ```yaml
    # For Java/Spring Boot Lambda
    functions:
      springApi:
        handler: org.springframework.cloud.function.adapter.aws.FunctionInvoker
        runtime: java17
        snapStart: true  # Reduces cold start from 10s to 1s
        memorySize: 2048
    ```¬∑
    ### 4. Warming Strategy¬∑
    ```typescript
    // Scheduled event to keep Lambda warm
    export const warmer = async (event: any) => {
      if (event.source === 'aws.events') {
        console.log('Warmer ping - keeping function warm');
        return { statusCode: 200, body: 'Warm' };
      }¬∑
      // Actual handler logic
      return await handleRequest(event);
    };
    ```¬∑
    ```yaml
    # serverless.yml - Warming schedule
    functions:
      api:
        handler: handler.warmer
        events:
          - http: ANY /api/{proxy+}
          - schedule:
              rate: rate(5 minutes)  # Ping every 5 minutes
              input:
                source: aws.events
    ```¬∑
    ---¬∑
    ## Cost Optimization¬∑
    ### 1. Right-Sizing Memory¬∑
    ```typescript
    // Lambda pricing: Memory √ó Duration
    // More memory = faster execution = potentially cheaper!¬∑
    // Example: Process 1000 items
    // 128 MB: 5000ms = $0.000000208 √ó 128 √ó 5 = $0.000133
    // 1024 MB: 625ms = $0.000001667 √ó 1024 √ó 0.625 = $0.000107 (cheaper!)¬∑
    // Run benchmarks to find optimal memory
    import { PerformanceObserver, performance } from 'perf_hooks';¬∑
    export const handler = async (event: any) => {
      const start = performance.now();¬∑
      // Your logic here
      await processItems(event.items);¬∑
      const duration = performance.now() - start;
      const memoryMB = parseInt(process.env.AWS_LAMBDA_FUNCTION_MEMORY_SIZE || '128');¬∑
      console.log(JSON.stringify({
        memoryMB,
        durationMs: duration,
        cost: calculateCost(memoryMB, duration)
      }));
    };¬∑
    function calculateCost(memoryMB: number, durationMs: number): number {
      const gbSeconds = (memoryMB / 1024) * (durationMs / 1000);
      return gbSeconds * 0.0000166667;  // AWS pricing per GB-second
    }
    ```¬∑
    ### 2. Caching Responses¬∑
    ```typescript
    // Edge function with aggressive caching
    export const runtime = 'edge';¬∑
    export async function GET(request: Request) {
      const data = await fetchExpensiveData();¬∑
      return new Response(JSON.stringify(data), {
        headers: {
          'Content-Type': 'application/json',
          'Cache-Control': 'public, s-maxage=3600, stale-while-revalidate=86400'
          // Cache for 1 hour, serve stale for 24 hours
        }
      });
    }
    ```¬∑
    ### 3. Batch Processing¬∑
    ```typescript
    // Process items in batches to reduce invocations
    import { SQSEvent } from 'aws-lambda';¬∑
    export const handler = async (event: SQSEvent) => {
      // Process all messages in one invocation (up to 10)
      const promises = event.Records.map(async (record) => {
        const data = JSON.parse(record.body);
        return processItem(data);
      });¬∑
      await Promise.all(promises);¬∑
      // Return success for all messages
      return { batchItemFailures: [] };
    };
    ```¬∑
    ---¬∑
    ## Deployment Patterns¬∑
    ### 1. AWS SAM Template¬∑
    ```yaml
    # template.yaml - AWS SAM (Serverless Application Model)
    AWSTemplateFormatVersion: '2010-09-09'
    Transform: AWS::Serverless-2016-10-31¬∑
    Globals:
      Function:
        Runtime: nodejs20.x
        Timeout: 30
        MemorySize: 256
        Environment:
          Variables:
            TABLE_NAME: !Ref UsersTable¬∑
    Resources:
      ApiFunction:
        Type: AWS::Serverless::Function
        Properties:
          Handler: dist/handler.main
          Events:
            Api:
              Type: Api
              Properties:
                Path: /api/{proxy+}
                Method: ANY
          Policies:
            - DynamoDBCrudPolicy:
                TableName: !Ref UsersTable¬∑
      UsersTable:
        Type: AWS::Serverless::SimpleTable
        Properties:
          PrimaryKey:
            Name: userId
            Type: String
    ```¬∑
    ### 2. Serverless Framework¬∑
    ```yaml
    # serverless.yml
    service: my-api¬∑
    provider:
      name: aws
      runtime: nodejs20.x
      region: us-east-1
      environment:
        TABLE_NAME: ${self:service}-users-${sls:stage}¬∑
    functions:
      api:
        handler: dist/handler.main
        events:
          - httpApi:
              path: /api/{proxy+}
              method: '*'
        iamRoleStatements:
          - Effect: Allow
            Action:
              - dynamodb:*
            Resource: !GetAtt UsersTable.Arn¬∑
    resources:
      Resources:
        UsersTable:
          Type: AWS::DynamoDB::Table
          Properties:
            BillingMode: PAY_PER_REQUEST
            AttributeDefinitions:
              - AttributeName: userId
                AttributeType: S
            KeySchema:
              - AttributeName: userId
                KeyType: HASH
    ```¬∑
    ### 3. Vercel Deployment¬∑
    ```json
    // vercel.json
    {
      \"functions\": {
        \"app/api/**/*.ts\": {
          \"runtime\": \"edge\",
          \"regions\": [\"iad1\", \"sfo1\", \"fra1\"],
          \"maxDuration\": 10
        }
      },
      \"env\": {
        \"DATABASE_URL\": \"@database-url\"
      }
    }
    ```¬∑
    ---¬∑
    ## Monitoring & Debugging¬∑
    ### 1. Structured Logging¬∑
    ```typescript
    import { APIGatewayProxyEvent, Context } from 'aws-lambda';¬∑
    // Structured logs for CloudWatch Logs Insights
    export const handler = async (event: APIGatewayProxyEvent, context: Context) => {
      const logger = {
        info: (message: string, meta?: any) => console.log(JSON.stringify({
          level: 'info',
          message,
          requestId: context.requestId,
          functionName: context.functionName,
          ...meta
        })),
        error: (message: string, error?: Error) => console.error(JSON.stringify({
          level: 'error',
          message,
          requestId: context.requestId,
          error: error?.message,
          stack: error?.stack
        }))
      };¬∑
      try {
        logger.info('Processing request', { path: event.path });
        const result = await processRequest(event);
        logger.info('Request completed', { duration: context.getRemainingTimeInMillis() });
        return result;
      } catch (error) {
        logger.error('Request failed', error as Error);
        throw error;
      }
    };
    ```¬∑
    ### 2. X-Ray Tracing¬∑
    ```typescript
    // Enable AWS X-Ray for distributed tracing
    import AWSXRay from 'aws-xray-sdk-core';
    import AWS from 'aws-sdk';¬∑
    const dynamodb = AWSXRay.captureAWSClient(new AWS.DynamoDB.DocumentClient());¬∑
    export const handler = async (event: any) => {
      const segment = AWSXRay.getSegment();
      const subsegment = segment?.addNewSubsegment('process-items');¬∑
      try {
        // Traced DynamoDB call
        const result = await dynamodb.get({
          TableName: 'Users',
          Key: { userId: event.userId }
        }).promise();¬∑
        subsegment?.close();
        return result;
      } catch (error) {
        subsegment?.addError(error as Error);
        subsegment?.close();
        throw error;
      }
    };
    ```¬∑
    ### 3. CloudWatch Metrics¬∑
    ```typescript
    import { CloudWatch } from '@aws-sdk/client-cloudwatch';¬∑
    const cloudwatch = new CloudWatch({ region: 'us-east-1' });¬∑
    export const handler = async (event: any) => {
      const start = Date.now();¬∑
      try {
        const result = await processRequest(event);¬∑
        // Custom metric
        await cloudwatch.putMetricData({
          Namespace: 'MyApp/Lambda',
          MetricData: [{
            MetricName: 'ProcessingDuration',
            Value: Date.now() - start,
            Unit: 'Milliseconds',
            Dimensions: [
              { Name: 'FunctionName', Value: process.env.AWS_LAMBDA_FUNCTION_NAME! }
            ]
          }]
        });¬∑
        return result;
      } catch (error) {
        // Error metric
        await cloudwatch.putMetricData({
          Namespace: 'MyApp/Lambda',
          MetricData: [{
            MetricName: 'Errors',
            Value: 1,
            Unit: 'Count'
          }]
        });¬∑
        throw error;
      }
    };
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `deploy-lambda.sh` - Deploy Lambda with SAM/Serverless Framework
    - `test-edge-function.sh` - Local testing for edge functions¬∑
    ### references/
    - `references/lambda-best-practices.md` - AWS Lambda optimization guide
    - `references/edge-runtime.md` - Vercel/Cloudflare edge runtime comparison
    - `references/serverless-pricing.md` - Cost comparison and optimization¬∑
    ### assets/
    - `assets/sam-templates/` - AWS SAM template examples
    - `assets/serverless-configs/` - Serverless Framework configurations¬∑
    ## Related Skills¬∑
    - `microservices` - Microservices vs serverless trade-offs
    - `edge-databases` - Edge computing with distributed databases
    - `api-design` - API design patterns for serverless functions
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ vector-databases ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: vector-databases
    description: Vector databases and semantic search using pgvector, embeddings, and similarity algorithms (cosine, euclidean, HNSW, IVFFlat). Use when implementing RAG systems, semantic search, recommendation engines, or AI features requiring embeddings. Provides 10-100x faster similarity search compared to brute-force approaches.
    ---¬∑
    # Vector Databases¬∑
    ## Overview¬∑
    Vector databases for storing and querying embeddings (high-dimensional vectors) using pgvector, similarity search algorithms (HNSW, IVFFlat), and semantic search patterns. Essential for RAG (Retrieval-Augmented Generation), recommendation systems, and AI-powered features.¬∑
    **Goal**: Efficient storage and retrieval of embeddings for semantic search and similarity matching¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing RAG systems (semantic search over documents)
    - Building recommendation engines (similar products, content)
    - Creating AI features (chatbots, Q&A, document search)
    - Storing embeddings from OpenAI, Cohere, or custom models
    - Optimizing similarity search performance (HNSW vs IVFFlat)
    - Implementing hybrid search (vector + full-text)
    - Migrating from Pinecone/Weaviate to pgvector¬∑
    **Triggers**: \"vector database\", \"pgvector\", \"embeddings\", \"semantic search\", \"similarity search\", \"RAG\", \"HNSW\", \"IVFFlat\"¬∑
    ---¬∑
    ## Quick Start: Vector Database Decision Tree¬∑
    ### When to Use pgvector vs Pinecone vs Weaviate¬∑
    **pgvector** (PostgreSQL extension):
    - ‚úÖ Already using PostgreSQL
    - ‚úÖ Want single database (relational + vector data)
    - ‚úÖ Cost-effective (no separate vector DB service)
    - ‚úÖ ACID transactions (join vectors with relational data)
    - ‚úÖ Up to 10M vectors (scales with PostgreSQL)
    - ‚úÖ Best for: Supabase projects, existing Postgres apps, cost optimization¬∑
    **Pinecone** (Managed vector DB):
    - ‚úÖ 100M+ vectors (massive scale)
    - ‚úÖ Real-time updates (low-latency writes)
    - ‚úÖ Metadata filtering (fast pre-filtering)
    - ‚úÖ Fully managed (no infrastructure)
    - ‚úÖ Multi-region replication
    - ‚úÖ Best for: Large-scale production apps, high-traffic APIs¬∑
    **Weaviate** (Open-source vector DB):
    - ‚úÖ Self-hosted (full control)
    - ‚úÖ Built-in vectorization (BERT, GPT, CLIP)
    - ‚úÖ GraphQL API
    - ‚úÖ Hybrid search (vector + keyword)
    - ‚úÖ Multi-tenancy support
    - ‚úÖ Best for: Self-hosted infrastructure, complex data models¬∑
    **Use Multiple** when:
    - pgvector for main app + Pinecone for external API (fast public queries)
    - Weaviate for document search + pgvector for user data¬∑
    ---¬∑
    ## pgvector Patterns¬∑
    ### 1. Installation & Setup¬∑
    ```sql
    -- Enable pgvector extension
    CREATE EXTENSION vector;¬∑
    -- Create table with vector column
    CREATE TABLE documents (
      id BIGSERIAL PRIMARY KEY,
      content TEXT NOT NULL,
      embedding VECTOR(1536), -- OpenAI ada-002 dimensions
      metadata JSONB,
      created_at TIMESTAMPTZ DEFAULT NOW()
    );¬∑
    -- Create index for similarity search (HNSW - fast, approximate)
    CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);¬∑
    -- Alternative: IVFFlat index (faster build time, slower queries)
    -- CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
    ```¬∑
    ### 2. Storing Embeddings¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    async function storeDocument(content: string, metadata?: any) {
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: content
      });¬∑
      const embedding = response.data[0].embedding; // Array of 1536 floats¬∑
      // Store in database
      const result = await db.query(
        `INSERT INTO documents (content, embedding, metadata)
         VALUES ($1, $2, $3)
         RETURNING id`,
        [content, embedding, metadata]
      );¬∑
      return result.rows[0].id;
    }¬∑
    // Example usage
    await storeDocument(
      'PostgreSQL is a powerful, open source object-relational database system.',
      { category: 'database', source: 'docs' }
    );
    ```¬∑
    ### 3. Similarity Search (Cosine, Euclidean, Inner Product)¬∑
    ```sql
    -- Cosine similarity (most common for embeddings)
    -- Range: -1 (opposite) to 1 (identical)
    -- 1 - (embedding <=> query_embedding) converts distance to similarity
    SELECT
      id,
      content,
      1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    ORDER BY embedding <=> $1::vector
    LIMIT 10;¬∑
    -- Euclidean distance (L2 distance)
    -- Lower distance = more similar
    SELECT
      id,
      content,
      embedding <-> $1::vector AS distance
    FROM documents
    ORDER BY embedding <-> $1::vector
    LIMIT 10;¬∑
    -- Inner product (dot product)
    -- Higher value = more similar
    SELECT
      id,
      content,
      embedding <#> $1::vector AS inner_product
    FROM documents
    ORDER BY embedding <#> $1::vector DESC
    LIMIT 10;
    ```¬∑
    ### 4. Semantic Search Implementation¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    async function semanticSearch(query: string, limit: number = 10) {
      // Generate query embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const queryEmbedding = response.data[0].embedding;¬∑
      // Search for similar documents
      const result = await db.query(
        `SELECT
           id,
           content,
           metadata,
           1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         WHERE 1 - (embedding <=> $1::vector) > 0.7 -- Threshold: 70% similarity
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        [queryEmbedding, limit]
      );¬∑
      return result.rows;
    }¬∑
    // Example usage
    const results = await semanticSearch('How do I optimize PostgreSQL queries?');
    console.log(results);
    // [
    //   { content: 'PostgreSQL query optimization guide...', similarity: 0.89 },
    //   { content: 'Indexes in PostgreSQL...', similarity: 0.82 }
    // ]
    ```¬∑
    ### 5. Hybrid Search (Vector + Full-Text)¬∑
    ```sql
    -- Create full-text search index
    ALTER TABLE documents ADD COLUMN content_tsv TSVECTOR
      GENERATED ALWAYS AS (to_tsvector('english', content)) STORED;¬∑
    CREATE INDEX ON documents USING GIN (content_tsv);¬∑
    -- Hybrid search (combines vector similarity + keyword matching)
    SELECT
      id,
      content,
      1 - (embedding <=> $1::vector) AS vector_similarity,
      ts_rank(content_tsv, to_tsquery('english', $2)) AS text_rank,
      (1 - (embedding <=> $1::vector)) * 0.7 +
        ts_rank(content_tsv, to_tsquery('english', $2)) * 0.3 AS combined_score
    FROM documents
    WHERE content_tsv @@ to_tsquery('english', $2)  -- Filter by keyword first
    ORDER BY combined_score DESC
    LIMIT 10;
    ```¬∑
    ```typescript
    // Hybrid search implementation
    async function hybridSearch(query: string, limit: number = 10) {
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Convert query to tsquery format (replace spaces with &)
      const tsquery = query.split(' ').join(' & ');¬∑
      const result = await db.query(
        `SELECT
           id,
           content,
           1 - (embedding <=> $1::vector) AS vector_similarity,
           ts_rank(content_tsv, to_tsquery('english', $2)) AS text_rank,
           (1 - (embedding <=> $1::vector)) * 0.7 +
             ts_rank(content_tsv, to_tsquery('english', $2)) * 0.3 AS combined_score
         FROM documents
         WHERE content_tsv @@ to_tsquery('english', $2)
         ORDER BY combined_score DESC
         LIMIT $3`,
        [embedding, tsquery, limit]
      );¬∑
      return result.rows;
    }
    ```¬∑
    ### 6. Metadata Filtering¬∑
    ```sql
    -- Search with metadata filters
    SELECT
      id,
      content,
      metadata,
      1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    WHERE
      metadata->>'category' = 'database' AND
      metadata->>'language' = 'en' AND
      (metadata->>'created_at')::timestamptz > NOW() - INTERVAL '30 days'
    ORDER BY embedding <=> $1::vector
    LIMIT 10;
    ```¬∑
    ```typescript
    // Filtered semantic search
    interface SearchFilters {
      category?: string;
      language?: string;
      dateAfter?: Date;
    }¬∑
    async function filteredSearch(
      query: string,
      filters: SearchFilters = {},
      limit: number = 10
    ) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Build WHERE clause dynamically
      const conditions: string[] = [];
      const params: any[] = [embedding, limit];
      let paramIndex = 3;¬∑
      if (filters.category) {
        conditions.push(`metadata->>'category' = $${paramIndex++}`);
        params.push(filters.category);
      }¬∑
      if (filters.language) {
        conditions.push(`metadata->>'language' = $${paramIndex++}`);
        params.push(filters.language);
      }¬∑
      if (filters.dateAfter) {
        conditions.push(`(metadata->>'created_at')::timestamptz > $${paramIndex++}`);
        params.push(filters.dateAfter);
      }¬∑
      const whereClause = conditions.length > 0
        ? `WHERE ${conditions.join(' AND ')}`
        : '';¬∑
      const result = await db.query(
        `SELECT
           id,
           content,
           metadata,
           1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         ${whereClause}
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        params
      );¬∑
      return result.rows;
    }
    ```¬∑
    ---¬∑
    ## Index Optimization¬∑
    ### 1. HNSW vs IVFFlat¬∑
    ```sql
    -- HNSW (Hierarchical Navigable Small World)
    -- ‚úÖ Pros: Fastest queries (10-100x faster than IVFFlat)
    -- ‚úÖ Pros: No training required
    -- ‚ùå Cons: Slower index build time
    -- ‚ùå Cons: Larger index size
    -- Best for: Production apps with frequent queries¬∑
    CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);¬∑
    -- Parameters:
    -- m = 16: Number of bi-directional links (higher = better recall, slower build)
    -- ef_construction = 64: Size of dynamic candidate list (higher = better recall, slower build)¬∑
    -- Query-time parameters:
    SET hnsw.ef_search = 100; -- Higher = better recall, slower queries¬∑¬∑
    -- IVFFlat (Inverted File with Flat Compression)
    -- ‚úÖ Pros: Faster index build time
    -- ‚úÖ Pros: Smaller index size
    -- ‚ùå Cons: Requires training (VACUUM ANALYZE)
    -- ‚ùå Cons: Slower queries than HNSW
    -- Best for: Development, infrequent queries, large batch updates¬∑
    CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);¬∑
    -- Parameters:
    -- lists = sqrt(num_rows): Number of clusters
    -- Example: 1M rows ‚Üí lists = 1000, 10M rows ‚Üí lists = 3162¬∑
    -- Query-time parameters:
    SET ivfflat.probes = 10; -- Higher = better recall, slower queries
    ```¬∑
    ### 2. Index Selection Guide¬∑
    ```typescript
    // Index selection based on dataset size and query patterns¬∑
    // Small dataset (< 100K vectors)
    // No index needed - brute force is fast enough
    // ALTER TABLE documents DROP INDEX IF EXISTS documents_embedding_idx;¬∑
    // Medium dataset (100K - 1M vectors)
    // Use IVFFlat for development, HNSW for production
    const indexConfig = {
      development: 'ivfflat (embedding vector_cosine_ops) WITH (lists = 316)',
      production: 'hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64)'
    };¬∑
    // Large dataset (1M - 10M vectors)
    // Use HNSW with tuned parameters
    const indexConfig = {
      production: 'hnsw (embedding vector_cosine_ops) WITH (m = 24, ef_construction = 128)'
    };¬∑
    // Very large dataset (10M+ vectors)
    // Consider sharding or Pinecone
    ```¬∑
    ### 3. Index Maintenance¬∑
    ```sql
    -- Rebuild index after bulk inserts
    REINDEX INDEX documents_embedding_idx;¬∑
    -- Update statistics (required for IVFFlat)
    VACUUM ANALYZE documents;¬∑
    -- Monitor index size
    SELECT
      schemaname,
      tablename,
      indexname,
      pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
    FROM pg_stat_user_indexes
    WHERE tablename = 'documents';
    ```¬∑
    ---¬∑
    ## RAG (Retrieval-Augmented Generation) Pattern¬∑
    ### 1. Complete RAG Implementation¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    // Step 1: Store documents with embeddings
    async function indexDocument(content: string, metadata?: any) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: content
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      await db.query(
        `INSERT INTO documents (content, embedding, metadata)
         VALUES ($1, $2, $3)`,
        [content, embedding, metadata]
      );
    }¬∑
    // Step 2: Retrieve relevant context
    async function retrieveContext(query: string, limit: number = 5) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      const result = await db.query(
        `SELECT content, 1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         WHERE 1 - (embedding <=> $1::vector) > 0.7
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        [embedding, limit]
      );¬∑
      return result.rows.map(row => row.content);
    }¬∑
    // Step 3: Generate answer with context
    async function askQuestion(question: string) {
      // Retrieve relevant documents
      const context = await retrieveContext(question);¬∑
      if (context.length === 0) {
        return { answer: 'No relevant information found.', sources: [] };
      }¬∑
      // Generate answer using context
      const completion = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are a helpful assistant. Answer the question based on the following context. If the answer is not in the context, say \"I don't have enough information to answer this question.\"\\n\\nContext:\\n${context.join('\\n\\n')}`
          },
          {
            role: 'user',
            content: question
          }
        ]
      });¬∑
      return {
        answer: completion.choices[0].message.content,
        sources: context
      };
    }¬∑
    // Example usage
    const result = await askQuestion('How do I optimize PostgreSQL queries?');
    console.log('Answer:', result.answer);
    console.log('Sources:', result.sources);
    ```¬∑
    ### 2. Chunking Strategies¬∑
    ```typescript
    // Split large documents into chunks for better retrieval
    function chunkDocument(text: string, chunkSize: number = 500, overlap: number = 50) {
      const chunks: string[] = [];
      let start = 0;¬∑
      while (start < text.length) {
        const end = Math.min(start + chunkSize, text.length);
        chunks.push(text.slice(start, end));
        start = end - overlap; // Overlap to maintain context
      }¬∑
      return chunks;
    }¬∑
    // Example: Index a large document
    async function indexLargeDocument(title: string, content: string) {
      const chunks = chunkDocument(content);¬∑
      for (const [index, chunk] of chunks.entries()) {
        await indexDocument(chunk, {
          title,
          chunk_index: index,
          total_chunks: chunks.length
        });
      }
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Batch Embedding Generation¬∑
    ```typescript
    // ‚úÖ Good - Batch embeddings (up to 2048 inputs)
    async function batchEmbeddings(texts: string[]) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: texts // Array of up to 2048 strings
      });¬∑
      return response.data.map(item => item.embedding);
    }¬∑
    // Store in single transaction
    async function batchIndexDocuments(documents: { content: string; metadata?: any }[]) {
      const contents = documents.map(doc => doc.content);
      const embeddings = await batchEmbeddings(contents);¬∑
      await db.query('BEGIN');¬∑
      for (let i = 0; i < documents.length; i++) {
        await db.query(
          `INSERT INTO documents (content, embedding, metadata)
           VALUES ($1, $2, $3)`,
          [documents[i].content, embeddings[i], documents[i].metadata]
        );
      }¬∑
      await db.query('COMMIT');
    }
    ```¬∑
    ### 2. Query Optimization¬∑
    ```sql
    -- ‚úÖ Good - Use index with similarity threshold
    SELECT id, content, 1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    WHERE 1 - (embedding <=> $1::vector) > 0.7 -- Pre-filter with threshold
    ORDER BY embedding <=> $1::vector
    LIMIT 10;¬∑
    -- ‚ùå Bad - Full scan without threshold
    SELECT id, content, 1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    ORDER BY embedding <=> $1::vector
    LIMIT 10;
    ```¬∑
    ### 3. Caching Embeddings¬∑
    ```typescript
    import { Redis } from 'ioredis';¬∑
    const redis = new Redis();¬∑
    async function getCachedEmbedding(text: string): Promise<number[] | null> {
      const cached = await redis.get(`embedding:${text}`);
      return cached ? JSON.parse(cached) : null;
    }¬∑
    async function setCachedEmbedding(text: string, embedding: number[]): Promise<void> {
      await redis.setex(`embedding:${text}`, 3600, JSON.stringify(embedding)); // 1 hour TTL
    }¬∑
    async function getEmbedding(text: string): Promise<number[]> {
      // Check cache first
      const cached = await getCachedEmbedding(text);
      if (cached) return cached;¬∑
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: text
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Cache result
      await setCachedEmbedding(text, embedding);¬∑
      return embedding;
    }
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-embeddings.py` - Batch generate embeddings from CSV/JSON
    - `migrate-to-pgvector.js` - Migrate from Pinecone/Weaviate to pgvector¬∑
    ### references/
    - `references/similarity-metrics.md` - Cosine vs Euclidean vs Inner Product comparison
    - `references/index-tuning.md` - HNSW vs IVFFlat parameter tuning guide
    - `references/rag-patterns.md` - RAG architecture patterns and chunking strategies
    - `references/embedding-models.md` - OpenAI, Cohere, Hugging Face embedding comparison¬∑
    ### assets/
    - `assets/migration-scripts/` - Pinecone ‚Üí pgvector migration scripts
    - `assets/benchmark-data/` - Performance benchmark datasets¬∑
    ## Related Skills¬∑
    - `schema-optimization` - Database indexing and query performance
    - `rls-policies` - Row-level security for multi-tenant vector data
    - `api-design` - REST/GraphQL APIs for semantic search
    - `edge-databases` - Supabase Edge Functions with pgvector
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ vector-databases ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: vector-databases
    description: Vector databases and semantic search using pgvector, embeddings, and similarity algorithms (cosine, euclidean, HNSW, IVFFlat). Use when implementing RAG systems, semantic search, recommendation engines, or AI features requiring embeddings. Provides 10-100x faster similarity search compared to brute-force approaches.
    ---¬∑
    # Vector Databases¬∑
    ## Overview¬∑
    Vector databases for storing and querying embeddings (high-dimensional vectors) using pgvector, similarity search algorithms (HNSW, IVFFlat), and semantic search patterns. Essential for RAG (Retrieval-Augmented Generation), recommendation systems, and AI-powered features.¬∑
    **Goal**: Efficient storage and retrieval of embeddings for semantic search and similarity matching¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Implementing RAG systems (semantic search over documents)
    - Building recommendation engines (similar products, content)
    - Creating AI features (chatbots, Q&A, document search)
    - Storing embeddings from OpenAI, Cohere, or custom models
    - Optimizing similarity search performance (HNSW vs IVFFlat)
    - Implementing hybrid search (vector + full-text)
    - Migrating from Pinecone/Weaviate to pgvector¬∑
    **Triggers**: \"vector database\", \"pgvector\", \"embeddings\", \"semantic search\", \"similarity search\", \"RAG\", \"HNSW\", \"IVFFlat\"¬∑
    ---¬∑
    ## Quick Start: Vector Database Decision Tree¬∑
    ### When to Use pgvector vs Pinecone vs Weaviate¬∑
    **pgvector** (PostgreSQL extension):
    - ‚úÖ Already using PostgreSQL
    - ‚úÖ Want single database (relational + vector data)
    - ‚úÖ Cost-effective (no separate vector DB service)
    - ‚úÖ ACID transactions (join vectors with relational data)
    - ‚úÖ Up to 10M vectors (scales with PostgreSQL)
    - ‚úÖ Best for: Supabase projects, existing Postgres apps, cost optimization¬∑
    **Pinecone** (Managed vector DB):
    - ‚úÖ 100M+ vectors (massive scale)
    - ‚úÖ Real-time updates (low-latency writes)
    - ‚úÖ Metadata filtering (fast pre-filtering)
    - ‚úÖ Fully managed (no infrastructure)
    - ‚úÖ Multi-region replication
    - ‚úÖ Best for: Large-scale production apps, high-traffic APIs¬∑
    **Weaviate** (Open-source vector DB):
    - ‚úÖ Self-hosted (full control)
    - ‚úÖ Built-in vectorization (BERT, GPT, CLIP)
    - ‚úÖ GraphQL API
    - ‚úÖ Hybrid search (vector + keyword)
    - ‚úÖ Multi-tenancy support
    - ‚úÖ Best for: Self-hosted infrastructure, complex data models¬∑
    **Use Multiple** when:
    - pgvector for main app + Pinecone for external API (fast public queries)
    - Weaviate for document search + pgvector for user data¬∑
    ---¬∑
    ## pgvector Patterns¬∑
    ### 1. Installation & Setup¬∑
    ```sql
    -- Enable pgvector extension
    CREATE EXTENSION vector;¬∑
    -- Create table with vector column
    CREATE TABLE documents (
      id BIGSERIAL PRIMARY KEY,
      content TEXT NOT NULL,
      embedding VECTOR(1536), -- OpenAI ada-002 dimensions
      metadata JSONB,
      created_at TIMESTAMPTZ DEFAULT NOW()
    );¬∑
    -- Create index for similarity search (HNSW - fast, approximate)
    CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);¬∑
    -- Alternative: IVFFlat index (faster build time, slower queries)
    -- CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
    ```¬∑
    ### 2. Storing Embeddings¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    async function storeDocument(content: string, metadata?: any) {
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: content
      });¬∑
      const embedding = response.data[0].embedding; // Array of 1536 floats¬∑
      // Store in database
      const result = await db.query(
        `INSERT INTO documents (content, embedding, metadata)
         VALUES ($1, $2, $3)
         RETURNING id`,
        [content, embedding, metadata]
      );¬∑
      return result.rows[0].id;
    }¬∑
    // Example usage
    await storeDocument(
      'PostgreSQL is a powerful, open source object-relational database system.',
      { category: 'database', source: 'docs' }
    );
    ```¬∑
    ### 3. Similarity Search (Cosine, Euclidean, Inner Product)¬∑
    ```sql
    -- Cosine similarity (most common for embeddings)
    -- Range: -1 (opposite) to 1 (identical)
    -- 1 - (embedding <=> query_embedding) converts distance to similarity
    SELECT
      id,
      content,
      1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    ORDER BY embedding <=> $1::vector
    LIMIT 10;¬∑
    -- Euclidean distance (L2 distance)
    -- Lower distance = more similar
    SELECT
      id,
      content,
      embedding <-> $1::vector AS distance
    FROM documents
    ORDER BY embedding <-> $1::vector
    LIMIT 10;¬∑
    -- Inner product (dot product)
    -- Higher value = more similar
    SELECT
      id,
      content,
      embedding <#> $1::vector AS inner_product
    FROM documents
    ORDER BY embedding <#> $1::vector DESC
    LIMIT 10;
    ```¬∑
    ### 4. Semantic Search Implementation¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    async function semanticSearch(query: string, limit: number = 10) {
      // Generate query embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const queryEmbedding = response.data[0].embedding;¬∑
      // Search for similar documents
      const result = await db.query(
        `SELECT
           id,
           content,
           metadata,
           1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         WHERE 1 - (embedding <=> $1::vector) > 0.7 -- Threshold: 70% similarity
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        [queryEmbedding, limit]
      );¬∑
      return result.rows;
    }¬∑
    // Example usage
    const results = await semanticSearch('How do I optimize PostgreSQL queries?');
    console.log(results);
    // [
    //   { content: 'PostgreSQL query optimization guide...', similarity: 0.89 },
    //   { content: 'Indexes in PostgreSQL...', similarity: 0.82 }
    // ]
    ```¬∑
    ### 5. Hybrid Search (Vector + Full-Text)¬∑
    ```sql
    -- Create full-text search index
    ALTER TABLE documents ADD COLUMN content_tsv TSVECTOR
      GENERATED ALWAYS AS (to_tsvector('english', content)) STORED;¬∑
    CREATE INDEX ON documents USING GIN (content_tsv);¬∑
    -- Hybrid search (combines vector similarity + keyword matching)
    SELECT
      id,
      content,
      1 - (embedding <=> $1::vector) AS vector_similarity,
      ts_rank(content_tsv, to_tsquery('english', $2)) AS text_rank,
      (1 - (embedding <=> $1::vector)) * 0.7 +
        ts_rank(content_tsv, to_tsquery('english', $2)) * 0.3 AS combined_score
    FROM documents
    WHERE content_tsv @@ to_tsquery('english', $2)  -- Filter by keyword first
    ORDER BY combined_score DESC
    LIMIT 10;
    ```¬∑
    ```typescript
    // Hybrid search implementation
    async function hybridSearch(query: string, limit: number = 10) {
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Convert query to tsquery format (replace spaces with &)
      const tsquery = query.split(' ').join(' & ');¬∑
      const result = await db.query(
        `SELECT
           id,
           content,
           1 - (embedding <=> $1::vector) AS vector_similarity,
           ts_rank(content_tsv, to_tsquery('english', $2)) AS text_rank,
           (1 - (embedding <=> $1::vector)) * 0.7 +
             ts_rank(content_tsv, to_tsquery('english', $2)) * 0.3 AS combined_score
         FROM documents
         WHERE content_tsv @@ to_tsquery('english', $2)
         ORDER BY combined_score DESC
         LIMIT $3`,
        [embedding, tsquery, limit]
      );¬∑
      return result.rows;
    }
    ```¬∑
    ### 6. Metadata Filtering¬∑
    ```sql
    -- Search with metadata filters
    SELECT
      id,
      content,
      metadata,
      1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    WHERE
      metadata->>'category' = 'database' AND
      metadata->>'language' = 'en' AND
      (metadata->>'created_at')::timestamptz > NOW() - INTERVAL '30 days'
    ORDER BY embedding <=> $1::vector
    LIMIT 10;
    ```¬∑
    ```typescript
    // Filtered semantic search
    interface SearchFilters {
      category?: string;
      language?: string;
      dateAfter?: Date;
    }¬∑
    async function filteredSearch(
      query: string,
      filters: SearchFilters = {},
      limit: number = 10
    ) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Build WHERE clause dynamically
      const conditions: string[] = [];
      const params: any[] = [embedding, limit];
      let paramIndex = 3;¬∑
      if (filters.category) {
        conditions.push(`metadata->>'category' = $${paramIndex++}`);
        params.push(filters.category);
      }¬∑
      if (filters.language) {
        conditions.push(`metadata->>'language' = $${paramIndex++}`);
        params.push(filters.language);
      }¬∑
      if (filters.dateAfter) {
        conditions.push(`(metadata->>'created_at')::timestamptz > $${paramIndex++}`);
        params.push(filters.dateAfter);
      }¬∑
      const whereClause = conditions.length > 0
        ? `WHERE ${conditions.join(' AND ')}`
        : '';¬∑
      const result = await db.query(
        `SELECT
           id,
           content,
           metadata,
           1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         ${whereClause}
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        params
      );¬∑
      return result.rows;
    }
    ```¬∑
    ---¬∑
    ## Index Optimization¬∑
    ### 1. HNSW vs IVFFlat¬∑
    ```sql
    -- HNSW (Hierarchical Navigable Small World)
    -- ‚úÖ Pros: Fastest queries (10-100x faster than IVFFlat)
    -- ‚úÖ Pros: No training required
    -- ‚ùå Cons: Slower index build time
    -- ‚ùå Cons: Larger index size
    -- Best for: Production apps with frequent queries¬∑
    CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);¬∑
    -- Parameters:
    -- m = 16: Number of bi-directional links (higher = better recall, slower build)
    -- ef_construction = 64: Size of dynamic candidate list (higher = better recall, slower build)¬∑
    -- Query-time parameters:
    SET hnsw.ef_search = 100; -- Higher = better recall, slower queries¬∑¬∑
    -- IVFFlat (Inverted File with Flat Compression)
    -- ‚úÖ Pros: Faster index build time
    -- ‚úÖ Pros: Smaller index size
    -- ‚ùå Cons: Requires training (VACUUM ANALYZE)
    -- ‚ùå Cons: Slower queries than HNSW
    -- Best for: Development, infrequent queries, large batch updates¬∑
    CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);¬∑
    -- Parameters:
    -- lists = sqrt(num_rows): Number of clusters
    -- Example: 1M rows ‚Üí lists = 1000, 10M rows ‚Üí lists = 3162¬∑
    -- Query-time parameters:
    SET ivfflat.probes = 10; -- Higher = better recall, slower queries
    ```¬∑
    ### 2. Index Selection Guide¬∑
    ```typescript
    // Index selection based on dataset size and query patterns¬∑
    // Small dataset (< 100K vectors)
    // No index needed - brute force is fast enough
    // ALTER TABLE documents DROP INDEX IF EXISTS documents_embedding_idx;¬∑
    // Medium dataset (100K - 1M vectors)
    // Use IVFFlat for development, HNSW for production
    const indexConfig = {
      development: 'ivfflat (embedding vector_cosine_ops) WITH (lists = 316)',
      production: 'hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64)'
    };¬∑
    // Large dataset (1M - 10M vectors)
    // Use HNSW with tuned parameters
    const indexConfig = {
      production: 'hnsw (embedding vector_cosine_ops) WITH (m = 24, ef_construction = 128)'
    };¬∑
    // Very large dataset (10M+ vectors)
    // Consider sharding or Pinecone
    ```¬∑
    ### 3. Index Maintenance¬∑
    ```sql
    -- Rebuild index after bulk inserts
    REINDEX INDEX documents_embedding_idx;¬∑
    -- Update statistics (required for IVFFlat)
    VACUUM ANALYZE documents;¬∑
    -- Monitor index size
    SELECT
      schemaname,
      tablename,
      indexname,
      pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
    FROM pg_stat_user_indexes
    WHERE tablename = 'documents';
    ```¬∑
    ---¬∑
    ## RAG (Retrieval-Augmented Generation) Pattern¬∑
    ### 1. Complete RAG Implementation¬∑
    ```typescript
    import OpenAI from 'openai';
    import { db } from './db';¬∑
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });¬∑
    // Step 1: Store documents with embeddings
    async function indexDocument(content: string, metadata?: any) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: content
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      await db.query(
        `INSERT INTO documents (content, embedding, metadata)
         VALUES ($1, $2, $3)`,
        [content, embedding, metadata]
      );
    }¬∑
    // Step 2: Retrieve relevant context
    async function retrieveContext(query: string, limit: number = 5) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: query
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      const result = await db.query(
        `SELECT content, 1 - (embedding <=> $1::vector) AS similarity
         FROM documents
         WHERE 1 - (embedding <=> $1::vector) > 0.7
         ORDER BY embedding <=> $1::vector
         LIMIT $2`,
        [embedding, limit]
      );¬∑
      return result.rows.map(row => row.content);
    }¬∑
    // Step 3: Generate answer with context
    async function askQuestion(question: string) {
      // Retrieve relevant documents
      const context = await retrieveContext(question);¬∑
      if (context.length === 0) {
        return { answer: 'No relevant information found.', sources: [] };
      }¬∑
      // Generate answer using context
      const completion = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are a helpful assistant. Answer the question based on the following context. If the answer is not in the context, say \"I don't have enough information to answer this question.\"\\n\\nContext:\\n${context.join('\\n\\n')}`
          },
          {
            role: 'user',
            content: question
          }
        ]
      });¬∑
      return {
        answer: completion.choices[0].message.content,
        sources: context
      };
    }¬∑
    // Example usage
    const result = await askQuestion('How do I optimize PostgreSQL queries?');
    console.log('Answer:', result.answer);
    console.log('Sources:', result.sources);
    ```¬∑
    ### 2. Chunking Strategies¬∑
    ```typescript
    // Split large documents into chunks for better retrieval
    function chunkDocument(text: string, chunkSize: number = 500, overlap: number = 50) {
      const chunks: string[] = [];
      let start = 0;¬∑
      while (start < text.length) {
        const end = Math.min(start + chunkSize, text.length);
        chunks.push(text.slice(start, end));
        start = end - overlap; // Overlap to maintain context
      }¬∑
      return chunks;
    }¬∑
    // Example: Index a large document
    async function indexLargeDocument(title: string, content: string) {
      const chunks = chunkDocument(content);¬∑
      for (const [index, chunk] of chunks.entries()) {
        await indexDocument(chunk, {
          title,
          chunk_index: index,
          total_chunks: chunks.length
        });
      }
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Batch Embedding Generation¬∑
    ```typescript
    // ‚úÖ Good - Batch embeddings (up to 2048 inputs)
    async function batchEmbeddings(texts: string[]) {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: texts // Array of up to 2048 strings
      });¬∑
      return response.data.map(item => item.embedding);
    }¬∑
    // Store in single transaction
    async function batchIndexDocuments(documents: { content: string; metadata?: any }[]) {
      const contents = documents.map(doc => doc.content);
      const embeddings = await batchEmbeddings(contents);¬∑
      await db.query('BEGIN');¬∑
      for (let i = 0; i < documents.length; i++) {
        await db.query(
          `INSERT INTO documents (content, embedding, metadata)
           VALUES ($1, $2, $3)`,
          [documents[i].content, embeddings[i], documents[i].metadata]
        );
      }¬∑
      await db.query('COMMIT');
    }
    ```¬∑
    ### 2. Query Optimization¬∑
    ```sql
    -- ‚úÖ Good - Use index with similarity threshold
    SELECT id, content, 1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    WHERE 1 - (embedding <=> $1::vector) > 0.7 -- Pre-filter with threshold
    ORDER BY embedding <=> $1::vector
    LIMIT 10;¬∑
    -- ‚ùå Bad - Full scan without threshold
    SELECT id, content, 1 - (embedding <=> $1::vector) AS similarity
    FROM documents
    ORDER BY embedding <=> $1::vector
    LIMIT 10;
    ```¬∑
    ### 3. Caching Embeddings¬∑
    ```typescript
    import { Redis } from 'ioredis';¬∑
    const redis = new Redis();¬∑
    async function getCachedEmbedding(text: string): Promise<number[] | null> {
      const cached = await redis.get(`embedding:${text}`);
      return cached ? JSON.parse(cached) : null;
    }¬∑
    async function setCachedEmbedding(text: string, embedding: number[]): Promise<void> {
      await redis.setex(`embedding:${text}`, 3600, JSON.stringify(embedding)); // 1 hour TTL
    }¬∑
    async function getEmbedding(text: string): Promise<number[]> {
      // Check cache first
      const cached = await getCachedEmbedding(text);
      if (cached) return cached;¬∑
      // Generate embedding
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: text
      });¬∑
      const embedding = response.data[0].embedding;¬∑
      // Cache result
      await setCachedEmbedding(text, embedding);¬∑
      return embedding;
    }
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-embeddings.py` - Batch generate embeddings from CSV/JSON
    - `migrate-to-pgvector.js` - Migrate from Pinecone/Weaviate to pgvector¬∑
    ### references/
    - `references/similarity-metrics.md` - Cosine vs Euclidean vs Inner Product comparison
    - `references/index-tuning.md` - HNSW vs IVFFlat parameter tuning guide
    - `references/rag-patterns.md` - RAG architecture patterns and chunking strategies
    - `references/embedding-models.md` - OpenAI, Cohere, Hugging Face embedding comparison¬∑
    ### assets/
    - `assets/migration-scripts/` - Pinecone ‚Üí pgvector migration scripts
    - `assets/benchmark-data/` - Performance benchmark datasets¬∑
    ## Related Skills¬∑
    - `schema-optimization` - Database indexing and query performance
    - `rls-policies` - Row-level security for multi-tenant vector data
    - `api-design` - REST/GraphQL APIs for semantic search
    - `edge-databases` - Supabase Edge Functions with pgvector
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ schema-optimization ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: schema-optimization
    description: Database schema optimization using denormalization, partitioning (range/list/hash), composite indexes, and query optimization. Use when optimizing database performance, scaling databases, or reducing query times. Achieves 10-100x query performance improvements through strategic indexing and schema design.
    ---¬∑
    # Schema Optimization¬∑
    ## Overview¬∑
    Database schema optimization techniques including denormalization strategies, table partitioning, composite indexing, and query optimization. Provides dramatic performance improvements for high-traffic applications and large datasets.¬∑
    **Goal**: 10-100x query performance improvement through strategic schema design¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Optimizing slow database queries
    - Scaling databases for high traffic
    - Implementing table partitioning for large tables
    - Designing composite indexes
    - Denormalizing for read-heavy workloads
    - Migrating to sharded architecture
    - Optimizing JOIN queries
    - Reducing database costs through efficiency¬∑
    **Triggers**: \"database optimization\", \"slow queries\", \"indexing\", \"partitioning\", \"denormalization\", \"query performance\", \"database scaling\"¬∑
    ---¬∑
    ## Quick Start: Optimization Strategy Decision Tree¬∑
    ### When to Use Indexing vs Denormalization vs Partitioning¬∑
    **Indexes** (Fast Lookups):
    - ‚úÖ Frequently queried columns (WHERE, JOIN, ORDER BY)
    - ‚úÖ Unique constraints (email, username)
    - ‚úÖ Foreign keys (relationships)
    - ‚úÖ Composite indexes (multi-column queries)
    - ‚úÖ Best for: Read-heavy workloads, point lookups¬∑
    **Denormalization** (Duplicate Data):
    - ‚úÖ Reduce JOIN overhead (copy data to avoid JOINs)
    - ‚úÖ Read-heavy workloads (99% reads, 1% writes)
    - ‚úÖ Calculated fields (totals, counts, aggregates)
    - ‚úÖ Best for: High-traffic read queries, reporting, dashboards¬∑
    **Partitioning** (Split Tables):
    - ‚úÖ Very large tables (100M+ rows)
    - ‚úÖ Time-series data (partition by date)
    - ‚úÖ Multi-tenant data (partition by tenant_id)
    - ‚úÖ Archive old data (drop old partitions)
    - ‚úÖ Best for: Massive datasets, time-series, multi-tenancy¬∑
    **Sharding** (Horizontal Scaling):
    - ‚úÖ Beyond single-server capacity
    - ‚úÖ Global distribution (geographic sharding)
    - ‚úÖ Tenant isolation (one shard per large customer)
    - ‚úÖ Best for: Massive scale, distributed systems¬∑
    ---¬∑
    ## Indexing Patterns¬∑
    ### 1. Single-Column Indexes¬∑
    ```sql
    -- Index frequently queried columns
    CREATE INDEX idx_users_email ON users (email);
    CREATE INDEX idx_posts_author_id ON posts (author_id);
    CREATE INDEX idx_orders_created_at ON orders (created_at);¬∑
    -- Unique index (constraint + index)
    CREATE UNIQUE INDEX idx_users_username ON users (username);¬∑
    -- Partial index (index subset of rows)
    CREATE INDEX idx_active_users ON users (email)
    WHERE deleted_at IS NULL;¬∑
    -- Performance comparison
    -- Without index: Sequential scan (1000ms)
    -- With index: Index scan (10ms) ‚Üí 100x faster
    ```¬∑
    ### 2. Composite Indexes (Multi-Column)¬∑
    ```sql
    -- Index for multi-column queries
    CREATE INDEX idx_users_status_created ON users (status, created_at DESC);¬∑
    -- ‚úÖ Good - Uses index
    SELECT * FROM users
    WHERE status = 'active'
    ORDER BY created_at DESC
    LIMIT 10;¬∑
    -- ‚úÖ Good - Uses index (leftmost prefix)
    SELECT * FROM users WHERE status = 'active';¬∑
    -- ‚ùå Bad - Doesn't use index (wrong column order)
    SELECT * FROM users WHERE created_at > '2024-01-01';¬∑
    -- Index column order matters:
    -- 1. Equality filters first (status = 'active')
    -- 2. Range filters second (created_at > '...')
    -- 3. Sort columns last (ORDER BY created_at)
    ```¬∑
    ### 3. Covering Indexes (Index-Only Scans)¬∑
    ```sql
    -- Include commonly selected columns in index
    CREATE INDEX idx_users_email_name_created ON users (email) INCLUDE (name, created_at);¬∑
    -- ‚úÖ Good - Index-only scan (no table lookup)
    SELECT name, created_at FROM users WHERE email = 'user@example.com';¬∑
    -- Performance: Index-only scan is 2-5x faster than index + table lookup
    ```¬∑
    ### 4. Expression Indexes (Computed Columns)¬∑
    ```sql
    -- Index on expression
    CREATE INDEX idx_users_lower_email ON users (LOWER(email));¬∑
    -- ‚úÖ Uses index
    SELECT * FROM users WHERE LOWER(email) = 'user@example.com';¬∑
    -- Full-text search index
    CREATE INDEX idx_posts_content_fts ON posts USING GIN (to_tsvector('english', content));¬∑
    -- ‚úÖ Uses full-text index
    SELECT * FROM posts WHERE to_tsvector('english', content) @@ to_tsquery('postgresql');
    ```¬∑
    ---¬∑
    ## Denormalization Patterns¬∑
    ### 1. Duplicate Foreign Key Data¬∑
    ```sql
    -- ‚ùå Bad - Requires JOIN for every query
    CREATE TABLE posts (
      id BIGSERIAL PRIMARY KEY,
      title TEXT,
      content TEXT,
      author_id INTEGER REFERENCES users(id)
    );¬∑
    -- Query requires JOIN
    SELECT posts.*, users.name AS author_name
    FROM posts
    JOIN users ON users.id = posts.author_id;¬∑
    -- ‚úÖ Good - Denormalized (duplicate author_name)
    CREATE TABLE posts (
      id BIGSERIAL PRIMARY KEY,
      title TEXT,
      content TEXT,
      author_id INTEGER REFERENCES users(id),
      author_name TEXT  -- Denormalized field
    );¬∑
    -- Query avoids JOIN (10x faster)
    SELECT * FROM posts;¬∑
    -- Trade-off: Must update author_name when user changes name
    -- Solution: Use trigger to maintain consistency
    CREATE OR REPLACE FUNCTION update_post_author_name()
    RETURNS TRIGGER AS $$
    BEGIN
      UPDATE posts
      SET author_name = NEW.name
      WHERE author_id = NEW.id;
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;¬∑
    CREATE TRIGGER update_posts_on_user_name_change
    AFTER UPDATE OF name ON users
    FOR EACH ROW
    EXECUTE FUNCTION update_post_author_name();
    ```¬∑
    ### 2. Pre-Calculated Aggregates¬∑
    ```sql
    -- ‚ùå Bad - Calculate COUNT on every request
    SELECT posts.*, COUNT(comments.id) AS comment_count
    FROM posts
    LEFT JOIN comments ON comments.post_id = posts.id
    GROUP BY posts.id;¬∑
    -- ‚úÖ Good - Store comment_count in posts table
    ALTER TABLE posts ADD COLUMN comment_count INTEGER DEFAULT 0;¬∑
    -- Update trigger to maintain count
    CREATE OR REPLACE FUNCTION update_post_comment_count()
    RETURNS TRIGGER AS $$
    BEGIN
      IF TG_OP = 'INSERT' THEN
        UPDATE posts SET comment_count = comment_count + 1 WHERE id = NEW.post_id;
      ELSIF TG_OP = 'DELETE' THEN
        UPDATE posts SET comment_count = comment_count - 1 WHERE id = OLD.post_id;
      END IF;
      RETURN NULL;
    END;
    $$ LANGUAGE plpgsql;¬∑
    CREATE TRIGGER maintain_post_comment_count
    AFTER INSERT OR DELETE ON comments
    FOR EACH ROW
    EXECUTE FUNCTION update_post_comment_count();¬∑
    -- Query is now simple (100x faster)
    SELECT * FROM posts WHERE comment_count > 10;
    ```¬∑
    ### 3. Materialized Views (Pre-Computed Queries)¬∑
    ```sql
    -- Create materialized view for expensive query
    CREATE MATERIALIZED VIEW user_stats AS
    SELECT
      users.id,
      users.name,
      COUNT(DISTINCT posts.id) AS post_count,
      COUNT(DISTINCT comments.id) AS comment_count,
      MAX(posts.created_at) AS last_post_at
    FROM users
    LEFT JOIN posts ON posts.author_id = users.id
    LEFT JOIN comments ON comments.author_id = users.id
    GROUP BY users.id, users.name;¬∑
    -- Create index on materialized view
    CREATE INDEX idx_user_stats_id ON user_stats (id);¬∑
    -- Query materialized view (instant results)
    SELECT * FROM user_stats WHERE post_count > 100;¬∑
    -- Refresh materialized view periodically
    REFRESH MATERIALIZED VIEW CONCURRENTLY user_stats;¬∑
    -- Schedule refresh with pg_cron or application cron job
    -- Recommendation: Refresh every 5-60 minutes depending on requirements
    ```¬∑
    ---¬∑
    ## Partitioning Patterns¬∑
    ### 1. Range Partitioning (Time-Series Data)¬∑
    ```sql
    -- Create partitioned table
    CREATE TABLE orders (
      id BIGSERIAL,
      user_id INTEGER,
      total DECIMAL,
      created_at TIMESTAMPTZ NOT NULL,
      PRIMARY KEY (id, created_at)
    ) PARTITION BY RANGE (created_at);¬∑
    -- Create partitions (one per quarter)
    CREATE TABLE orders_2024_q1 PARTITION OF orders
    FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');¬∑
    CREATE TABLE orders_2024_q2 PARTITION OF orders
    FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');¬∑
    CREATE TABLE orders_2024_q3 PARTITION OF orders
    FOR VALUES FROM ('2024-07-01') TO ('2024-10-01');¬∑
    CREATE TABLE orders_2024_q4 PARTITION OF orders
    FOR VALUES FROM ('2024-10-01') TO ('2025-01-01');¬∑
    -- Create indexes on each partition
    CREATE INDEX idx_orders_2024_q1_user_id ON orders_2024_q1 (user_id);
    CREATE INDEX idx_orders_2024_q2_user_id ON orders_2024_q2 (user_id);¬∑
    -- Query automatically uses correct partition (partition pruning)
    SELECT * FROM orders
    WHERE created_at >= '2024-06-01' AND created_at < '2024-07-01';
    -- Only scans orders_2024_q2 partition ‚Üí Much faster¬∑
    -- Archive old partitions
    DETACH PARTITION orders_2024_q1; -- Remove from parent table
    DROP TABLE orders_2024_q1; -- Or move to archive
    ```¬∑
    ### 2. List Partitioning (Categories)¬∑
    ```sql
    -- Partition by region
    CREATE TABLE sales (
      id BIGSERIAL,
      amount DECIMAL,
      region TEXT NOT NULL,
      created_at TIMESTAMPTZ,
      PRIMARY KEY (id, region)
    ) PARTITION BY LIST (region);¬∑
    CREATE TABLE sales_us PARTITION OF sales FOR VALUES IN ('US');
    CREATE TABLE sales_eu PARTITION OF sales FOR VALUES IN ('EU', 'UK', 'FR', 'DE');
    CREATE TABLE sales_asia PARTITION OF sales FOR VALUES IN ('JP', 'CN', 'IN');¬∑
    -- Query only scans relevant partition
    SELECT * FROM sales WHERE region = 'US';
    -- Only scans sales_us partition
    ```¬∑
    ### 3. Hash Partitioning (Distribute Load)¬∑
    ```sql
    -- Partition by hash (distribute evenly)
    CREATE TABLE users (
      id BIGSERIAL PRIMARY KEY,
      email TEXT,
      name TEXT
    ) PARTITION BY HASH (id);¬∑
    -- Create 4 partitions
    CREATE TABLE users_p0 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 0);
    CREATE TABLE users_p1 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 1);
    CREATE TABLE users_p2 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 2);
    CREATE TABLE users_p3 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 3);¬∑
    -- Rows distributed evenly across partitions
    -- Good for load balancing, not for querying specific partitions
    ```¬∑
    ---¬∑
    ## Query Optimization¬∑
    ### 1. EXPLAIN ANALYZE (Query Planning)¬∑
    ```sql
    -- Analyze query performance
    EXPLAIN ANALYZE
    SELECT posts.*, users.name AS author_name
    FROM posts
    JOIN users ON users.id = posts.author_id
    WHERE posts.created_at > NOW() - INTERVAL '7 days'
    ORDER BY posts.created_at DESC
    LIMIT 10;¬∑
    -- Output shows:
    -- - Execution time
    -- - Index usage (Seq Scan vs Index Scan)
    -- - Join method (Nested Loop, Hash Join, Merge Join)
    -- - Rows scanned vs rows returned¬∑
    -- ‚ùå Bad - Sequential Scan (slow)
    -- Seq Scan on posts  (cost=0.00..10000.00 rows=100000 width=100) (actual time=0.012..150.234 rows=100000 loops=1)¬∑
    -- ‚úÖ Good - Index Scan (fast)
    -- Index Scan using idx_posts_created_at on posts  (cost=0.42..8.44 rows=10 width=100) (actual time=0.012..0.034 rows=10 loops=1)
    ```¬∑
    ### 2. N+1 Query Problem¬∑
    ```typescript
    // ‚ùå Bad - N+1 queries (1 query + N queries for each post)
    const posts = await db.post.findMany();
    for (const post of posts) {
      post.author = await db.user.findUnique({ where: { id: post.authorId } });
    }
    // Result: 1 + 100 = 101 queries for 100 posts¬∑
    // ‚úÖ Good - Single query with JOIN
    const posts = await db.post.findMany({
      include: { author: true }
    });
    // Result: 1 query for 100 posts (100x faster)¬∑
    // ‚úÖ Good - Batch queries with DataLoader (see api-design skill)
    const posts = await db.post.findMany();
    const authors = await userLoader.loadMany(posts.map(p => p.authorId));
    // Result: 2 queries total (1 for posts, 1 batched for users)
    ```¬∑
    ### 3. SELECT Only Needed Columns¬∑
    ```sql
    -- ‚ùå Bad - Fetches all columns (slower, more memory)
    SELECT * FROM users WHERE id = 123;¬∑
    -- ‚úÖ Good - Only fetch needed columns
    SELECT id, name, email FROM users WHERE id = 123;¬∑
    -- Performance impact:
    -- 10 columns: 100% baseline
    -- 3 columns: 30% of baseline (3.3x faster)
    ```¬∑
    ### 4. LIMIT with Pagination¬∑
    ```sql
    -- ‚ùå Bad - OFFSET with large values is slow
    SELECT * FROM posts
    ORDER BY created_at DESC
    OFFSET 10000 LIMIT 10;
    -- Must scan 10,010 rows to skip first 10,000¬∑
    -- ‚úÖ Good - Cursor pagination (keyset pagination)
    SELECT * FROM posts
    WHERE created_at < '2024-01-15 10:30:00'  -- Last seen cursor
    ORDER BY created_at DESC
    LIMIT 10;
    -- Only scans 10 rows using index
    ```¬∑
    ---¬∑
    ## Database Configuration¬∑
    ### 1. Connection Pooling¬∑
    ```typescript
    import { Pool } from 'pg';¬∑
    // ‚úÖ Good - Connection pool (reuse connections)
    const pool = new Pool({
      host: 'localhost',
      port: 5432,
      database: 'mydb',
      user: 'user',
      password: 'password',
      max: 20, // Maximum connections in pool
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000
    });¬∑
    // Reuse connections
    const result = await pool.query('SELECT * FROM users WHERE id = $1', [123]);
    ```¬∑
    ### 2. PostgreSQL Tuning¬∑
    ```sql
    -- Increase shared_buffers (25% of RAM)
    ALTER SYSTEM SET shared_buffers = '4GB';¬∑
    -- Increase work_mem (for complex queries)
    ALTER SYSTEM SET work_mem = '64MB';¬∑
    -- Increase maintenance_work_mem (for VACUUM, INDEX creation)
    ALTER SYSTEM SET maintenance_work_mem = '512MB';¬∑
    -- Enable query planning statistics
    ALTER SYSTEM SET track_activities = on;
    ALTER SYSTEM SET track_counts = on;¬∑
    -- Reload configuration
    SELECT pg_reload_conf();
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `analyze-slow-queries.js` - Find and analyze slow queries from logs
    - `generate-indexes.js` - Suggest indexes based on query patterns¬∑
    ### references/
    - `references/postgres-performance.md` - PostgreSQL tuning guide
    - `references/partitioning-strategies.md` - When and how to partition tables
    - `references/denormalization-patterns.md` - Safe denormalization techniques
    - `references/index-types.md` - B-tree, Hash, GIN, GiST, BRIN indexes¬∑
    ### assets/
    - `assets/query-examples/` - Optimized query templates
    - `assets/monitoring-dashboards/` - Grafana dashboards for database metrics¬∑
    ## Related Skills¬∑
    - `vector-databases` - pgvector index optimization (HNSW vs IVFFlat)
    - `rls-policies` - Performance impact of RLS policies
    - `api-design` - N+1 query prevention with DataLoader
    - `edge-databases` - Read replicas and connection pooling
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ schema-optimization ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: schema-optimization
    description: Database schema optimization using denormalization, partitioning (range/list/hash), composite indexes, and query optimization. Use when optimizing database performance, scaling databases, or reducing query times. Achieves 10-100x query performance improvements through strategic indexing and schema design.
    ---¬∑
    # Schema Optimization¬∑
    ## Overview¬∑
    Database schema optimization techniques including denormalization strategies, table partitioning, composite indexing, and query optimization. Provides dramatic performance improvements for high-traffic applications and large datasets.¬∑
    **Goal**: 10-100x query performance improvement through strategic schema design¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Optimizing slow database queries
    - Scaling databases for high traffic
    - Implementing table partitioning for large tables
    - Designing composite indexes
    - Denormalizing for read-heavy workloads
    - Migrating to sharded architecture
    - Optimizing JOIN queries
    - Reducing database costs through efficiency¬∑
    **Triggers**: \"database optimization\", \"slow queries\", \"indexing\", \"partitioning\", \"denormalization\", \"query performance\", \"database scaling\"¬∑
    ---¬∑
    ## Quick Start: Optimization Strategy Decision Tree¬∑
    ### When to Use Indexing vs Denormalization vs Partitioning¬∑
    **Indexes** (Fast Lookups):
    - ‚úÖ Frequently queried columns (WHERE, JOIN, ORDER BY)
    - ‚úÖ Unique constraints (email, username)
    - ‚úÖ Foreign keys (relationships)
    - ‚úÖ Composite indexes (multi-column queries)
    - ‚úÖ Best for: Read-heavy workloads, point lookups¬∑
    **Denormalization** (Duplicate Data):
    - ‚úÖ Reduce JOIN overhead (copy data to avoid JOINs)
    - ‚úÖ Read-heavy workloads (99% reads, 1% writes)
    - ‚úÖ Calculated fields (totals, counts, aggregates)
    - ‚úÖ Best for: High-traffic read queries, reporting, dashboards¬∑
    **Partitioning** (Split Tables):
    - ‚úÖ Very large tables (100M+ rows)
    - ‚úÖ Time-series data (partition by date)
    - ‚úÖ Multi-tenant data (partition by tenant_id)
    - ‚úÖ Archive old data (drop old partitions)
    - ‚úÖ Best for: Massive datasets, time-series, multi-tenancy¬∑
    **Sharding** (Horizontal Scaling):
    - ‚úÖ Beyond single-server capacity
    - ‚úÖ Global distribution (geographic sharding)
    - ‚úÖ Tenant isolation (one shard per large customer)
    - ‚úÖ Best for: Massive scale, distributed systems¬∑
    ---¬∑
    ## Indexing Patterns¬∑
    ### 1. Single-Column Indexes¬∑
    ```sql
    -- Index frequently queried columns
    CREATE INDEX idx_users_email ON users (email);
    CREATE INDEX idx_posts_author_id ON posts (author_id);
    CREATE INDEX idx_orders_created_at ON orders (created_at);¬∑
    -- Unique index (constraint + index)
    CREATE UNIQUE INDEX idx_users_username ON users (username);¬∑
    -- Partial index (index subset of rows)
    CREATE INDEX idx_active_users ON users (email)
    WHERE deleted_at IS NULL;¬∑
    -- Performance comparison
    -- Without index: Sequential scan (1000ms)
    -- With index: Index scan (10ms) ‚Üí 100x faster
    ```¬∑
    ### 2. Composite Indexes (Multi-Column)¬∑
    ```sql
    -- Index for multi-column queries
    CREATE INDEX idx_users_status_created ON users (status, created_at DESC);¬∑
    -- ‚úÖ Good - Uses index
    SELECT * FROM users
    WHERE status = 'active'
    ORDER BY created_at DESC
    LIMIT 10;¬∑
    -- ‚úÖ Good - Uses index (leftmost prefix)
    SELECT * FROM users WHERE status = 'active';¬∑
    -- ‚ùå Bad - Doesn't use index (wrong column order)
    SELECT * FROM users WHERE created_at > '2024-01-01';¬∑
    -- Index column order matters:
    -- 1. Equality filters first (status = 'active')
    -- 2. Range filters second (created_at > '...')
    -- 3. Sort columns last (ORDER BY created_at)
    ```¬∑
    ### 3. Covering Indexes (Index-Only Scans)¬∑
    ```sql
    -- Include commonly selected columns in index
    CREATE INDEX idx_users_email_name_created ON users (email) INCLUDE (name, created_at);¬∑
    -- ‚úÖ Good - Index-only scan (no table lookup)
    SELECT name, created_at FROM users WHERE email = 'user@example.com';¬∑
    -- Performance: Index-only scan is 2-5x faster than index + table lookup
    ```¬∑
    ### 4. Expression Indexes (Computed Columns)¬∑
    ```sql
    -- Index on expression
    CREATE INDEX idx_users_lower_email ON users (LOWER(email));¬∑
    -- ‚úÖ Uses index
    SELECT * FROM users WHERE LOWER(email) = 'user@example.com';¬∑
    -- Full-text search index
    CREATE INDEX idx_posts_content_fts ON posts USING GIN (to_tsvector('english', content));¬∑
    -- ‚úÖ Uses full-text index
    SELECT * FROM posts WHERE to_tsvector('english', content) @@ to_tsquery('postgresql');
    ```¬∑
    ---¬∑
    ## Denormalization Patterns¬∑
    ### 1. Duplicate Foreign Key Data¬∑
    ```sql
    -- ‚ùå Bad - Requires JOIN for every query
    CREATE TABLE posts (
      id BIGSERIAL PRIMARY KEY,
      title TEXT,
      content TEXT,
      author_id INTEGER REFERENCES users(id)
    );¬∑
    -- Query requires JOIN
    SELECT posts.*, users.name AS author_name
    FROM posts
    JOIN users ON users.id = posts.author_id;¬∑
    -- ‚úÖ Good - Denormalized (duplicate author_name)
    CREATE TABLE posts (
      id BIGSERIAL PRIMARY KEY,
      title TEXT,
      content TEXT,
      author_id INTEGER REFERENCES users(id),
      author_name TEXT  -- Denormalized field
    );¬∑
    -- Query avoids JOIN (10x faster)
    SELECT * FROM posts;¬∑
    -- Trade-off: Must update author_name when user changes name
    -- Solution: Use trigger to maintain consistency
    CREATE OR REPLACE FUNCTION update_post_author_name()
    RETURNS TRIGGER AS $$
    BEGIN
      UPDATE posts
      SET author_name = NEW.name
      WHERE author_id = NEW.id;
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;¬∑
    CREATE TRIGGER update_posts_on_user_name_change
    AFTER UPDATE OF name ON users
    FOR EACH ROW
    EXECUTE FUNCTION update_post_author_name();
    ```¬∑
    ### 2. Pre-Calculated Aggregates¬∑
    ```sql
    -- ‚ùå Bad - Calculate COUNT on every request
    SELECT posts.*, COUNT(comments.id) AS comment_count
    FROM posts
    LEFT JOIN comments ON comments.post_id = posts.id
    GROUP BY posts.id;¬∑
    -- ‚úÖ Good - Store comment_count in posts table
    ALTER TABLE posts ADD COLUMN comment_count INTEGER DEFAULT 0;¬∑
    -- Update trigger to maintain count
    CREATE OR REPLACE FUNCTION update_post_comment_count()
    RETURNS TRIGGER AS $$
    BEGIN
      IF TG_OP = 'INSERT' THEN
        UPDATE posts SET comment_count = comment_count + 1 WHERE id = NEW.post_id;
      ELSIF TG_OP = 'DELETE' THEN
        UPDATE posts SET comment_count = comment_count - 1 WHERE id = OLD.post_id;
      END IF;
      RETURN NULL;
    END;
    $$ LANGUAGE plpgsql;¬∑
    CREATE TRIGGER maintain_post_comment_count
    AFTER INSERT OR DELETE ON comments
    FOR EACH ROW
    EXECUTE FUNCTION update_post_comment_count();¬∑
    -- Query is now simple (100x faster)
    SELECT * FROM posts WHERE comment_count > 10;
    ```¬∑
    ### 3. Materialized Views (Pre-Computed Queries)¬∑
    ```sql
    -- Create materialized view for expensive query
    CREATE MATERIALIZED VIEW user_stats AS
    SELECT
      users.id,
      users.name,
      COUNT(DISTINCT posts.id) AS post_count,
      COUNT(DISTINCT comments.id) AS comment_count,
      MAX(posts.created_at) AS last_post_at
    FROM users
    LEFT JOIN posts ON posts.author_id = users.id
    LEFT JOIN comments ON comments.author_id = users.id
    GROUP BY users.id, users.name;¬∑
    -- Create index on materialized view
    CREATE INDEX idx_user_stats_id ON user_stats (id);¬∑
    -- Query materialized view (instant results)
    SELECT * FROM user_stats WHERE post_count > 100;¬∑
    -- Refresh materialized view periodically
    REFRESH MATERIALIZED VIEW CONCURRENTLY user_stats;¬∑
    -- Schedule refresh with pg_cron or application cron job
    -- Recommendation: Refresh every 5-60 minutes depending on requirements
    ```¬∑
    ---¬∑
    ## Partitioning Patterns¬∑
    ### 1. Range Partitioning (Time-Series Data)¬∑
    ```sql
    -- Create partitioned table
    CREATE TABLE orders (
      id BIGSERIAL,
      user_id INTEGER,
      total DECIMAL,
      created_at TIMESTAMPTZ NOT NULL,
      PRIMARY KEY (id, created_at)
    ) PARTITION BY RANGE (created_at);¬∑
    -- Create partitions (one per quarter)
    CREATE TABLE orders_2024_q1 PARTITION OF orders
    FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');¬∑
    CREATE TABLE orders_2024_q2 PARTITION OF orders
    FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');¬∑
    CREATE TABLE orders_2024_q3 PARTITION OF orders
    FOR VALUES FROM ('2024-07-01') TO ('2024-10-01');¬∑
    CREATE TABLE orders_2024_q4 PARTITION OF orders
    FOR VALUES FROM ('2024-10-01') TO ('2025-01-01');¬∑
    -- Create indexes on each partition
    CREATE INDEX idx_orders_2024_q1_user_id ON orders_2024_q1 (user_id);
    CREATE INDEX idx_orders_2024_q2_user_id ON orders_2024_q2 (user_id);¬∑
    -- Query automatically uses correct partition (partition pruning)
    SELECT * FROM orders
    WHERE created_at >= '2024-06-01' AND created_at < '2024-07-01';
    -- Only scans orders_2024_q2 partition ‚Üí Much faster¬∑
    -- Archive old partitions
    DETACH PARTITION orders_2024_q1; -- Remove from parent table
    DROP TABLE orders_2024_q1; -- Or move to archive
    ```¬∑
    ### 2. List Partitioning (Categories)¬∑
    ```sql
    -- Partition by region
    CREATE TABLE sales (
      id BIGSERIAL,
      amount DECIMAL,
      region TEXT NOT NULL,
      created_at TIMESTAMPTZ,
      PRIMARY KEY (id, region)
    ) PARTITION BY LIST (region);¬∑
    CREATE TABLE sales_us PARTITION OF sales FOR VALUES IN ('US');
    CREATE TABLE sales_eu PARTITION OF sales FOR VALUES IN ('EU', 'UK', 'FR', 'DE');
    CREATE TABLE sales_asia PARTITION OF sales FOR VALUES IN ('JP', 'CN', 'IN');¬∑
    -- Query only scans relevant partition
    SELECT * FROM sales WHERE region = 'US';
    -- Only scans sales_us partition
    ```¬∑
    ### 3. Hash Partitioning (Distribute Load)¬∑
    ```sql
    -- Partition by hash (distribute evenly)
    CREATE TABLE users (
      id BIGSERIAL PRIMARY KEY,
      email TEXT,
      name TEXT
    ) PARTITION BY HASH (id);¬∑
    -- Create 4 partitions
    CREATE TABLE users_p0 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 0);
    CREATE TABLE users_p1 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 1);
    CREATE TABLE users_p2 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 2);
    CREATE TABLE users_p3 PARTITION OF users FOR VALUES WITH (MODULUS 4, REMAINDER 3);¬∑
    -- Rows distributed evenly across partitions
    -- Good for load balancing, not for querying specific partitions
    ```¬∑
    ---¬∑
    ## Query Optimization¬∑
    ### 1. EXPLAIN ANALYZE (Query Planning)¬∑
    ```sql
    -- Analyze query performance
    EXPLAIN ANALYZE
    SELECT posts.*, users.name AS author_name
    FROM posts
    JOIN users ON users.id = posts.author_id
    WHERE posts.created_at > NOW() - INTERVAL '7 days'
    ORDER BY posts.created_at DESC
    LIMIT 10;¬∑
    -- Output shows:
    -- - Execution time
    -- - Index usage (Seq Scan vs Index Scan)
    -- - Join method (Nested Loop, Hash Join, Merge Join)
    -- - Rows scanned vs rows returned¬∑
    -- ‚ùå Bad - Sequential Scan (slow)
    -- Seq Scan on posts  (cost=0.00..10000.00 rows=100000 width=100) (actual time=0.012..150.234 rows=100000 loops=1)¬∑
    -- ‚úÖ Good - Index Scan (fast)
    -- Index Scan using idx_posts_created_at on posts  (cost=0.42..8.44 rows=10 width=100) (actual time=0.012..0.034 rows=10 loops=1)
    ```¬∑
    ### 2. N+1 Query Problem¬∑
    ```typescript
    // ‚ùå Bad - N+1 queries (1 query + N queries for each post)
    const posts = await db.post.findMany();
    for (const post of posts) {
      post.author = await db.user.findUnique({ where: { id: post.authorId } });
    }
    // Result: 1 + 100 = 101 queries for 100 posts¬∑
    // ‚úÖ Good - Single query with JOIN
    const posts = await db.post.findMany({
      include: { author: true }
    });
    // Result: 1 query for 100 posts (100x faster)¬∑
    // ‚úÖ Good - Batch queries with DataLoader (see api-design skill)
    const posts = await db.post.findMany();
    const authors = await userLoader.loadMany(posts.map(p => p.authorId));
    // Result: 2 queries total (1 for posts, 1 batched for users)
    ```¬∑
    ### 3. SELECT Only Needed Columns¬∑
    ```sql
    -- ‚ùå Bad - Fetches all columns (slower, more memory)
    SELECT * FROM users WHERE id = 123;¬∑
    -- ‚úÖ Good - Only fetch needed columns
    SELECT id, name, email FROM users WHERE id = 123;¬∑
    -- Performance impact:
    -- 10 columns: 100% baseline
    -- 3 columns: 30% of baseline (3.3x faster)
    ```¬∑
    ### 4. LIMIT with Pagination¬∑
    ```sql
    -- ‚ùå Bad - OFFSET with large values is slow
    SELECT * FROM posts
    ORDER BY created_at DESC
    OFFSET 10000 LIMIT 10;
    -- Must scan 10,010 rows to skip first 10,000¬∑
    -- ‚úÖ Good - Cursor pagination (keyset pagination)
    SELECT * FROM posts
    WHERE created_at < '2024-01-15 10:30:00'  -- Last seen cursor
    ORDER BY created_at DESC
    LIMIT 10;
    -- Only scans 10 rows using index
    ```¬∑
    ---¬∑
    ## Database Configuration¬∑
    ### 1. Connection Pooling¬∑
    ```typescript
    import { Pool } from 'pg';¬∑
    // ‚úÖ Good - Connection pool (reuse connections)
    const pool = new Pool({
      host: 'localhost',
      port: 5432,
      database: 'mydb',
      user: 'user',
      password: 'password',
      max: 20, // Maximum connections in pool
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000
    });¬∑
    // Reuse connections
    const result = await pool.query('SELECT * FROM users WHERE id = $1', [123]);
    ```¬∑
    ### 2. PostgreSQL Tuning¬∑
    ```sql
    -- Increase shared_buffers (25% of RAM)
    ALTER SYSTEM SET shared_buffers = '4GB';¬∑
    -- Increase work_mem (for complex queries)
    ALTER SYSTEM SET work_mem = '64MB';¬∑
    -- Increase maintenance_work_mem (for VACUUM, INDEX creation)
    ALTER SYSTEM SET maintenance_work_mem = '512MB';¬∑
    -- Enable query planning statistics
    ALTER SYSTEM SET track_activities = on;
    ALTER SYSTEM SET track_counts = on;¬∑
    -- Reload configuration
    SELECT pg_reload_conf();
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `analyze-slow-queries.js` - Find and analyze slow queries from logs
    - `generate-indexes.js` - Suggest indexes based on query patterns¬∑
    ### references/
    - `references/postgres-performance.md` - PostgreSQL tuning guide
    - `references/partitioning-strategies.md` - When and how to partition tables
    - `references/denormalization-patterns.md` - Safe denormalization techniques
    - `references/index-types.md` - B-tree, Hash, GIN, GiST, BRIN indexes¬∑
    ### assets/
    - `assets/query-examples/` - Optimized query templates
    - `assets/monitoring-dashboards/` - Grafana dashboards for database metrics¬∑
    ## Related Skills¬∑
    - `vector-databases` - pgvector index optimization (HNSW vs IVFFlat)
    - `rls-policies` - Performance impact of RLS policies
    - `api-design` - N+1 query prevention with DataLoader
    - `edge-databases` - Read replicas and connection pooling
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ schema-optimization ‚Ä∫ should be at least 500 lines (comprehensive documentation)

    expect(received).toBeGreaterThanOrEqual(expected)

    Expected: >= 500
    Received:    484

      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {
      115 |           const lineCount = content.split('\n').length;
    > 116 |           expect(lineCount).toBeGreaterThanOrEqual(500);
          |                             ^
      117 |         });
      118 |       });
      119 |     });

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:116:29)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ rls-policies ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: rls-policies
    description: Row-Level Security (RLS) policies for multi-tenant PostgreSQL/Supabase applications. Use when implementing tenant isolation, role-based access control, or securing data at the row level. Provides automatic security enforcement at the database layer without application-level checks.
    ---¬∑
    # Row-Level Security (RLS) Policies¬∑
    ## Overview¬∑
    Row-Level Security (RLS) policies in PostgreSQL/Supabase for automatic tenant isolation and role-based access control. Enforces security at the database layer, ensuring users can only access their own data without application-level security checks.¬∑
    **Goal**: Automatic, database-enforced multi-tenant security and RBAC¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building multi-tenant SaaS applications
    - Implementing role-based access control (RBAC)
    - Securing data at the row level
    - Migrating to Supabase (RLS required for security)
    - Enforcing organization/team data isolation
    - Implementing user-level data privacy
    - Preventing data leaks between tenants
    - Simplifying application security logic¬∑
    **Triggers**: \"RLS\", \"row-level security\", \"multi-tenant\", \"tenant isolation\", \"Supabase security\", \"RBAC\", \"data isolation\"¬∑
    ---¬∑
    ## Quick Start: RLS Strategy Decision Tree¬∑
    ### When to Use RLS vs Application-Level Security¬∑
    **RLS (Database-Level Security)**:
    - ‚úÖ Automatic enforcement (can't be bypassed)
    - ‚úÖ Multi-tenant SaaS (tenant isolation)
    - ‚úÖ Works across all queries (no code changes needed)
    - ‚úÖ Performance optimized by database
    - ‚úÖ Audit-friendly (security in one place)
    - ‚úÖ Best for: Multi-tenant apps, Supabase, strict security requirements¬∑
    **Application-Level Security**:
    - ‚úÖ Complex business logic (dynamic rules)
    - ‚úÖ Cross-database queries
    - ‚úÖ Easier debugging (visible in code)
    - ‚úÖ More flexibility
    - ‚úÖ Best for: Simple apps, complex authorization logic, non-PostgreSQL¬∑
    **Hybrid** (RLS + Application):
    - ‚úÖ RLS for base security (tenant isolation)
    - ‚úÖ Application for business logic (permissions, features)
    - ‚úÖ Best for: Production SaaS applications¬∑
    ---¬∑
    ## Basic RLS Patterns¬∑
    ### 1. Enable RLS on Table¬∑
    ```sql
    -- Enable RLS on table
    ALTER TABLE posts ENABLE ROW LEVEL SECURITY;¬∑
    -- Now all queries are blocked by default (no rows returned)
    -- Must create policies to allow access
    ```¬∑
    ### 2. Simple User Isolation¬∑
    ```sql
    -- Users can only see their own posts
    CREATE POLICY user_isolation ON posts
    FOR SELECT
    USING (auth.uid() = user_id);¬∑
    -- Users can only insert their own posts
    CREATE POLICY user_insert ON posts
    FOR INSERT
    WITH CHECK (auth.uid() = user_id);¬∑
    -- Users can only update their own posts
    CREATE POLICY user_update ON posts
    FOR UPDATE
    USING (auth.uid() = user_id)
    WITH CHECK (auth.uid() = user_id);¬∑
    -- Users can only delete their own posts
    CREATE POLICY user_delete ON posts
    FOR DELETE
    USING (auth.uid() = user_id);¬∑
    -- Test queries
    SELECT * FROM posts;  -- Only returns posts where user_id = current user
    INSERT INTO posts (user_id, title) VALUES (auth.uid(), 'My Post');  -- ‚úÖ Allowed
    INSERT INTO posts (user_id, title) VALUES ('other-user-id', 'Hack');  -- ‚ùå Blocked
    ```¬∑
    ### 3. Multi-Tenant Isolation¬∑
    ```sql
    -- Schema: Each table has organization_id column
    ALTER TABLE projects ADD COLUMN organization_id UUID REFERENCES organizations(id);¬∑
    -- Enable RLS
    ALTER TABLE projects ENABLE ROW LEVEL SECURITY;¬∑
    -- Tenant isolation policy
    CREATE POLICY tenant_isolation ON projects
    FOR ALL
    USING (organization_id = (
      SELECT organization_id FROM users WHERE id = auth.uid()
    ));¬∑
    -- Alternative: Using custom claim in JWT
    CREATE POLICY tenant_isolation ON projects
    FOR ALL
    USING (organization_id = auth.jwt() ->> 'organization_id');¬∑
    -- Result: Users can ONLY access data from their organization
    SELECT * FROM projects;  -- Only returns projects from user's organization
    ```¬∑
    ---¬∑
    ## Role-Based Access Control (RBAC)¬∑
    ### 1. Role Hierarchy¬∑
    ```sql
    -- User roles enum
    CREATE TYPE user_role AS ENUM ('user', 'moderator', 'admin', 'owner');¬∑
    -- Users table with role
    ALTER TABLE users ADD COLUMN role user_role DEFAULT 'user';¬∑
    -- Policy: Admins can see all posts
    CREATE POLICY admin_all_access ON posts
    FOR ALL
    USING (
      (SELECT role FROM users WHERE id = auth.uid()) IN ('admin', 'owner')
    );¬∑
    -- Policy: Regular users can only see their own posts
    CREATE POLICY user_own_posts ON posts
    FOR SELECT
    USING (
      user_id = auth.uid()
      OR
      (SELECT role FROM users WHERE id = auth.uid()) IN ('admin', 'owner')
    );
    ```¬∑
    ### 2. Permission-Based Access¬∑
    ```sql
    -- Permissions table
    CREATE TABLE permissions (
      user_id UUID REFERENCES users(id),
      resource TEXT,
      action TEXT,
      PRIMARY KEY (user_id, resource, action)
    );¬∑
    -- Policy: Check permissions table
    CREATE POLICY permission_based ON documents
    FOR SELECT
    USING (
      EXISTS (
        SELECT 1 FROM permissions
        WHERE user_id = auth.uid()
          AND resource = 'documents'
          AND action = 'read'
      )
    );
    ```¬∑
    ### 3. Team-Based Access¬∑
    ```sql
    -- Team membership table
    CREATE TABLE team_members (
      team_id UUID REFERENCES teams(id),
      user_id UUID REFERENCES users(id),
      role TEXT,
      PRIMARY KEY (team_id, user_id)
    );¬∑
    -- Projects belong to teams
    ALTER TABLE projects ADD COLUMN team_id UUID REFERENCES teams(id);¬∑
    -- Policy: Team members can access team projects
    CREATE POLICY team_access ON projects
    FOR ALL
    USING (
      team_id IN (
        SELECT team_id FROM team_members WHERE user_id = auth.uid()
      )
    );
    ```¬∑
    ---¬∑
    ## Advanced RLS Patterns¬∑
    ### 1. Conditional Policies (Public + Private)¬∑
    ```sql
    -- Posts can be public or private
    ALTER TABLE posts ADD COLUMN is_public BOOLEAN DEFAULT false;¬∑
    -- Policy: Users can see public posts OR their own private posts
    CREATE POLICY public_or_own ON posts
    FOR SELECT
    USING (
      is_public = true
      OR
      user_id = auth.uid()
    );
    ```¬∑
    ### 2. Hierarchical Policies (Organization + Team + User)¬∑
    ```sql
    -- Policy combining multiple levels
    CREATE POLICY hierarchical_access ON documents
    FOR SELECT
    USING (
      -- Same organization
      organization_id = (SELECT organization_id FROM users WHERE id = auth.uid())
      AND (
        -- Public to organization
        visibility = 'organization'
        OR
        -- Same team
        (visibility = 'team' AND team_id IN (
          SELECT team_id FROM team_members WHERE user_id = auth.uid()
        ))
        OR
        -- Owner
        user_id = auth.uid()
      )
    );
    ```¬∑
    ### 3. Time-Based Policies¬∑
    ```sql
    -- Policy: Only show active projects (not archived)
    CREATE POLICY active_projects ON projects
    FOR SELECT
    USING (
      archived_at IS NULL
      OR
      archived_at > NOW() - INTERVAL '30 days'
    );
    ```¬∑
    ### 4. Bypass RLS for Service Roles¬∑
    ```sql
    -- Create service role (for background jobs, admin tasks)
    CREATE ROLE service_role;¬∑
    -- Grant bypass RLS privilege
    GRANT service_role TO postgres;
    ALTER ROLE service_role BYPASSRLS;¬∑
    -- Use service role for admin operations
    SET ROLE service_role;
    SELECT * FROM posts;  -- Returns ALL posts (RLS bypassed)
    RESET ROLE;
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Policy Performance¬∑
    ```sql
    -- ‚ùå Bad - Subquery executes for every row
    CREATE POLICY slow_policy ON posts
    FOR SELECT
    USING (
      user_id IN (SELECT user_id FROM team_members WHERE team_id = '...')
    );¬∑
    -- ‚úÖ Good - Use JOIN instead
    CREATE POLICY fast_policy ON posts
    FOR SELECT
    USING (
      EXISTS (
        SELECT 1 FROM team_members
        WHERE team_members.user_id = posts.user_id
          AND team_members.team_id = '...'
      )
    );¬∑
    -- ‚úÖ Better - Cache current user context
    -- Set session variable at connection time
    SET myapp.current_user_id = '123';
    SET myapp.current_organization_id = '456';¬∑
    CREATE POLICY cached_policy ON posts
    FOR SELECT
    USING (
      organization_id = current_setting('myapp.current_organization_id')::UUID
    );
    ```¬∑
    ### 2. Index for RLS¬∑
    ```sql
    -- Create indexes on columns used in RLS policies
    CREATE INDEX idx_posts_user_id ON posts (user_id);
    CREATE INDEX idx_posts_organization_id ON posts (organization_id);
    CREATE INDEX idx_team_members_user_id ON team_members (user_id);¬∑
    -- Composite index for multi-column policies
    CREATE INDEX idx_posts_org_user ON posts (organization_id, user_id);
    ```¬∑
    ---¬∑
    ## Testing RLS Policies¬∑
    ### 1. Test as Different Users¬∑
    ```sql
    -- Test as user 1
    SET ROLE authenticated;
    SET request.jwt.claim.sub = 'user-1-id';¬∑
    SELECT * FROM posts;  -- Should only see user 1's posts¬∑
    -- Test as user 2
    SET request.jwt.claim.sub = 'user-2-id';¬∑
    SELECT * FROM posts;  -- Should only see user 2's posts¬∑
    -- Reset
    RESET ROLE;
    ```¬∑
    ### 2. Automated Policy Tests¬∑
    ```sql
    -- Test function
    CREATE OR REPLACE FUNCTION test_rls_policies()
    RETURNS void AS $$
    DECLARE
      user1_id UUID := 'user-1';
      user2_id UUID := 'user-2';
    BEGIN
      -- Test user isolation
      SET request.jwt.claim.sub = user1_id;¬∑
      IF (SELECT COUNT(*) FROM posts WHERE user_id != user1_id) > 0 THEN
        RAISE EXCEPTION 'User 1 can see other users posts!';
      END IF;¬∑
      -- Test insert restriction
      BEGIN
        INSERT INTO posts (user_id, title) VALUES (user2_id, 'Hack');
        RAISE EXCEPTION 'User 1 inserted post as user 2!';
      EXCEPTION WHEN OTHERS THEN
        -- Expected to fail
      END;¬∑
      RAISE NOTICE 'All RLS tests passed!';
    END;
    $$ LANGUAGE plpgsql;¬∑
    -- Run tests
    SELECT test_rls_policies();
    ```¬∑
    ---¬∑
    ## Supabase-Specific Patterns¬∑
    ### 1. Auth Helpers¬∑
    ```typescript
    // Client-side: Supabase automatically adds JWT to requests
    import { createClient } from '@supabase/supabase-js';¬∑
    const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);¬∑
    // Login user
    await supabase.auth.signInWithPassword({ email, password });¬∑
    // Query automatically filtered by RLS
    const { data } = await supabase.from('posts').select('*');
    // Only returns posts allowed by RLS policies¬∑
    // auth.uid() in policies automatically uses JWT from request
    ```¬∑
    ### 2. Service Role for Admin¬∑
    ```typescript
    // Server-side: Use service role to bypass RLS
    const supabaseAdmin = createClient(
      SUPABASE_URL,
      SUPABASE_SERVICE_ROLE_KEY  // Has BYPASSRLS permission
    );¬∑
    // Returns ALL rows (RLS bypassed)
    const { data } = await supabaseAdmin.from('posts').select('*');
    ```¬∑
    ### 3. Custom Claims in JWT¬∑
    ```sql
    -- Policy using custom JWT claim
    CREATE POLICY organization_access ON projects
    FOR ALL
    USING (
      organization_id = (auth.jwt() ->> 'organization_id')::UUID
    );
    ```¬∑
    ---¬∑
    ## Security Best Practices¬∑
    ### 1. Always Enable RLS¬∑
    ```sql
    -- ‚úÖ Good - Enable RLS on all user tables
    ALTER TABLE posts ENABLE ROW LEVEL SECURITY;
    ALTER TABLE comments ENABLE ROW LEVEL SECURITY;
    ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;¬∑
    -- ‚ùå Bad - Forgetting to enable RLS = data leak
    -- Table without RLS = ALL users can see ALL data!
    ```¬∑
    ### 2. Test with Multiple Users¬∑
    ```sql
    -- Always test policies with:
    -- 1. Owner of resource
    -- 2. Different user in same organization
    -- 3. User in different organization
    -- 4. Unauthenticated user
    -- 5. Admin/service role
    ```¬∑
    ### 3. Audit RLS Policies¬∑
    ```sql
    -- List all tables without RLS
    SELECT schemaname, tablename
    FROM pg_tables
    WHERE schemaname = 'public'
      AND tablename NOT IN (
        SELECT tablename FROM pg_policies
      )
      AND tablename NOT LIKE 'pg_%';¬∑
    -- List all RLS policies
    SELECT schemaname, tablename, policyname, permissive, roles, cmd, qual
    FROM pg_policies
    WHERE schemaname = 'public';
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `audit-rls.js` - Find tables without RLS enabled
    - `test-rls-policies.js` - Automated RLS policy testing¬∑
    ### references/
    - `references/rls-patterns.md` - Common RLS patterns for SaaS
    - `references/supabase-auth.md` - Supabase auth.uid() and JWT helpers
    - `references/rls-performance.md` - RLS query optimization techniques
    - `references/multi-tenant-architecture.md` - Multi-tenant database design¬∑
    ### assets/
    - `assets/policy-templates/` - RLS policy templates for common use cases
    - `assets/test-scripts/` - RLS testing scripts¬∑
    ## Related Skills¬∑
    - `auth-security` - Authentication integration with RLS
    - `schema-optimization` - Index optimization for RLS policies
    - `api-design` - Supabase client integration with RLS
    - `vector-databases` - RLS for multi-tenant vector data
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ rls-policies ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: rls-policies
    description: Row-Level Security (RLS) policies for multi-tenant PostgreSQL/Supabase applications. Use when implementing tenant isolation, role-based access control, or securing data at the row level. Provides automatic security enforcement at the database layer without application-level checks.
    ---¬∑
    # Row-Level Security (RLS) Policies¬∑
    ## Overview¬∑
    Row-Level Security (RLS) policies in PostgreSQL/Supabase for automatic tenant isolation and role-based access control. Enforces security at the database layer, ensuring users can only access their own data without application-level security checks.¬∑
    **Goal**: Automatic, database-enforced multi-tenant security and RBAC¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building multi-tenant SaaS applications
    - Implementing role-based access control (RBAC)
    - Securing data at the row level
    - Migrating to Supabase (RLS required for security)
    - Enforcing organization/team data isolation
    - Implementing user-level data privacy
    - Preventing data leaks between tenants
    - Simplifying application security logic¬∑
    **Triggers**: \"RLS\", \"row-level security\", \"multi-tenant\", \"tenant isolation\", \"Supabase security\", \"RBAC\", \"data isolation\"¬∑
    ---¬∑
    ## Quick Start: RLS Strategy Decision Tree¬∑
    ### When to Use RLS vs Application-Level Security¬∑
    **RLS (Database-Level Security)**:
    - ‚úÖ Automatic enforcement (can't be bypassed)
    - ‚úÖ Multi-tenant SaaS (tenant isolation)
    - ‚úÖ Works across all queries (no code changes needed)
    - ‚úÖ Performance optimized by database
    - ‚úÖ Audit-friendly (security in one place)
    - ‚úÖ Best for: Multi-tenant apps, Supabase, strict security requirements¬∑
    **Application-Level Security**:
    - ‚úÖ Complex business logic (dynamic rules)
    - ‚úÖ Cross-database queries
    - ‚úÖ Easier debugging (visible in code)
    - ‚úÖ More flexibility
    - ‚úÖ Best for: Simple apps, complex authorization logic, non-PostgreSQL¬∑
    **Hybrid** (RLS + Application):
    - ‚úÖ RLS for base security (tenant isolation)
    - ‚úÖ Application for business logic (permissions, features)
    - ‚úÖ Best for: Production SaaS applications¬∑
    ---¬∑
    ## Basic RLS Patterns¬∑
    ### 1. Enable RLS on Table¬∑
    ```sql
    -- Enable RLS on table
    ALTER TABLE posts ENABLE ROW LEVEL SECURITY;¬∑
    -- Now all queries are blocked by default (no rows returned)
    -- Must create policies to allow access
    ```¬∑
    ### 2. Simple User Isolation¬∑
    ```sql
    -- Users can only see their own posts
    CREATE POLICY user_isolation ON posts
    FOR SELECT
    USING (auth.uid() = user_id);¬∑
    -- Users can only insert their own posts
    CREATE POLICY user_insert ON posts
    FOR INSERT
    WITH CHECK (auth.uid() = user_id);¬∑
    -- Users can only update their own posts
    CREATE POLICY user_update ON posts
    FOR UPDATE
    USING (auth.uid() = user_id)
    WITH CHECK (auth.uid() = user_id);¬∑
    -- Users can only delete their own posts
    CREATE POLICY user_delete ON posts
    FOR DELETE
    USING (auth.uid() = user_id);¬∑
    -- Test queries
    SELECT * FROM posts;  -- Only returns posts where user_id = current user
    INSERT INTO posts (user_id, title) VALUES (auth.uid(), 'My Post');  -- ‚úÖ Allowed
    INSERT INTO posts (user_id, title) VALUES ('other-user-id', 'Hack');  -- ‚ùå Blocked
    ```¬∑
    ### 3. Multi-Tenant Isolation¬∑
    ```sql
    -- Schema: Each table has organization_id column
    ALTER TABLE projects ADD COLUMN organization_id UUID REFERENCES organizations(id);¬∑
    -- Enable RLS
    ALTER TABLE projects ENABLE ROW LEVEL SECURITY;¬∑
    -- Tenant isolation policy
    CREATE POLICY tenant_isolation ON projects
    FOR ALL
    USING (organization_id = (
      SELECT organization_id FROM users WHERE id = auth.uid()
    ));¬∑
    -- Alternative: Using custom claim in JWT
    CREATE POLICY tenant_isolation ON projects
    FOR ALL
    USING (organization_id = auth.jwt() ->> 'organization_id');¬∑
    -- Result: Users can ONLY access data from their organization
    SELECT * FROM projects;  -- Only returns projects from user's organization
    ```¬∑
    ---¬∑
    ## Role-Based Access Control (RBAC)¬∑
    ### 1. Role Hierarchy¬∑
    ```sql
    -- User roles enum
    CREATE TYPE user_role AS ENUM ('user', 'moderator', 'admin', 'owner');¬∑
    -- Users table with role
    ALTER TABLE users ADD COLUMN role user_role DEFAULT 'user';¬∑
    -- Policy: Admins can see all posts
    CREATE POLICY admin_all_access ON posts
    FOR ALL
    USING (
      (SELECT role FROM users WHERE id = auth.uid()) IN ('admin', 'owner')
    );¬∑
    -- Policy: Regular users can only see their own posts
    CREATE POLICY user_own_posts ON posts
    FOR SELECT
    USING (
      user_id = auth.uid()
      OR
      (SELECT role FROM users WHERE id = auth.uid()) IN ('admin', 'owner')
    );
    ```¬∑
    ### 2. Permission-Based Access¬∑
    ```sql
    -- Permissions table
    CREATE TABLE permissions (
      user_id UUID REFERENCES users(id),
      resource TEXT,
      action TEXT,
      PRIMARY KEY (user_id, resource, action)
    );¬∑
    -- Policy: Check permissions table
    CREATE POLICY permission_based ON documents
    FOR SELECT
    USING (
      EXISTS (
        SELECT 1 FROM permissions
        WHERE user_id = auth.uid()
          AND resource = 'documents'
          AND action = 'read'
      )
    );
    ```¬∑
    ### 3. Team-Based Access¬∑
    ```sql
    -- Team membership table
    CREATE TABLE team_members (
      team_id UUID REFERENCES teams(id),
      user_id UUID REFERENCES users(id),
      role TEXT,
      PRIMARY KEY (team_id, user_id)
    );¬∑
    -- Projects belong to teams
    ALTER TABLE projects ADD COLUMN team_id UUID REFERENCES teams(id);¬∑
    -- Policy: Team members can access team projects
    CREATE POLICY team_access ON projects
    FOR ALL
    USING (
      team_id IN (
        SELECT team_id FROM team_members WHERE user_id = auth.uid()
      )
    );
    ```¬∑
    ---¬∑
    ## Advanced RLS Patterns¬∑
    ### 1. Conditional Policies (Public + Private)¬∑
    ```sql
    -- Posts can be public or private
    ALTER TABLE posts ADD COLUMN is_public BOOLEAN DEFAULT false;¬∑
    -- Policy: Users can see public posts OR their own private posts
    CREATE POLICY public_or_own ON posts
    FOR SELECT
    USING (
      is_public = true
      OR
      user_id = auth.uid()
    );
    ```¬∑
    ### 2. Hierarchical Policies (Organization + Team + User)¬∑
    ```sql
    -- Policy combining multiple levels
    CREATE POLICY hierarchical_access ON documents
    FOR SELECT
    USING (
      -- Same organization
      organization_id = (SELECT organization_id FROM users WHERE id = auth.uid())
      AND (
        -- Public to organization
        visibility = 'organization'
        OR
        -- Same team
        (visibility = 'team' AND team_id IN (
          SELECT team_id FROM team_members WHERE user_id = auth.uid()
        ))
        OR
        -- Owner
        user_id = auth.uid()
      )
    );
    ```¬∑
    ### 3. Time-Based Policies¬∑
    ```sql
    -- Policy: Only show active projects (not archived)
    CREATE POLICY active_projects ON projects
    FOR SELECT
    USING (
      archived_at IS NULL
      OR
      archived_at > NOW() - INTERVAL '30 days'
    );
    ```¬∑
    ### 4. Bypass RLS for Service Roles¬∑
    ```sql
    -- Create service role (for background jobs, admin tasks)
    CREATE ROLE service_role;¬∑
    -- Grant bypass RLS privilege
    GRANT service_role TO postgres;
    ALTER ROLE service_role BYPASSRLS;¬∑
    -- Use service role for admin operations
    SET ROLE service_role;
    SELECT * FROM posts;  -- Returns ALL posts (RLS bypassed)
    RESET ROLE;
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Policy Performance¬∑
    ```sql
    -- ‚ùå Bad - Subquery executes for every row
    CREATE POLICY slow_policy ON posts
    FOR SELECT
    USING (
      user_id IN (SELECT user_id FROM team_members WHERE team_id = '...')
    );¬∑
    -- ‚úÖ Good - Use JOIN instead
    CREATE POLICY fast_policy ON posts
    FOR SELECT
    USING (
      EXISTS (
        SELECT 1 FROM team_members
        WHERE team_members.user_id = posts.user_id
          AND team_members.team_id = '...'
      )
    );¬∑
    -- ‚úÖ Better - Cache current user context
    -- Set session variable at connection time
    SET myapp.current_user_id = '123';
    SET myapp.current_organization_id = '456';¬∑
    CREATE POLICY cached_policy ON posts
    FOR SELECT
    USING (
      organization_id = current_setting('myapp.current_organization_id')::UUID
    );
    ```¬∑
    ### 2. Index for RLS¬∑
    ```sql
    -- Create indexes on columns used in RLS policies
    CREATE INDEX idx_posts_user_id ON posts (user_id);
    CREATE INDEX idx_posts_organization_id ON posts (organization_id);
    CREATE INDEX idx_team_members_user_id ON team_members (user_id);¬∑
    -- Composite index for multi-column policies
    CREATE INDEX idx_posts_org_user ON posts (organization_id, user_id);
    ```¬∑
    ---¬∑
    ## Testing RLS Policies¬∑
    ### 1. Test as Different Users¬∑
    ```sql
    -- Test as user 1
    SET ROLE authenticated;
    SET request.jwt.claim.sub = 'user-1-id';¬∑
    SELECT * FROM posts;  -- Should only see user 1's posts¬∑
    -- Test as user 2
    SET request.jwt.claim.sub = 'user-2-id';¬∑
    SELECT * FROM posts;  -- Should only see user 2's posts¬∑
    -- Reset
    RESET ROLE;
    ```¬∑
    ### 2. Automated Policy Tests¬∑
    ```sql
    -- Test function
    CREATE OR REPLACE FUNCTION test_rls_policies()
    RETURNS void AS $$
    DECLARE
      user1_id UUID := 'user-1';
      user2_id UUID := 'user-2';
    BEGIN
      -- Test user isolation
      SET request.jwt.claim.sub = user1_id;¬∑
      IF (SELECT COUNT(*) FROM posts WHERE user_id != user1_id) > 0 THEN
        RAISE EXCEPTION 'User 1 can see other users posts!';
      END IF;¬∑
      -- Test insert restriction
      BEGIN
        INSERT INTO posts (user_id, title) VALUES (user2_id, 'Hack');
        RAISE EXCEPTION 'User 1 inserted post as user 2!';
      EXCEPTION WHEN OTHERS THEN
        -- Expected to fail
      END;¬∑
      RAISE NOTICE 'All RLS tests passed!';
    END;
    $$ LANGUAGE plpgsql;¬∑
    -- Run tests
    SELECT test_rls_policies();
    ```¬∑
    ---¬∑
    ## Supabase-Specific Patterns¬∑
    ### 1. Auth Helpers¬∑
    ```typescript
    // Client-side: Supabase automatically adds JWT to requests
    import { createClient } from '@supabase/supabase-js';¬∑
    const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);¬∑
    // Login user
    await supabase.auth.signInWithPassword({ email, password });¬∑
    // Query automatically filtered by RLS
    const { data } = await supabase.from('posts').select('*');
    // Only returns posts allowed by RLS policies¬∑
    // auth.uid() in policies automatically uses JWT from request
    ```¬∑
    ### 2. Service Role for Admin¬∑
    ```typescript
    // Server-side: Use service role to bypass RLS
    const supabaseAdmin = createClient(
      SUPABASE_URL,
      SUPABASE_SERVICE_ROLE_KEY  // Has BYPASSRLS permission
    );¬∑
    // Returns ALL rows (RLS bypassed)
    const { data } = await supabaseAdmin.from('posts').select('*');
    ```¬∑
    ### 3. Custom Claims in JWT¬∑
    ```sql
    -- Policy using custom JWT claim
    CREATE POLICY organization_access ON projects
    FOR ALL
    USING (
      organization_id = (auth.jwt() ->> 'organization_id')::UUID
    );
    ```¬∑
    ---¬∑
    ## Security Best Practices¬∑
    ### 1. Always Enable RLS¬∑
    ```sql
    -- ‚úÖ Good - Enable RLS on all user tables
    ALTER TABLE posts ENABLE ROW LEVEL SECURITY;
    ALTER TABLE comments ENABLE ROW LEVEL SECURITY;
    ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;¬∑
    -- ‚ùå Bad - Forgetting to enable RLS = data leak
    -- Table without RLS = ALL users can see ALL data!
    ```¬∑
    ### 2. Test with Multiple Users¬∑
    ```sql
    -- Always test policies with:
    -- 1. Owner of resource
    -- 2. Different user in same organization
    -- 3. User in different organization
    -- 4. Unauthenticated user
    -- 5. Admin/service role
    ```¬∑
    ### 3. Audit RLS Policies¬∑
    ```sql
    -- List all tables without RLS
    SELECT schemaname, tablename
    FROM pg_tables
    WHERE schemaname = 'public'
      AND tablename NOT IN (
        SELECT tablename FROM pg_policies
      )
      AND tablename NOT LIKE 'pg_%';¬∑
    -- List all RLS policies
    SELECT schemaname, tablename, policyname, permissive, roles, cmd, qual
    FROM pg_policies
    WHERE schemaname = 'public';
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `audit-rls.js` - Find tables without RLS enabled
    - `test-rls-policies.js` - Automated RLS policy testing¬∑
    ### references/
    - `references/rls-patterns.md` - Common RLS patterns for SaaS
    - `references/supabase-auth.md` - Supabase auth.uid() and JWT helpers
    - `references/rls-performance.md` - RLS query optimization techniques
    - `references/multi-tenant-architecture.md` - Multi-tenant database design¬∑
    ### assets/
    - `assets/policy-templates/` - RLS policy templates for common use cases
    - `assets/test-scripts/` - RLS testing scripts¬∑
    ## Related Skills¬∑
    - `auth-security` - Authentication integration with RLS
    - `schema-optimization` - Index optimization for RLS policies
    - `api-design` - Supabase client integration with RLS
    - `vector-databases` - RLS for multi-tenant vector data
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ rls-policies ‚Ä∫ should be at least 500 lines (comprehensive documentation)

    expect(received).toBeGreaterThanOrEqual(expected)

    Expected: >= 500
    Received:    493

      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {
      115 |           const lineCount = content.split('\n').length;
    > 116 |           expect(lineCount).toBeGreaterThanOrEqual(500);
          |                             ^
      117 |         });
      118 |       });
      119 |     });

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:116:29)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ edge-databases ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: edge-databases
    description: Edge database patterns using Supabase Edge Functions, Cloudflare D1, and read replicas for globally distributed, low-latency data access. Use when building apps requiring <100ms database queries worldwide. Optimizes for edge caching, connection pooling, and geo-distribution. Best for user-facing applications with global audiences.
    ---¬∑
    # Edge Databases¬∑
    ## Overview¬∑
    Edge database patterns for globally distributed, low-latency data access using Supabase Edge Functions, Cloudflare D1, read replicas, and edge caching strategies. Enables <100ms database queries from anywhere in the world.¬∑
    **Goal**: Sub-100ms database access globally through edge computing and strategic data distribution¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building global applications with users worldwide
    - Reducing database latency from 200-500ms to <100ms
    - Scaling read-heavy workloads (10:1 read/write ratio or higher)
    - Implementing edge authentication and authorization
    - Processing user requests at the edge (closest to user)
    - Reducing backend server costs with edge caching
    - Building real-time collaborative applications
    - Serving static + dynamic content from the edge¬∑
    **Triggers**: \"edge database\", \"read replicas\", \"global distribution\", \"low latency\", \"edge functions\", \"D1\", \"edge caching\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Each Pattern¬∑
    **Supabase Edge Functions + Postgres**:
    - ‚úÖ Full PostgreSQL compatibility (relationships, transactions)
    - ‚úÖ RLS (Row-Level Security) at edge
    - ‚úÖ Real-time subscriptions
    - ‚úÖ Built-in auth integration
    - ‚úÖ Best for: PostgreSQL apps, multi-tenant SaaS, real-time features¬∑
    **Cloudflare D1 (SQLite at Edge)**:
    - ‚úÖ SQLite at every edge location (200+ cities)
    - ‚úÖ Zero cold starts (<1ms queries)
    - ‚úÖ Global replication (eventual consistency)
    - ‚úÖ Best for: Read-heavy apps, static + dynamic content, low-cost scaling¬∑
    **PlanetScale (MySQL at Edge)**:
    - ‚úÖ MySQL compatibility
    - ‚úÖ Branching (database per feature branch)
    - ‚úÖ Global read replicas
    - ‚úÖ Best for: MySQL apps, team collaboration, schema changes¬∑
    **Vercel Postgres (Neon)**:
    - ‚úÖ Serverless PostgreSQL
    - ‚úÖ Auto-scaling (scale to zero)
    - ‚úÖ Branching for preview deployments
    - ‚úÖ Best for: Next.js apps, Vercel ecosystem¬∑
    **Read Replicas + Edge Cache**:
    - ‚úÖ Traditional databases (PostgreSQL, MySQL)
    - ‚úÖ Replicas in multiple regions
    - ‚úÖ Edge caching (Redis, Cloudflare KV)
    - ‚úÖ Best for: Existing apps, gradual migration¬∑
    ---¬∑
    ## Supabase Edge Functions¬∑
    ### 1. Basic Edge Function with Postgres¬∑
    ```typescript
    // supabase/functions/hello/index.ts
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    serve(async (req) => {
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? ''
      );¬∑
      // Query runs from edge (closest to user)
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .limit(10);¬∑
      if (error) {
        return new Response(JSON.stringify({ error: error.message }), {
          status: 500,
          headers: { 'Content-Type': 'application/json' }
        });
      }¬∑
      return new Response(JSON.stringify({ users: data }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ### 2. Edge Function with RLS (Row-Level Security)¬∑
    ```typescript
    // Edge function with user authentication
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    serve(async (req) => {
      // Get JWT from Authorization header
      const authHeader = req.headers.get('Authorization')?.split(' ')[1];¬∑
      if (!authHeader) {
        return new Response(JSON.stringify({ error: 'Unauthorized' }), {
          status: 401
        });
      }¬∑
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? '',
        {
          global: {
            headers: { Authorization: `Bearer ${authHeader}` }
          }
        }
      );¬∑
      // RLS policies automatically applied based on JWT
      const { data: userPosts, error } = await supabase
        .from('posts')
        .select('*')
        .eq('user_id', (await supabase.auth.getUser()).data.user?.id);¬∑
      return new Response(JSON.stringify({ posts: userPosts }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ### 3. Edge Function with Connection Pooling¬∑
    ```typescript
    // Optimize for high concurrency - connection pooling
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { Pool } from 'https://deno.land/x/postgres@v0.17.0/mod.ts';¬∑
    // Create pool outside handler - reused across invocations
    const pool = new Pool({
      user: Deno.env.get('DB_USER'),
      password: Deno.env.get('DB_PASSWORD'),
      database: Deno.env.get('DB_NAME'),
      hostname: Deno.env.get('DB_HOST'),
      port: 5432,
      tls: { enabled: true }
    }, 3);  // Max 3 connections per isolate¬∑
    serve(async (req) => {
      const client = await pool.connect();¬∑
      try {
        const result = await client.queryObject`
          SELECT * FROM users WHERE active = true
        `;¬∑
        return new Response(JSON.stringify({ users: result.rows }), {
          headers: { 'Content-Type': 'application/json' }
        });
      } finally {
        client.release();
      }
    });
    ```¬∑
    ### 4. Edge Function with Caching¬∑
    ```typescript
    // Edge caching with Supabase Edge Functions
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    const cache = new Map();¬∑
    serve(async (req) => {
      const url = new URL(req.url);
      const userId = url.searchParams.get('userId');
      const cacheKey = `user:${userId}`;¬∑
      // Check cache first
      const cached = cache.get(cacheKey);
      if (cached && Date.now() - cached.timestamp < 60000) {
        return new Response(JSON.stringify({ user: cached.data, cached: true }), {
          headers: { 'Content-Type': 'application/json' }
        });
      }¬∑
      // Cache miss - query database
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? ''
      );¬∑
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .eq('id', userId)
        .single();¬∑
      if (!error && data) {
        cache.set(cacheKey, { data, timestamp: Date.now() });
      }¬∑
      return new Response(JSON.stringify({ user: data, cached: false }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ---¬∑
    ## Cloudflare D1 (SQLite at Edge)¬∑
    ### 1. Basic D1 Query¬∑
    ```typescript
    // Cloudflare Worker with D1 database
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { pathname } = new URL(request.url);¬∑
        if (pathname === '/api/users') {
          // Query runs at edge (200+ locations)
          const { results } = await env.DB.prepare(
            'SELECT * FROM users WHERE active = 1 LIMIT 10'
          ).all();¬∑
          return Response.json({ users: results });
        }¬∑
        return new Response('Not found', { status: 404 });
      }
    };
    ```¬∑
    ### 2. D1 with Prepared Statements¬∑
    ```typescript
    // Secure queries with prepared statements (prevents SQL injection)
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { searchParams } = new URL(request.url);
        const userId = searchParams.get('userId');¬∑
        if (!userId) {
          return Response.json({ error: 'userId required' }, { status: 400 });
        }¬∑
        // Prepared statement - safe from SQL injection
        const stmt = env.DB.prepare('SELECT * FROM users WHERE id = ?').bind(userId);
        const user = await stmt.first();¬∑
        if (!user) {
          return Response.json({ error: 'User not found' }, { status: 404 });
        }¬∑
        return Response.json({ user });
      }
    };
    ```¬∑
    ### 3. D1 Batch Operations¬∑
    ```typescript
    // Batch writes for better performance
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        if (request.method === 'POST') {
          const { users } = await request.json();¬∑
          // Batch insert - single round trip
          const results = await env.DB.batch([
            ...users.map((user: any) =>
              env.DB.prepare('INSERT INTO users (name, email) VALUES (?, ?)').bind(
                user.name,
                user.email
              )
            )
          ]);¬∑
          return Response.json({
            inserted: results.length,
            results
          });
        }¬∑
        return new Response('Method not allowed', { status: 405 });
      }
    };
    ```¬∑
    ### 4. D1 Migrations¬∑
    ```sql
    -- migrations/0001_create_users.sql
    CREATE TABLE IF NOT EXISTS users (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      name TEXT NOT NULL,
      email TEXT UNIQUE NOT NULL,
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP
    );¬∑
    CREATE INDEX idx_users_email ON users(email);¬∑
    -- migrations/0002_create_posts.sql
    CREATE TABLE IF NOT EXISTS posts (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      user_id INTEGER NOT NULL,
      title TEXT NOT NULL,
      content TEXT,
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      FOREIGN KEY (user_id) REFERENCES users(id)
    );¬∑
    CREATE INDEX idx_posts_user_id ON posts(user_id);
    ```¬∑
    ```bash
    # Apply migrations
    wrangler d1 migrations apply my-database --remote¬∑
    # Rollback
    wrangler d1 execute my-database --file=migrations/rollback.sql --remote
    ```¬∑
    ---¬∑
    ## Read Replicas Pattern¬∑
    ### 1. PostgreSQL Read Replicas¬∑
    ```typescript
    // Primary + read replicas with automatic routing
    import { Pool } from 'pg';¬∑
    // Primary database (writes)
    const primaryPool = new Pool({
      host: 'primary.db.example.com',
      database: 'myapp',
      user: 'app_user',
      password: process.env.DB_PASSWORD,
      max: 20
    });¬∑
    // Read replicas (reads) - geographically distributed
    const replicaPools = {
      'us-east': new Pool({
        host: 'replica-us-east.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      }),
      'eu-west': new Pool({
        host: 'replica-eu-west.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      }),
      'ap-south': new Pool({
        host: 'replica-ap-south.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      })
    };¬∑
    // Auto-route based on region
    export function getDbPool(operation: 'read' | 'write', region?: string) {
      if (operation === 'write') {
        return primaryPool;
      }¬∑
      // Read from nearest replica
      const replicaRegion = region || process.env.AWS_REGION || 'us-east';
      const pool = replicaPools[replicaRegion] || replicaPools['us-east'];
      return pool;
    }¬∑
    // Usage
    export async function getUser(userId: string, region?: string) {
      const pool = getDbPool('read', region);
      const result = await pool.query('SELECT * FROM users WHERE id = $1', [userId]);
      return result.rows[0];
    }¬∑
    export async function updateUser(userId: string, data: any) {
      const pool = getDbPool('write');
      const result = await pool.query(
        'UPDATE users SET name = $1, email = $2 WHERE id = $3 RETURNING *',
        [data.name, data.email, userId]
      );
      return result.rows[0];
    }
    ```¬∑
    ### 2. Replica Lag Handling¬∑
    ```typescript
    // Handle replication lag gracefully
    import { Pool } from 'pg';¬∑
    interface WriteResult {
      data: any;
      version: number;  // Timestamp or version number
    }¬∑
    // Write to primary and return version
    export async function createPost(userId: string, title: string): Promise<WriteResult> {
      const pool = getDbPool('write');
      const result = await pool.query(
        `INSERT INTO posts (user_id, title, created_at)
         VALUES ($1, $2, NOW())
         RETURNING *, EXTRACT(EPOCH FROM created_at) as version`,
        [userId, title]
      );¬∑
      return {
        data: result.rows[0],
        version: result.rows[0].version
      };
    }¬∑
    // Read from replica with version check
    export async function getPost(postId: string, minVersion?: number, region?: string) {
      const pool = getDbPool('read', region);¬∑
      if (minVersion) {
        // Wait for replica to catch up (max 5 seconds)
        for (let i = 0; i < 10; i++) {
          const result = await pool.query(
            `SELECT *, EXTRACT(EPOCH FROM created_at) as version
             FROM posts WHERE id = $1`,
            [postId]
          );¬∑
          if (result.rows[0] && result.rows[0].version >= minVersion) {
            return result.rows[0];
          }¬∑
          // Replica lagging - wait 500ms and retry
          await new Promise(resolve => setTimeout(resolve, 500));
        }¬∑
        // Fallback to primary if replica too slow
        console.warn('Replica lag too high, reading from primary');
        const primaryPool = getDbPool('write');
        const result = await primaryPool.query('SELECT * FROM posts WHERE id = $1', [postId]);
        return result.rows[0];
      }¬∑
      // No version check - allow stale data
      const result = await pool.query('SELECT * FROM posts WHERE id = $1', [postId]);
      return result.rows[0];
    }
    ```¬∑
    ---¬∑
    ## Edge Caching Strategies¬∑
    ### 1. Redis at Edge (Upstash)¬∑
    ```typescript
    // Upstash Redis - globally distributed
    import { Redis } from '@upstash/redis';¬∑
    const redis = new Redis({
      url: process.env.UPSTASH_REDIS_URL!,
      token: process.env.UPSTASH_REDIS_TOKEN!
    });¬∑
    export async function getUserCached(userId: string) {
      // Try cache first
      const cached = await redis.get(`user:${userId}`);
      if (cached) {
        return cached;
      }¬∑
      // Cache miss - query database
      const user = await db.users.findUnique({ where: { id: userId } });¬∑
      // Cache for 1 hour
      await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));¬∑
      return user;
    }¬∑
    // Invalidate cache on write
    export async function updateUserCached(userId: string, data: any) {
      const user = await db.users.update({
        where: { id: userId },
        data
      });¬∑
      // Update cache
      await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));¬∑
      return user;
    }
    ```¬∑
    ### 2. Cloudflare KV (Key-Value Store)¬∑
    ```typescript
    // Cloudflare KV - edge caching with eventual consistency
    interface Env {
      USER_CACHE: KVNamespace;
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { searchParams } = new URL(request.url);
        const userId = searchParams.get('userId');¬∑
        // Try KV cache first (edge - <1ms)
        const cached = await env.USER_CACHE.get(`user:${userId}`, { type: 'json' });
        if (cached) {
          return Response.json({ user: cached, cached: true });
        }¬∑
        // Cache miss - query D1 database
        const user = await env.DB.prepare('SELECT * FROM users WHERE id = ?')
          .bind(userId)
          .first();¬∑
        // Cache in KV (60s TTL)
        await env.USER_CACHE.put(`user:${userId}`, JSON.stringify(user), {
          expirationTtl: 60
        });¬∑
        return Response.json({ user, cached: false });
      }
    };
    ```¬∑
    ### 3. Stale-While-Revalidate Pattern¬∑
    ```typescript
    // Next.js Edge API with SWR caching
    export const runtime = 'edge';¬∑
    import { kv } from '@vercel/kv';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const userId = searchParams.get('userId');¬∑
      const cacheKey = `user:${userId}`;¬∑
      // Get from cache
      const cached = await kv.get(cacheKey);¬∑
      if (cached) {
        // Serve cached data immediately
        const response = Response.json({ user: cached, cached: true });¬∑
        // Revalidate in background (non-blocking)
        revalidateUser(userId, cacheKey);¬∑
        return response;
      }¬∑
      // Cache miss - fetch and cache
      const user = await fetchUser(userId);
      await kv.setex(cacheKey, 3600, JSON.stringify(user));¬∑
      return Response.json({ user, cached: false });
    }¬∑
    // Background revalidation
    async function revalidateUser(userId: string, cacheKey: string) {
      try {
        const user = await fetchUser(userId);
        await kv.setex(cacheKey, 3600, JSON.stringify(user));
      } catch (error) {
        console.error('Revalidation failed:', error);
      }
    }
    ```¬∑
    ---¬∑
    ## Multi-Region Deployment¬∑
    ### 1. Fly.io Multi-Region Postgres¬∑
    ```toml
    # fly.toml - Deploy to multiple regions
    app = \"myapp\"
    primary_region = \"iad\"  # US East (primary)¬∑
    [env]
      DATABASE_URL = \"postgresql://...\"¬∑
    [[services]]
      internal_port = 3000
      protocol = \"tcp\"¬∑
      [[services.ports]]
        port = 80
        handlers = [\"http\"]¬∑
      [[services.ports]]
        port = 443
        handlers = [\"tls\", \"http\"]¬∑
    # Read replicas in multiple regions
    [[services.regions]]
      region = \"iad\"  # US East (primary)¬∑
    [[services.regions]]
      region = \"lhr\"  # London¬∑
    [[services.regions]]
      region = \"syd\"  # Sydney
    ```¬∑
    ### 2. PlanetScale Global Reads¬∑
    ```typescript
    // PlanetScale - automatic read routing
    import { connect } from '@planetscale/database';¬∑
    const config = {
      host: process.env.DATABASE_HOST,
      username: process.env.DATABASE_USERNAME,
      password: process.env.DATABASE_PASSWORD
    };¬∑
    // Connects to nearest replica automatically
    const conn = connect(config);¬∑
    export async function getUsers() {
      // Reads from nearest replica
      const results = await conn.execute('SELECT * FROM users');
      return results.rows;
    }¬∑
    export async function createUser(name: string, email: string) {
      // Writes go to primary
      const results = await conn.execute(
        'INSERT INTO users (name, email) VALUES (?, ?)',
        [name, email]
      );
      return results.insertId;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Connection Pooling¬∑
    ```typescript
    // Supabase with Supavisor (connection pooler)
    import { createClient } from '@supabase/supabase-js';¬∑
    // Use transaction mode for short-lived connections
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_ANON_KEY!,
      {
        db: {
          schema: 'public'
        },
        global: {
          headers: {
            'x-connection-mode': 'transaction'  // Pool connections
          }
        }
      }
    );¬∑
    // Session mode for long-lived connections (edge functions)
    const supabaseSession = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!,
      {
        global: {
          headers: {
            'x-connection-mode': 'session'
          }
        }
      }
    );
    ```¬∑
    ### 2. Query Optimization for Edge¬∑
    ```typescript
    // Optimize queries for edge latency
    import { createClient } from '@supabase/supabase-js';¬∑
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_ANON_KEY!
    );¬∑
    // BAD: Multiple round trips
    async function getUserWithPostsBad(userId: string) {
      const { data: user } = await supabase
        .from('users')
        .select('*')
        .eq('id', userId)
        .single();¬∑
      const { data: posts } = await supabase
        .from('posts')
        .select('*')
        .eq('user_id', userId);¬∑
      return { user, posts };  // 2 round trips!
    }¬∑
    // GOOD: Single round trip with join
    async function getUserWithPostsGood(userId: string) {
      const { data } = await supabase
        .from('users')
        .select(`
          *,
          posts (*)
        `)
        .eq('id', userId)
        .single();¬∑
      return data;  // 1 round trip!
    }
    ```¬∑
    ### 3. Materialized Views for Edge¬∑
    ```sql
    -- Create materialized view for frequently accessed data
    CREATE MATERIALIZED VIEW user_stats AS
    SELECT
      u.id,
      u.name,
      COUNT(p.id) as post_count,
      MAX(p.created_at) as last_post_at
    FROM users u
    LEFT JOIN posts p ON p.user_id = u.id
    GROUP BY u.id, u.name;¬∑
    CREATE INDEX idx_user_stats_id ON user_stats(id);¬∑
    -- Refresh periodically (cron job)
    REFRESH MATERIALIZED VIEW CONCURRENTLY user_stats;
    ```¬∑
    ```typescript
    // Query materialized view at edge - blazing fast!
    const { data } = await supabase
      .from('user_stats')
      .select('*')
      .eq('id', userId)
      .single();
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `setup-read-replicas.sh` - Configure PostgreSQL read replicas
    - `deploy-edge-function.sh` - Deploy Supabase/Cloudflare edge functions¬∑
    ### references/
    - `references/edge-db-comparison.md` - D1 vs Supabase vs PlanetScale
    - `references/replication-lag.md` - Handling eventual consistency
    - `references/edge-caching.md` - Caching strategies for edge¬∑
    ### assets/
    - `assets/edge-configs/` - Edge function configuration examples
    - `assets/migration-scripts/` - D1/Supabase migration scripts¬∑
    ## Related Skills¬∑
    - `serverless` - Serverless functions at the edge
    - `rls-policies` - Row-Level Security for multi-tenant edge apps
    - `schema-optimization` - Database schema design for edge performance
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ edge-databases ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: edge-databases
    description: Edge database patterns using Supabase Edge Functions, Cloudflare D1, and read replicas for globally distributed, low-latency data access. Use when building apps requiring <100ms database queries worldwide. Optimizes for edge caching, connection pooling, and geo-distribution. Best for user-facing applications with global audiences.
    ---¬∑
    # Edge Databases¬∑
    ## Overview¬∑
    Edge database patterns for globally distributed, low-latency data access using Supabase Edge Functions, Cloudflare D1, read replicas, and edge caching strategies. Enables <100ms database queries from anywhere in the world.¬∑
    **Goal**: Sub-100ms database access globally through edge computing and strategic data distribution¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building global applications with users worldwide
    - Reducing database latency from 200-500ms to <100ms
    - Scaling read-heavy workloads (10:1 read/write ratio or higher)
    - Implementing edge authentication and authorization
    - Processing user requests at the edge (closest to user)
    - Reducing backend server costs with edge caching
    - Building real-time collaborative applications
    - Serving static + dynamic content from the edge¬∑
    **Triggers**: \"edge database\", \"read replicas\", \"global distribution\", \"low latency\", \"edge functions\", \"D1\", \"edge caching\"¬∑
    ---¬∑
    ## Quick Start: Architecture Decision Tree¬∑
    ### When to Use Each Pattern¬∑
    **Supabase Edge Functions + Postgres**:
    - ‚úÖ Full PostgreSQL compatibility (relationships, transactions)
    - ‚úÖ RLS (Row-Level Security) at edge
    - ‚úÖ Real-time subscriptions
    - ‚úÖ Built-in auth integration
    - ‚úÖ Best for: PostgreSQL apps, multi-tenant SaaS, real-time features¬∑
    **Cloudflare D1 (SQLite at Edge)**:
    - ‚úÖ SQLite at every edge location (200+ cities)
    - ‚úÖ Zero cold starts (<1ms queries)
    - ‚úÖ Global replication (eventual consistency)
    - ‚úÖ Best for: Read-heavy apps, static + dynamic content, low-cost scaling¬∑
    **PlanetScale (MySQL at Edge)**:
    - ‚úÖ MySQL compatibility
    - ‚úÖ Branching (database per feature branch)
    - ‚úÖ Global read replicas
    - ‚úÖ Best for: MySQL apps, team collaboration, schema changes¬∑
    **Vercel Postgres (Neon)**:
    - ‚úÖ Serverless PostgreSQL
    - ‚úÖ Auto-scaling (scale to zero)
    - ‚úÖ Branching for preview deployments
    - ‚úÖ Best for: Next.js apps, Vercel ecosystem¬∑
    **Read Replicas + Edge Cache**:
    - ‚úÖ Traditional databases (PostgreSQL, MySQL)
    - ‚úÖ Replicas in multiple regions
    - ‚úÖ Edge caching (Redis, Cloudflare KV)
    - ‚úÖ Best for: Existing apps, gradual migration¬∑
    ---¬∑
    ## Supabase Edge Functions¬∑
    ### 1. Basic Edge Function with Postgres¬∑
    ```typescript
    // supabase/functions/hello/index.ts
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    serve(async (req) => {
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? ''
      );¬∑
      // Query runs from edge (closest to user)
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .limit(10);¬∑
      if (error) {
        return new Response(JSON.stringify({ error: error.message }), {
          status: 500,
          headers: { 'Content-Type': 'application/json' }
        });
      }¬∑
      return new Response(JSON.stringify({ users: data }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ### 2. Edge Function with RLS (Row-Level Security)¬∑
    ```typescript
    // Edge function with user authentication
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    serve(async (req) => {
      // Get JWT from Authorization header
      const authHeader = req.headers.get('Authorization')?.split(' ')[1];¬∑
      if (!authHeader) {
        return new Response(JSON.stringify({ error: 'Unauthorized' }), {
          status: 401
        });
      }¬∑
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? '',
        {
          global: {
            headers: { Authorization: `Bearer ${authHeader}` }
          }
        }
      );¬∑
      // RLS policies automatically applied based on JWT
      const { data: userPosts, error } = await supabase
        .from('posts')
        .select('*')
        .eq('user_id', (await supabase.auth.getUser()).data.user?.id);¬∑
      return new Response(JSON.stringify({ posts: userPosts }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ### 3. Edge Function with Connection Pooling¬∑
    ```typescript
    // Optimize for high concurrency - connection pooling
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { Pool } from 'https://deno.land/x/postgres@v0.17.0/mod.ts';¬∑
    // Create pool outside handler - reused across invocations
    const pool = new Pool({
      user: Deno.env.get('DB_USER'),
      password: Deno.env.get('DB_PASSWORD'),
      database: Deno.env.get('DB_NAME'),
      hostname: Deno.env.get('DB_HOST'),
      port: 5432,
      tls: { enabled: true }
    }, 3);  // Max 3 connections per isolate¬∑
    serve(async (req) => {
      const client = await pool.connect();¬∑
      try {
        const result = await client.queryObject`
          SELECT * FROM users WHERE active = true
        `;¬∑
        return new Response(JSON.stringify({ users: result.rows }), {
          headers: { 'Content-Type': 'application/json' }
        });
      } finally {
        client.release();
      }
    });
    ```¬∑
    ### 4. Edge Function with Caching¬∑
    ```typescript
    // Edge caching with Supabase Edge Functions
    import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
    import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';¬∑
    const cache = new Map();¬∑
    serve(async (req) => {
      const url = new URL(req.url);
      const userId = url.searchParams.get('userId');
      const cacheKey = `user:${userId}`;¬∑
      // Check cache first
      const cached = cache.get(cacheKey);
      if (cached && Date.now() - cached.timestamp < 60000) {
        return new Response(JSON.stringify({ user: cached.data, cached: true }), {
          headers: { 'Content-Type': 'application/json' }
        });
      }¬∑
      // Cache miss - query database
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') ?? '',
        Deno.env.get('SUPABASE_ANON_KEY') ?? ''
      );¬∑
      const { data, error } = await supabase
        .from('users')
        .select('*')
        .eq('id', userId)
        .single();¬∑
      if (!error && data) {
        cache.set(cacheKey, { data, timestamp: Date.now() });
      }¬∑
      return new Response(JSON.stringify({ user: data, cached: false }), {
        headers: { 'Content-Type': 'application/json' }
      });
    });
    ```¬∑
    ---¬∑
    ## Cloudflare D1 (SQLite at Edge)¬∑
    ### 1. Basic D1 Query¬∑
    ```typescript
    // Cloudflare Worker with D1 database
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { pathname } = new URL(request.url);¬∑
        if (pathname === '/api/users') {
          // Query runs at edge (200+ locations)
          const { results } = await env.DB.prepare(
            'SELECT * FROM users WHERE active = 1 LIMIT 10'
          ).all();¬∑
          return Response.json({ users: results });
        }¬∑
        return new Response('Not found', { status: 404 });
      }
    };
    ```¬∑
    ### 2. D1 with Prepared Statements¬∑
    ```typescript
    // Secure queries with prepared statements (prevents SQL injection)
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { searchParams } = new URL(request.url);
        const userId = searchParams.get('userId');¬∑
        if (!userId) {
          return Response.json({ error: 'userId required' }, { status: 400 });
        }¬∑
        // Prepared statement - safe from SQL injection
        const stmt = env.DB.prepare('SELECT * FROM users WHERE id = ?').bind(userId);
        const user = await stmt.first();¬∑
        if (!user) {
          return Response.json({ error: 'User not found' }, { status: 404 });
        }¬∑
        return Response.json({ user });
      }
    };
    ```¬∑
    ### 3. D1 Batch Operations¬∑
    ```typescript
    // Batch writes for better performance
    interface Env {
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        if (request.method === 'POST') {
          const { users } = await request.json();¬∑
          // Batch insert - single round trip
          const results = await env.DB.batch([
            ...users.map((user: any) =>
              env.DB.prepare('INSERT INTO users (name, email) VALUES (?, ?)').bind(
                user.name,
                user.email
              )
            )
          ]);¬∑
          return Response.json({
            inserted: results.length,
            results
          });
        }¬∑
        return new Response('Method not allowed', { status: 405 });
      }
    };
    ```¬∑
    ### 4. D1 Migrations¬∑
    ```sql
    -- migrations/0001_create_users.sql
    CREATE TABLE IF NOT EXISTS users (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      name TEXT NOT NULL,
      email TEXT UNIQUE NOT NULL,
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP
    );¬∑
    CREATE INDEX idx_users_email ON users(email);¬∑
    -- migrations/0002_create_posts.sql
    CREATE TABLE IF NOT EXISTS posts (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      user_id INTEGER NOT NULL,
      title TEXT NOT NULL,
      content TEXT,
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      FOREIGN KEY (user_id) REFERENCES users(id)
    );¬∑
    CREATE INDEX idx_posts_user_id ON posts(user_id);
    ```¬∑
    ```bash
    # Apply migrations
    wrangler d1 migrations apply my-database --remote¬∑
    # Rollback
    wrangler d1 execute my-database --file=migrations/rollback.sql --remote
    ```¬∑
    ---¬∑
    ## Read Replicas Pattern¬∑
    ### 1. PostgreSQL Read Replicas¬∑
    ```typescript
    // Primary + read replicas with automatic routing
    import { Pool } from 'pg';¬∑
    // Primary database (writes)
    const primaryPool = new Pool({
      host: 'primary.db.example.com',
      database: 'myapp',
      user: 'app_user',
      password: process.env.DB_PASSWORD,
      max: 20
    });¬∑
    // Read replicas (reads) - geographically distributed
    const replicaPools = {
      'us-east': new Pool({
        host: 'replica-us-east.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      }),
      'eu-west': new Pool({
        host: 'replica-eu-west.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      }),
      'ap-south': new Pool({
        host: 'replica-ap-south.db.example.com',
        database: 'myapp',
        user: 'app_user',
        password: process.env.DB_PASSWORD,
        max: 50
      })
    };¬∑
    // Auto-route based on region
    export function getDbPool(operation: 'read' | 'write', region?: string) {
      if (operation === 'write') {
        return primaryPool;
      }¬∑
      // Read from nearest replica
      const replicaRegion = region || process.env.AWS_REGION || 'us-east';
      const pool = replicaPools[replicaRegion] || replicaPools['us-east'];
      return pool;
    }¬∑
    // Usage
    export async function getUser(userId: string, region?: string) {
      const pool = getDbPool('read', region);
      const result = await pool.query('SELECT * FROM users WHERE id = $1', [userId]);
      return result.rows[0];
    }¬∑
    export async function updateUser(userId: string, data: any) {
      const pool = getDbPool('write');
      const result = await pool.query(
        'UPDATE users SET name = $1, email = $2 WHERE id = $3 RETURNING *',
        [data.name, data.email, userId]
      );
      return result.rows[0];
    }
    ```¬∑
    ### 2. Replica Lag Handling¬∑
    ```typescript
    // Handle replication lag gracefully
    import { Pool } from 'pg';¬∑
    interface WriteResult {
      data: any;
      version: number;  // Timestamp or version number
    }¬∑
    // Write to primary and return version
    export async function createPost(userId: string, title: string): Promise<WriteResult> {
      const pool = getDbPool('write');
      const result = await pool.query(
        `INSERT INTO posts (user_id, title, created_at)
         VALUES ($1, $2, NOW())
         RETURNING *, EXTRACT(EPOCH FROM created_at) as version`,
        [userId, title]
      );¬∑
      return {
        data: result.rows[0],
        version: result.rows[0].version
      };
    }¬∑
    // Read from replica with version check
    export async function getPost(postId: string, minVersion?: number, region?: string) {
      const pool = getDbPool('read', region);¬∑
      if (minVersion) {
        // Wait for replica to catch up (max 5 seconds)
        for (let i = 0; i < 10; i++) {
          const result = await pool.query(
            `SELECT *, EXTRACT(EPOCH FROM created_at) as version
             FROM posts WHERE id = $1`,
            [postId]
          );¬∑
          if (result.rows[0] && result.rows[0].version >= minVersion) {
            return result.rows[0];
          }¬∑
          // Replica lagging - wait 500ms and retry
          await new Promise(resolve => setTimeout(resolve, 500));
        }¬∑
        // Fallback to primary if replica too slow
        console.warn('Replica lag too high, reading from primary');
        const primaryPool = getDbPool('write');
        const result = await primaryPool.query('SELECT * FROM posts WHERE id = $1', [postId]);
        return result.rows[0];
      }¬∑
      // No version check - allow stale data
      const result = await pool.query('SELECT * FROM posts WHERE id = $1', [postId]);
      return result.rows[0];
    }
    ```¬∑
    ---¬∑
    ## Edge Caching Strategies¬∑
    ### 1. Redis at Edge (Upstash)¬∑
    ```typescript
    // Upstash Redis - globally distributed
    import { Redis } from '@upstash/redis';¬∑
    const redis = new Redis({
      url: process.env.UPSTASH_REDIS_URL!,
      token: process.env.UPSTASH_REDIS_TOKEN!
    });¬∑
    export async function getUserCached(userId: string) {
      // Try cache first
      const cached = await redis.get(`user:${userId}`);
      if (cached) {
        return cached;
      }¬∑
      // Cache miss - query database
      const user = await db.users.findUnique({ where: { id: userId } });¬∑
      // Cache for 1 hour
      await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));¬∑
      return user;
    }¬∑
    // Invalidate cache on write
    export async function updateUserCached(userId: string, data: any) {
      const user = await db.users.update({
        where: { id: userId },
        data
      });¬∑
      // Update cache
      await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));¬∑
      return user;
    }
    ```¬∑
    ### 2. Cloudflare KV (Key-Value Store)¬∑
    ```typescript
    // Cloudflare KV - edge caching with eventual consistency
    interface Env {
      USER_CACHE: KVNamespace;
      DB: D1Database;
    }¬∑
    export default {
      async fetch(request: Request, env: Env): Promise<Response> {
        const { searchParams } = new URL(request.url);
        const userId = searchParams.get('userId');¬∑
        // Try KV cache first (edge - <1ms)
        const cached = await env.USER_CACHE.get(`user:${userId}`, { type: 'json' });
        if (cached) {
          return Response.json({ user: cached, cached: true });
        }¬∑
        // Cache miss - query D1 database
        const user = await env.DB.prepare('SELECT * FROM users WHERE id = ?')
          .bind(userId)
          .first();¬∑
        // Cache in KV (60s TTL)
        await env.USER_CACHE.put(`user:${userId}`, JSON.stringify(user), {
          expirationTtl: 60
        });¬∑
        return Response.json({ user, cached: false });
      }
    };
    ```¬∑
    ### 3. Stale-While-Revalidate Pattern¬∑
    ```typescript
    // Next.js Edge API with SWR caching
    export const runtime = 'edge';¬∑
    import { kv } from '@vercel/kv';¬∑
    export async function GET(request: Request) {
      const { searchParams } = new URL(request.url);
      const userId = searchParams.get('userId');¬∑
      const cacheKey = `user:${userId}`;¬∑
      // Get from cache
      const cached = await kv.get(cacheKey);¬∑
      if (cached) {
        // Serve cached data immediately
        const response = Response.json({ user: cached, cached: true });¬∑
        // Revalidate in background (non-blocking)
        revalidateUser(userId, cacheKey);¬∑
        return response;
      }¬∑
      // Cache miss - fetch and cache
      const user = await fetchUser(userId);
      await kv.setex(cacheKey, 3600, JSON.stringify(user));¬∑
      return Response.json({ user, cached: false });
    }¬∑
    // Background revalidation
    async function revalidateUser(userId: string, cacheKey: string) {
      try {
        const user = await fetchUser(userId);
        await kv.setex(cacheKey, 3600, JSON.stringify(user));
      } catch (error) {
        console.error('Revalidation failed:', error);
      }
    }
    ```¬∑
    ---¬∑
    ## Multi-Region Deployment¬∑
    ### 1. Fly.io Multi-Region Postgres¬∑
    ```toml
    # fly.toml - Deploy to multiple regions
    app = \"myapp\"
    primary_region = \"iad\"  # US East (primary)¬∑
    [env]
      DATABASE_URL = \"postgresql://...\"¬∑
    [[services]]
      internal_port = 3000
      protocol = \"tcp\"¬∑
      [[services.ports]]
        port = 80
        handlers = [\"http\"]¬∑
      [[services.ports]]
        port = 443
        handlers = [\"tls\", \"http\"]¬∑
    # Read replicas in multiple regions
    [[services.regions]]
      region = \"iad\"  # US East (primary)¬∑
    [[services.regions]]
      region = \"lhr\"  # London¬∑
    [[services.regions]]
      region = \"syd\"  # Sydney
    ```¬∑
    ### 2. PlanetScale Global Reads¬∑
    ```typescript
    // PlanetScale - automatic read routing
    import { connect } from '@planetscale/database';¬∑
    const config = {
      host: process.env.DATABASE_HOST,
      username: process.env.DATABASE_USERNAME,
      password: process.env.DATABASE_PASSWORD
    };¬∑
    // Connects to nearest replica automatically
    const conn = connect(config);¬∑
    export async function getUsers() {
      // Reads from nearest replica
      const results = await conn.execute('SELECT * FROM users');
      return results.rows;
    }¬∑
    export async function createUser(name: string, email: string) {
      // Writes go to primary
      const results = await conn.execute(
        'INSERT INTO users (name, email) VALUES (?, ?)',
        [name, email]
      );
      return results.insertId;
    }
    ```¬∑
    ---¬∑
    ## Performance Optimization¬∑
    ### 1. Connection Pooling¬∑
    ```typescript
    // Supabase with Supavisor (connection pooler)
    import { createClient } from '@supabase/supabase-js';¬∑
    // Use transaction mode for short-lived connections
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_ANON_KEY!,
      {
        db: {
          schema: 'public'
        },
        global: {
          headers: {
            'x-connection-mode': 'transaction'  // Pool connections
          }
        }
      }
    );¬∑
    // Session mode for long-lived connections (edge functions)
    const supabaseSession = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!,
      {
        global: {
          headers: {
            'x-connection-mode': 'session'
          }
        }
      }
    );
    ```¬∑
    ### 2. Query Optimization for Edge¬∑
    ```typescript
    // Optimize queries for edge latency
    import { createClient } from '@supabase/supabase-js';¬∑
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_ANON_KEY!
    );¬∑
    // BAD: Multiple round trips
    async function getUserWithPostsBad(userId: string) {
      const { data: user } = await supabase
        .from('users')
        .select('*')
        .eq('id', userId)
        .single();¬∑
      const { data: posts } = await supabase
        .from('posts')
        .select('*')
        .eq('user_id', userId);¬∑
      return { user, posts };  // 2 round trips!
    }¬∑
    // GOOD: Single round trip with join
    async function getUserWithPostsGood(userId: string) {
      const { data } = await supabase
        .from('users')
        .select(`
          *,
          posts (*)
        `)
        .eq('id', userId)
        .single();¬∑
      return data;  // 1 round trip!
    }
    ```¬∑
    ### 3. Materialized Views for Edge¬∑
    ```sql
    -- Create materialized view for frequently accessed data
    CREATE MATERIALIZED VIEW user_stats AS
    SELECT
      u.id,
      u.name,
      COUNT(p.id) as post_count,
      MAX(p.created_at) as last_post_at
    FROM users u
    LEFT JOIN posts p ON p.user_id = u.id
    GROUP BY u.id, u.name;¬∑
    CREATE INDEX idx_user_stats_id ON user_stats(id);¬∑
    -- Refresh periodically (cron job)
    REFRESH MATERIALIZED VIEW CONCURRENTLY user_stats;
    ```¬∑
    ```typescript
    // Query materialized view at edge - blazing fast!
    const { data } = await supabase
      .from('user_stats')
      .select('*')
      .eq('id', userId)
      .single();
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `setup-read-replicas.sh` - Configure PostgreSQL read replicas
    - `deploy-edge-function.sh` - Deploy Supabase/Cloudflare edge functions¬∑
    ### references/
    - `references/edge-db-comparison.md` - D1 vs Supabase vs PlanetScale
    - `references/replication-lag.md` - Handling eventual consistency
    - `references/edge-caching.md` - Caching strategies for edge¬∑
    ### assets/
    - `assets/edge-configs/` - Edge function configuration examples
    - `assets/migration-scripts/` - D1/Supabase migration scripts¬∑
    ## Related Skills¬∑
    - `serverless` - Serverless functions at the edge
    - `rls-policies` - Row-Level Security for multi-tenant edge apps
    - `schema-optimization` - Database schema design for edge performance
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ ml-pipelines ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: ml-pipelines
    description: ML model training pipelines, feature engineering, experiment tracking with MLflow/Kubeflow. Use when building training pipelines, feature stores, hyperparameter tuning, or orchestrating ML workflows. Covers data preprocessing, model training, distributed training, and experiment management. Reduces ML pipeline development time by 50%.
    ---¬∑
    # ML Pipelines¬∑
    ## Overview¬∑
    Production-grade ML model training pipelines covering data preprocessing, feature engineering, model training, hyperparameter tuning, and experiment tracking. Supports MLflow, Kubeflow, and custom pipeline frameworks.¬∑
    **Goal**: Build scalable, reproducible ML training pipelines that track experiments and enable efficient model development¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building model training pipelines from scratch
    - Implementing feature engineering and preprocessing
    - Setting up experiment tracking (MLflow, Weights & Biases)
    - Orchestrating distributed training (Ray, Horovod)
    - Creating feature stores (Feast, Tecton)
    - Hyperparameter tuning at scale (Optuna, Ray Tune)
    - Migrating from notebooks to production pipelines¬∑
    **Triggers**: \"ML pipeline\", \"model training\", \"feature engineering\", \"MLflow\", \"Kubeflow\", \"hyperparameter tuning\", \"experiment tracking\", \"feature store\"¬∑
    ---¬∑
    ## Quick Start: Pipeline Architecture Decision Tree¬∑
    ### When to Use Different Pipeline Frameworks¬∑
    **MLflow** (Experiment tracking, model registry):
    - ‚úÖ Experiment tracking and reproducibility
    - ‚úÖ Model versioning and registry
    - ‚úÖ Simple local or cloud deployment
    - ‚úÖ Python-first workflows
    - ‚úÖ Integration with scikit-learn, PyTorch, TensorFlow
    - ‚úÖ Best for: Small to medium teams, research projects¬∑
    **Kubeflow Pipelines** (Kubernetes-native ML workflows):
    - ‚úÖ Complex multi-step workflows
    - ‚úÖ Kubernetes-based infrastructure
    - ‚úÖ Distributed training at scale
    - ‚úÖ Component reusability
    - ‚úÖ Production-grade orchestration
    - ‚úÖ Best for: Large teams, enterprise ML platforms¬∑
    **Ray** (Distributed compute framework):
    - ‚úÖ Distributed training and tuning
    - ‚úÖ Hyperparameter optimization at scale
    - ‚úÖ Python-native API
    - ‚úÖ Flexible compute allocation
    - ‚úÖ Best for: Large-scale training, HPO¬∑
    **Custom (Airflow/Prefect + Python)**:
    - ‚úÖ Full control over workflow
    - ‚úÖ Integration with existing data pipelines
    - ‚úÖ Custom scheduling and monitoring
    - ‚úÖ Best for: Unique requirements, existing infrastructure¬∑
    ---¬∑
    ## MLflow Training Pipeline¬∑
    ### 1. Experiment Setup¬∑
    ```python
    # training/experiment_config.py
    import mlflow
    import os
    from dataclasses import dataclass
    from typing import Dict, Any¬∑
    @dataclass
    class ExperimentConfig:
        \"\"\"MLflow experiment configuration\"\"\"
        experiment_name: str
        tracking_uri: str = \"http://localhost:5000\"
        artifact_location: str = \"./mlruns\"¬∑
        def setup(self) -> str:
            \"\"\"Setup MLflow experiment and return experiment ID\"\"\"
            mlflow.set_tracking_uri(self.tracking_uri)¬∑
            # Create or get existing experiment
            experiment = mlflow.get_experiment_by_name(self.experiment_name)
            if experiment is None:
                experiment_id = mlflow.create_experiment(
                    name=self.experiment_name,
                    artifact_location=self.artifact_location
                )
            else:
                experiment_id = experiment.experiment_id¬∑
            mlflow.set_experiment(self.experiment_name)
            return experiment_id¬∑
    # Usage
    config = ExperimentConfig(
        experiment_name=\"user-churn-prediction\",
        tracking_uri=\"http://mlflow.company.com\",
        artifact_location=\"s3://ml-artifacts/experiments\"
    )
    experiment_id = config.setup()
    ```¬∑
    ### 2. Feature Engineering Pipeline¬∑
    ```python
    # features/preprocessing.py
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from typing import List, Tuple¬∑
    class FeatureEngineer:
        \"\"\"Feature engineering pipeline with versioning\"\"\"¬∑
        def __init__(self, version: str = \"v1\"):
            self.version = version
            self.numeric_features = []
            self.categorical_features = []
            self.pipeline = None¬∑
        def fit_transform(
            self,
            df: pd.DataFrame,
            target_col: str
        ) -> Tuple[np.ndarray, np.ndarray]:
            \"\"\"Fit pipeline and transform data\"\"\"¬∑
            # Separate features and target
            X = df.drop(columns=[target_col])
            y = df[target_col]¬∑
            # Identify feature types
            self.numeric_features = X.select_dtypes(
                include=['int64', 'float64']
            ).columns.tolist()
            self.categorical_features = X.select_dtypes(
                include=['object', 'category']
            ).columns.tolist()¬∑
            # Create preprocessing pipeline
            numeric_transformer = Pipeline([
                ('scaler', StandardScaler())
            ])¬∑
            categorical_transformer = Pipeline([
                ('encoder', LabelEncoder()) # Use OneHotEncoder for multiple categories
            ])¬∑
            self.pipeline = ColumnTransformer(
                transformers=[
                    ('num', numeric_transformer, self.numeric_features),
                    ('cat', categorical_transformer, self.categorical_features)
                ]
            )¬∑
            # Fit and transform
            X_transformed = self.pipeline.fit_transform(X)¬∑
            return X_transformed, y.values¬∑
        def transform(self, df: pd.DataFrame) -> np.ndarray:
            \"\"\"Transform new data using fitted pipeline\"\"\"
            if self.pipeline is None:
                raise ValueError(\"Pipeline not fitted. Call fit_transform first.\")¬∑
            return self.pipeline.transform(df)¬∑
        def get_feature_names(self) -> List[str]:
            \"\"\"Get feature names after transformation\"\"\"
            return self.numeric_features + self.categorical_features¬∑
    # Custom feature engineering
    class ChurnFeatureEngineer(FeatureEngineer):
        \"\"\"Domain-specific features for churn prediction\"\"\"¬∑
        def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
            \"\"\"Create domain-specific features\"\"\"
            df = df.copy()¬∑
            # Tenure buckets
            df['tenure_bucket'] = pd.cut(
                df['tenure'],
                bins=[0, 12, 24, 48, np.inf],
                labels=['0-1y', '1-2y', '2-4y', '4y+']
            )¬∑
            # Usage intensity
            df['usage_intensity'] = (
                df['monthly_minutes'] / df['tenure']
            ).fillna(0)¬∑
            # Revenue per month
            df['revenue_per_month'] = (
                df['total_revenue'] / df['tenure']
            ).fillna(0)¬∑
            # Recent activity drop
            df['activity_drop'] = (
                df['prev_month_minutes'] - df['current_month_minutes']
            ) / df['prev_month_minutes'].replace(0, 1)¬∑
            return df¬∑
    # Usage
    engineer = ChurnFeatureEngineer(version=\"v1\")
    df_engineered = engineer.engineer_features(df)
    X, y = engineer.fit_transform(df_engineered, target_col='churned')
    ```¬∑
    ### 3. Training Pipeline with MLflow¬∑
    ```python
    # training/train.py
    import mlflow
    import mlflow.sklearn
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score,
        f1_score, roc_auc_score, confusion_matrix
    )
    import numpy as np
    from typing import Dict, Any
    import joblib¬∑
    class MLflowTrainer:
        \"\"\"Model training with MLflow tracking\"\"\"¬∑
        def __init__(self, config: ExperimentConfig):
            self.config = config
            self.config.setup()¬∑
        def train_model(
            self,
            X: np.ndarray,
            y: np.ndarray,
            model_params: Dict[str, Any],
            tags: Dict[str, str] = None
        ) -> str:
            \"\"\"Train model and log to MLflow\"\"\"¬∑
            # Start MLflow run
            with mlflow.start_run(tags=tags) as run:
                # Split data
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )¬∑
                # Log parameters
                mlflow.log_params(model_params)
                mlflow.log_param(\"train_size\", len(X_train))
                mlflow.log_param(\"test_size\", len(X_test))¬∑
                # Train model
                model = RandomForestClassifier(**model_params, random_state=42)
                model.fit(X_train, y_train)¬∑
                # Cross-validation
                cv_scores = cross_val_score(
                    model, X_train, y_train, cv=5, scoring='roc_auc'
                )
                mlflow.log_metric(\"cv_roc_auc_mean\", cv_scores.mean())
                mlflow.log_metric(\"cv_roc_auc_std\", cv_scores.std())¬∑
                # Predictions
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]¬∑
                # Log metrics
                metrics = {
                    'accuracy': accuracy_score(y_test, y_pred),
                    'precision': precision_score(y_test, y_pred),
                    'recall': recall_score(y_test, y_pred),
                    'f1': f1_score(y_test, y_pred),
                    'roc_auc': roc_auc_score(y_test, y_pred_proba)
                }
                mlflow.log_metrics(metrics)¬∑
                # Log confusion matrix as artifact
                cm = confusion_matrix(y_test, y_pred)
                np.savetxt(\"confusion_matrix.txt\", cm, fmt='%d')
                mlflow.log_artifact(\"confusion_matrix.txt\")¬∑
                # Log feature importances
                feature_importance = pd.DataFrame({
                    'feature': range(X.shape[1]),
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=False)
                feature_importance.to_csv(\"feature_importance.csv\", index=False)
                mlflow.log_artifact(\"feature_importance.csv\")¬∑
                # Log model
                mlflow.sklearn.log_model(
                    model,
                    \"model\",
                    registered_model_name=f\"{self.config.experiment_name}-model\"
                )¬∑
                print(f\"‚úÖ Model trained successfully\")
                print(f\"Run ID: {run.info.run_id}\")
                print(f\"Metrics: {metrics}\")¬∑
                return run.info.run_id¬∑
    # Usage
    trainer = MLflowTrainer(config)
    run_id = trainer.train_model(
        X, y,
        model_params={
            'n_estimators': 100,
            'max_depth': 10,
            'min_samples_split': 5,
            'min_samples_leaf': 2
        },
        tags={
            'version': 'v1',
            'model_type': 'random_forest',
            'engineer': 'Dr.AI-ML'
        }
    )
    ```¬∑
    ### 4. Hyperparameter Tuning with Optuna + MLflow¬∑
    ```python
    # training/hyperparameter_tuning.py
    import optuna
    from optuna.integration.mlflow import MLflowCallback
    import mlflow
    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestClassifier
    import numpy as np¬∑
    class OptunaMLflowTuner:
        \"\"\"Hyperparameter tuning with Optuna + MLflow integration\"\"\"¬∑
        def __init__(self, config: ExperimentConfig):
            self.config = config
            self.config.setup()¬∑
        def objective(self, trial: optuna.Trial, X: np.ndarray, y: np.ndarray) -> float:
            \"\"\"Optuna objective function\"\"\"¬∑
            # Suggest hyperparameters
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 5, 30),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                'max_features': trial.suggest_categorical(
                    'max_features', ['sqrt', 'log2', None]
                ),
                'random_state': 42
            }¬∑
            # Train model with cross-validation
            model = RandomForestClassifier(**params)
            scores = cross_val_score(
                model, X, y, cv=5, scoring='roc_auc', n_jobs=-1
            )¬∑
            return scores.mean()¬∑
        def tune(
            self,
            X: np.ndarray,
            y: np.ndarray,
            n_trials: int = 100
        ) -> Dict[str, Any]:
            \"\"\"Run hyperparameter tuning\"\"\"¬∑
            # Create MLflow callback
            mlflow_callback = MLflowCallback(
                tracking_uri=self.config.tracking_uri,
                metric_name=\"roc_auc_cv\"
            )¬∑
            # Create study
            study = optuna.create_study(
                study_name=f\"{self.config.experiment_name}-tuning\",
                direction='maximize',
                sampler=optuna.samplers.TPESampler(seed=42)
            )¬∑
            # Optimize
            study.optimize(
                lambda trial: self.objective(trial, X, y),
                n_trials=n_trials,
                callbacks=[mlflow_callback],
                n_jobs=-1
            )¬∑
            print(f\"‚úÖ Tuning complete\")
            print(f\"Best ROC-AUC: {study.best_value:.4f}\")
            print(f\"Best params: {study.best_params}\")¬∑
            return {
                'best_params': study.best_params,
                'best_value': study.best_value,
                'study': study
            }¬∑
    # Usage
    tuner = OptunaMLflowTuner(config)
    results = tuner.tune(X, y, n_trials=100)¬∑
    # Train final model with best params
    trainer = MLflowTrainer(config)
    run_id = trainer.train_model(X, y, results['best_params'])
    ```¬∑
    ---¬∑
    ## Kubeflow Pipelines¬∑
    ### 1. Pipeline Component¬∑
    ```python
    # kubeflow/components/preprocess.py
    from kfp import dsl
    from kfp.dsl import Dataset, Input, Output, Model¬∑
    @dsl.component(
        base_image='python:3.10',
        packages_to_install=['pandas==2.0.0', 'scikit-learn==1.3.0']
    )
    def preprocess_data(
        input_data: Input[Dataset],
        output_features: Output[Dataset],
        test_size: float = 0.2
    ):
        \"\"\"Preprocess data for training\"\"\"
        import pandas as pd
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler
        import pickle¬∑
        # Load data
        df = pd.read_csv(input_data.path)¬∑
        # Feature engineering
        X = df.drop(columns=['target'])
        y = df['target']¬∑
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )¬∑
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)¬∑
        # Save processed data
        processed_data = {
            'X_train': X_train_scaled,
            'X_test': X_test_scaled,
            'y_train': y_train.values,
            'y_test': y_test.values,
            'scaler': scaler
        }¬∑
        with open(output_features.path, 'wb') as f:
            pickle.dump(processed_data, f)¬∑
    @dsl.component(
        base_image='python:3.10',
        packages_to_install=['scikit-learn==1.3.0', 'mlflow==2.8.0']
    )
    def train_model(
        input_features: Input[Dataset],
        output_model: Output[Model],
        n_estimators: int = 100,
        max_depth: int = 10
    ):
        \"\"\"Train ML model\"\"\"
        import pickle
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score, roc_auc_score
        import mlflow¬∑
        # Load processed data
        with open(input_features.path, 'rb') as f:
            data = pickle.load(f)¬∑
        X_train = data['X_train']
        y_train = data['y_train']
        X_test = data['X_test']
        y_test = data['y_test']¬∑
        # Train model
        with mlflow.start_run():
            model = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42
            )
            model.fit(X_train, y_train)¬∑
            # Evaluate
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]¬∑
            accuracy = accuracy_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_pred_proba)¬∑
            # Log metrics
            mlflow.log_metric(\"accuracy\", accuracy)
            mlflow.log_metric(\"roc_auc\", roc_auc)¬∑
            # Save model
            with open(output_model.path, 'wb') as f:
                pickle.dump({'model': model, 'scaler': data['scaler']}, f)¬∑
            print(f\"Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\")
    ```¬∑
    ### 2. Pipeline Definition¬∑
    ```python
    # kubeflow/pipelines/training_pipeline.py
    from kfp import dsl
    from kfp.dsl import Dataset, Model¬∑
    @dsl.pipeline(
        name='ML Training Pipeline',
        description='End-to-end ML training pipeline with Kubeflow'
    )
    def training_pipeline(
        data_path: str,
        n_estimators: int = 100,
        max_depth: int = 10,
        test_size: float = 0.2
    ):
        \"\"\"Complete ML training pipeline\"\"\"¬∑
        # Step 1: Load data
        load_data_task = load_data(data_path=data_path)¬∑
        # Step 2: Preprocess
        preprocess_task = preprocess_data(
            input_data=load_data_task.outputs['output_data'],
            test_size=test_size
        )¬∑
        # Step 3: Train model
        train_task = train_model(
            input_features=preprocess_task.outputs['output_features'],
            n_estimators=n_estimators,
            max_depth=max_depth
        )¬∑
        # Step 4: Evaluate model
        evaluate_task = evaluate_model(
            input_model=train_task.outputs['output_model'],
            input_features=preprocess_task.outputs['output_features']
        )¬∑
        # Step 5: Deploy if metrics pass threshold
        with dsl.Condition(evaluate_task.outputs['roc_auc'] >= 0.85):
            deploy_model(
                input_model=train_task.outputs['output_model'],
                model_name='churn-predictor'
            )¬∑
    # Compile pipeline
    from kfp import compiler¬∑
    compiler.Compiler().compile(
        pipeline_func=training_pipeline,
        package_path='training_pipeline.yaml'
    )¬∑
    # Submit pipeline
    from kfp.client import Client¬∑
    client = Client(host='http://kubeflow.company.com')
    run = client.create_run_from_pipeline_func(
        training_pipeline,
        arguments={
            'data_path': 's3://ml-data/churn-data.csv',
            'n_estimators': 200,
            'max_depth': 15,
            'test_size': 0.2
        }
    )
    ```¬∑
    ---¬∑
    ## Distributed Training with Ray¬∑
    ### Ray Train Example¬∑
    ```python
    # training/ray_distributed.py
    import ray
    from ray import train
    from ray.train import ScalingConfig
    from ray.train.torch import TorchTrainer
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset¬∑
    def train_func(config: dict):
        \"\"\"Training function for Ray\"\"\"¬∑
        # Get data from Ray
        train_dataset = train.get_dataset_shard(\"train\")¬∑
        # Create model
        model = nn.Sequential(
            nn.Linear(config['input_dim'], 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )¬∑
        # Wrap model with Ray
        model = train.torch.prepare_model(model)¬∑
        # Optimizer
        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])
        criterion = nn.BCELoss()¬∑
        # Training loop
        for epoch in range(config['epochs']):
            model.train()
            total_loss = 0¬∑
            for batch in train_dataset.iter_torch_batches(batch_size=config['batch_size']):
                X = batch['features']
                y = batch['labels']¬∑
                optimizer.zero_grad()
                outputs = model(X)
                loss = criterion(outputs, y)
                loss.backward()
                optimizer.step()¬∑
                total_loss += loss.item()¬∑
            # Report metrics to Ray
            train.report({
                'epoch': epoch,
                'loss': total_loss / len(train_dataset)
            })¬∑
    # Initialize Ray
    ray.init(address='auto')  # Connect to Ray cluster¬∑
    # Create trainer
    trainer = TorchTrainer(
        train_func,
        train_loop_config={
            'input_dim': 100,
            'lr': 0.001,
            'epochs': 10,
            'batch_size': 128
        },
        scaling_config=ScalingConfig(
            num_workers=4,  # 4 distributed workers
            use_gpu=True
        ),
        datasets={'train': ray_dataset}
    )¬∑
    # Train
    result = trainer.fit()
    print(f\"Final metrics: {result.metrics}\")
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `execute-mlflow-training.py` - Run MLflow training pipeline
    - `execute-kubeflow-pipeline.py` - Submit Kubeflow pipeline
    - `execute-hyperparameter-tuning.py` - Run Optuna tuning¬∑
    ### references/
    - `references/mlflow-setup.md` - MLflow server setup and configuration
    - `references/kubeflow-components.md` - Kubeflow component library
    - `references/feature-engineering-patterns.md` - Common feature engineering techniques
    - `references/distributed-training.md` - Ray/Horovod distributed training¬∑
    ### assets/
    - `assets/pipeline-templates/` - Kubeflow YAML templates
    - `assets/mlflow-configs/` - MLflow tracking server configs¬∑
    ## Related Skills¬∑
    - `rag-optimization` - RAG system training and fine-tuning
    - `model-deployment` - Deploy trained models to production
    - `vector-databases` - Feature store and embedding storage
    - `testing-strategies` - ML model testing and validation
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ ml-pipelines ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: ml-pipelines
    description: ML model training pipelines, feature engineering, experiment tracking with MLflow/Kubeflow. Use when building training pipelines, feature stores, hyperparameter tuning, or orchestrating ML workflows. Covers data preprocessing, model training, distributed training, and experiment management. Reduces ML pipeline development time by 50%.
    ---¬∑
    # ML Pipelines¬∑
    ## Overview¬∑
    Production-grade ML model training pipelines covering data preprocessing, feature engineering, model training, hyperparameter tuning, and experiment tracking. Supports MLflow, Kubeflow, and custom pipeline frameworks.¬∑
    **Goal**: Build scalable, reproducible ML training pipelines that track experiments and enable efficient model development¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building model training pipelines from scratch
    - Implementing feature engineering and preprocessing
    - Setting up experiment tracking (MLflow, Weights & Biases)
    - Orchestrating distributed training (Ray, Horovod)
    - Creating feature stores (Feast, Tecton)
    - Hyperparameter tuning at scale (Optuna, Ray Tune)
    - Migrating from notebooks to production pipelines¬∑
    **Triggers**: \"ML pipeline\", \"model training\", \"feature engineering\", \"MLflow\", \"Kubeflow\", \"hyperparameter tuning\", \"experiment tracking\", \"feature store\"¬∑
    ---¬∑
    ## Quick Start: Pipeline Architecture Decision Tree¬∑
    ### When to Use Different Pipeline Frameworks¬∑
    **MLflow** (Experiment tracking, model registry):
    - ‚úÖ Experiment tracking and reproducibility
    - ‚úÖ Model versioning and registry
    - ‚úÖ Simple local or cloud deployment
    - ‚úÖ Python-first workflows
    - ‚úÖ Integration with scikit-learn, PyTorch, TensorFlow
    - ‚úÖ Best for: Small to medium teams, research projects¬∑
    **Kubeflow Pipelines** (Kubernetes-native ML workflows):
    - ‚úÖ Complex multi-step workflows
    - ‚úÖ Kubernetes-based infrastructure
    - ‚úÖ Distributed training at scale
    - ‚úÖ Component reusability
    - ‚úÖ Production-grade orchestration
    - ‚úÖ Best for: Large teams, enterprise ML platforms¬∑
    **Ray** (Distributed compute framework):
    - ‚úÖ Distributed training and tuning
    - ‚úÖ Hyperparameter optimization at scale
    - ‚úÖ Python-native API
    - ‚úÖ Flexible compute allocation
    - ‚úÖ Best for: Large-scale training, HPO¬∑
    **Custom (Airflow/Prefect + Python)**:
    - ‚úÖ Full control over workflow
    - ‚úÖ Integration with existing data pipelines
    - ‚úÖ Custom scheduling and monitoring
    - ‚úÖ Best for: Unique requirements, existing infrastructure¬∑
    ---¬∑
    ## MLflow Training Pipeline¬∑
    ### 1. Experiment Setup¬∑
    ```python
    # training/experiment_config.py
    import mlflow
    import os
    from dataclasses import dataclass
    from typing import Dict, Any¬∑
    @dataclass
    class ExperimentConfig:
        \"\"\"MLflow experiment configuration\"\"\"
        experiment_name: str
        tracking_uri: str = \"http://localhost:5000\"
        artifact_location: str = \"./mlruns\"¬∑
        def setup(self) -> str:
            \"\"\"Setup MLflow experiment and return experiment ID\"\"\"
            mlflow.set_tracking_uri(self.tracking_uri)¬∑
            # Create or get existing experiment
            experiment = mlflow.get_experiment_by_name(self.experiment_name)
            if experiment is None:
                experiment_id = mlflow.create_experiment(
                    name=self.experiment_name,
                    artifact_location=self.artifact_location
                )
            else:
                experiment_id = experiment.experiment_id¬∑
            mlflow.set_experiment(self.experiment_name)
            return experiment_id¬∑
    # Usage
    config = ExperimentConfig(
        experiment_name=\"user-churn-prediction\",
        tracking_uri=\"http://mlflow.company.com\",
        artifact_location=\"s3://ml-artifacts/experiments\"
    )
    experiment_id = config.setup()
    ```¬∑
    ### 2. Feature Engineering Pipeline¬∑
    ```python
    # features/preprocessing.py
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from typing import List, Tuple¬∑
    class FeatureEngineer:
        \"\"\"Feature engineering pipeline with versioning\"\"\"¬∑
        def __init__(self, version: str = \"v1\"):
            self.version = version
            self.numeric_features = []
            self.categorical_features = []
            self.pipeline = None¬∑
        def fit_transform(
            self,
            df: pd.DataFrame,
            target_col: str
        ) -> Tuple[np.ndarray, np.ndarray]:
            \"\"\"Fit pipeline and transform data\"\"\"¬∑
            # Separate features and target
            X = df.drop(columns=[target_col])
            y = df[target_col]¬∑
            # Identify feature types
            self.numeric_features = X.select_dtypes(
                include=['int64', 'float64']
            ).columns.tolist()
            self.categorical_features = X.select_dtypes(
                include=['object', 'category']
            ).columns.tolist()¬∑
            # Create preprocessing pipeline
            numeric_transformer = Pipeline([
                ('scaler', StandardScaler())
            ])¬∑
            categorical_transformer = Pipeline([
                ('encoder', LabelEncoder()) # Use OneHotEncoder for multiple categories
            ])¬∑
            self.pipeline = ColumnTransformer(
                transformers=[
                    ('num', numeric_transformer, self.numeric_features),
                    ('cat', categorical_transformer, self.categorical_features)
                ]
            )¬∑
            # Fit and transform
            X_transformed = self.pipeline.fit_transform(X)¬∑
            return X_transformed, y.values¬∑
        def transform(self, df: pd.DataFrame) -> np.ndarray:
            \"\"\"Transform new data using fitted pipeline\"\"\"
            if self.pipeline is None:
                raise ValueError(\"Pipeline not fitted. Call fit_transform first.\")¬∑
            return self.pipeline.transform(df)¬∑
        def get_feature_names(self) -> List[str]:
            \"\"\"Get feature names after transformation\"\"\"
            return self.numeric_features + self.categorical_features¬∑
    # Custom feature engineering
    class ChurnFeatureEngineer(FeatureEngineer):
        \"\"\"Domain-specific features for churn prediction\"\"\"¬∑
        def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
            \"\"\"Create domain-specific features\"\"\"
            df = df.copy()¬∑
            # Tenure buckets
            df['tenure_bucket'] = pd.cut(
                df['tenure'],
                bins=[0, 12, 24, 48, np.inf],
                labels=['0-1y', '1-2y', '2-4y', '4y+']
            )¬∑
            # Usage intensity
            df['usage_intensity'] = (
                df['monthly_minutes'] / df['tenure']
            ).fillna(0)¬∑
            # Revenue per month
            df['revenue_per_month'] = (
                df['total_revenue'] / df['tenure']
            ).fillna(0)¬∑
            # Recent activity drop
            df['activity_drop'] = (
                df['prev_month_minutes'] - df['current_month_minutes']
            ) / df['prev_month_minutes'].replace(0, 1)¬∑
            return df¬∑
    # Usage
    engineer = ChurnFeatureEngineer(version=\"v1\")
    df_engineered = engineer.engineer_features(df)
    X, y = engineer.fit_transform(df_engineered, target_col='churned')
    ```¬∑
    ### 3. Training Pipeline with MLflow¬∑
    ```python
    # training/train.py
    import mlflow
    import mlflow.sklearn
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score,
        f1_score, roc_auc_score, confusion_matrix
    )
    import numpy as np
    from typing import Dict, Any
    import joblib¬∑
    class MLflowTrainer:
        \"\"\"Model training with MLflow tracking\"\"\"¬∑
        def __init__(self, config: ExperimentConfig):
            self.config = config
            self.config.setup()¬∑
        def train_model(
            self,
            X: np.ndarray,
            y: np.ndarray,
            model_params: Dict[str, Any],
            tags: Dict[str, str] = None
        ) -> str:
            \"\"\"Train model and log to MLflow\"\"\"¬∑
            # Start MLflow run
            with mlflow.start_run(tags=tags) as run:
                # Split data
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )¬∑
                # Log parameters
                mlflow.log_params(model_params)
                mlflow.log_param(\"train_size\", len(X_train))
                mlflow.log_param(\"test_size\", len(X_test))¬∑
                # Train model
                model = RandomForestClassifier(**model_params, random_state=42)
                model.fit(X_train, y_train)¬∑
                # Cross-validation
                cv_scores = cross_val_score(
                    model, X_train, y_train, cv=5, scoring='roc_auc'
                )
                mlflow.log_metric(\"cv_roc_auc_mean\", cv_scores.mean())
                mlflow.log_metric(\"cv_roc_auc_std\", cv_scores.std())¬∑
                # Predictions
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]¬∑
                # Log metrics
                metrics = {
                    'accuracy': accuracy_score(y_test, y_pred),
                    'precision': precision_score(y_test, y_pred),
                    'recall': recall_score(y_test, y_pred),
                    'f1': f1_score(y_test, y_pred),
                    'roc_auc': roc_auc_score(y_test, y_pred_proba)
                }
                mlflow.log_metrics(metrics)¬∑
                # Log confusion matrix as artifact
                cm = confusion_matrix(y_test, y_pred)
                np.savetxt(\"confusion_matrix.txt\", cm, fmt='%d')
                mlflow.log_artifact(\"confusion_matrix.txt\")¬∑
                # Log feature importances
                feature_importance = pd.DataFrame({
                    'feature': range(X.shape[1]),
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=False)
                feature_importance.to_csv(\"feature_importance.csv\", index=False)
                mlflow.log_artifact(\"feature_importance.csv\")¬∑
                # Log model
                mlflow.sklearn.log_model(
                    model,
                    \"model\",
                    registered_model_name=f\"{self.config.experiment_name}-model\"
                )¬∑
                print(f\"‚úÖ Model trained successfully\")
                print(f\"Run ID: {run.info.run_id}\")
                print(f\"Metrics: {metrics}\")¬∑
                return run.info.run_id¬∑
    # Usage
    trainer = MLflowTrainer(config)
    run_id = trainer.train_model(
        X, y,
        model_params={
            'n_estimators': 100,
            'max_depth': 10,
            'min_samples_split': 5,
            'min_samples_leaf': 2
        },
        tags={
            'version': 'v1',
            'model_type': 'random_forest',
            'engineer': 'Dr.AI-ML'
        }
    )
    ```¬∑
    ### 4. Hyperparameter Tuning with Optuna + MLflow¬∑
    ```python
    # training/hyperparameter_tuning.py
    import optuna
    from optuna.integration.mlflow import MLflowCallback
    import mlflow
    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestClassifier
    import numpy as np¬∑
    class OptunaMLflowTuner:
        \"\"\"Hyperparameter tuning with Optuna + MLflow integration\"\"\"¬∑
        def __init__(self, config: ExperimentConfig):
            self.config = config
            self.config.setup()¬∑
        def objective(self, trial: optuna.Trial, X: np.ndarray, y: np.ndarray) -> float:
            \"\"\"Optuna objective function\"\"\"¬∑
            # Suggest hyperparameters
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 5, 30),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                'max_features': trial.suggest_categorical(
                    'max_features', ['sqrt', 'log2', None]
                ),
                'random_state': 42
            }¬∑
            # Train model with cross-validation
            model = RandomForestClassifier(**params)
            scores = cross_val_score(
                model, X, y, cv=5, scoring='roc_auc', n_jobs=-1
            )¬∑
            return scores.mean()¬∑
        def tune(
            self,
            X: np.ndarray,
            y: np.ndarray,
            n_trials: int = 100
        ) -> Dict[str, Any]:
            \"\"\"Run hyperparameter tuning\"\"\"¬∑
            # Create MLflow callback
            mlflow_callback = MLflowCallback(
                tracking_uri=self.config.tracking_uri,
                metric_name=\"roc_auc_cv\"
            )¬∑
            # Create study
            study = optuna.create_study(
                study_name=f\"{self.config.experiment_name}-tuning\",
                direction='maximize',
                sampler=optuna.samplers.TPESampler(seed=42)
            )¬∑
            # Optimize
            study.optimize(
                lambda trial: self.objective(trial, X, y),
                n_trials=n_trials,
                callbacks=[mlflow_callback],
                n_jobs=-1
            )¬∑
            print(f\"‚úÖ Tuning complete\")
            print(f\"Best ROC-AUC: {study.best_value:.4f}\")
            print(f\"Best params: {study.best_params}\")¬∑
            return {
                'best_params': study.best_params,
                'best_value': study.best_value,
                'study': study
            }¬∑
    # Usage
    tuner = OptunaMLflowTuner(config)
    results = tuner.tune(X, y, n_trials=100)¬∑
    # Train final model with best params
    trainer = MLflowTrainer(config)
    run_id = trainer.train_model(X, y, results['best_params'])
    ```¬∑
    ---¬∑
    ## Kubeflow Pipelines¬∑
    ### 1. Pipeline Component¬∑
    ```python
    # kubeflow/components/preprocess.py
    from kfp import dsl
    from kfp.dsl import Dataset, Input, Output, Model¬∑
    @dsl.component(
        base_image='python:3.10',
        packages_to_install=['pandas==2.0.0', 'scikit-learn==1.3.0']
    )
    def preprocess_data(
        input_data: Input[Dataset],
        output_features: Output[Dataset],
        test_size: float = 0.2
    ):
        \"\"\"Preprocess data for training\"\"\"
        import pandas as pd
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler
        import pickle¬∑
        # Load data
        df = pd.read_csv(input_data.path)¬∑
        # Feature engineering
        X = df.drop(columns=['target'])
        y = df['target']¬∑
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )¬∑
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)¬∑
        # Save processed data
        processed_data = {
            'X_train': X_train_scaled,
            'X_test': X_test_scaled,
            'y_train': y_train.values,
            'y_test': y_test.values,
            'scaler': scaler
        }¬∑
        with open(output_features.path, 'wb') as f:
            pickle.dump(processed_data, f)¬∑
    @dsl.component(
        base_image='python:3.10',
        packages_to_install=['scikit-learn==1.3.0', 'mlflow==2.8.0']
    )
    def train_model(
        input_features: Input[Dataset],
        output_model: Output[Model],
        n_estimators: int = 100,
        max_depth: int = 10
    ):
        \"\"\"Train ML model\"\"\"
        import pickle
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score, roc_auc_score
        import mlflow¬∑
        # Load processed data
        with open(input_features.path, 'rb') as f:
            data = pickle.load(f)¬∑
        X_train = data['X_train']
        y_train = data['y_train']
        X_test = data['X_test']
        y_test = data['y_test']¬∑
        # Train model
        with mlflow.start_run():
            model = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42
            )
            model.fit(X_train, y_train)¬∑
            # Evaluate
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]¬∑
            accuracy = accuracy_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_pred_proba)¬∑
            # Log metrics
            mlflow.log_metric(\"accuracy\", accuracy)
            mlflow.log_metric(\"roc_auc\", roc_auc)¬∑
            # Save model
            with open(output_model.path, 'wb') as f:
                pickle.dump({'model': model, 'scaler': data['scaler']}, f)¬∑
            print(f\"Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\")
    ```¬∑
    ### 2. Pipeline Definition¬∑
    ```python
    # kubeflow/pipelines/training_pipeline.py
    from kfp import dsl
    from kfp.dsl import Dataset, Model¬∑
    @dsl.pipeline(
        name='ML Training Pipeline',
        description='End-to-end ML training pipeline with Kubeflow'
    )
    def training_pipeline(
        data_path: str,
        n_estimators: int = 100,
        max_depth: int = 10,
        test_size: float = 0.2
    ):
        \"\"\"Complete ML training pipeline\"\"\"¬∑
        # Step 1: Load data
        load_data_task = load_data(data_path=data_path)¬∑
        # Step 2: Preprocess
        preprocess_task = preprocess_data(
            input_data=load_data_task.outputs['output_data'],
            test_size=test_size
        )¬∑
        # Step 3: Train model
        train_task = train_model(
            input_features=preprocess_task.outputs['output_features'],
            n_estimators=n_estimators,
            max_depth=max_depth
        )¬∑
        # Step 4: Evaluate model
        evaluate_task = evaluate_model(
            input_model=train_task.outputs['output_model'],
            input_features=preprocess_task.outputs['output_features']
        )¬∑
        # Step 5: Deploy if metrics pass threshold
        with dsl.Condition(evaluate_task.outputs['roc_auc'] >= 0.85):
            deploy_model(
                input_model=train_task.outputs['output_model'],
                model_name='churn-predictor'
            )¬∑
    # Compile pipeline
    from kfp import compiler¬∑
    compiler.Compiler().compile(
        pipeline_func=training_pipeline,
        package_path='training_pipeline.yaml'
    )¬∑
    # Submit pipeline
    from kfp.client import Client¬∑
    client = Client(host='http://kubeflow.company.com')
    run = client.create_run_from_pipeline_func(
        training_pipeline,
        arguments={
            'data_path': 's3://ml-data/churn-data.csv',
            'n_estimators': 200,
            'max_depth': 15,
            'test_size': 0.2
        }
    )
    ```¬∑
    ---¬∑
    ## Distributed Training with Ray¬∑
    ### Ray Train Example¬∑
    ```python
    # training/ray_distributed.py
    import ray
    from ray import train
    from ray.train import ScalingConfig
    from ray.train.torch import TorchTrainer
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset¬∑
    def train_func(config: dict):
        \"\"\"Training function for Ray\"\"\"¬∑
        # Get data from Ray
        train_dataset = train.get_dataset_shard(\"train\")¬∑
        # Create model
        model = nn.Sequential(
            nn.Linear(config['input_dim'], 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )¬∑
        # Wrap model with Ray
        model = train.torch.prepare_model(model)¬∑
        # Optimizer
        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])
        criterion = nn.BCELoss()¬∑
        # Training loop
        for epoch in range(config['epochs']):
            model.train()
            total_loss = 0¬∑
            for batch in train_dataset.iter_torch_batches(batch_size=config['batch_size']):
                X = batch['features']
                y = batch['labels']¬∑
                optimizer.zero_grad()
                outputs = model(X)
                loss = criterion(outputs, y)
                loss.backward()
                optimizer.step()¬∑
                total_loss += loss.item()¬∑
            # Report metrics to Ray
            train.report({
                'epoch': epoch,
                'loss': total_loss / len(train_dataset)
            })¬∑
    # Initialize Ray
    ray.init(address='auto')  # Connect to Ray cluster¬∑
    # Create trainer
    trainer = TorchTrainer(
        train_func,
        train_loop_config={
            'input_dim': 100,
            'lr': 0.001,
            'epochs': 10,
            'batch_size': 128
        },
        scaling_config=ScalingConfig(
            num_workers=4,  # 4 distributed workers
            use_gpu=True
        ),
        datasets={'train': ray_dataset}
    )¬∑
    # Train
    result = trainer.fit()
    print(f\"Final metrics: {result.metrics}\")
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `execute-mlflow-training.py` - Run MLflow training pipeline
    - `execute-kubeflow-pipeline.py` - Submit Kubeflow pipeline
    - `execute-hyperparameter-tuning.py` - Run Optuna tuning¬∑
    ### references/
    - `references/mlflow-setup.md` - MLflow server setup and configuration
    - `references/kubeflow-components.md` - Kubeflow component library
    - `references/feature-engineering-patterns.md` - Common feature engineering techniques
    - `references/distributed-training.md` - Ray/Horovod distributed training¬∑
    ### assets/
    - `assets/pipeline-templates/` - Kubeflow YAML templates
    - `assets/mlflow-configs/` - MLflow tracking server configs¬∑
    ## Related Skills¬∑
    - `rag-optimization` - RAG system training and fine-tuning
    - `model-deployment` - Deploy trained models to production
    - `vector-databases` - Feature store and embedding storage
    - `testing-strategies` - ML model testing and validation
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ rag-optimization ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: rag-optimization
    description: RAG system optimization, embedding strategies, retrieval methods, reranking. Use when optimizing RAG performance, implementing hybrid search, fine-tuning embeddings, or improving retrieval accuracy. Covers embedding models, chunking strategies, reranking algorithms, and evaluation metrics. Improves RAG accuracy by 40%.
    ---¬∑
    # RAG Optimization¬∑
    ## Overview¬∑
    Advanced RAG (Retrieval-Augmented Generation) system optimization covering embedding strategies, retrieval methods, reranking algorithms, and hybrid search. Focus on improving retrieval accuracy, latency, and relevance.¬∑
    **Goal**: Build high-performance RAG systems with 90%+ retrieval accuracy and sub-200ms latency¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Optimizing existing RAG systems for accuracy/speed
    - Implementing hybrid search (dense + sparse retrieval)
    - Fine-tuning embedding models for domain-specific data
    - Adding reranking layers (cross-encoders, LLM reranking)
    - Evaluating RAG performance (MRR, NDCG, recall@k)
    - Optimizing chunking strategies for different content types
    - Implementing GraphRAG or advanced retrieval patterns¬∑
    **Triggers**: \"RAG optimization\", \"embedding strategy\", \"hybrid search\", \"reranking\", \"retrieval accuracy\", \"chunking\", \"GraphRAG\"¬∑
    ---¬∑
    ## Quick Start: RAG Architecture Decision Tree¬∑
    ### Choosing the Right RAG Strategy¬∑
    **Basic RAG** (Single vector search):
    - ‚úÖ Simple use case with clean documents
    - ‚úÖ Domain-general content (no specialized vocabulary)
    - ‚úÖ Small corpus (<10K documents)
    - ‚úÖ Latency not critical (>500ms acceptable)
    - ‚úÖ Best for: FAQs, documentation, simple Q&A¬∑
    **Hybrid Search** (Dense + Sparse):
    - ‚úÖ Mix of semantic and keyword matching needed
    - ‚úÖ Technical content with specific terminology
    - ‚úÖ Medium corpus (10K-1M documents)
    - ‚úÖ Better recall than pure vector search
    - ‚úÖ Best for: Code search, technical docs, legal documents¬∑
    **Reranked RAG** (Retrieve more, rerank top):
    - ‚úÖ High accuracy required (90%+ precision)
    - ‚úÖ Willing to trade latency for quality
    - ‚úÖ Complex queries with nuanced context
    - ‚úÖ Best for: Customer support, research, compliance¬∑
    **GraphRAG** (Knowledge graph + vectors):
    - ‚úÖ Highly interconnected data
    - ‚úÖ Multi-hop reasoning required
    - ‚úÖ Entity relationships matter
    - ‚úÖ Best for: Knowledge bases, enterprise search¬∑
    **Fine-tuned Embeddings** (Custom model):
    - ‚úÖ Domain-specific vocabulary (medical, legal, finance)
    - ‚úÖ Proprietary terminology
    - ‚úÖ Have labeled data for fine-tuning
    - ‚úÖ Best for: Specialized domains, enterprise search¬∑
    ---¬∑
    ## Embedding Optimization¬∑
    ### 1. Choosing Embedding Models¬∑
    ```python
    # rag/embeddings/model_selection.py
    from sentence_transformers import SentenceTransformer
    from typing import List, Dict
    import numpy as np¬∑
    class EmbeddingModelSelector:
        \"\"\"Select optimal embedding model for your use case\"\"\"¬∑
        # Model comparison (as of 2024)
        MODELS = {
            'openai-ada-002': {
                'dimensions': 1536,
                'max_tokens': 8191,
                'cost_per_1k': 0.0001,
                'latency_ms': 50,
                'use_case': 'General purpose, high quality'
            },
            'text-embedding-3-small': {
                'dimensions': 1536,
                'max_tokens': 8191,
                'cost_per_1k': 0.00002,
                'latency_ms': 30,
                'use_case': 'Cost-optimized, good quality'
            },
            'all-MiniLM-L6-v2': {
                'dimensions': 384,
                'max_tokens': 256,
                'cost_per_1k': 0,  # Self-hosted
                'latency_ms': 10,
                'use_case': 'Fast, self-hosted, decent quality'
            },
            'all-mpnet-base-v2': {
                'dimensions': 768,
                'max_tokens': 514,
                'cost_per_1k': 0,
                'latency_ms': 20,
                'use_case': 'Best self-hosted quality'
            },
            'bge-large-en-v1.5': {
                'dimensions': 1024,
                'max_tokens': 512,
                'cost_per_1k': 0,
                'latency_ms': 30,
                'use_case': 'SOTA open-source'
            }
        }¬∑
        @staticmethod
        def recommend(
            corpus_size: int,
            budget: str,  # 'low', 'medium', 'high'
            latency_requirement: int,  # milliseconds
            domain: str = 'general'
        ) -> str:
            \"\"\"Recommend embedding model based on requirements\"\"\"¬∑
            if budget == 'low' or corpus_size > 1_000_000:
                # Self-hosted models
                if latency_requirement < 15:
                    return 'all-MiniLM-L6-v2'
                else:
                    return 'bge-large-en-v1.5'¬∑
            if budget == 'medium':
                return 'text-embedding-3-small'¬∑
            # High budget or high quality requirement
            return 'openai-ada-002'¬∑
    # Usage
    model_name = EmbeddingModelSelector.recommend(
        corpus_size=100_000,
        budget='medium',
        latency_requirement=50,
        domain='technical-docs'
    )
    print(f\"Recommended model: {model_name}\")
    ```¬∑
    ### 2. Advanced Chunking Strategies¬∑
    ```python
    # rag/chunking/strategies.py
    from typing import List, Dict
    import re¬∑
    class ChunkingStrategy:
        \"\"\"Advanced document chunking strategies\"\"\"¬∑
        @staticmethod
        def semantic_chunking(
            text: str,
            model: SentenceTransformer,
            similarity_threshold: float = 0.5
        ) -> List[str]:
            \"\"\"Chunk based on semantic similarity (not fixed size)\"\"\"
            sentences = re.split(r'(?<=[.!?])\\s+', text)¬∑
            if not sentences:
                return []¬∑
            # Get embeddings for all sentences
            embeddings = model.encode(sentences)¬∑
            chunks = []
            current_chunk = [sentences[0]]
            current_embedding = embeddings[0]¬∑
            for i in range(1, len(sentences)):
                # Calculate similarity with current chunk
                similarity = np.dot(current_embedding, embeddings[i]) / (
                    np.linalg.norm(current_embedding) * np.linalg.norm(embeddings[i])
                )¬∑
                if similarity >= similarity_threshold:
                    # Add to current chunk
                    current_chunk.append(sentences[i])
                    # Update chunk embedding (average)
                    current_embedding = (current_embedding + embeddings[i]) / 2
                else:
                    # Start new chunk
                    chunks.append(' '.join(current_chunk))
                    current_chunk = [sentences[i]]
                    current_embedding = embeddings[i]¬∑
            # Add last chunk
            if current_chunk:
                chunks.append(' '.join(current_chunk))¬∑
            return chunks¬∑
        @staticmethod
        def hierarchical_chunking(
            text: str,
            chunk_sizes: List[int] = [512, 1024, 2048]
        ) -> Dict[str, List[str]]:
            \"\"\"Create multiple granularity chunks\"\"\"
            chunks = {}¬∑
            for size in chunk_sizes:
                # Simple character-based chunking (can be enhanced with tokens)
                chunks[f'size_{size}'] = [
                    text[i:i+size]
                    for i in range(0, len(text), size)
                ]¬∑
            return chunks¬∑
        @staticmethod
        def overlap_chunking(
            text: str,
            chunk_size: int = 512,
            overlap: int = 128
        ) -> List[str]:
            \"\"\"Chunking with overlap for context preservation\"\"\"
            chunks = []
            start = 0¬∑
            while start < len(text):
                end = start + chunk_size
                chunk = text[start:end]
                chunks.append(chunk)
                start += (chunk_size - overlap)¬∑
            return chunks¬∑
        @staticmethod
        def markdown_aware_chunking(
            markdown_text: str,
            max_tokens: int = 512
        ) -> List[Dict[str, str]]:
            \"\"\"Chunk markdown preserving structure\"\"\"
            chunks = []¬∑
            # Split by headers
            sections = re.split(r'(^#{1,6}\\s+.+$)', markdown_text, flags=re.MULTILINE)¬∑
            current_header = \"\"
            current_content = \"\"¬∑
            for section in sections:
                if re.match(r'^#{1,6}\\s+', section):
                    # Save previous section
                    if current_content:
                        chunks.append({
                            'header': current_header,
                            'content': current_content.strip(),
                            'hierarchy': current_header.count('#')
                        })¬∑
                    current_header = section
                    current_content = \"\"
                else:
                    current_content += section¬∑
            # Add last section
            if current_content:
                chunks.append({
                    'header': current_header,
                    'content': current_content.strip(),
                    'hierarchy': current_header.count('#') if current_header else 0
                })¬∑
            return chunks¬∑
    # Usage
    chunker = ChunkingStrategy()¬∑
    # Semantic chunking (best quality, slower)
    semantic_chunks = chunker.semantic_chunking(text, model)¬∑
    # Overlap chunking (good balance)
    overlap_chunks = chunker.overlap_chunking(text, chunk_size=512, overlap=128)¬∑
    # Markdown-aware (for docs)
    md_chunks = chunker.markdown_aware_chunking(markdown_text)
    ```¬∑
    ### 3. Fine-tuning Embeddings¬∑
    ```python
    # rag/embeddings/fine_tune.py
    from sentence_transformers import SentenceTransformer, InputExample, losses
    from torch.utils.data import DataLoader
    from typing import List, Tuple¬∑
    class EmbeddingFineTuner:
        \"\"\"Fine-tune embedding models for domain-specific data\"\"\"¬∑
        def __init__(self, base_model: str = 'all-MiniLM-L6-v2'):
            self.model = SentenceTransformer(base_model)¬∑
        def prepare_training_data(
            self,
            positive_pairs: List[Tuple[str, str]],
            negative_pairs: List[Tuple[str, str]]
        ) -> List[InputExample]:
            \"\"\"Prepare training examples\"\"\"
            examples = []¬∑
            # Positive pairs (query, relevant doc) -> label 1
            for query, doc in positive_pairs:
                examples.append(InputExample(texts=[query, doc], label=1.0))¬∑
            # Negative pairs (query, irrelevant doc) -> label 0
            for query, doc in negative_pairs:
                examples.append(InputExample(texts=[query, doc], label=0.0))¬∑
            return examples¬∑
        def fine_tune(
            self,
            training_examples: List[InputExample],
            epochs: int = 4,
            batch_size: int = 16,
            output_path: str = './fine-tuned-model'
        ):
            \"\"\"Fine-tune the model\"\"\"¬∑
            # Create DataLoader
            train_dataloader = DataLoader(
                training_examples,
                shuffle=True,
                batch_size=batch_size
            )¬∑
            # Define loss function (Contrastive Loss)
            train_loss = losses.CosineSimilarityLoss(self.model)¬∑
            # Train
            self.model.fit(
                train_objectives=[(train_dataloader, train_loss)],
                epochs=epochs,
                warmup_steps=100,
                output_path=output_path
            )¬∑
            print(f\"‚úÖ Model fine-tuned and saved to {output_path}\")¬∑
    # Usage
    tuner = EmbeddingFineTuner(base_model='all-MiniLM-L6-v2')¬∑
    # Prepare training data from your domain
    positive_pairs = [
        (\"What is kubernetes?\", \"Kubernetes is a container orchestration platform...\"),
        (\"How to scale pods?\", \"Use kubectl scale deployment to scale pods...\")
    ]¬∑
    negative_pairs = [
        (\"What is kubernetes?\", \"Python is a programming language...\"),
        (\"How to scale pods?\", \"JavaScript is used for web development...\")
    ]¬∑
    examples = tuner.prepare_training_data(positive_pairs, negative_pairs)
    tuner.fine_tune(examples, epochs=4, output_path='./k8s-embeddings')
    ```¬∑
    ---¬∑
    ## Hybrid Search¬∑
    ### Combining Dense and Sparse Retrieval¬∑
    ```python
    # rag/retrieval/hybrid_search.py
    from typing import List, Dict, Tuple
    from sentence_transformers import SentenceTransformer
    from rank_bm25 import BM25Okapi
    import numpy as np¬∑
    class HybridSearchEngine:
        \"\"\"Hybrid search combining dense (vector) and sparse (BM25) retrieval\"\"\"¬∑
        def __init__(
            self,
            embedding_model: str = 'all-MiniLM-L6-v2',
            alpha: float = 0.5  # Weight: 0=sparse only, 1=dense only
        ):
            self.embedding_model = SentenceTransformer(embedding_model)
            self.alpha = alpha
            self.bm25 = None
            self.documents = []
            self.embeddings = None¬∑
        def index_documents(self, documents: List[str]):
            \"\"\"Index documents for both dense and sparse retrieval\"\"\"
            self.documents = documents¬∑
            # Dense indexing (vector embeddings)
            print(\"Creating dense embeddings...\")
            self.embeddings = self.embedding_model.encode(
                documents,
                show_progress_bar=True
            )¬∑
            # Sparse indexing (BM25)
            print(\"Creating BM25 index...\")
            tokenized_docs = [doc.lower().split() for doc in documents]
            self.bm25 = BM25Okapi(tokenized_docs)¬∑
            print(f\"‚úÖ Indexed {len(documents)} documents\")¬∑
        def search(
            self,
            query: str,
            top_k: int = 10
        ) -> List[Tuple[int, float, str]]:
            \"\"\"Hybrid search combining dense and sparse scores\"\"\"¬∑
            # Dense retrieval (vector similarity)
            query_embedding = self.embedding_model.encode([query])[0]
            dense_scores = np.dot(self.embeddings, query_embedding)
            dense_scores = (dense_scores - dense_scores.min()) / (
                dense_scores.max() - dense_scores.min() + 1e-10
            )  # Normalize to [0, 1]¬∑
            # Sparse retrieval (BM25)
            tokenized_query = query.lower().split()
            sparse_scores = self.bm25.get_scores(tokenized_query)
            sparse_scores = (sparse_scores - sparse_scores.min()) / (
                sparse_scores.max() - sparse_scores.min() + 1e-10
            )  # Normalize to [0, 1]¬∑
            # Combine scores
            hybrid_scores = (
                self.alpha * dense_scores +
                (1 - self.alpha) * sparse_scores
            )¬∑
            # Get top-k results
            top_indices = np.argsort(hybrid_scores)[::-1][:top_k]¬∑
            results = [
                (idx, hybrid_scores[idx], self.documents[idx])
                for idx in top_indices
            ]¬∑
            return results¬∑
    # Usage
    search_engine = HybridSearchEngine(alpha=0.7)  # 70% dense, 30% sparse¬∑
    documents = [
        \"Kubernetes is a container orchestration platform\",
        \"Docker containers package applications\",
        \"Microservices architecture splits applications\",
        # ... more documents
    ]¬∑
    search_engine.index_documents(documents)¬∑
    results = search_engine.search(\"container management\", top_k=5)
    for idx, score, doc in results:
        print(f\"Score: {score:.4f} | {doc[:100]}\")
    ```¬∑
    ---¬∑
    ## Reranking¬∑
    ### Cross-Encoder Reranking¬∑
    ```python
    # rag/reranking/cross_encoder.py
    from sentence_transformers import CrossEncoder
    from typing import List, Tuple¬∑
    class RerankerPipeline:
        \"\"\"Two-stage retrieval: fast retrieval + slow reranking\"\"\"¬∑
        def __init__(
            self,
            retrieval_model: str = 'all-MiniLM-L6-v2',
            reranker_model: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'
        ):
            # Stage 1: Fast bi-encoder for initial retrieval
            self.retriever = SentenceTransformer(retrieval_model)¬∑
            # Stage 2: Slow cross-encoder for reranking
            self.reranker = CrossEncoder(reranker_model)¬∑
        def retrieve_and_rerank(
            self,
            query: str,
            documents: List[str],
            top_k_retrieve: int = 100,
            top_k_rerank: int = 10
        ) -> List[Tuple[float, str]]:
            \"\"\"Two-stage retrieval with reranking\"\"\"¬∑
            # Stage 1: Fast retrieval (get top 100)
            query_embedding = self.retriever.encode([query])[0]
            doc_embeddings = self.retriever.encode(documents)¬∑
            # Calculate similarities
            similarities = np.dot(doc_embeddings, query_embedding)
            top_indices = np.argsort(similarities)[::-1][:top_k_retrieve]¬∑
            # Get candidate documents
            candidates = [(documents[idx], similarities[idx]) for idx in top_indices]¬∑
            # Stage 2: Reranking (top 100 -> top 10)
            query_doc_pairs = [[query, doc] for doc, _ in candidates]
            rerank_scores = self.reranker.predict(query_doc_pairs)¬∑
            # Sort by rerank scores
            reranked = sorted(
                zip(rerank_scores, [doc for doc, _ in candidates]),
                key=lambda x: x[0],
                reverse=True
            )[:top_k_rerank]¬∑
            return reranked¬∑
    # Usage
    reranker = RerankerPipeline()¬∑
    results = reranker.retrieve_and_rerank(
        query=\"How to deploy kubernetes cluster?\",
        documents=all_documents,
        top_k_retrieve=100,  # Fast retrieval
        top_k_rerank=10      # Slow but accurate reranking
    )¬∑
    for score, doc in results:
        print(f\"Score: {score:.4f} | {doc[:100]}\")
    ```¬∑
    ### LLM-based Reranking¬∑
    ```python
    # rag/reranking/llm_reranker.py
    import anthropic
    from typing import List, Tuple¬∑
    class LLMReranker:
        \"\"\"Use LLM to rerank retrieved documents\"\"\"¬∑
        def __init__(self, api_key: str):
            self.client = anthropic.Anthropic(api_key=api_key)¬∑
        def rerank(
            self,
            query: str,
            documents: List[str],
            top_k: int = 5
        ) -> List[Tuple[int, str]]:
            \"\"\"LLM-based reranking for highest quality\"\"\"¬∑
            # Create prompt for LLM
            docs_text = \"\\n\\n\".join([
                f\"Document {i+1}:\\n{doc}\"
                for i, doc in enumerate(documents)
            ])¬∑
            prompt = f\"\"\"Given the query and documents below, rank the documents by relevance to the query.
    Return ONLY a comma-separated list of document numbers in order of relevance (most relevant first).¬∑
    Query: {query}¬∑
    {docs_text}¬∑
    Ranking (comma-separated numbers):\"\"\"¬∑
            # Call LLM
            message = self.client.messages.create(
                model=\"claude-3-5-sonnet-20241022\",
                max_tokens=100,
                messages=[{\"role\": \"user\", \"content\": prompt}]
            )¬∑
            # Parse response
            ranking_text = message.content[0].text.strip()
            rankings = [int(x.strip()) - 1 for x in ranking_text.split(',')]¬∑
            # Return reranked documents
            reranked = [
                (rank, documents[rank])
                for rank in rankings[:top_k]
                if rank < len(documents)
            ]¬∑
            return reranked¬∑
    # Usage (expensive, use only when quality is critical)
    llm_reranker = LLMReranker(api_key=\"your-api-key\")¬∑
    top_docs = llm_reranker.rerank(
        query=\"What are best practices for kubernetes security?\",
        documents=candidate_documents,
        top_k=5
    )
    ```¬∑
    ---¬∑
    ## RAG Evaluation¬∑
    ### Comprehensive Metrics¬∑
    ```python
    # rag/evaluation/metrics.py
    from typing import List, Set
    import numpy as np¬∑
    class RAGEvaluator:
        \"\"\"Evaluate RAG system performance\"\"\"¬∑
        @staticmethod
        def recall_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Recall@K: What % of relevant docs were retrieved in top-k?\"\"\"
            retrieved_k = set(retrieved[:k])
            return len(retrieved_k & relevant) / len(relevant) if relevant else 0¬∑
        @staticmethod
        def precision_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Precision@K: What % of top-k retrieved docs are relevant?\"\"\"
            retrieved_k = set(retrieved[:k])
            return len(retrieved_k & relevant) / k if k > 0 else 0¬∑
        @staticmethod
        def mrr(retrieved_list: List[List[str]], relevant_list: List[Set[str]]) -> float:
            \"\"\"Mean Reciprocal Rank: Average of 1/rank of first relevant doc\"\"\"
            reciprocal_ranks = []¬∑
            for retrieved, relevant in zip(retrieved_list, relevant_list):
                for i, doc_id in enumerate(retrieved):
                    if doc_id in relevant:
                        reciprocal_ranks.append(1 / (i + 1))
                        break
                else:
                    reciprocal_ranks.append(0)¬∑
            return np.mean(reciprocal_ranks)¬∑
        @staticmethod
        def ndcg_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Normalized Discounted Cumulative Gain@K\"\"\"
            dcg = 0
            for i, doc_id in enumerate(retrieved[:k]):
                if doc_id in relevant:
                    dcg += 1 / np.log2(i + 2)  # +2 because log2(1) = 0¬∑
            # Ideal DCG (all relevant docs at top)
            idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(relevant))))¬∑
            return dcg / idcg if idcg > 0 else 0¬∑
    # Usage
    evaluator = RAGEvaluator()¬∑
    retrieved_docs = ['doc1', 'doc3', 'doc5', 'doc2', 'doc8']
    relevant_docs = {'doc1', 'doc2', 'doc4'}¬∑
    recall_5 = evaluator.recall_at_k(retrieved_docs, relevant_docs, k=5)
    precision_5 = evaluator.precision_at_k(retrieved_docs, relevant_docs, k=5)
    ndcg_5 = evaluator.ndcg_at_k(retrieved_docs, relevant_docs, k=5)¬∑
    print(f\"Recall@5: {recall_5:.2%}\")       # 66% (2 out of 3 relevant docs)
    print(f\"Precision@5: {precision_5:.2%}\") # 40% (2 relevant out of 5 retrieved)
    print(f\"NDCG@5: {ndcg_5:.3f}\")
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `benchmark-embeddings.py` - Compare embedding model performance
    - `evaluate-rag-system.py` - Run full RAG evaluation suite
    - `tune-hybrid-search.py` - Optimize alpha parameter for hybrid search¬∑
    ### references/
    - `references/embedding-models.md` - Comparison of popular embedding models
    - `references/chunking-strategies.md` - Chunking best practices by content type
    - `references/reranking-methods.md` - Cross-encoder vs LLM reranking tradeoffs¬∑
    ### assets/
    - `assets/evaluation-datasets/` - Standard RAG evaluation datasets
    - `assets/fine-tuning-data/` - Example training data for embeddings¬∑
    ## Related Skills¬∑
    - `ml-pipelines` - Fine-tuning embedding models
    - `vector-databases` - Efficient vector storage and retrieval
    - `model-deployment` - Deploying RAG systems to production
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ rag-optimization ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: rag-optimization
    description: RAG system optimization, embedding strategies, retrieval methods, reranking. Use when optimizing RAG performance, implementing hybrid search, fine-tuning embeddings, or improving retrieval accuracy. Covers embedding models, chunking strategies, reranking algorithms, and evaluation metrics. Improves RAG accuracy by 40%.
    ---¬∑
    # RAG Optimization¬∑
    ## Overview¬∑
    Advanced RAG (Retrieval-Augmented Generation) system optimization covering embedding strategies, retrieval methods, reranking algorithms, and hybrid search. Focus on improving retrieval accuracy, latency, and relevance.¬∑
    **Goal**: Build high-performance RAG systems with 90%+ retrieval accuracy and sub-200ms latency¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Optimizing existing RAG systems for accuracy/speed
    - Implementing hybrid search (dense + sparse retrieval)
    - Fine-tuning embedding models for domain-specific data
    - Adding reranking layers (cross-encoders, LLM reranking)
    - Evaluating RAG performance (MRR, NDCG, recall@k)
    - Optimizing chunking strategies for different content types
    - Implementing GraphRAG or advanced retrieval patterns¬∑
    **Triggers**: \"RAG optimization\", \"embedding strategy\", \"hybrid search\", \"reranking\", \"retrieval accuracy\", \"chunking\", \"GraphRAG\"¬∑
    ---¬∑
    ## Quick Start: RAG Architecture Decision Tree¬∑
    ### Choosing the Right RAG Strategy¬∑
    **Basic RAG** (Single vector search):
    - ‚úÖ Simple use case with clean documents
    - ‚úÖ Domain-general content (no specialized vocabulary)
    - ‚úÖ Small corpus (<10K documents)
    - ‚úÖ Latency not critical (>500ms acceptable)
    - ‚úÖ Best for: FAQs, documentation, simple Q&A¬∑
    **Hybrid Search** (Dense + Sparse):
    - ‚úÖ Mix of semantic and keyword matching needed
    - ‚úÖ Technical content with specific terminology
    - ‚úÖ Medium corpus (10K-1M documents)
    - ‚úÖ Better recall than pure vector search
    - ‚úÖ Best for: Code search, technical docs, legal documents¬∑
    **Reranked RAG** (Retrieve more, rerank top):
    - ‚úÖ High accuracy required (90%+ precision)
    - ‚úÖ Willing to trade latency for quality
    - ‚úÖ Complex queries with nuanced context
    - ‚úÖ Best for: Customer support, research, compliance¬∑
    **GraphRAG** (Knowledge graph + vectors):
    - ‚úÖ Highly interconnected data
    - ‚úÖ Multi-hop reasoning required
    - ‚úÖ Entity relationships matter
    - ‚úÖ Best for: Knowledge bases, enterprise search¬∑
    **Fine-tuned Embeddings** (Custom model):
    - ‚úÖ Domain-specific vocabulary (medical, legal, finance)
    - ‚úÖ Proprietary terminology
    - ‚úÖ Have labeled data for fine-tuning
    - ‚úÖ Best for: Specialized domains, enterprise search¬∑
    ---¬∑
    ## Embedding Optimization¬∑
    ### 1. Choosing Embedding Models¬∑
    ```python
    # rag/embeddings/model_selection.py
    from sentence_transformers import SentenceTransformer
    from typing import List, Dict
    import numpy as np¬∑
    class EmbeddingModelSelector:
        \"\"\"Select optimal embedding model for your use case\"\"\"¬∑
        # Model comparison (as of 2024)
        MODELS = {
            'openai-ada-002': {
                'dimensions': 1536,
                'max_tokens': 8191,
                'cost_per_1k': 0.0001,
                'latency_ms': 50,
                'use_case': 'General purpose, high quality'
            },
            'text-embedding-3-small': {
                'dimensions': 1536,
                'max_tokens': 8191,
                'cost_per_1k': 0.00002,
                'latency_ms': 30,
                'use_case': 'Cost-optimized, good quality'
            },
            'all-MiniLM-L6-v2': {
                'dimensions': 384,
                'max_tokens': 256,
                'cost_per_1k': 0,  # Self-hosted
                'latency_ms': 10,
                'use_case': 'Fast, self-hosted, decent quality'
            },
            'all-mpnet-base-v2': {
                'dimensions': 768,
                'max_tokens': 514,
                'cost_per_1k': 0,
                'latency_ms': 20,
                'use_case': 'Best self-hosted quality'
            },
            'bge-large-en-v1.5': {
                'dimensions': 1024,
                'max_tokens': 512,
                'cost_per_1k': 0,
                'latency_ms': 30,
                'use_case': 'SOTA open-source'
            }
        }¬∑
        @staticmethod
        def recommend(
            corpus_size: int,
            budget: str,  # 'low', 'medium', 'high'
            latency_requirement: int,  # milliseconds
            domain: str = 'general'
        ) -> str:
            \"\"\"Recommend embedding model based on requirements\"\"\"¬∑
            if budget == 'low' or corpus_size > 1_000_000:
                # Self-hosted models
                if latency_requirement < 15:
                    return 'all-MiniLM-L6-v2'
                else:
                    return 'bge-large-en-v1.5'¬∑
            if budget == 'medium':
                return 'text-embedding-3-small'¬∑
            # High budget or high quality requirement
            return 'openai-ada-002'¬∑
    # Usage
    model_name = EmbeddingModelSelector.recommend(
        corpus_size=100_000,
        budget='medium',
        latency_requirement=50,
        domain='technical-docs'
    )
    print(f\"Recommended model: {model_name}\")
    ```¬∑
    ### 2. Advanced Chunking Strategies¬∑
    ```python
    # rag/chunking/strategies.py
    from typing import List, Dict
    import re¬∑
    class ChunkingStrategy:
        \"\"\"Advanced document chunking strategies\"\"\"¬∑
        @staticmethod
        def semantic_chunking(
            text: str,
            model: SentenceTransformer,
            similarity_threshold: float = 0.5
        ) -> List[str]:
            \"\"\"Chunk based on semantic similarity (not fixed size)\"\"\"
            sentences = re.split(r'(?<=[.!?])\\s+', text)¬∑
            if not sentences:
                return []¬∑
            # Get embeddings for all sentences
            embeddings = model.encode(sentences)¬∑
            chunks = []
            current_chunk = [sentences[0]]
            current_embedding = embeddings[0]¬∑
            for i in range(1, len(sentences)):
                # Calculate similarity with current chunk
                similarity = np.dot(current_embedding, embeddings[i]) / (
                    np.linalg.norm(current_embedding) * np.linalg.norm(embeddings[i])
                )¬∑
                if similarity >= similarity_threshold:
                    # Add to current chunk
                    current_chunk.append(sentences[i])
                    # Update chunk embedding (average)
                    current_embedding = (current_embedding + embeddings[i]) / 2
                else:
                    # Start new chunk
                    chunks.append(' '.join(current_chunk))
                    current_chunk = [sentences[i]]
                    current_embedding = embeddings[i]¬∑
            # Add last chunk
            if current_chunk:
                chunks.append(' '.join(current_chunk))¬∑
            return chunks¬∑
        @staticmethod
        def hierarchical_chunking(
            text: str,
            chunk_sizes: List[int] = [512, 1024, 2048]
        ) -> Dict[str, List[str]]:
            \"\"\"Create multiple granularity chunks\"\"\"
            chunks = {}¬∑
            for size in chunk_sizes:
                # Simple character-based chunking (can be enhanced with tokens)
                chunks[f'size_{size}'] = [
                    text[i:i+size]
                    for i in range(0, len(text), size)
                ]¬∑
            return chunks¬∑
        @staticmethod
        def overlap_chunking(
            text: str,
            chunk_size: int = 512,
            overlap: int = 128
        ) -> List[str]:
            \"\"\"Chunking with overlap for context preservation\"\"\"
            chunks = []
            start = 0¬∑
            while start < len(text):
                end = start + chunk_size
                chunk = text[start:end]
                chunks.append(chunk)
                start += (chunk_size - overlap)¬∑
            return chunks¬∑
        @staticmethod
        def markdown_aware_chunking(
            markdown_text: str,
            max_tokens: int = 512
        ) -> List[Dict[str, str]]:
            \"\"\"Chunk markdown preserving structure\"\"\"
            chunks = []¬∑
            # Split by headers
            sections = re.split(r'(^#{1,6}\\s+.+$)', markdown_text, flags=re.MULTILINE)¬∑
            current_header = \"\"
            current_content = \"\"¬∑
            for section in sections:
                if re.match(r'^#{1,6}\\s+', section):
                    # Save previous section
                    if current_content:
                        chunks.append({
                            'header': current_header,
                            'content': current_content.strip(),
                            'hierarchy': current_header.count('#')
                        })¬∑
                    current_header = section
                    current_content = \"\"
                else:
                    current_content += section¬∑
            # Add last section
            if current_content:
                chunks.append({
                    'header': current_header,
                    'content': current_content.strip(),
                    'hierarchy': current_header.count('#') if current_header else 0
                })¬∑
            return chunks¬∑
    # Usage
    chunker = ChunkingStrategy()¬∑
    # Semantic chunking (best quality, slower)
    semantic_chunks = chunker.semantic_chunking(text, model)¬∑
    # Overlap chunking (good balance)
    overlap_chunks = chunker.overlap_chunking(text, chunk_size=512, overlap=128)¬∑
    # Markdown-aware (for docs)
    md_chunks = chunker.markdown_aware_chunking(markdown_text)
    ```¬∑
    ### 3. Fine-tuning Embeddings¬∑
    ```python
    # rag/embeddings/fine_tune.py
    from sentence_transformers import SentenceTransformer, InputExample, losses
    from torch.utils.data import DataLoader
    from typing import List, Tuple¬∑
    class EmbeddingFineTuner:
        \"\"\"Fine-tune embedding models for domain-specific data\"\"\"¬∑
        def __init__(self, base_model: str = 'all-MiniLM-L6-v2'):
            self.model = SentenceTransformer(base_model)¬∑
        def prepare_training_data(
            self,
            positive_pairs: List[Tuple[str, str]],
            negative_pairs: List[Tuple[str, str]]
        ) -> List[InputExample]:
            \"\"\"Prepare training examples\"\"\"
            examples = []¬∑
            # Positive pairs (query, relevant doc) -> label 1
            for query, doc in positive_pairs:
                examples.append(InputExample(texts=[query, doc], label=1.0))¬∑
            # Negative pairs (query, irrelevant doc) -> label 0
            for query, doc in negative_pairs:
                examples.append(InputExample(texts=[query, doc], label=0.0))¬∑
            return examples¬∑
        def fine_tune(
            self,
            training_examples: List[InputExample],
            epochs: int = 4,
            batch_size: int = 16,
            output_path: str = './fine-tuned-model'
        ):
            \"\"\"Fine-tune the model\"\"\"¬∑
            # Create DataLoader
            train_dataloader = DataLoader(
                training_examples,
                shuffle=True,
                batch_size=batch_size
            )¬∑
            # Define loss function (Contrastive Loss)
            train_loss = losses.CosineSimilarityLoss(self.model)¬∑
            # Train
            self.model.fit(
                train_objectives=[(train_dataloader, train_loss)],
                epochs=epochs,
                warmup_steps=100,
                output_path=output_path
            )¬∑
            print(f\"‚úÖ Model fine-tuned and saved to {output_path}\")¬∑
    # Usage
    tuner = EmbeddingFineTuner(base_model='all-MiniLM-L6-v2')¬∑
    # Prepare training data from your domain
    positive_pairs = [
        (\"What is kubernetes?\", \"Kubernetes is a container orchestration platform...\"),
        (\"How to scale pods?\", \"Use kubectl scale deployment to scale pods...\")
    ]¬∑
    negative_pairs = [
        (\"What is kubernetes?\", \"Python is a programming language...\"),
        (\"How to scale pods?\", \"JavaScript is used for web development...\")
    ]¬∑
    examples = tuner.prepare_training_data(positive_pairs, negative_pairs)
    tuner.fine_tune(examples, epochs=4, output_path='./k8s-embeddings')
    ```¬∑
    ---¬∑
    ## Hybrid Search¬∑
    ### Combining Dense and Sparse Retrieval¬∑
    ```python
    # rag/retrieval/hybrid_search.py
    from typing import List, Dict, Tuple
    from sentence_transformers import SentenceTransformer
    from rank_bm25 import BM25Okapi
    import numpy as np¬∑
    class HybridSearchEngine:
        \"\"\"Hybrid search combining dense (vector) and sparse (BM25) retrieval\"\"\"¬∑
        def __init__(
            self,
            embedding_model: str = 'all-MiniLM-L6-v2',
            alpha: float = 0.5  # Weight: 0=sparse only, 1=dense only
        ):
            self.embedding_model = SentenceTransformer(embedding_model)
            self.alpha = alpha
            self.bm25 = None
            self.documents = []
            self.embeddings = None¬∑
        def index_documents(self, documents: List[str]):
            \"\"\"Index documents for both dense and sparse retrieval\"\"\"
            self.documents = documents¬∑
            # Dense indexing (vector embeddings)
            print(\"Creating dense embeddings...\")
            self.embeddings = self.embedding_model.encode(
                documents,
                show_progress_bar=True
            )¬∑
            # Sparse indexing (BM25)
            print(\"Creating BM25 index...\")
            tokenized_docs = [doc.lower().split() for doc in documents]
            self.bm25 = BM25Okapi(tokenized_docs)¬∑
            print(f\"‚úÖ Indexed {len(documents)} documents\")¬∑
        def search(
            self,
            query: str,
            top_k: int = 10
        ) -> List[Tuple[int, float, str]]:
            \"\"\"Hybrid search combining dense and sparse scores\"\"\"¬∑
            # Dense retrieval (vector similarity)
            query_embedding = self.embedding_model.encode([query])[0]
            dense_scores = np.dot(self.embeddings, query_embedding)
            dense_scores = (dense_scores - dense_scores.min()) / (
                dense_scores.max() - dense_scores.min() + 1e-10
            )  # Normalize to [0, 1]¬∑
            # Sparse retrieval (BM25)
            tokenized_query = query.lower().split()
            sparse_scores = self.bm25.get_scores(tokenized_query)
            sparse_scores = (sparse_scores - sparse_scores.min()) / (
                sparse_scores.max() - sparse_scores.min() + 1e-10
            )  # Normalize to [0, 1]¬∑
            # Combine scores
            hybrid_scores = (
                self.alpha * dense_scores +
                (1 - self.alpha) * sparse_scores
            )¬∑
            # Get top-k results
            top_indices = np.argsort(hybrid_scores)[::-1][:top_k]¬∑
            results = [
                (idx, hybrid_scores[idx], self.documents[idx])
                for idx in top_indices
            ]¬∑
            return results¬∑
    # Usage
    search_engine = HybridSearchEngine(alpha=0.7)  # 70% dense, 30% sparse¬∑
    documents = [
        \"Kubernetes is a container orchestration platform\",
        \"Docker containers package applications\",
        \"Microservices architecture splits applications\",
        # ... more documents
    ]¬∑
    search_engine.index_documents(documents)¬∑
    results = search_engine.search(\"container management\", top_k=5)
    for idx, score, doc in results:
        print(f\"Score: {score:.4f} | {doc[:100]}\")
    ```¬∑
    ---¬∑
    ## Reranking¬∑
    ### Cross-Encoder Reranking¬∑
    ```python
    # rag/reranking/cross_encoder.py
    from sentence_transformers import CrossEncoder
    from typing import List, Tuple¬∑
    class RerankerPipeline:
        \"\"\"Two-stage retrieval: fast retrieval + slow reranking\"\"\"¬∑
        def __init__(
            self,
            retrieval_model: str = 'all-MiniLM-L6-v2',
            reranker_model: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'
        ):
            # Stage 1: Fast bi-encoder for initial retrieval
            self.retriever = SentenceTransformer(retrieval_model)¬∑
            # Stage 2: Slow cross-encoder for reranking
            self.reranker = CrossEncoder(reranker_model)¬∑
        def retrieve_and_rerank(
            self,
            query: str,
            documents: List[str],
            top_k_retrieve: int = 100,
            top_k_rerank: int = 10
        ) -> List[Tuple[float, str]]:
            \"\"\"Two-stage retrieval with reranking\"\"\"¬∑
            # Stage 1: Fast retrieval (get top 100)
            query_embedding = self.retriever.encode([query])[0]
            doc_embeddings = self.retriever.encode(documents)¬∑
            # Calculate similarities
            similarities = np.dot(doc_embeddings, query_embedding)
            top_indices = np.argsort(similarities)[::-1][:top_k_retrieve]¬∑
            # Get candidate documents
            candidates = [(documents[idx], similarities[idx]) for idx in top_indices]¬∑
            # Stage 2: Reranking (top 100 -> top 10)
            query_doc_pairs = [[query, doc] for doc, _ in candidates]
            rerank_scores = self.reranker.predict(query_doc_pairs)¬∑
            # Sort by rerank scores
            reranked = sorted(
                zip(rerank_scores, [doc for doc, _ in candidates]),
                key=lambda x: x[0],
                reverse=True
            )[:top_k_rerank]¬∑
            return reranked¬∑
    # Usage
    reranker = RerankerPipeline()¬∑
    results = reranker.retrieve_and_rerank(
        query=\"How to deploy kubernetes cluster?\",
        documents=all_documents,
        top_k_retrieve=100,  # Fast retrieval
        top_k_rerank=10      # Slow but accurate reranking
    )¬∑
    for score, doc in results:
        print(f\"Score: {score:.4f} | {doc[:100]}\")
    ```¬∑
    ### LLM-based Reranking¬∑
    ```python
    # rag/reranking/llm_reranker.py
    import anthropic
    from typing import List, Tuple¬∑
    class LLMReranker:
        \"\"\"Use LLM to rerank retrieved documents\"\"\"¬∑
        def __init__(self, api_key: str):
            self.client = anthropic.Anthropic(api_key=api_key)¬∑
        def rerank(
            self,
            query: str,
            documents: List[str],
            top_k: int = 5
        ) -> List[Tuple[int, str]]:
            \"\"\"LLM-based reranking for highest quality\"\"\"¬∑
            # Create prompt for LLM
            docs_text = \"\\n\\n\".join([
                f\"Document {i+1}:\\n{doc}\"
                for i, doc in enumerate(documents)
            ])¬∑
            prompt = f\"\"\"Given the query and documents below, rank the documents by relevance to the query.
    Return ONLY a comma-separated list of document numbers in order of relevance (most relevant first).¬∑
    Query: {query}¬∑
    {docs_text}¬∑
    Ranking (comma-separated numbers):\"\"\"¬∑
            # Call LLM
            message = self.client.messages.create(
                model=\"claude-3-5-sonnet-20241022\",
                max_tokens=100,
                messages=[{\"role\": \"user\", \"content\": prompt}]
            )¬∑
            # Parse response
            ranking_text = message.content[0].text.strip()
            rankings = [int(x.strip()) - 1 for x in ranking_text.split(',')]¬∑
            # Return reranked documents
            reranked = [
                (rank, documents[rank])
                for rank in rankings[:top_k]
                if rank < len(documents)
            ]¬∑
            return reranked¬∑
    # Usage (expensive, use only when quality is critical)
    llm_reranker = LLMReranker(api_key=\"your-api-key\")¬∑
    top_docs = llm_reranker.rerank(
        query=\"What are best practices for kubernetes security?\",
        documents=candidate_documents,
        top_k=5
    )
    ```¬∑
    ---¬∑
    ## RAG Evaluation¬∑
    ### Comprehensive Metrics¬∑
    ```python
    # rag/evaluation/metrics.py
    from typing import List, Set
    import numpy as np¬∑
    class RAGEvaluator:
        \"\"\"Evaluate RAG system performance\"\"\"¬∑
        @staticmethod
        def recall_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Recall@K: What % of relevant docs were retrieved in top-k?\"\"\"
            retrieved_k = set(retrieved[:k])
            return len(retrieved_k & relevant) / len(relevant) if relevant else 0¬∑
        @staticmethod
        def precision_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Precision@K: What % of top-k retrieved docs are relevant?\"\"\"
            retrieved_k = set(retrieved[:k])
            return len(retrieved_k & relevant) / k if k > 0 else 0¬∑
        @staticmethod
        def mrr(retrieved_list: List[List[str]], relevant_list: List[Set[str]]) -> float:
            \"\"\"Mean Reciprocal Rank: Average of 1/rank of first relevant doc\"\"\"
            reciprocal_ranks = []¬∑
            for retrieved, relevant in zip(retrieved_list, relevant_list):
                for i, doc_id in enumerate(retrieved):
                    if doc_id in relevant:
                        reciprocal_ranks.append(1 / (i + 1))
                        break
                else:
                    reciprocal_ranks.append(0)¬∑
            return np.mean(reciprocal_ranks)¬∑
        @staticmethod
        def ndcg_at_k(
            retrieved: List[str],
            relevant: Set[str],
            k: int
        ) -> float:
            \"\"\"Normalized Discounted Cumulative Gain@K\"\"\"
            dcg = 0
            for i, doc_id in enumerate(retrieved[:k]):
                if doc_id in relevant:
                    dcg += 1 / np.log2(i + 2)  # +2 because log2(1) = 0¬∑
            # Ideal DCG (all relevant docs at top)
            idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(relevant))))¬∑
            return dcg / idcg if idcg > 0 else 0¬∑
    # Usage
    evaluator = RAGEvaluator()¬∑
    retrieved_docs = ['doc1', 'doc3', 'doc5', 'doc2', 'doc8']
    relevant_docs = {'doc1', 'doc2', 'doc4'}¬∑
    recall_5 = evaluator.recall_at_k(retrieved_docs, relevant_docs, k=5)
    precision_5 = evaluator.precision_at_k(retrieved_docs, relevant_docs, k=5)
    ndcg_5 = evaluator.ndcg_at_k(retrieved_docs, relevant_docs, k=5)¬∑
    print(f\"Recall@5: {recall_5:.2%}\")       # 66% (2 out of 3 relevant docs)
    print(f\"Precision@5: {precision_5:.2%}\") # 40% (2 relevant out of 5 retrieved)
    print(f\"NDCG@5: {ndcg_5:.3f}\")
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `benchmark-embeddings.py` - Compare embedding model performance
    - `evaluate-rag-system.py` - Run full RAG evaluation suite
    - `tune-hybrid-search.py` - Optimize alpha parameter for hybrid search¬∑
    ### references/
    - `references/embedding-models.md` - Comparison of popular embedding models
    - `references/chunking-strategies.md` - Chunking best practices by content type
    - `references/reranking-methods.md` - Cross-encoder vs LLM reranking tradeoffs¬∑
    ### assets/
    - `assets/evaluation-datasets/` - Standard RAG evaluation datasets
    - `assets/fine-tuning-data/` - Example training data for embeddings¬∑
    ## Related Skills¬∑
    - `ml-pipelines` - Fine-tuning embedding models
    - `vector-databases` - Efficient vector storage and retrieval
    - `model-deployment` - Deploying RAG systems to production
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ model-deployment ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: model-deployment
    description: ML model serving with TensorFlow Serving, TorchServe, A/B testing, monitoring. Use when deploying models to production, setting up model endpoints, implementing canary deployments, or monitoring model performance. Covers containerization, scaling, versioning, and observability. Reduces deployment time by 60%.
    ---¬∑
    # Model Deployment¬∑
    ## Overview¬∑
    Production ML model deployment covering model serving (TensorFlow Serving, TorchServe, Triton), containerization, A/B testing, canary deployments, and comprehensive monitoring. Focus on reliability, scalability, and observability.¬∑
    **Goal**: Deploy ML models to production with 99.9% uptime, <100ms latency, and full observability¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Deploying ML models to production endpoints
    - Setting up model serving infrastructure (TensorFlow Serving, TorchServe)
    - Implementing A/B testing for model versions
    - Creating canary or blue-green deployments
    - Monitoring model performance and drift
    - Scaling model inference (GPU/CPU)
    - Building model version management
    - Implementing model explainability in production¬∑
    **Triggers**: \"model deployment\", \"model serving\", \"TensorFlow Serving\", \"TorchServe\", \"A/B testing\", \"canary deployment\", \"model monitoring\", \"inference\"¬∑
    ---¬∑
    ## Quick Start: Deployment Strategy Decision Tree¬∑
    ### Choosing the Right Deployment Pattern¬∑
    **REST API (FastAPI/Flask)**:
    - ‚úÖ Simple deployment with full control
    - ‚úÖ Easy to integrate with existing services
    - ‚úÖ Batch or single predictions
    - ‚úÖ Custom preprocessing/postprocessing
    - ‚úÖ Best for: Small-medium scale, custom logic¬∑
    **TensorFlow Serving** (TF models):
    - ‚úÖ High-performance TensorFlow model serving
    - ‚úÖ gRPC and REST APIs
    - ‚úÖ Model versioning built-in
    - ‚úÖ GPU support
    - ‚úÖ Best for: TensorFlow models, high throughput¬∑
    **TorchServe** (PyTorch models):
    - ‚úÖ Official PyTorch serving
    - ‚úÖ Multi-model serving
    - ‚úÖ Model management APIs
    - ‚úÖ Metrics and logging
    - ‚úÖ Best for: PyTorch models, production-grade¬∑
    **Triton Inference Server** (Multi-framework):
    - ‚úÖ Supports TensorFlow, PyTorch, ONNX, custom
    - ‚úÖ Dynamic batching
    - ‚úÖ Concurrent model execution
    - ‚úÖ GPU optimization
    - ‚úÖ Best for: Multi-framework, maximum performance¬∑
    **Serverless (AWS Lambda, Cloud Functions)**:
    - ‚úÖ Auto-scaling to zero
    - ‚úÖ Pay-per-request
    - ‚úÖ Low maintenance
    - ‚úÖ Best for: Sporadic traffic, cost optimization¬∑
    ---¬∑
    ## FastAPI Model Serving¬∑
    ### 1. Basic Model API¬∑
    ```python
    # api/model_server.py
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    from typing import List, Dict, Any
    import joblib
    import numpy as np
    from prometheus_client import Counter, Histogram, make_asgi_app
    import time¬∑
    # Load model at startup
    model = None
    scaler = None¬∑
    app = FastAPI(title=\"ML Model API\", version=\"1.0.0\")¬∑
    # Prometheus metrics
    prediction_counter = Counter(
        'model_predictions_total',
        'Total number of predictions',
        ['model_version', 'status']
    )
    prediction_latency = Histogram(
        'model_prediction_latency_seconds',
        'Prediction latency in seconds',
        ['model_version']
    )¬∑
    class PredictionRequest(BaseModel):
        features: List[float]¬∑
    class PredictionResponse(BaseModel):
        prediction: float
        probability: float
        model_version: str
        latency_ms: float¬∑
    @app.on_event(\"startup\")
    async def load_model():
        \"\"\"Load model on startup\"\"\"
        global model, scaler
        model = joblib.load(\"models/churn_model_v1.pkl\")
        scaler = joblib.load(\"models/scaler_v1.pkl\")
        print(\"‚úÖ Model loaded successfully\")¬∑
    @app.post(\"/predict\", response_model=PredictionResponse)
    async def predict(request: PredictionRequest):
        \"\"\"Make prediction\"\"\"
        start_time = time.time()¬∑
        try:
            # Preprocess
            features = np.array(request.features).reshape(1, -1)
            features_scaled = scaler.transform(features)¬∑
            # Predict
            prediction = model.predict(features_scaled)[0]
            probability = model.predict_proba(features_scaled)[0][1]¬∑
            # Metrics
            latency = (time.time() - start_time) * 1000
            prediction_counter.labels(model_version=\"v1\", status=\"success\").inc()
            prediction_latency.labels(model_version=\"v1\").observe(time.time() - start_time)¬∑
            return PredictionResponse(
                prediction=float(prediction),
                probability=float(probability),
                model_version=\"v1\",
                latency_ms=latency
            )¬∑
        except Exception as e:
            prediction_counter.labels(model_version=\"v1\", status=\"error\").inc()
            raise HTTPException(status_code=500, detail=str(e))¬∑
    @app.post(\"/predict_batch\")
    async def predict_batch(requests: List[PredictionRequest]):
        \"\"\"Batch predictions for efficiency\"\"\"
        features = np.array([req.features for req in requests])
        features_scaled = scaler.transform(features)¬∑
        predictions = model.predict(features_scaled)
        probabilities = model.predict_proba(features_scaled)[:, 1]¬∑
        return [
            {
                \"prediction\": float(pred),
                \"probability\": float(prob),
                \"model_version\": \"v1\"
            }
            for pred, prob in zip(predictions, probabilities)
        ]¬∑
    @app.get(\"/health\")
    async def health_check():
        \"\"\"Health check endpoint\"\"\"
        return {
            \"status\": \"healthy\",
            \"model_loaded\": model is not None,
            \"model_version\": \"v1\"
        }¬∑
    # Prometheus metrics endpoint
    app.mount(\"/metrics\", make_asgi_app())¬∑
    # Run with: uvicorn api.model_server:app --host 0.0.0.0 --port 8000
    ```¬∑
    ### 2. Model Versioning and A/B Testing¬∑
    ```python
    # api/ab_testing.py
    from fastapi import FastAPI, Request
    from typing import Dict
    import joblib
    import random
    import hashlib¬∑
    app = FastAPI()¬∑
    # Load multiple model versions
    models = {
        \"v1\": joblib.load(\"models/model_v1.pkl\"),
        \"v2\": joblib.load(\"models/model_v2.pkl\"),
        \"v3\": joblib.load(\"models/model_v3.pkl\")
    }¬∑
    # A/B test configuration
    AB_CONFIG = {
        \"v1\": 0.5,   # 50% traffic
        \"v2\": 0.3,   # 30% traffic
        \"v3\": 0.2    # 20% traffic
    }¬∑
    def select_model_version(user_id: str) -> str:
        \"\"\"Deterministic A/B test assignment based on user_id\"\"\"
        # Hash user_id for consistent assignment
        hash_value = int(hashlib.md5(user_id.encode()).hexdigest(), 16)
        random_value = (hash_value % 100) / 100.0¬∑
        cumulative = 0
        for version, probability in AB_CONFIG.items():
            cumulative += probability
            if random_value < cumulative:
                return version¬∑
        return \"v1\"  # Default¬∑
    @app.post(\"/predict\")
    async def predict_ab(request: PredictionRequest, user_id: str):
        \"\"\"Prediction with A/B testing\"\"\"¬∑
        # Select model version for this user
        model_version = select_model_version(user_id)
        model = models[model_version]¬∑
        # Make prediction
        features = np.array(request.features).reshape(1, -1)
        prediction = model.predict(features)[0]¬∑
        # Log for analysis
        log_prediction(
            user_id=user_id,
            model_version=model_version,
            features=request.features,
            prediction=prediction
        )¬∑
        return {
            \"prediction\": float(prediction),
            \"model_version\": model_version,
            \"ab_test\": True
        }
    ```¬∑
    ### 3. Canary Deployment¬∑
    ```python
    # api/canary_deployment.py
    from fastapi import FastAPI
    import joblib
    import random
    from datetime import datetime, timedelta¬∑
    app = FastAPI()¬∑
    # Load models
    stable_model = joblib.load(\"models/stable_v1.pkl\")
    canary_model = joblib.load(\"models/canary_v2.pkl\")¬∑
    # Canary configuration
    CANARY_CONFIG = {
        \"enabled\": True,
        \"traffic_percentage\": 0.1,  # Start with 10%
        \"start_time\": datetime.now(),
        \"duration_hours\": 24,
        \"rollback_on_error_rate\": 0.05  # Rollback if >5% errors
    }¬∑
    # Metrics
    canary_metrics = {
        \"stable\": {\"success\": 0, \"error\": 0},
        \"canary\": {\"success\": 0, \"error\": 0}
    }¬∑
    def should_use_canary() -> bool:
        \"\"\"Decide whether to use canary model\"\"\"
        if not CANARY_CONFIG[\"enabled\"]:
            return False¬∑
        # Check if canary period has expired
        elapsed = datetime.now() - CANARY_CONFIG[\"start_time\"]
        if elapsed > timedelta(hours=CANARY_CONFIG[\"duration_hours\"]):
            return False¬∑
        # Check error rate
        canary_error_rate = (
            canary_metrics[\"canary\"][\"error\"] /
            max(sum(canary_metrics[\"canary\"].values()), 1)
        )
        if canary_error_rate > CANARY_CONFIG[\"rollback_on_error_rate\"]:
            print(\"‚ö†Ô∏è Canary error rate too high, rolling back\")
            CANARY_CONFIG[\"enabled\"] = False
            return False¬∑
        # Random traffic split
        return random.random() < CANARY_CONFIG[\"traffic_percentage\"]¬∑
    @app.post(\"/predict\")
    async def predict_canary(request: PredictionRequest):
        \"\"\"Prediction with canary deployment\"\"\"¬∑
        use_canary = should_use_canary()
        model = canary_model if use_canary else stable_model
        version = \"canary_v2\" if use_canary else \"stable_v1\"¬∑
        try:
            # Make prediction
            features = np.array(request.features).reshape(1, -1)
            prediction = model.predict(features)[0]¬∑
            # Update metrics
            metrics_key = \"canary\" if use_canary else \"stable\"
            canary_metrics[metrics_key][\"success\"] += 1¬∑
            return {
                \"prediction\": float(prediction),
                \"model_version\": version,
                \"deployment_type\": \"canary\" if use_canary else \"stable\"
            }¬∑
        except Exception as e:
            # Update error metrics
            metrics_key = \"canary\" if use_canary else \"stable\"
            canary_metrics[metrics_key][\"error\"] += 1
            raise¬∑
    @app.get(\"/canary_metrics\")
    async def get_canary_metrics():
        \"\"\"Get canary deployment metrics\"\"\"
        return {
            \"config\": CANARY_CONFIG,
            \"metrics\": canary_metrics,
            \"canary_error_rate\": (
                canary_metrics[\"canary\"][\"error\"] /
                max(sum(canary_metrics[\"canary\"].values()), 1)
            )
        }
    ```¬∑
    ---¬∑
    ## TensorFlow Serving¬∑
    ### 1. Export TensorFlow Model¬∑
    ```python
    # deployment/export_tf_model.py
    import tensorflow as tf
    from tensorflow import keras
    import os¬∑
    def export_model_for_serving(
        model: keras.Model,
        export_path: str,
        version: int = 1
    ):
        \"\"\"Export TensorFlow model for TF Serving\"\"\"¬∑
        # Create versioned directory
        model_path = os.path.join(export_path, str(version))¬∑
        # Save in SavedModel format
        tf.saved_model.save(model, model_path)¬∑
        print(f\"‚úÖ Model exported to {model_path}\")
        print(f\"Signature: {list(model.signatures.keys())}\")¬∑
    # Usage
    model = keras.models.load_model(\"models/churn_model.h5\")
    export_model_for_serving(model, export_path=\"./tf-models/churn\", version=1)¬∑
    # Directory structure:
    # tf-models/
    #   churn/
    #     1/
    #       saved_model.pb
    #       variables/
    ```¬∑
    ### 2. Deploy with Docker¬∑
    ```dockerfile
    # deployment/Dockerfile.tfserving
    FROM tensorflow/serving:latest¬∑
    # Copy model
    COPY tf-models/churn /models/churn¬∑
    # Expose ports
    EXPOSE 8500  # gRPC
    EXPOSE 8501  # REST¬∑
    # Set model name
    ENV MODEL_NAME=churn¬∑
    # Run TensorFlow Serving
    CMD [\"tensorflow_model_server\", \\
         \"--port=8500\", \\
         \"--rest_api_port=8501\", \\
         \"--model_name=${MODEL_NAME}\", \\
         \"--model_base_path=/models/${MODEL_NAME}\"]
    ```¬∑
    ```bash
    # Build and run
    docker build -t churn-model-serving -f Dockerfile.tfserving .
    docker run -p 8500:8500 -p 8501:8501 churn-model-serving¬∑
    # Test REST API
    curl -X POST http://localhost:8501/v1/models/churn:predict \\
      -H \"Content-Type: application/json\" \\
      -d '{\"instances\": [[0.5, 1.2, 3.4, 2.1]]}'
    ```¬∑
    ### 3. Client for TF Serving¬∑
    ```python
    # deployment/tf_serving_client.py
    import requests
    import grpc
    import tensorflow as tf
    from tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc
    import numpy as np¬∑
    class TFServingClient:
        \"\"\"Client for TensorFlow Serving\"\"\"¬∑
        def __init__(self, host: str = \"localhost\", rest_port: int = 8501, grpc_port: int = 8500):
            self.rest_url = f\"http://{host}:{rest_port}\"
            self.grpc_channel = grpc.insecure_channel(f\"{host}:{grpc_port}\")
            self.grpc_stub = prediction_service_pb2_grpc.PredictionServiceStub(self.grpc_channel)¬∑
        def predict_rest(self, model_name: str, instances: list, version: int = None):
            \"\"\"Predict using REST API\"\"\"
            url = f\"{self.rest_url}/v1/models/{model_name}\"
            if version:
                url += f\"/versions/{version}\"
            url += \":predict\"¬∑
            response = requests.post(url, json={\"instances\": instances})
            return response.json()¬∑
        def predict_grpc(self, model_name: str, data: np.ndarray, version: int = None):
            \"\"\"Predict using gRPC (faster)\"\"\"
            request = predict_pb2.PredictRequest()
            request.model_spec.name = model_name
            if version:
                request.model_spec.version.value = version¬∑
            request.inputs['input'].CopyFrom(
                tf.make_tensor_proto(data, dtype=tf.float32)
            )¬∑
            result = self.grpc_stub.Predict(request, timeout=10.0)
            return result¬∑
    # Usage
    client = TFServingClient()¬∑
    # REST API (easier, slower)
    result = client.predict_rest(\"churn\", instances=[[0.5, 1.2, 3.4, 2.1]])
    print(f\"Prediction: {result['predictions']}\")¬∑
    # gRPC (faster, more complex)
    data = np.array([[0.5, 1.2, 3.4, 2.1]], dtype=np.float32)
    result = client.predict_grpc(\"churn\", data)
    print(f\"Prediction: {result.outputs['output'].float_val}\")
    ```¬∑
    ---¬∑
    ## TorchServe¬∑
    ### 1. Create Model Archive¬∑
    ```python
    # deployment/torch_handler.py
    from ts.torch_handler.base_handler import BaseHandler
    import torch
    import numpy as np¬∑
    class ChurnPredictionHandler(BaseHandler):
        \"\"\"Custom TorchServe handler\"\"\"¬∑
        def preprocess(self, data):
            \"\"\"Preprocess input data\"\"\"
            features = data[0].get(\"features\")
            if features is None:
                features = data[0].get(\"body\")¬∑
            # Convert to tensor
            tensor = torch.FloatTensor(features)
            return tensor¬∑
        def inference(self, data):
            \"\"\"Run inference\"\"\"
            with torch.no_grad():
                prediction = self.model(data)
            return prediction¬∑
        def postprocess(self, inference_output):
            \"\"\"Postprocess output\"\"\"
            # Apply softmax for probabilities
            probabilities = torch.softmax(inference_output, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1)¬∑
            return [
                {
                    \"prediction\": int(predicted_class[0]),
                    \"probability\": float(probabilities[0][1]),
                    \"all_probabilities\": probabilities[0].tolist()
                }
            ]¬∑
    # Save handler
    # torch_handler.py should be in same directory as model
    ```¬∑
    ```bash
    # Create model archive (.mar file)
    torch-model-archiver \\
      --model-name churn-predictor \\
      --version 1.0 \\
      --serialized-file models/churn_model.pt \\
      --handler torch_handler.py \\
      --export-path model-store/¬∑
    # Directory structure:
    # model-store/
    #   churn-predictor.mar
    ```¬∑
    ### 2. Deploy with TorchServe¬∑
    ```yaml
    # deployment/torchserve-config.yaml
    inference_address: http://0.0.0.0:8080
    management_address: http://0.0.0.0:8081
    metrics_address: http://0.0.0.0:8082¬∑
    models:
      churn-predictor:
        1.0:
          defaultVersion: true
          marName: churn-predictor.mar
          minWorkers: 2
          maxWorkers: 4
          batchSize: 8
          maxBatchDelay: 100
          responseTimeout: 120
    ```¬∑
    ```bash
    # Start TorchServe
    torchserve --start \\
      --model-store model-store/ \\
      --models churn-predictor=churn-predictor.mar \\
      --ts-config deployment/torchserve-config.yaml¬∑
    # Test prediction
    curl -X POST http://localhost:8080/predictions/churn-predictor \\
      -H \"Content-Type: application/json\" \\
      -d '{\"features\": [0.5, 1.2, 3.4, 2.1]}'¬∑
    # Management API
    curl http://localhost:8081/models  # List models
    curl -X PUT http://localhost:8081/models/churn-predictor?min_worker=4  # Scale workers
    ```¬∑
    ---¬∑
    ## Model Monitoring¬∑
    ### Comprehensive Monitoring System¬∑
    ```python
    # monitoring/model_monitor.py
    from prometheus_client import Counter, Histogram, Gauge, Summary
    import logging
    from datetime import datetime
    from typing import Dict, Any
    import numpy as np
    from scipy import stats¬∑
    # Prometheus metrics
    prediction_latency = Histogram(
        'model_prediction_latency_seconds',
        'Model prediction latency',
        ['model_version', 'endpoint']
    )¬∑
    prediction_count = Counter(
        'model_predictions_total',
        'Total predictions',
        ['model_version', 'prediction_class', 'status']
    )¬∑
    model_accuracy = Gauge(
        'model_accuracy',
        'Model accuracy over time window',
        ['model_version', 'time_window']
    )¬∑
    feature_drift = Gauge(
        'feature_drift_score',
        'Feature distribution drift score (KS statistic)',
        ['model_version', 'feature_name']
    )¬∑
    class ModelMonitor:
        \"\"\"Comprehensive model monitoring\"\"\"¬∑
        def __init__(self, reference_data: np.ndarray, feature_names: list):
            self.reference_data = reference_data
            self.feature_names = feature_names
            self.predictions_window = []
            self.actuals_window = []¬∑
        def log_prediction(
            self,
            model_version: str,
            features: np.ndarray,
            prediction: float,
            latency: float,
            actual: float = None
        ):
            \"\"\"Log prediction with monitoring\"\"\"¬∑
            # Log latency
            prediction_latency.labels(
                model_version=model_version,
                endpoint=\"/predict\"
            ).observe(latency)¬∑
            # Log prediction count
            prediction_count.labels(
                model_version=model_version,
                prediction_class=str(int(prediction)),
                status=\"success\"
            ).inc()¬∑
            # Store for drift detection
            self.predictions_window.append((features, prediction, actual))¬∑
            # Check drift every 100 predictions
            if len(self.predictions_window) >= 100:
                self.detect_drift(model_version)
                self.predictions_window = []¬∑
        def detect_drift(self, model_version: str):
            \"\"\"Detect feature drift using KS test\"\"\"¬∑
            current_features = np.array([
                p[0] for p in self.predictions_window
            ])¬∑
            for i, feature_name in enumerate(self.feature_names):
                # Kolmogorov-Smirnov test
                ks_statistic, p_value = stats.ks_2samp(
                    self.reference_data[:, i],
                    current_features[:, i]
                )¬∑
                # Log drift metric
                feature_drift.labels(
                    model_version=model_version,
                    feature_name=feature_name
                ).set(ks_statistic)¬∑
                # Alert if significant drift (p < 0.05)
                if p_value < 0.05:
                    logging.warning(
                        f\"‚ö†Ô∏è Feature drift detected: {feature_name} \"
                        f\"(KS={ks_statistic:.4f}, p={p_value:.4f})\"
                    )¬∑
        def calculate_accuracy(self, model_version: str, time_window: str = \"1h\"):
            \"\"\"Calculate model accuracy over time window\"\"\"¬∑
            # Filter predictions with actuals
            predictions_with_actuals = [
                (p[1], p[2])
                for p in self.predictions_window
                if p[2] is not None
            ]¬∑
            if not predictions_with_actuals:
                return¬∑
            predictions, actuals = zip(*predictions_with_actuals)
            accuracy = np.mean(np.array(predictions) == np.array(actuals))¬∑
            # Log accuracy metric
            model_accuracy.labels(
                model_version=model_version,
                time_window=time_window
            ).set(accuracy)¬∑
    # Usage
    monitor = ModelMonitor(
        reference_data=training_features,
        feature_names=['age', 'tenure', 'usage', 'revenue']
    )¬∑
    # In prediction endpoint
    start_time = time.time()
    prediction = model.predict(features)
    latency = time.time() - start_time¬∑
    monitor.log_prediction(
        model_version=\"v1\",
        features=features,
        prediction=prediction,
        latency=latency,
        actual=None  # Set when feedback received
    )
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `deploy-model.sh` - Deploy model to production
    - `rollback-model.sh` - Rollback to previous model version
    - `benchmark-inference.py` - Benchmark model inference performance¬∑
    ### references/
    - `references/tf-serving-guide.md` - TensorFlow Serving setup and configuration
    - `references/torchserve-guide.md` - TorchServe deployment patterns
    - `references/monitoring-dashboards.md` - Grafana dashboard templates
    - `references/ab-testing-methodology.md` - Statistical A/B testing for models¬∑
    ### assets/
    - `assets/docker-compose/` - Docker Compose files for model serving
    - `assets/k8s-manifests/` - Kubernetes deployment manifests
    - `assets/grafana-dashboards/` - Grafana JSON dashboards¬∑
    ## Related Skills¬∑
    - `ml-pipelines` - Training models for deployment
    - `microservices` - Model as microservice pattern
    - `serverless` - Serverless model deployment
    - `testing-strategies` - Model testing and validation
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ model-deployment ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: model-deployment
    description: ML model serving with TensorFlow Serving, TorchServe, A/B testing, monitoring. Use when deploying models to production, setting up model endpoints, implementing canary deployments, or monitoring model performance. Covers containerization, scaling, versioning, and observability. Reduces deployment time by 60%.
    ---¬∑
    # Model Deployment¬∑
    ## Overview¬∑
    Production ML model deployment covering model serving (TensorFlow Serving, TorchServe, Triton), containerization, A/B testing, canary deployments, and comprehensive monitoring. Focus on reliability, scalability, and observability.¬∑
    **Goal**: Deploy ML models to production with 99.9% uptime, <100ms latency, and full observability¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Deploying ML models to production endpoints
    - Setting up model serving infrastructure (TensorFlow Serving, TorchServe)
    - Implementing A/B testing for model versions
    - Creating canary or blue-green deployments
    - Monitoring model performance and drift
    - Scaling model inference (GPU/CPU)
    - Building model version management
    - Implementing model explainability in production¬∑
    **Triggers**: \"model deployment\", \"model serving\", \"TensorFlow Serving\", \"TorchServe\", \"A/B testing\", \"canary deployment\", \"model monitoring\", \"inference\"¬∑
    ---¬∑
    ## Quick Start: Deployment Strategy Decision Tree¬∑
    ### Choosing the Right Deployment Pattern¬∑
    **REST API (FastAPI/Flask)**:
    - ‚úÖ Simple deployment with full control
    - ‚úÖ Easy to integrate with existing services
    - ‚úÖ Batch or single predictions
    - ‚úÖ Custom preprocessing/postprocessing
    - ‚úÖ Best for: Small-medium scale, custom logic¬∑
    **TensorFlow Serving** (TF models):
    - ‚úÖ High-performance TensorFlow model serving
    - ‚úÖ gRPC and REST APIs
    - ‚úÖ Model versioning built-in
    - ‚úÖ GPU support
    - ‚úÖ Best for: TensorFlow models, high throughput¬∑
    **TorchServe** (PyTorch models):
    - ‚úÖ Official PyTorch serving
    - ‚úÖ Multi-model serving
    - ‚úÖ Model management APIs
    - ‚úÖ Metrics and logging
    - ‚úÖ Best for: PyTorch models, production-grade¬∑
    **Triton Inference Server** (Multi-framework):
    - ‚úÖ Supports TensorFlow, PyTorch, ONNX, custom
    - ‚úÖ Dynamic batching
    - ‚úÖ Concurrent model execution
    - ‚úÖ GPU optimization
    - ‚úÖ Best for: Multi-framework, maximum performance¬∑
    **Serverless (AWS Lambda, Cloud Functions)**:
    - ‚úÖ Auto-scaling to zero
    - ‚úÖ Pay-per-request
    - ‚úÖ Low maintenance
    - ‚úÖ Best for: Sporadic traffic, cost optimization¬∑
    ---¬∑
    ## FastAPI Model Serving¬∑
    ### 1. Basic Model API¬∑
    ```python
    # api/model_server.py
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    from typing import List, Dict, Any
    import joblib
    import numpy as np
    from prometheus_client import Counter, Histogram, make_asgi_app
    import time¬∑
    # Load model at startup
    model = None
    scaler = None¬∑
    app = FastAPI(title=\"ML Model API\", version=\"1.0.0\")¬∑
    # Prometheus metrics
    prediction_counter = Counter(
        'model_predictions_total',
        'Total number of predictions',
        ['model_version', 'status']
    )
    prediction_latency = Histogram(
        'model_prediction_latency_seconds',
        'Prediction latency in seconds',
        ['model_version']
    )¬∑
    class PredictionRequest(BaseModel):
        features: List[float]¬∑
    class PredictionResponse(BaseModel):
        prediction: float
        probability: float
        model_version: str
        latency_ms: float¬∑
    @app.on_event(\"startup\")
    async def load_model():
        \"\"\"Load model on startup\"\"\"
        global model, scaler
        model = joblib.load(\"models/churn_model_v1.pkl\")
        scaler = joblib.load(\"models/scaler_v1.pkl\")
        print(\"‚úÖ Model loaded successfully\")¬∑
    @app.post(\"/predict\", response_model=PredictionResponse)
    async def predict(request: PredictionRequest):
        \"\"\"Make prediction\"\"\"
        start_time = time.time()¬∑
        try:
            # Preprocess
            features = np.array(request.features).reshape(1, -1)
            features_scaled = scaler.transform(features)¬∑
            # Predict
            prediction = model.predict(features_scaled)[0]
            probability = model.predict_proba(features_scaled)[0][1]¬∑
            # Metrics
            latency = (time.time() - start_time) * 1000
            prediction_counter.labels(model_version=\"v1\", status=\"success\").inc()
            prediction_latency.labels(model_version=\"v1\").observe(time.time() - start_time)¬∑
            return PredictionResponse(
                prediction=float(prediction),
                probability=float(probability),
                model_version=\"v1\",
                latency_ms=latency
            )¬∑
        except Exception as e:
            prediction_counter.labels(model_version=\"v1\", status=\"error\").inc()
            raise HTTPException(status_code=500, detail=str(e))¬∑
    @app.post(\"/predict_batch\")
    async def predict_batch(requests: List[PredictionRequest]):
        \"\"\"Batch predictions for efficiency\"\"\"
        features = np.array([req.features for req in requests])
        features_scaled = scaler.transform(features)¬∑
        predictions = model.predict(features_scaled)
        probabilities = model.predict_proba(features_scaled)[:, 1]¬∑
        return [
            {
                \"prediction\": float(pred),
                \"probability\": float(prob),
                \"model_version\": \"v1\"
            }
            for pred, prob in zip(predictions, probabilities)
        ]¬∑
    @app.get(\"/health\")
    async def health_check():
        \"\"\"Health check endpoint\"\"\"
        return {
            \"status\": \"healthy\",
            \"model_loaded\": model is not None,
            \"model_version\": \"v1\"
        }¬∑
    # Prometheus metrics endpoint
    app.mount(\"/metrics\", make_asgi_app())¬∑
    # Run with: uvicorn api.model_server:app --host 0.0.0.0 --port 8000
    ```¬∑
    ### 2. Model Versioning and A/B Testing¬∑
    ```python
    # api/ab_testing.py
    from fastapi import FastAPI, Request
    from typing import Dict
    import joblib
    import random
    import hashlib¬∑
    app = FastAPI()¬∑
    # Load multiple model versions
    models = {
        \"v1\": joblib.load(\"models/model_v1.pkl\"),
        \"v2\": joblib.load(\"models/model_v2.pkl\"),
        \"v3\": joblib.load(\"models/model_v3.pkl\")
    }¬∑
    # A/B test configuration
    AB_CONFIG = {
        \"v1\": 0.5,   # 50% traffic
        \"v2\": 0.3,   # 30% traffic
        \"v3\": 0.2    # 20% traffic
    }¬∑
    def select_model_version(user_id: str) -> str:
        \"\"\"Deterministic A/B test assignment based on user_id\"\"\"
        # Hash user_id for consistent assignment
        hash_value = int(hashlib.md5(user_id.encode()).hexdigest(), 16)
        random_value = (hash_value % 100) / 100.0¬∑
        cumulative = 0
        for version, probability in AB_CONFIG.items():
            cumulative += probability
            if random_value < cumulative:
                return version¬∑
        return \"v1\"  # Default¬∑
    @app.post(\"/predict\")
    async def predict_ab(request: PredictionRequest, user_id: str):
        \"\"\"Prediction with A/B testing\"\"\"¬∑
        # Select model version for this user
        model_version = select_model_version(user_id)
        model = models[model_version]¬∑
        # Make prediction
        features = np.array(request.features).reshape(1, -1)
        prediction = model.predict(features)[0]¬∑
        # Log for analysis
        log_prediction(
            user_id=user_id,
            model_version=model_version,
            features=request.features,
            prediction=prediction
        )¬∑
        return {
            \"prediction\": float(prediction),
            \"model_version\": model_version,
            \"ab_test\": True
        }
    ```¬∑
    ### 3. Canary Deployment¬∑
    ```python
    # api/canary_deployment.py
    from fastapi import FastAPI
    import joblib
    import random
    from datetime import datetime, timedelta¬∑
    app = FastAPI()¬∑
    # Load models
    stable_model = joblib.load(\"models/stable_v1.pkl\")
    canary_model = joblib.load(\"models/canary_v2.pkl\")¬∑
    # Canary configuration
    CANARY_CONFIG = {
        \"enabled\": True,
        \"traffic_percentage\": 0.1,  # Start with 10%
        \"start_time\": datetime.now(),
        \"duration_hours\": 24,
        \"rollback_on_error_rate\": 0.05  # Rollback if >5% errors
    }¬∑
    # Metrics
    canary_metrics = {
        \"stable\": {\"success\": 0, \"error\": 0},
        \"canary\": {\"success\": 0, \"error\": 0}
    }¬∑
    def should_use_canary() -> bool:
        \"\"\"Decide whether to use canary model\"\"\"
        if not CANARY_CONFIG[\"enabled\"]:
            return False¬∑
        # Check if canary period has expired
        elapsed = datetime.now() - CANARY_CONFIG[\"start_time\"]
        if elapsed > timedelta(hours=CANARY_CONFIG[\"duration_hours\"]):
            return False¬∑
        # Check error rate
        canary_error_rate = (
            canary_metrics[\"canary\"][\"error\"] /
            max(sum(canary_metrics[\"canary\"].values()), 1)
        )
        if canary_error_rate > CANARY_CONFIG[\"rollback_on_error_rate\"]:
            print(\"‚ö†Ô∏è Canary error rate too high, rolling back\")
            CANARY_CONFIG[\"enabled\"] = False
            return False¬∑
        # Random traffic split
        return random.random() < CANARY_CONFIG[\"traffic_percentage\"]¬∑
    @app.post(\"/predict\")
    async def predict_canary(request: PredictionRequest):
        \"\"\"Prediction with canary deployment\"\"\"¬∑
        use_canary = should_use_canary()
        model = canary_model if use_canary else stable_model
        version = \"canary_v2\" if use_canary else \"stable_v1\"¬∑
        try:
            # Make prediction
            features = np.array(request.features).reshape(1, -1)
            prediction = model.predict(features)[0]¬∑
            # Update metrics
            metrics_key = \"canary\" if use_canary else \"stable\"
            canary_metrics[metrics_key][\"success\"] += 1¬∑
            return {
                \"prediction\": float(prediction),
                \"model_version\": version,
                \"deployment_type\": \"canary\" if use_canary else \"stable\"
            }¬∑
        except Exception as e:
            # Update error metrics
            metrics_key = \"canary\" if use_canary else \"stable\"
            canary_metrics[metrics_key][\"error\"] += 1
            raise¬∑
    @app.get(\"/canary_metrics\")
    async def get_canary_metrics():
        \"\"\"Get canary deployment metrics\"\"\"
        return {
            \"config\": CANARY_CONFIG,
            \"metrics\": canary_metrics,
            \"canary_error_rate\": (
                canary_metrics[\"canary\"][\"error\"] /
                max(sum(canary_metrics[\"canary\"].values()), 1)
            )
        }
    ```¬∑
    ---¬∑
    ## TensorFlow Serving¬∑
    ### 1. Export TensorFlow Model¬∑
    ```python
    # deployment/export_tf_model.py
    import tensorflow as tf
    from tensorflow import keras
    import os¬∑
    def export_model_for_serving(
        model: keras.Model,
        export_path: str,
        version: int = 1
    ):
        \"\"\"Export TensorFlow model for TF Serving\"\"\"¬∑
        # Create versioned directory
        model_path = os.path.join(export_path, str(version))¬∑
        # Save in SavedModel format
        tf.saved_model.save(model, model_path)¬∑
        print(f\"‚úÖ Model exported to {model_path}\")
        print(f\"Signature: {list(model.signatures.keys())}\")¬∑
    # Usage
    model = keras.models.load_model(\"models/churn_model.h5\")
    export_model_for_serving(model, export_path=\"./tf-models/churn\", version=1)¬∑
    # Directory structure:
    # tf-models/
    #   churn/
    #     1/
    #       saved_model.pb
    #       variables/
    ```¬∑
    ### 2. Deploy with Docker¬∑
    ```dockerfile
    # deployment/Dockerfile.tfserving
    FROM tensorflow/serving:latest¬∑
    # Copy model
    COPY tf-models/churn /models/churn¬∑
    # Expose ports
    EXPOSE 8500  # gRPC
    EXPOSE 8501  # REST¬∑
    # Set model name
    ENV MODEL_NAME=churn¬∑
    # Run TensorFlow Serving
    CMD [\"tensorflow_model_server\", \\
         \"--port=8500\", \\
         \"--rest_api_port=8501\", \\
         \"--model_name=${MODEL_NAME}\", \\
         \"--model_base_path=/models/${MODEL_NAME}\"]
    ```¬∑
    ```bash
    # Build and run
    docker build -t churn-model-serving -f Dockerfile.tfserving .
    docker run -p 8500:8500 -p 8501:8501 churn-model-serving¬∑
    # Test REST API
    curl -X POST http://localhost:8501/v1/models/churn:predict \\
      -H \"Content-Type: application/json\" \\
      -d '{\"instances\": [[0.5, 1.2, 3.4, 2.1]]}'
    ```¬∑
    ### 3. Client for TF Serving¬∑
    ```python
    # deployment/tf_serving_client.py
    import requests
    import grpc
    import tensorflow as tf
    from tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc
    import numpy as np¬∑
    class TFServingClient:
        \"\"\"Client for TensorFlow Serving\"\"\"¬∑
        def __init__(self, host: str = \"localhost\", rest_port: int = 8501, grpc_port: int = 8500):
            self.rest_url = f\"http://{host}:{rest_port}\"
            self.grpc_channel = grpc.insecure_channel(f\"{host}:{grpc_port}\")
            self.grpc_stub = prediction_service_pb2_grpc.PredictionServiceStub(self.grpc_channel)¬∑
        def predict_rest(self, model_name: str, instances: list, version: int = None):
            \"\"\"Predict using REST API\"\"\"
            url = f\"{self.rest_url}/v1/models/{model_name}\"
            if version:
                url += f\"/versions/{version}\"
            url += \":predict\"¬∑
            response = requests.post(url, json={\"instances\": instances})
            return response.json()¬∑
        def predict_grpc(self, model_name: str, data: np.ndarray, version: int = None):
            \"\"\"Predict using gRPC (faster)\"\"\"
            request = predict_pb2.PredictRequest()
            request.model_spec.name = model_name
            if version:
                request.model_spec.version.value = version¬∑
            request.inputs['input'].CopyFrom(
                tf.make_tensor_proto(data, dtype=tf.float32)
            )¬∑
            result = self.grpc_stub.Predict(request, timeout=10.0)
            return result¬∑
    # Usage
    client = TFServingClient()¬∑
    # REST API (easier, slower)
    result = client.predict_rest(\"churn\", instances=[[0.5, 1.2, 3.4, 2.1]])
    print(f\"Prediction: {result['predictions']}\")¬∑
    # gRPC (faster, more complex)
    data = np.array([[0.5, 1.2, 3.4, 2.1]], dtype=np.float32)
    result = client.predict_grpc(\"churn\", data)
    print(f\"Prediction: {result.outputs['output'].float_val}\")
    ```¬∑
    ---¬∑
    ## TorchServe¬∑
    ### 1. Create Model Archive¬∑
    ```python
    # deployment/torch_handler.py
    from ts.torch_handler.base_handler import BaseHandler
    import torch
    import numpy as np¬∑
    class ChurnPredictionHandler(BaseHandler):
        \"\"\"Custom TorchServe handler\"\"\"¬∑
        def preprocess(self, data):
            \"\"\"Preprocess input data\"\"\"
            features = data[0].get(\"features\")
            if features is None:
                features = data[0].get(\"body\")¬∑
            # Convert to tensor
            tensor = torch.FloatTensor(features)
            return tensor¬∑
        def inference(self, data):
            \"\"\"Run inference\"\"\"
            with torch.no_grad():
                prediction = self.model(data)
            return prediction¬∑
        def postprocess(self, inference_output):
            \"\"\"Postprocess output\"\"\"
            # Apply softmax for probabilities
            probabilities = torch.softmax(inference_output, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1)¬∑
            return [
                {
                    \"prediction\": int(predicted_class[0]),
                    \"probability\": float(probabilities[0][1]),
                    \"all_probabilities\": probabilities[0].tolist()
                }
            ]¬∑
    # Save handler
    # torch_handler.py should be in same directory as model
    ```¬∑
    ```bash
    # Create model archive (.mar file)
    torch-model-archiver \\
      --model-name churn-predictor \\
      --version 1.0 \\
      --serialized-file models/churn_model.pt \\
      --handler torch_handler.py \\
      --export-path model-store/¬∑
    # Directory structure:
    # model-store/
    #   churn-predictor.mar
    ```¬∑
    ### 2. Deploy with TorchServe¬∑
    ```yaml
    # deployment/torchserve-config.yaml
    inference_address: http://0.0.0.0:8080
    management_address: http://0.0.0.0:8081
    metrics_address: http://0.0.0.0:8082¬∑
    models:
      churn-predictor:
        1.0:
          defaultVersion: true
          marName: churn-predictor.mar
          minWorkers: 2
          maxWorkers: 4
          batchSize: 8
          maxBatchDelay: 100
          responseTimeout: 120
    ```¬∑
    ```bash
    # Start TorchServe
    torchserve --start \\
      --model-store model-store/ \\
      --models churn-predictor=churn-predictor.mar \\
      --ts-config deployment/torchserve-config.yaml¬∑
    # Test prediction
    curl -X POST http://localhost:8080/predictions/churn-predictor \\
      -H \"Content-Type: application/json\" \\
      -d '{\"features\": [0.5, 1.2, 3.4, 2.1]}'¬∑
    # Management API
    curl http://localhost:8081/models  # List models
    curl -X PUT http://localhost:8081/models/churn-predictor?min_worker=4  # Scale workers
    ```¬∑
    ---¬∑
    ## Model Monitoring¬∑
    ### Comprehensive Monitoring System¬∑
    ```python
    # monitoring/model_monitor.py
    from prometheus_client import Counter, Histogram, Gauge, Summary
    import logging
    from datetime import datetime
    from typing import Dict, Any
    import numpy as np
    from scipy import stats¬∑
    # Prometheus metrics
    prediction_latency = Histogram(
        'model_prediction_latency_seconds',
        'Model prediction latency',
        ['model_version', 'endpoint']
    )¬∑
    prediction_count = Counter(
        'model_predictions_total',
        'Total predictions',
        ['model_version', 'prediction_class', 'status']
    )¬∑
    model_accuracy = Gauge(
        'model_accuracy',
        'Model accuracy over time window',
        ['model_version', 'time_window']
    )¬∑
    feature_drift = Gauge(
        'feature_drift_score',
        'Feature distribution drift score (KS statistic)',
        ['model_version', 'feature_name']
    )¬∑
    class ModelMonitor:
        \"\"\"Comprehensive model monitoring\"\"\"¬∑
        def __init__(self, reference_data: np.ndarray, feature_names: list):
            self.reference_data = reference_data
            self.feature_names = feature_names
            self.predictions_window = []
            self.actuals_window = []¬∑
        def log_prediction(
            self,
            model_version: str,
            features: np.ndarray,
            prediction: float,
            latency: float,
            actual: float = None
        ):
            \"\"\"Log prediction with monitoring\"\"\"¬∑
            # Log latency
            prediction_latency.labels(
                model_version=model_version,
                endpoint=\"/predict\"
            ).observe(latency)¬∑
            # Log prediction count
            prediction_count.labels(
                model_version=model_version,
                prediction_class=str(int(prediction)),
                status=\"success\"
            ).inc()¬∑
            # Store for drift detection
            self.predictions_window.append((features, prediction, actual))¬∑
            # Check drift every 100 predictions
            if len(self.predictions_window) >= 100:
                self.detect_drift(model_version)
                self.predictions_window = []¬∑
        def detect_drift(self, model_version: str):
            \"\"\"Detect feature drift using KS test\"\"\"¬∑
            current_features = np.array([
                p[0] for p in self.predictions_window
            ])¬∑
            for i, feature_name in enumerate(self.feature_names):
                # Kolmogorov-Smirnov test
                ks_statistic, p_value = stats.ks_2samp(
                    self.reference_data[:, i],
                    current_features[:, i]
                )¬∑
                # Log drift metric
                feature_drift.labels(
                    model_version=model_version,
                    feature_name=feature_name
                ).set(ks_statistic)¬∑
                # Alert if significant drift (p < 0.05)
                if p_value < 0.05:
                    logging.warning(
                        f\"‚ö†Ô∏è Feature drift detected: {feature_name} \"
                        f\"(KS={ks_statistic:.4f}, p={p_value:.4f})\"
                    )¬∑
        def calculate_accuracy(self, model_version: str, time_window: str = \"1h\"):
            \"\"\"Calculate model accuracy over time window\"\"\"¬∑
            # Filter predictions with actuals
            predictions_with_actuals = [
                (p[1], p[2])
                for p in self.predictions_window
                if p[2] is not None
            ]¬∑
            if not predictions_with_actuals:
                return¬∑
            predictions, actuals = zip(*predictions_with_actuals)
            accuracy = np.mean(np.array(predictions) == np.array(actuals))¬∑
            # Log accuracy metric
            model_accuracy.labels(
                model_version=model_version,
                time_window=time_window
            ).set(accuracy)¬∑
    # Usage
    monitor = ModelMonitor(
        reference_data=training_features,
        feature_names=['age', 'tenure', 'usage', 'revenue']
    )¬∑
    # In prediction endpoint
    start_time = time.time()
    prediction = model.predict(features)
    latency = time.time() - start_time¬∑
    monitor.log_prediction(
        model_version=\"v1\",
        features=features,
        prediction=prediction,
        latency=latency,
        actual=None  # Set when feedback received
    )
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `deploy-model.sh` - Deploy model to production
    - `rollback-model.sh` - Rollback to previous model version
    - `benchmark-inference.py` - Benchmark model inference performance¬∑
    ### references/
    - `references/tf-serving-guide.md` - TensorFlow Serving setup and configuration
    - `references/torchserve-guide.md` - TorchServe deployment patterns
    - `references/monitoring-dashboards.md` - Grafana dashboard templates
    - `references/ab-testing-methodology.md` - Statistical A/B testing for models¬∑
    ### assets/
    - `assets/docker-compose/` - Docker Compose files for model serving
    - `assets/k8s-manifests/` - Kubernetes deployment manifests
    - `assets/grafana-dashboards/` - Grafana JSON dashboards¬∑
    ## Related Skills¬∑
    - `ml-pipelines` - Training models for deployment
    - `microservices` - Model as microservice pattern
    - `serverless` - Serverless model deployment
    - `testing-strategies` - Model testing and validation
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ workflow-orchestration ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: workflow-orchestration
    description: Multi-agent workflows, handoff patterns, state management. Use when coordinating multiple agents, implementing handoff protocols, managing workflow state, or building complex multi-step agent systems. Covers OPERA methodology, agent contracts, state persistence, and error recovery. Enables 3x faster multi-agent development.
    ---¬∑
    # Workflow Orchestration¬∑
    ## Overview¬∑
    Multi-agent workflow orchestration using OPERA (Orchestration Protocol for Engineering and Research Agents) methodology. Covers agent handoffs, state management, contract validation, and error recovery for complex multi-agent systems.¬∑
    **Goal**: Build reliable multi-agent workflows with 95%+ handoff success rate and complete state recovery¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Coordinating multiple OPERA agents (Alex-BA, Marcus-Backend, James-Frontend, etc.)
    - Implementing agent handoff protocols
    - Managing workflow state across agents
    - Building complex multi-step workflows (planning ‚Üí implementation ‚Üí testing)
    - Creating custom agent orchestration patterns
    - Debugging agent handoff failures
    - Implementing workflow error recovery¬∑
    **Triggers**: \"agent handoff\", \"workflow orchestration\", \"OPERA\", \"multi-agent\", \"agent coordination\", \"state management\", \"handoff contract\"¬∑
    ---¬∑
    ## Quick Start: Workflow Pattern Decision Tree¬∑
    ### Choosing the Right Orchestration Pattern¬∑
    **Sequential Handoff** (Agent A ‚Üí Agent B ‚Üí Agent C):
    - ‚úÖ Linear workflow with clear dependencies
    - ‚úÖ Each agent depends on previous output
    - ‚úÖ Example: Plan (Sarah-PM) ‚Üí Design (James-Frontend) ‚Üí Implement (Marcus-Backend)
    - ‚úÖ Best for: Feature development, documentation flows¬∑
    **Parallel Execution** (Multiple agents simultaneously):
    - ‚úÖ Independent tasks that can run concurrently
    - ‚úÖ Results merged at the end
    - ‚úÖ Example: Frontend (James) + Backend (Marcus) + Database (Dana) in parallel
    - ‚úÖ Best for: Full-stack features, large refactors¬∑
    **Conditional Routing** (If/else agent selection):
    - ‚úÖ Agent selection based on context
    - ‚úÖ Example: If frontend ‚Üí James, If backend ‚Üí Marcus, If ML ‚Üí Dr.AI-ML
    - ‚úÖ Best for: Auto-routing based on file types, adaptive workflows¬∑
    **Feedback Loop** (Agent A ‚Üí Agent B ‚Üí back to Agent A):
    - ‚úÖ Iterative refinement needed
    - ‚úÖ Example: Maria-QA finds issues ‚Üí Marcus fixes ‚Üí Maria re-validates
    - ‚úÖ Best for: Quality assurance, code review cycles¬∑
    **Hub-and-Spoke** (Coordinator ‚Üí Multiple specialists):
    - ‚úÖ Central coordinator delegates to specialists
    - ‚úÖ Example: Sarah-PM coordinates Alex-BA + Marcus + James + Maria
    - ‚úÖ Best for: Complex projects, project management¬∑
    ---¬∑
    ## OPERA Handoff Protocol¬∑
    ### 1. Handoff Contract Schema¬∑
    ```typescript
    // orchestration/contracts/handoff-contract.ts
    import { z } from 'zod';¬∑
    /**
     * Standard OPERA handoff contract
     * All agent handoffs must conform to this schema
     */
    export const HandoffContractSchema = z.object({
      // Handoff metadata
      handoff_id: z.string().uuid(),
      timestamp: z.string().datetime(),¬∑
      // Source agent
      from_agent: z.object({
        name: z.enum([
          'alex-ba',
          'marcus-backend',
          'james-frontend',
          'dana-database',
          'maria-qa',
          'dr-ai-ml',
          'sarah-pm',
          'oliver-mcp'
        ]),
        version: z.string(),
        phase: z.enum(['PLAN', 'DESIGN', 'BUILD', 'TEST', 'DEPLOY', 'CODIFY'])
      }),¬∑
      // Target agent
      to_agent: z.object({
        name: z.string(),
        required_capabilities: z.array(z.string()).optional(),
        priority: z.enum(['p0', 'p1', 'p2', 'p3']).default('p1')
      }),¬∑
      // Handoff payload
      payload: z.object({
        // Context from previous work
        context: z.object({
          feature_description: z.string(),
          previous_decisions: z.array(z.string()).optional(),
          constraints: z.array(z.string()).optional(),
          dependencies: z.array(z.string()).optional()
        }),¬∑
        // Work artifacts
        artifacts: z.array(z.object({
          type: z.enum(['code', 'design', 'documentation', 'test', 'data']),
          path: z.string(),
          description: z.string(),
          format: z.string().optional()
        })).optional(),¬∑
        // Expected output
        expected_output: z.object({
          deliverables: z.array(z.string()),
          acceptance_criteria: z.array(z.string()),
          estimated_effort_hours: z.number().optional()
        }),¬∑
        // Continuation conditions
        on_success: z.object({
          next_agent: z.string().optional(),
          action: z.enum(['handoff', 'complete', 'loop'])
        }),¬∑
        on_failure: z.object({
          retry_strategy: z.enum(['retry', 'rollback', 'escalate']),
          fallback_agent: z.string().optional(),
          max_retries: z.number().default(3)
        })
      }),¬∑
      // State management
      state: z.object({
        workflow_id: z.string(),
        current_phase: z.string(),
        completed_phases: z.array(z.string()),
        shared_memory: z.record(z.any()).optional()
      })
    });¬∑
    export type HandoffContract = z.infer<typeof HandoffContractSchema>;
    ```¬∑
    ### 2. Handoff Manager¬∑
    ```typescript
    // orchestration/handoff-manager.ts
    import { HandoffContract, HandoffContractSchema } from './contracts/handoff-contract.js';
    import { v4 as uuidv4 } from 'uuid';
    import { promises as fs } from 'fs';
    import path from 'path';¬∑
    export class HandoffManager {
      private stateDir: string;¬∑
      constructor(stateDir: string = '.versatil/state') {
        this.stateDir = stateDir;
      }¬∑
      /**
       * Create a new handoff contract
       */
      async createHandoff(params: {
        fromAgent: string;
        toAgent: string;
        context: any;
        expectedOutput: any;
        workflowId: string;
      }): Promise<HandoffContract> {
        const contract: HandoffContract = {
          handoff_id: uuidv4(),
          timestamp: new Date().toISOString(),¬∑
          from_agent: {
            name: params.fromAgent as any,
            version: '1.0.0',
            phase: this.detectPhase(params.fromAgent)
          },¬∑
          to_agent: {
            name: params.toAgent,
            priority: 'p1'
          },¬∑
          payload: {
            context: params.context,
            expected_output: params.expectedOutput,
            on_success: { action: 'handoff' },
            on_failure: { retry_strategy: 'retry', max_retries: 3 }
          },¬∑
          state: {
            workflow_id: params.workflowId,
            current_phase: this.detectPhase(params.fromAgent),
            completed_phases: []
          }
        };¬∑
        // Validate contract
        HandoffContractSchema.parse(contract);¬∑
        // Persist to disk
        await this.saveHandoff(contract);¬∑
        console.log(`‚úÖ Handoff created: ${params.fromAgent} ‚Üí ${params.toAgent}`);
        return contract;
      }¬∑
      /**
       * Execute handoff to target agent
       */
      async executeHandoff(contract: HandoffContract): Promise<void> {
        console.log(`üîÑ Executing handoff: ${contract.from_agent.name} ‚Üí ${contract.to_agent.name}`);¬∑
        // Load target agent
        const agent = await this.loadAgent(contract.to_agent.name);¬∑
        // Pass contract to agent
        try {
          await agent.execute(contract);¬∑
          // Update state on success
          await this.updateHandoffStatus(contract.handoff_id, 'completed');¬∑
          // Handle on_success action
          if (contract.payload.on_success.next_agent) {
            await this.createHandoff({
              fromAgent: contract.to_agent.name,
              toAgent: contract.payload.on_success.next_agent,
              context: { ...contract.payload.context },
              expectedOutput: contract.payload.expected_output,
              workflowId: contract.state.workflow_id
            });
          }¬∑
        } catch (error) {
          console.error(`‚ùå Handoff failed: ${error.message}`);¬∑
          // Handle on_failure strategy
          await this.handleFailure(contract, error);
        }
      }¬∑
      /**
       * Handle handoff failure
       */
      private async handleFailure(contract: HandoffContract, error: Error): Promise<void> {
        const { retry_strategy, max_retries, fallback_agent } = contract.payload.on_failure;¬∑
        // Check retry count
        const retryCount = await this.getRetryCount(contract.handoff_id);¬∑
        if (retry_strategy === 'retry' && retryCount < max_retries) {
          console.log(`üîÑ Retrying handoff (attempt ${retryCount + 1}/${max_retries})`);
          await this.incrementRetryCount(contract.handoff_id);
          await this.executeHandoff(contract);¬∑
        } else if (retry_strategy === 'rollback') {
          console.log('‚Ü©Ô∏è Rolling back to previous agent');
          await this.rollbackToPreviousAgent(contract);¬∑
        } else if (retry_strategy === 'escalate' && fallback_agent) {
          console.log(`‚¨ÜÔ∏è Escalating to fallback agent: ${fallback_agent}`);
          contract.to_agent.name = fallback_agent;
          await this.executeHandoff(contract);¬∑
        } else {
          // Final failure
          await this.updateHandoffStatus(contract.handoff_id, 'failed');
          throw new Error(`Handoff failed after ${retryCount} retries: ${error.message}`);
        }
      }¬∑
      /**
       * Detect phase from agent name
       */
      private detectPhase(agentName: string): 'PLAN' | 'DESIGN' | 'BUILD' | 'TEST' | 'DEPLOY' | 'CODIFY' {
        const phaseMap: Record<string, any> = {
          'sarah-pm': 'PLAN',
          'alex-ba': 'PLAN',
          'james-frontend': 'BUILD',
          'marcus-backend': 'BUILD',
          'dana-database': 'BUILD',
          'maria-qa': 'TEST',
          'oliver-mcp': 'DEPLOY'
        };
        return phaseMap[agentName] || 'BUILD';
      }¬∑
      /**
       * Save handoff to disk
       */
      private async saveHandoff(contract: HandoffContract): Promise<void> {
        const filePath = path.join(this.stateDir, 'handoffs', `${contract.handoff_id}.json`);
        await fs.mkdir(path.dirname(filePath), { recursive: true });
        await fs.writeFile(filePath, JSON.stringify(contract, null, 2));
      }¬∑
      /**
       * Load agent by name
       */
      private async loadAgent(agentName: string): Promise<any> {
        // Load agent definition from .claude/agents/{agentName}.md
        const agentPath = path.join('.claude', 'agents', `${agentName}.md`);
        const agentDef = await fs.readFile(agentPath, 'utf-8');¬∑
        // Return agent interface
        return {
          name: agentName,
          execute: async (contract: HandoffContract) => {
            // Agent execution logic
            console.log(`Executing agent: ${agentName}`);
          }
        };
      }¬∑
      private async updateHandoffStatus(handoffId: string, status: string): Promise<void> {
        // Implementation
      }¬∑
      private async getRetryCount(handoffId: string): Promise<number> {
        // Implementation
        return 0;
      }¬∑
      private async incrementRetryCount(handoffId: string): Promise<void> {
        // Implementation
      }¬∑
      private async rollbackToPreviousAgent(contract: HandoffContract): Promise<void> {
        // Implementation
      }
    }¬∑
    // Usage
    const manager = new HandoffManager();¬∑
    const handoff = await manager.createHandoff({
      fromAgent: 'sarah-pm',
      toAgent: 'marcus-backend',
      context: {
        feature_description: 'Add user authentication API',
        constraints: ['Use JWT tokens', 'OAuth2 support']
      },
      expectedOutput: {
        deliverables: ['auth-api.ts', 'auth.test.ts'],
        acceptance_criteria: ['80%+ test coverage', 'Security audit passed']
      },
      workflowId: 'workflow-123'
    });¬∑
    await manager.executeHandoff(handoff);
    ```¬∑
    ---¬∑
    ## Workflow State Management¬∑
    ### Persistent State Store¬∑
    ```typescript
    // orchestration/state/workflow-state.ts
    import { promises as fs } from 'fs';
    import path from 'path';¬∑
    export interface WorkflowState {
      workflow_id: string;
      started_at: string;
      updated_at: string;
      status: 'pending' | 'in_progress' | 'completed' | 'failed';¬∑
      // Workflow definition
      workflow: {
        name: string;
        phases: string[];
        current_phase: string;
        completed_phases: string[];
      };¬∑
      // Agents involved
      agents: {
        name: string;
        status: 'pending' | 'in_progress' | 'completed' | 'failed';
        started_at?: string;
        completed_at?: string;
      }[];¬∑
      // Shared memory (cross-agent data)
      memory: Record<string, any>;¬∑
      // Artifacts produced
      artifacts: {
        agent: string;
        type: string;
        path: string;
        created_at: string;
      }[];
    }¬∑
    export class WorkflowStateManager {
      private stateDir: string;¬∑
      constructor(stateDir: string = '.versatil/state/workflows') {
        this.stateDir = stateDir;
      }¬∑
      /**
       * Create new workflow state
       */
      async createWorkflow(params: {
        name: string;
        phases: string[];
      }): Promise<WorkflowState> {
        const workflowId = `workflow-${Date.now()}`;¬∑
        const state: WorkflowState = {
          workflow_id: workflowId,
          started_at: new Date().toISOString(),
          updated_at: new Date().toISOString(),
          status: 'pending',¬∑
          workflow: {
            name: params.name,
            phases: params.phases,
            current_phase: params.phases[0],
            completed_phases: []
          },¬∑
          agents: [],
          memory: {},
          artifacts: []
        };¬∑
        await this.saveState(state);
        return state;
      }¬∑
      /**
       * Update workflow state
       */
      async updateWorkflow(
        workflowId: string,
        updates: Partial<WorkflowState>
      ): Promise<WorkflowState> {
        const state = await this.loadState(workflowId);¬∑
        const updatedState = {
          ...state,
          ...updates,
          updated_at: new Date().toISOString()
        };¬∑
        await this.saveState(updatedState);
        return updatedState;
      }¬∑
      /**
       * Store value in shared memory
       */
      async setMemory(
        workflowId: string,
        key: string,
        value: any
      ): Promise<void> {
        const state = await this.loadState(workflowId);
        state.memory[key] = value;
        await this.saveState(state);
      }¬∑
      /**
       * Retrieve value from shared memory
       */
      async getMemory(workflowId: string, key: string): Promise<any> {
        const state = await this.loadState(workflowId);
        return state.memory[key];
      }¬∑
      /**
       * Add artifact to workflow
       */
      async addArtifact(
        workflowId: string,
        artifact: { agent: string; type: string; path: string }
      ): Promise<void> {
        const state = await this.loadState(workflowId);¬∑
        state.artifacts.push({
          ...artifact,
          created_at: new Date().toISOString()
        });¬∑
        await this.saveState(state);
      }¬∑
      /**
       * Mark phase as complete
       */
      async completePhase(workflowId: string, phase: string): Promise<void> {
        const state = await this.loadState(workflowId);¬∑
        state.workflow.completed_phases.push(phase);¬∑
        // Move to next phase
        const currentIndex = state.workflow.phases.indexOf(phase);
        if (currentIndex < state.workflow.phases.length - 1) {
          state.workflow.current_phase = state.workflow.phases[currentIndex + 1];
        } else {
          // All phases complete
          state.status = 'completed';
        }¬∑
        await this.saveState(state);
      }¬∑
      private async saveState(state: WorkflowState): Promise<void> {
        const filePath = path.join(this.stateDir, `${state.workflow_id}.json`);
        await fs.mkdir(this.stateDir, { recursive: true });
        await fs.writeFile(filePath, JSON.stringify(state, null, 2));
      }¬∑
      private async loadState(workflowId: string): Promise<WorkflowState> {
        const filePath = path.join(this.stateDir, `${workflowId}.json`);
        const content = await fs.readFile(filePath, 'utf-8');
        return JSON.parse(content);
      }
    }¬∑
    // Usage
    const stateManager = new WorkflowStateManager();¬∑
    // Create workflow
    const workflow = await stateManager.createWorkflow({
      name: 'user-auth-feature',
      phases: ['PLAN', 'BUILD', 'TEST', 'DEPLOY']
    });¬∑
    // Store shared data
    await stateManager.setMemory(workflow.workflow_id, 'api_endpoint', '/api/auth');¬∑
    // Add artifact
    await stateManager.addArtifact(workflow.workflow_id, {
      agent: 'marcus-backend',
      type: 'code',
      path: 'src/api/auth.ts'
    });¬∑
    // Complete phase
    await stateManager.completePhase(workflow.workflow_id, 'PLAN');
    ```¬∑
    ---¬∑
    ## Workflow Patterns¬∑
    ### Sequential Workflow¬∑
    ```typescript
    // orchestration/patterns/sequential.ts
    import { HandoffManager } from '../handoff-manager.js';
    import { WorkflowStateManager } from '../state/workflow-state.js';¬∑
    export class SequentialWorkflow {
      private handoffManager: HandoffManager;
      private stateManager: WorkflowStateManager;¬∑
      constructor() {
        this.handoffManager = new HandoffManager();
        this.stateManager = new WorkflowStateManager();
      }¬∑
      /**
       * Execute sequential workflow: A ‚Üí B ‚Üí C
       */
      async execute(steps: {
        agent: string;
        context: any;
        expectedOutput: any;
      }[]): Promise<void> {
        // Create workflow
        const workflow = await this.stateManager.createWorkflow({
          name: 'sequential-workflow',
          phases: steps.map((_, i) => `step-${i + 1}`)
        });¬∑
        console.log(`üöÄ Starting sequential workflow: ${steps.length} steps`);¬∑
        // Execute steps sequentially
        for (let i = 0; i < steps.length; i++) {
          const step = steps[i];
          const nextStep = steps[i + 1];¬∑
          console.log(`üìç Step ${i + 1}/${steps.length}: ${step.agent}`);¬∑
          // Create handoff
          const handoff = await this.handoffManager.createHandoff({
            fromAgent: i === 0 ? 'system' : steps[i - 1].agent,
            toAgent: step.agent,
            context: step.context,
            expectedOutput: step.expectedOutput,
            workflowId: workflow.workflow_id
          });¬∑
          // Execute handoff
          await this.handoffManager.executeHandoff(handoff);¬∑
          // Mark phase complete
          await this.stateManager.completePhase(workflow.workflow_id, `step-${i + 1}`);
        }¬∑
        console.log('‚úÖ Sequential workflow completed');
      }
    }¬∑
    // Usage
    const workflow = new SequentialWorkflow();¬∑
    await workflow.execute([
      {
        agent: 'alex-ba',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['requirements.md'] }
      },
      {
        agent: 'marcus-backend',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['auth-api.ts'] }
      },
      {
        agent: 'maria-qa',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['auth.test.ts'] }
      }
    ]);
    ```¬∑
    ### Parallel Workflow¬∑
    ```typescript
    // orchestration/patterns/parallel.ts
    export class ParallelWorkflow {
      private handoffManager: HandoffManager;
      private stateManager: WorkflowStateManager;¬∑
      /**
       * Execute parallel workflow: A + B + C simultaneously
       */
      async execute(tasks: {
        agent: string;
        context: any;
        expectedOutput: any;
      }[]): Promise<void> {
        const workflow = await this.stateManager.createWorkflow({
          name: 'parallel-workflow',
          phases: ['execute', 'merge']
        });¬∑
        console.log(`üöÄ Starting parallel workflow: ${tasks.length} tasks`);¬∑
        // Create handoffs for all tasks
        const handoffPromises = tasks.map(task =>
          this.handoffManager.createHandoff({
            fromAgent: 'system',
            toAgent: task.agent,
            context: task.context,
            expectedOutput: task.expectedOutput,
            workflowId: workflow.workflow_id
          })
        );¬∑
        const handoffs = await Promise.all(handoffPromises);¬∑
        // Execute all in parallel
        const executionPromises = handoffs.map(handoff =>
          this.handoffManager.executeHandoff(handoff)
        );¬∑
        await Promise.all(executionPromises);¬∑
        console.log('‚úÖ Parallel workflow completed');
      }
    }¬∑
    // Usage
    const workflow = new ParallelWorkflow();¬∑
    await workflow.execute([
      {
        agent: 'james-frontend',
        context: { component: 'LoginForm' },
        expectedOutput: { deliverables: ['LoginForm.tsx'] }
      },
      {
        agent: 'marcus-backend',
        context: { endpoint: 'POST /auth/login' },
        expectedOutput: { deliverables: ['auth-api.ts'] }
      },
      {
        agent: 'dana-database',
        context: { table: 'users' },
        expectedOutput: { deliverables: ['migration-001-users.sql'] }
      }
    ]);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `execute-workflow.ts` - Run pre-defined workflows
    - `validate-handoff.ts` - Validate handoff contracts
    - `recover-workflow.ts` - Recover failed workflows¬∑
    ### references/
    - `references/opera-methodology.md` - Complete OPERA protocol specification
    - `references/handoff-patterns.md` - Common handoff patterns
    - `references/state-management.md` - State persistence best practices¬∑
    ### assets/
    - `assets/workflow-templates/` - Pre-built workflow templates
    - `assets/handoff-schemas/` - JSON schemas for contracts¬∑
    ## Related Skills¬∑
    - `opera-orchestration` - OPERA agent system architecture
    - `cross-domain-patterns` - Full-stack multi-agent patterns
    - `quality-gates` - Contract validation in workflows
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ workflow-orchestration ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: workflow-orchestration
    description: Multi-agent workflows, handoff patterns, state management. Use when coordinating multiple agents, implementing handoff protocols, managing workflow state, or building complex multi-step agent systems. Covers OPERA methodology, agent contracts, state persistence, and error recovery. Enables 3x faster multi-agent development.
    ---¬∑
    # Workflow Orchestration¬∑
    ## Overview¬∑
    Multi-agent workflow orchestration using OPERA (Orchestration Protocol for Engineering and Research Agents) methodology. Covers agent handoffs, state management, contract validation, and error recovery for complex multi-agent systems.¬∑
    **Goal**: Build reliable multi-agent workflows with 95%+ handoff success rate and complete state recovery¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Coordinating multiple OPERA agents (Alex-BA, Marcus-Backend, James-Frontend, etc.)
    - Implementing agent handoff protocols
    - Managing workflow state across agents
    - Building complex multi-step workflows (planning ‚Üí implementation ‚Üí testing)
    - Creating custom agent orchestration patterns
    - Debugging agent handoff failures
    - Implementing workflow error recovery¬∑
    **Triggers**: \"agent handoff\", \"workflow orchestration\", \"OPERA\", \"multi-agent\", \"agent coordination\", \"state management\", \"handoff contract\"¬∑
    ---¬∑
    ## Quick Start: Workflow Pattern Decision Tree¬∑
    ### Choosing the Right Orchestration Pattern¬∑
    **Sequential Handoff** (Agent A ‚Üí Agent B ‚Üí Agent C):
    - ‚úÖ Linear workflow with clear dependencies
    - ‚úÖ Each agent depends on previous output
    - ‚úÖ Example: Plan (Sarah-PM) ‚Üí Design (James-Frontend) ‚Üí Implement (Marcus-Backend)
    - ‚úÖ Best for: Feature development, documentation flows¬∑
    **Parallel Execution** (Multiple agents simultaneously):
    - ‚úÖ Independent tasks that can run concurrently
    - ‚úÖ Results merged at the end
    - ‚úÖ Example: Frontend (James) + Backend (Marcus) + Database (Dana) in parallel
    - ‚úÖ Best for: Full-stack features, large refactors¬∑
    **Conditional Routing** (If/else agent selection):
    - ‚úÖ Agent selection based on context
    - ‚úÖ Example: If frontend ‚Üí James, If backend ‚Üí Marcus, If ML ‚Üí Dr.AI-ML
    - ‚úÖ Best for: Auto-routing based on file types, adaptive workflows¬∑
    **Feedback Loop** (Agent A ‚Üí Agent B ‚Üí back to Agent A):
    - ‚úÖ Iterative refinement needed
    - ‚úÖ Example: Maria-QA finds issues ‚Üí Marcus fixes ‚Üí Maria re-validates
    - ‚úÖ Best for: Quality assurance, code review cycles¬∑
    **Hub-and-Spoke** (Coordinator ‚Üí Multiple specialists):
    - ‚úÖ Central coordinator delegates to specialists
    - ‚úÖ Example: Sarah-PM coordinates Alex-BA + Marcus + James + Maria
    - ‚úÖ Best for: Complex projects, project management¬∑
    ---¬∑
    ## OPERA Handoff Protocol¬∑
    ### 1. Handoff Contract Schema¬∑
    ```typescript
    // orchestration/contracts/handoff-contract.ts
    import { z } from 'zod';¬∑
    /**
     * Standard OPERA handoff contract
     * All agent handoffs must conform to this schema
     */
    export const HandoffContractSchema = z.object({
      // Handoff metadata
      handoff_id: z.string().uuid(),
      timestamp: z.string().datetime(),¬∑
      // Source agent
      from_agent: z.object({
        name: z.enum([
          'alex-ba',
          'marcus-backend',
          'james-frontend',
          'dana-database',
          'maria-qa',
          'dr-ai-ml',
          'sarah-pm',
          'oliver-mcp'
        ]),
        version: z.string(),
        phase: z.enum(['PLAN', 'DESIGN', 'BUILD', 'TEST', 'DEPLOY', 'CODIFY'])
      }),¬∑
      // Target agent
      to_agent: z.object({
        name: z.string(),
        required_capabilities: z.array(z.string()).optional(),
        priority: z.enum(['p0', 'p1', 'p2', 'p3']).default('p1')
      }),¬∑
      // Handoff payload
      payload: z.object({
        // Context from previous work
        context: z.object({
          feature_description: z.string(),
          previous_decisions: z.array(z.string()).optional(),
          constraints: z.array(z.string()).optional(),
          dependencies: z.array(z.string()).optional()
        }),¬∑
        // Work artifacts
        artifacts: z.array(z.object({
          type: z.enum(['code', 'design', 'documentation', 'test', 'data']),
          path: z.string(),
          description: z.string(),
          format: z.string().optional()
        })).optional(),¬∑
        // Expected output
        expected_output: z.object({
          deliverables: z.array(z.string()),
          acceptance_criteria: z.array(z.string()),
          estimated_effort_hours: z.number().optional()
        }),¬∑
        // Continuation conditions
        on_success: z.object({
          next_agent: z.string().optional(),
          action: z.enum(['handoff', 'complete', 'loop'])
        }),¬∑
        on_failure: z.object({
          retry_strategy: z.enum(['retry', 'rollback', 'escalate']),
          fallback_agent: z.string().optional(),
          max_retries: z.number().default(3)
        })
      }),¬∑
      // State management
      state: z.object({
        workflow_id: z.string(),
        current_phase: z.string(),
        completed_phases: z.array(z.string()),
        shared_memory: z.record(z.any()).optional()
      })
    });¬∑
    export type HandoffContract = z.infer<typeof HandoffContractSchema>;
    ```¬∑
    ### 2. Handoff Manager¬∑
    ```typescript
    // orchestration/handoff-manager.ts
    import { HandoffContract, HandoffContractSchema } from './contracts/handoff-contract.js';
    import { v4 as uuidv4 } from 'uuid';
    import { promises as fs } from 'fs';
    import path from 'path';¬∑
    export class HandoffManager {
      private stateDir: string;¬∑
      constructor(stateDir: string = '.versatil/state') {
        this.stateDir = stateDir;
      }¬∑
      /**
       * Create a new handoff contract
       */
      async createHandoff(params: {
        fromAgent: string;
        toAgent: string;
        context: any;
        expectedOutput: any;
        workflowId: string;
      }): Promise<HandoffContract> {
        const contract: HandoffContract = {
          handoff_id: uuidv4(),
          timestamp: new Date().toISOString(),¬∑
          from_agent: {
            name: params.fromAgent as any,
            version: '1.0.0',
            phase: this.detectPhase(params.fromAgent)
          },¬∑
          to_agent: {
            name: params.toAgent,
            priority: 'p1'
          },¬∑
          payload: {
            context: params.context,
            expected_output: params.expectedOutput,
            on_success: { action: 'handoff' },
            on_failure: { retry_strategy: 'retry', max_retries: 3 }
          },¬∑
          state: {
            workflow_id: params.workflowId,
            current_phase: this.detectPhase(params.fromAgent),
            completed_phases: []
          }
        };¬∑
        // Validate contract
        HandoffContractSchema.parse(contract);¬∑
        // Persist to disk
        await this.saveHandoff(contract);¬∑
        console.log(`‚úÖ Handoff created: ${params.fromAgent} ‚Üí ${params.toAgent}`);
        return contract;
      }¬∑
      /**
       * Execute handoff to target agent
       */
      async executeHandoff(contract: HandoffContract): Promise<void> {
        console.log(`üîÑ Executing handoff: ${contract.from_agent.name} ‚Üí ${contract.to_agent.name}`);¬∑
        // Load target agent
        const agent = await this.loadAgent(contract.to_agent.name);¬∑
        // Pass contract to agent
        try {
          await agent.execute(contract);¬∑
          // Update state on success
          await this.updateHandoffStatus(contract.handoff_id, 'completed');¬∑
          // Handle on_success action
          if (contract.payload.on_success.next_agent) {
            await this.createHandoff({
              fromAgent: contract.to_agent.name,
              toAgent: contract.payload.on_success.next_agent,
              context: { ...contract.payload.context },
              expectedOutput: contract.payload.expected_output,
              workflowId: contract.state.workflow_id
            });
          }¬∑
        } catch (error) {
          console.error(`‚ùå Handoff failed: ${error.message}`);¬∑
          // Handle on_failure strategy
          await this.handleFailure(contract, error);
        }
      }¬∑
      /**
       * Handle handoff failure
       */
      private async handleFailure(contract: HandoffContract, error: Error): Promise<void> {
        const { retry_strategy, max_retries, fallback_agent } = contract.payload.on_failure;¬∑
        // Check retry count
        const retryCount = await this.getRetryCount(contract.handoff_id);¬∑
        if (retry_strategy === 'retry' && retryCount < max_retries) {
          console.log(`üîÑ Retrying handoff (attempt ${retryCount + 1}/${max_retries})`);
          await this.incrementRetryCount(contract.handoff_id);
          await this.executeHandoff(contract);¬∑
        } else if (retry_strategy === 'rollback') {
          console.log('‚Ü©Ô∏è Rolling back to previous agent');
          await this.rollbackToPreviousAgent(contract);¬∑
        } else if (retry_strategy === 'escalate' && fallback_agent) {
          console.log(`‚¨ÜÔ∏è Escalating to fallback agent: ${fallback_agent}`);
          contract.to_agent.name = fallback_agent;
          await this.executeHandoff(contract);¬∑
        } else {
          // Final failure
          await this.updateHandoffStatus(contract.handoff_id, 'failed');
          throw new Error(`Handoff failed after ${retryCount} retries: ${error.message}`);
        }
      }¬∑
      /**
       * Detect phase from agent name
       */
      private detectPhase(agentName: string): 'PLAN' | 'DESIGN' | 'BUILD' | 'TEST' | 'DEPLOY' | 'CODIFY' {
        const phaseMap: Record<string, any> = {
          'sarah-pm': 'PLAN',
          'alex-ba': 'PLAN',
          'james-frontend': 'BUILD',
          'marcus-backend': 'BUILD',
          'dana-database': 'BUILD',
          'maria-qa': 'TEST',
          'oliver-mcp': 'DEPLOY'
        };
        return phaseMap[agentName] || 'BUILD';
      }¬∑
      /**
       * Save handoff to disk
       */
      private async saveHandoff(contract: HandoffContract): Promise<void> {
        const filePath = path.join(this.stateDir, 'handoffs', `${contract.handoff_id}.json`);
        await fs.mkdir(path.dirname(filePath), { recursive: true });
        await fs.writeFile(filePath, JSON.stringify(contract, null, 2));
      }¬∑
      /**
       * Load agent by name
       */
      private async loadAgent(agentName: string): Promise<any> {
        // Load agent definition from .claude/agents/{agentName}.md
        const agentPath = path.join('.claude', 'agents', `${agentName}.md`);
        const agentDef = await fs.readFile(agentPath, 'utf-8');¬∑
        // Return agent interface
        return {
          name: agentName,
          execute: async (contract: HandoffContract) => {
            // Agent execution logic
            console.log(`Executing agent: ${agentName}`);
          }
        };
      }¬∑
      private async updateHandoffStatus(handoffId: string, status: string): Promise<void> {
        // Implementation
      }¬∑
      private async getRetryCount(handoffId: string): Promise<number> {
        // Implementation
        return 0;
      }¬∑
      private async incrementRetryCount(handoffId: string): Promise<void> {
        // Implementation
      }¬∑
      private async rollbackToPreviousAgent(contract: HandoffContract): Promise<void> {
        // Implementation
      }
    }¬∑
    // Usage
    const manager = new HandoffManager();¬∑
    const handoff = await manager.createHandoff({
      fromAgent: 'sarah-pm',
      toAgent: 'marcus-backend',
      context: {
        feature_description: 'Add user authentication API',
        constraints: ['Use JWT tokens', 'OAuth2 support']
      },
      expectedOutput: {
        deliverables: ['auth-api.ts', 'auth.test.ts'],
        acceptance_criteria: ['80%+ test coverage', 'Security audit passed']
      },
      workflowId: 'workflow-123'
    });¬∑
    await manager.executeHandoff(handoff);
    ```¬∑
    ---¬∑
    ## Workflow State Management¬∑
    ### Persistent State Store¬∑
    ```typescript
    // orchestration/state/workflow-state.ts
    import { promises as fs } from 'fs';
    import path from 'path';¬∑
    export interface WorkflowState {
      workflow_id: string;
      started_at: string;
      updated_at: string;
      status: 'pending' | 'in_progress' | 'completed' | 'failed';¬∑
      // Workflow definition
      workflow: {
        name: string;
        phases: string[];
        current_phase: string;
        completed_phases: string[];
      };¬∑
      // Agents involved
      agents: {
        name: string;
        status: 'pending' | 'in_progress' | 'completed' | 'failed';
        started_at?: string;
        completed_at?: string;
      }[];¬∑
      // Shared memory (cross-agent data)
      memory: Record<string, any>;¬∑
      // Artifacts produced
      artifacts: {
        agent: string;
        type: string;
        path: string;
        created_at: string;
      }[];
    }¬∑
    export class WorkflowStateManager {
      private stateDir: string;¬∑
      constructor(stateDir: string = '.versatil/state/workflows') {
        this.stateDir = stateDir;
      }¬∑
      /**
       * Create new workflow state
       */
      async createWorkflow(params: {
        name: string;
        phases: string[];
      }): Promise<WorkflowState> {
        const workflowId = `workflow-${Date.now()}`;¬∑
        const state: WorkflowState = {
          workflow_id: workflowId,
          started_at: new Date().toISOString(),
          updated_at: new Date().toISOString(),
          status: 'pending',¬∑
          workflow: {
            name: params.name,
            phases: params.phases,
            current_phase: params.phases[0],
            completed_phases: []
          },¬∑
          agents: [],
          memory: {},
          artifacts: []
        };¬∑
        await this.saveState(state);
        return state;
      }¬∑
      /**
       * Update workflow state
       */
      async updateWorkflow(
        workflowId: string,
        updates: Partial<WorkflowState>
      ): Promise<WorkflowState> {
        const state = await this.loadState(workflowId);¬∑
        const updatedState = {
          ...state,
          ...updates,
          updated_at: new Date().toISOString()
        };¬∑
        await this.saveState(updatedState);
        return updatedState;
      }¬∑
      /**
       * Store value in shared memory
       */
      async setMemory(
        workflowId: string,
        key: string,
        value: any
      ): Promise<void> {
        const state = await this.loadState(workflowId);
        state.memory[key] = value;
        await this.saveState(state);
      }¬∑
      /**
       * Retrieve value from shared memory
       */
      async getMemory(workflowId: string, key: string): Promise<any> {
        const state = await this.loadState(workflowId);
        return state.memory[key];
      }¬∑
      /**
       * Add artifact to workflow
       */
      async addArtifact(
        workflowId: string,
        artifact: { agent: string; type: string; path: string }
      ): Promise<void> {
        const state = await this.loadState(workflowId);¬∑
        state.artifacts.push({
          ...artifact,
          created_at: new Date().toISOString()
        });¬∑
        await this.saveState(state);
      }¬∑
      /**
       * Mark phase as complete
       */
      async completePhase(workflowId: string, phase: string): Promise<void> {
        const state = await this.loadState(workflowId);¬∑
        state.workflow.completed_phases.push(phase);¬∑
        // Move to next phase
        const currentIndex = state.workflow.phases.indexOf(phase);
        if (currentIndex < state.workflow.phases.length - 1) {
          state.workflow.current_phase = state.workflow.phases[currentIndex + 1];
        } else {
          // All phases complete
          state.status = 'completed';
        }¬∑
        await this.saveState(state);
      }¬∑
      private async saveState(state: WorkflowState): Promise<void> {
        const filePath = path.join(this.stateDir, `${state.workflow_id}.json`);
        await fs.mkdir(this.stateDir, { recursive: true });
        await fs.writeFile(filePath, JSON.stringify(state, null, 2));
      }¬∑
      private async loadState(workflowId: string): Promise<WorkflowState> {
        const filePath = path.join(this.stateDir, `${workflowId}.json`);
        const content = await fs.readFile(filePath, 'utf-8');
        return JSON.parse(content);
      }
    }¬∑
    // Usage
    const stateManager = new WorkflowStateManager();¬∑
    // Create workflow
    const workflow = await stateManager.createWorkflow({
      name: 'user-auth-feature',
      phases: ['PLAN', 'BUILD', 'TEST', 'DEPLOY']
    });¬∑
    // Store shared data
    await stateManager.setMemory(workflow.workflow_id, 'api_endpoint', '/api/auth');¬∑
    // Add artifact
    await stateManager.addArtifact(workflow.workflow_id, {
      agent: 'marcus-backend',
      type: 'code',
      path: 'src/api/auth.ts'
    });¬∑
    // Complete phase
    await stateManager.completePhase(workflow.workflow_id, 'PLAN');
    ```¬∑
    ---¬∑
    ## Workflow Patterns¬∑
    ### Sequential Workflow¬∑
    ```typescript
    // orchestration/patterns/sequential.ts
    import { HandoffManager } from '../handoff-manager.js';
    import { WorkflowStateManager } from '../state/workflow-state.js';¬∑
    export class SequentialWorkflow {
      private handoffManager: HandoffManager;
      private stateManager: WorkflowStateManager;¬∑
      constructor() {
        this.handoffManager = new HandoffManager();
        this.stateManager = new WorkflowStateManager();
      }¬∑
      /**
       * Execute sequential workflow: A ‚Üí B ‚Üí C
       */
      async execute(steps: {
        agent: string;
        context: any;
        expectedOutput: any;
      }[]): Promise<void> {
        // Create workflow
        const workflow = await this.stateManager.createWorkflow({
          name: 'sequential-workflow',
          phases: steps.map((_, i) => `step-${i + 1}`)
        });¬∑
        console.log(`üöÄ Starting sequential workflow: ${steps.length} steps`);¬∑
        // Execute steps sequentially
        for (let i = 0; i < steps.length; i++) {
          const step = steps[i];
          const nextStep = steps[i + 1];¬∑
          console.log(`üìç Step ${i + 1}/${steps.length}: ${step.agent}`);¬∑
          // Create handoff
          const handoff = await this.handoffManager.createHandoff({
            fromAgent: i === 0 ? 'system' : steps[i - 1].agent,
            toAgent: step.agent,
            context: step.context,
            expectedOutput: step.expectedOutput,
            workflowId: workflow.workflow_id
          });¬∑
          // Execute handoff
          await this.handoffManager.executeHandoff(handoff);¬∑
          // Mark phase complete
          await this.stateManager.completePhase(workflow.workflow_id, `step-${i + 1}`);
        }¬∑
        console.log('‚úÖ Sequential workflow completed');
      }
    }¬∑
    // Usage
    const workflow = new SequentialWorkflow();¬∑
    await workflow.execute([
      {
        agent: 'alex-ba',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['requirements.md'] }
      },
      {
        agent: 'marcus-backend',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['auth-api.ts'] }
      },
      {
        agent: 'maria-qa',
        context: { feature: 'Add user auth' },
        expectedOutput: { deliverables: ['auth.test.ts'] }
      }
    ]);
    ```¬∑
    ### Parallel Workflow¬∑
    ```typescript
    // orchestration/patterns/parallel.ts
    export class ParallelWorkflow {
      private handoffManager: HandoffManager;
      private stateManager: WorkflowStateManager;¬∑
      /**
       * Execute parallel workflow: A + B + C simultaneously
       */
      async execute(tasks: {
        agent: string;
        context: any;
        expectedOutput: any;
      }[]): Promise<void> {
        const workflow = await this.stateManager.createWorkflow({
          name: 'parallel-workflow',
          phases: ['execute', 'merge']
        });¬∑
        console.log(`üöÄ Starting parallel workflow: ${tasks.length} tasks`);¬∑
        // Create handoffs for all tasks
        const handoffPromises = tasks.map(task =>
          this.handoffManager.createHandoff({
            fromAgent: 'system',
            toAgent: task.agent,
            context: task.context,
            expectedOutput: task.expectedOutput,
            workflowId: workflow.workflow_id
          })
        );¬∑
        const handoffs = await Promise.all(handoffPromises);¬∑
        // Execute all in parallel
        const executionPromises = handoffs.map(handoff =>
          this.handoffManager.executeHandoff(handoff)
        );¬∑
        await Promise.all(executionPromises);¬∑
        console.log('‚úÖ Parallel workflow completed');
      }
    }¬∑
    // Usage
    const workflow = new ParallelWorkflow();¬∑
    await workflow.execute([
      {
        agent: 'james-frontend',
        context: { component: 'LoginForm' },
        expectedOutput: { deliverables: ['LoginForm.tsx'] }
      },
      {
        agent: 'marcus-backend',
        context: { endpoint: 'POST /auth/login' },
        expectedOutput: { deliverables: ['auth-api.ts'] }
      },
      {
        agent: 'dana-database',
        context: { table: 'users' },
        expectedOutput: { deliverables: ['migration-001-users.sql'] }
      }
    ]);
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `execute-workflow.ts` - Run pre-defined workflows
    - `validate-handoff.ts` - Validate handoff contracts
    - `recover-workflow.ts` - Recover failed workflows¬∑
    ### references/
    - `references/opera-methodology.md` - Complete OPERA protocol specification
    - `references/handoff-patterns.md` - Common handoff patterns
    - `references/state-management.md` - State persistence best practices¬∑
    ### assets/
    - `assets/workflow-templates/` - Pre-built workflow templates
    - `assets/handoff-schemas/` - JSON schemas for contracts¬∑
    ## Related Skills¬∑
    - `opera-orchestration` - OPERA agent system architecture
    - `cross-domain-patterns` - Full-stack multi-agent patterns
    - `quality-gates` - Contract validation in workflows
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ cross-domain-patterns ‚Ä∫ should have Key Patterns section

    expect(received).toContain(expected) // indexOf

    Expected substring: "## Key Patterns"
    Received string:    "---
    name: cross-domain-patterns
    description: Full-stack patterns combining frontend, backend, database skills. Use when building complete features, implementing end-to-end flows, or coordinating frontend + backend + database work. Covers authentication flows, real-time features, file uploads, and multi-tier architectures. Accelerates full-stack development by 45%.
    ---¬∑
    # Cross-Domain Patterns¬∑
    ## Overview¬∑
    Full-stack development patterns that combine frontend (James-Frontend), backend (Marcus-Backend), and database (Dana-Database) skills. Provides battle-tested patterns for complete feature implementation from UI to database.¬∑
    **Goal**: Build production-ready full-stack features with consistent patterns across all tiers¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building complete features (UI + API + Database)
    - Implementing authentication/authorization flows
    - Creating real-time features (WebSockets, SSE)
    - Building file upload/download systems
    - Implementing search with filters and pagination
    - Creating multi-tenant applications
    - Building dashboards with live data
    - Coordinating frontend + backend + database agents¬∑
    **Triggers**: \"full-stack feature\", \"end-to-end\", \"authentication flow\", \"real-time\", \"file upload\", \"search feature\", \"multi-tier\"¬∑
    ---¬∑
    ## Quick Start: Full-Stack Pattern Selection¬∑
    ### Common Full-Stack Patterns¬∑
    **CRUD with Pagination** (Create, Read, Update, Delete):
    - ‚úÖ Standard resource management
    - ‚úÖ List with pagination, filtering, sorting
    - ‚úÖ Form validation on frontend + backend
    - ‚úÖ Best for: User management, content management¬∑
    **Authentication Flow** (Login, signup, password reset):
    - ‚úÖ JWT tokens or session-based auth
    - ‚úÖ OAuth2/OpenID Connect integration
    - ‚úÖ Protected routes on frontend + backend
    - ‚úÖ Best for: User authentication, third-party login¬∑
    **Real-Time Features** (Live updates):
    - ‚úÖ WebSocket or Server-Sent Events
    - ‚úÖ Optimistic UI updates
    - ‚úÖ State synchronization
    - ‚úÖ Best for: Chat, notifications, live dashboards¬∑
    **File Upload/Download** (Secure file handling):
    - ‚úÖ Direct upload to S3/Cloud Storage
    - ‚úÖ Signed URLs for security
    - ‚úÖ Progress tracking
    - ‚úÖ Best for: Profile pictures, document management¬∑
    **Search & Filters** (Advanced querying):
    - ‚úÖ Full-text search (Postgres, Elasticsearch)
    - ‚úÖ Dynamic filters
    - ‚úÖ Faceted search
    - ‚úÖ Best for: E-commerce, content discovery¬∑
    ---¬∑
    ## Pattern 1: Authentication Flow¬∑
    ### Frontend (React + React Router)¬∑
    ```typescript
    // frontend/auth/LoginForm.tsx
    import React, { useState } from 'react';
    import { useNavigate } from 'react-router-dom';
    import { useAuth } from './AuthContext';¬∑
    export function LoginForm() {
      const [email, setEmail] = useState('');
      const [password, setPassword] = useState('');
      const [error, setError] = useState('');
      const [loading, setLoading] = useState(false);¬∑
      const { login } = useAuth();
      const navigate = useNavigate();¬∑
      const handleSubmit = async (e: React.FormEvent) => {
        e.preventDefault();
        setError('');
        setLoading(true);¬∑
        try {
          await login(email, password);
          navigate('/dashboard');
        } catch (err: any) {
          setError(err.message || 'Login failed');
        } finally {
          setLoading(false);
        }
      };¬∑
      return (
        <form onSubmit={handleSubmit} className=\"login-form\">
          <h2>Login</h2>¬∑
          {error && <div className=\"error\">{error}</div>}¬∑
          <div className=\"form-group\">
            <label htmlFor=\"email\">Email</label>
            <input
              id=\"email\"
              type=\"email\"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              required
              disabled={loading}
            />
          </div>¬∑
          <div className=\"form-group\">
            <label htmlFor=\"password\">Password</label>
            <input
              id=\"password\"
              type=\"password\"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              required
              disabled={loading}
            />
          </div>¬∑
          <button type=\"submit\" disabled={loading}>
            {loading ? 'Logging in...' : 'Login'}
          </button>
        </form>
      );
    }¬∑
    // frontend/auth/AuthContext.tsx
    import React, { createContext, useContext, useState, useEffect } from 'react';
    import axios from 'axios';¬∑
    interface User {
      id: string;
      email: string;
      name: string;
    }¬∑
    interface AuthContextType {
      user: User | null;
      login: (email: string, password: string) => Promise<void>;
      logout: () => Promise<void>;
      loading: boolean;
    }¬∑
    const AuthContext = createContext<AuthContextType | undefined>(undefined);¬∑
    export function AuthProvider({ children }: { children: React.ReactNode }) {
      const [user, setUser] = useState<User | null>(null);
      const [loading, setLoading] = useState(true);¬∑
      // Check for existing session on mount
      useEffect(() => {
        const token = localStorage.getItem('auth_token');
        if (token) {
          // Set axios default header
          axios.defaults.headers.common['Authorization'] = `Bearer ${token}`;¬∑
          // Fetch current user
          fetchCurrentUser();
        } else {
          setLoading(false);
        }
      }, []);¬∑
      const fetchCurrentUser = async () => {
        try {
          const response = await axios.get('/api/auth/me');
          setUser(response.data);
        } catch (error) {
          // Token invalid, clear it
          localStorage.removeItem('auth_token');
          delete axios.defaults.headers.common['Authorization'];
        } finally {
          setLoading(false);
        }
      };¬∑
      const login = async (email: string, password: string) => {
        const response = await axios.post('/api/auth/login', { email, password });¬∑
        const { token, user } = response.data;¬∑
        // Store token
        localStorage.setItem('auth_token', token);¬∑
        // Set axios header
        axios.defaults.headers.common['Authorization'] = `Bearer ${token}`;¬∑
        setUser(user);
      };¬∑
      const logout = async () => {
        await axios.post('/api/auth/logout');¬∑
        // Clear token
        localStorage.removeItem('auth_token');
        delete axios.defaults.headers.common['Authorization'];¬∑
        setUser(null);
      };¬∑
      return (
        <AuthContext.Provider value={{ user, login, logout, loading }}>
          {children}
        </AuthContext.Provider>
      );
    }¬∑
    export function useAuth() {
      const context = useContext(AuthContext);
      if (!context) throw new Error('useAuth must be used within AuthProvider');
      return context;
    }¬∑
    // frontend/auth/ProtectedRoute.tsx
    import { Navigate } from 'react-router-dom';
    import { useAuth } from './AuthContext';¬∑
    export function ProtectedRoute({ children }: { children: React.ReactNode }) {
      const { user, loading } = useAuth();¬∑
      if (loading) return <div>Loading...</div>;¬∑
      if (!user) return <Navigate to=\"/login\" />;¬∑
      return <>{children}</>;
    }
    ```¬∑
    ### Backend (Express + JWT)¬∑
    ```typescript
    // backend/api/auth.ts
    import express from 'express';
    import bcrypt from 'bcryptjs';
    import jwt from 'jsonwebtoken';
    import { z } from 'zod';
    import { prisma } from '../db.js';¬∑
    const router = express.Router();¬∑
    const JWT_SECRET = process.env.JWT_SECRET!;
    const JWT_EXPIRES_IN = '7d';¬∑
    // Validation schemas
    const LoginSchema = z.object({
      email: z.string().email(),
      password: z.string().min(8)
    });¬∑
    const SignupSchema = z.object({
      email: z.string().email(),
      password: z.string().min(8),
      name: z.string().min(2)
    });¬∑
    // POST /api/auth/signup
    router.post('/signup', async (req, res) => {
      try {
        // Validate input
        const { email, password, name } = SignupSchema.parse(req.body);¬∑
        // Check if user exists
        const existingUser = await prisma.user.findUnique({ where: { email } });
        if (existingUser) {
          return res.status(409).json({ error: 'User already exists' });
        }¬∑
        // Hash password
        const passwordHash = await bcrypt.hash(password, 10);¬∑
        // Create user
        const user = await prisma.user.create({
          data: {
            email,
            password_hash: passwordHash,
            name
          },
          select: {
            id: true,
            email: true,
            name: true,
            created_at: true
          }
        });¬∑
        // Generate JWT
        const token = jwt.sign({ userId: user.id }, JWT_SECRET, {
          expiresIn: JWT_EXPIRES_IN
        });¬∑
        res.status(201).json({ token, user });¬∑
      } catch (error) {
        if (error instanceof z.ZodError) {
          return res.status(400).json({ error: 'Invalid input', details: error.errors });
        }
        console.error(error);
        res.status(500).json({ error: 'Signup failed' });
      }
    });¬∑
    // POST /api/auth/login
    router.post('/login', async (req, res) => {
      try {
        // Validate input
        const { email, password } = LoginSchema.parse(req.body);¬∑
        // Find user
        const user = await prisma.user.findUnique({ where: { email } });
        if (!user) {
          return res.status(401).json({ error: 'Invalid credentials' });
        }¬∑
        // Verify password
        const isValid = await bcrypt.compare(password, user.password_hash);
        if (!isValid) {
          return res.status(401).json({ error: 'Invalid credentials' });
        }¬∑
        // Generate JWT
        const token = jwt.sign({ userId: user.id }, JWT_SECRET, {
          expiresIn: JWT_EXPIRES_IN
        });¬∑
        res.json({
          token,
          user: {
            id: user.id,
            email: user.email,
            name: user.name
          }
        });¬∑
      } catch (error) {
        if (error instanceof z.ZodError) {
          return res.status(400).json({ error: 'Invalid input' });
        }
        console.error(error);
        res.status(500).json({ error: 'Login failed' });
      }
    });¬∑
    // GET /api/auth/me
    router.get('/me', authenticateToken, async (req, res) => {
      try {
        const user = await prisma.user.findUnique({
          where: { id: req.userId },
          select: {
            id: true,
            email: true,
            name: true,
            created_at: true
          }
        });¬∑
        if (!user) {
          return res.status(404).json({ error: 'User not found' });
        }¬∑
        res.json(user);¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to fetch user' });
      }
    });¬∑
    // Middleware: Authenticate JWT token
    export function authenticateToken(req: any, res: any, next: any) {
      const authHeader = req.headers['authorization'];
      const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN¬∑
      if (!token) {
        return res.status(401).json({ error: 'No token provided' });
      }¬∑
      jwt.verify(token, JWT_SECRET, (err: any, payload: any) => {
        if (err) {
          return res.status(403).json({ error: 'Invalid token' });
        }¬∑
        req.userId = payload.userId;
        next();
      });
    }¬∑
    export default router;
    ```¬∑
    ### Database (Prisma Schema)¬∑
    ```prisma
    // database/schema.prisma
    model User {
      id            String   @id @default(uuid())
      email         String   @unique
      password_hash String
      name          String
      created_at    DateTime @default(now())
      updated_at    DateTime @updatedAt¬∑
      // Relations
      sessions      Session[]
      posts         Post[]¬∑
      @@index([email])
    }¬∑
    model Session {
      id         String   @id @default(uuid())
      user_id    String
      token      String   @unique
      expires_at DateTime
      created_at DateTime @default(now())¬∑
      user User @relation(fields: [user_id], references: [id], onDelete: Cascade)¬∑
      @@index([user_id])
      @@index([token])
    }
    ```¬∑
    ---¬∑
    ## Pattern 2: Real-Time Features (WebSocket)¬∑
    ### Frontend (React + Socket.IO)¬∑
    ```typescript
    // frontend/realtime/useWebSocket.ts
    import { useEffect, useState } from 'react';
    import { io, Socket } from 'socket.io-client';¬∑
    export function useWebSocket(url: string) {
      const [socket, setSocket] = useState<Socket | null>(null);
      const [connected, setConnected] = useState(false);¬∑
      useEffect(() => {
        const token = localStorage.getItem('auth_token');¬∑
        const newSocket = io(url, {
          auth: { token },
          reconnection: true,
          reconnectionDelay: 1000
        });¬∑
        newSocket.on('connect', () => {
          console.log('WebSocket connected');
          setConnected(true);
        });¬∑
        newSocket.on('disconnect', () => {
          console.log('WebSocket disconnected');
          setConnected(false);
        });¬∑
        setSocket(newSocket);¬∑
        return () => {
          newSocket.close();
        };
      }, [url]);¬∑
      return { socket, connected };
    }¬∑
    // frontend/realtime/ChatRoom.tsx
    import React, { useState, useEffect } from 'react';
    import { useWebSocket } from './useWebSocket';¬∑
    interface Message {
      id: string;
      user: string;
      text: string;
      timestamp: string;
    }¬∑
    export function ChatRoom({ roomId }: { roomId: string }) {
      const [messages, setMessages] = useState<Message[]>([]);
      const [inputText, setInputText] = useState('');¬∑
      const { socket, connected } = useWebSocket('http://localhost:3000');¬∑
      useEffect(() => {
        if (!socket) return;¬∑
        // Join room
        socket.emit('join_room', { roomId });¬∑
        // Listen for messages
        socket.on('new_message', (message: Message) => {
          setMessages(prev => [...prev, message]);
        });¬∑
        // Load history
        socket.emit('get_history', { roomId }, (history: Message[]) => {
          setMessages(history);
        });¬∑
        return () => {
          socket.off('new_message');
          socket.emit('leave_room', { roomId });
        };
      }, [socket, roomId]);¬∑
      const sendMessage = () => {
        if (!socket || !inputText.trim()) return;¬∑
        socket.emit('send_message', {
          roomId,
          text: inputText
        });¬∑
        setInputText('');
      };¬∑
      return (
        <div className=\"chat-room\">
          <div className=\"status\">
            {connected ? 'üü¢ Connected' : 'üî¥ Disconnected'}
          </div>¬∑
          <div className=\"messages\">
            {messages.map(msg => (
              <div key={msg.id} className=\"message\">
                <strong>{msg.user}:</strong> {msg.text}
              </div>
            ))}
          </div>¬∑
          <div className=\"input\">
            <input
              type=\"text\"
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
              disabled={!connected}
            />
            <button onClick={sendMessage} disabled={!connected}>
              Send
            </button>
          </div>
        </div>
      );
    }
    ```¬∑
    ### Backend (Socket.IO)¬∑
    ```typescript
    // backend/realtime/socket-server.ts
    import { Server } from 'socket.io';
    import jwt from 'jsonwebtoken';
    import { prisma } from '../db.js';¬∑
    export function setupWebSocket(httpServer: any) {
      const io = new Server(httpServer, {
        cors: {
          origin: process.env.FRONTEND_URL,
          credentials: true
        }
      });¬∑
      // Authentication middleware
      io.use(async (socket, next) => {
        try {
          const token = socket.handshake.auth.token;¬∑
          if (!token) {
            return next(new Error('Authentication error'));
          }¬∑
          const payload = jwt.verify(token, process.env.JWT_SECRET!) as any;
          socket.data.userId = payload.userId;¬∑
          next();
        } catch (error) {
          next(new Error('Authentication error'));
        }
      });¬∑
      io.on('connection', (socket) => {
        console.log(`User connected: ${socket.data.userId}`);¬∑
        // Join room
        socket.on('join_room', async ({ roomId }) => {
          socket.join(roomId);
          console.log(`User ${socket.data.userId} joined room ${roomId}`);¬∑
          // Notify others
          socket.to(roomId).emit('user_joined', {
            userId: socket.data.userId
          });
        });¬∑
        // Leave room
        socket.on('leave_room', ({ roomId }) => {
          socket.leave(roomId);
          socket.to(roomId).emit('user_left', {
            userId: socket.data.userId
          });
        });¬∑
        // Send message
        socket.on('send_message', async ({ roomId, text }) => {
          // Save to database
          const message = await prisma.message.create({
            data: {
              room_id: roomId,
              user_id: socket.data.userId,
              text
            },
            include: {
              user: {
                select: { name: true }
              }
            }
          });¬∑
          // Broadcast to room
          io.to(roomId).emit('new_message', {
            id: message.id,
            user: message.user.name,
            text: message.text,
            timestamp: message.created_at
          });
        });¬∑
        // Get message history
        socket.on('get_history', async ({ roomId }, callback) => {
          const messages = await prisma.message.findMany({
            where: { room_id: roomId },
            include: {
              user: {
                select: { name: true }
              }
            },
            orderBy: { created_at: 'asc' },
            take: 100
          });¬∑
          callback(messages.map(msg => ({
            id: msg.id,
            user: msg.user.name,
            text: msg.text,
            timestamp: msg.created_at
          })));
        });¬∑
        socket.on('disconnect', () => {
          console.log(`User disconnected: ${socket.data.userId}`);
        });
      });¬∑
      return io;
    }
    ```¬∑
    ---¬∑
    ## Pattern 3: File Upload (Direct to S3)¬∑
    ### Frontend (React + Presigned URLs)¬∑
    ```typescript
    // frontend/upload/FileUpload.tsx
    import React, { useState } from 'react';
    import axios from 'axios';¬∑
    export function FileUpload() {
      const [file, setFile] = useState<File | null>(null);
      const [uploading, setUploading] = useState(false);
      const [progress, setProgress] = useState(0);
      const [uploadedUrl, setUploadedUrl] = useState('');¬∑
      const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        if (e.target.files && e.target.files[0]) {
          setFile(e.target.files[0]);
        }
      };¬∑
      const handleUpload = async () => {
        if (!file) return;¬∑
        setUploading(true);
        setProgress(0);¬∑
        try {
          // Step 1: Get presigned URL from backend
          const { data } = await axios.post('/api/upload/presigned-url', {
            filename: file.name,
            contentType: file.type
          });¬∑
          const { uploadUrl, fileUrl } = data;¬∑
          // Step 2: Upload directly to S3
          await axios.put(uploadUrl, file, {
            headers: {
              'Content-Type': file.type
            },
            onUploadProgress: (progressEvent) => {
              const percentCompleted = Math.round(
                (progressEvent.loaded * 100) / (progressEvent.total || 1)
              );
              setProgress(percentCompleted);
            }
          });¬∑
          // Step 3: Save file metadata to backend
          await axios.post('/api/upload/complete', {
            filename: file.name,
            fileUrl,
            size: file.size,
            contentType: file.type
          });¬∑
          setUploadedUrl(fileUrl);
          alert('Upload successful!');¬∑
        } catch (error) {
          console.error('Upload failed:', error);
          alert('Upload failed');
        } finally {
          setUploading(false);
        }
      };¬∑
      return (
        <div className=\"file-upload\">
          <input
            type=\"file\"
            onChange={handleFileChange}
            disabled={uploading}
          />¬∑
          <button onClick={handleUpload} disabled={!file || uploading}>
            {uploading ? `Uploading ${progress}%` : 'Upload'}
          </button>¬∑
          {uploadedUrl && (
            <div>
              <p>File uploaded successfully!</p>
              <a href={uploadedUrl} target=\"_blank\" rel=\"noopener noreferrer\">
                View File
              </a>
            </div>
          )}
        </div>
      );
    }
    ```¬∑
    ### Backend (Express + AWS S3)¬∑
    ```typescript
    // backend/api/upload.ts
    import express from 'express';
    import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
    import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
    import { v4 as uuidv4 } from 'uuid';
    import { authenticateToken } from './auth.js';
    import { prisma } from '../db.js';¬∑
    const router = express.Router();¬∑
    const s3Client = new S3Client({
      region: process.env.AWS_REGION!,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!
      }
    });¬∑
    const BUCKET_NAME = process.env.S3_BUCKET_NAME!;¬∑
    // POST /api/upload/presigned-url
    router.post('/presigned-url', authenticateToken, async (req, res) => {
      try {
        const { filename, contentType } = req.body;¬∑
        // Generate unique key
        const fileExtension = filename.split('.').pop();
        const key = `uploads/${req.userId}/${uuidv4()}.${fileExtension}`;¬∑
        // Create presigned URL (valid for 5 minutes)
        const command = new PutObjectCommand({
          Bucket: BUCKET_NAME,
          Key: key,
          ContentType: contentType
        });¬∑
        const uploadUrl = await getSignedUrl(s3Client, command, {
          expiresIn: 300
        });¬∑
        const fileUrl = `https://${BUCKET_NAME}.s3.amazonaws.com/${key}`;¬∑
        res.json({ uploadUrl, fileUrl, key });¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to generate presigned URL' });
      }
    });¬∑
    // POST /api/upload/complete
    router.post('/complete', authenticateToken, async (req, res) => {
      try {
        const { filename, fileUrl, size, contentType } = req.body;¬∑
        // Save file metadata to database
        const file = await prisma.file.create({
          data: {
            user_id: req.userId,
            filename,
            url: fileUrl,
            size,
            content_type: contentType
          }
        });¬∑
        res.json(file);¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to save file metadata' });
      }
    });¬∑
    export default router;
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-fullstack-crud.ts` - Scaffold complete CRUD feature
    - `test-fullstack-flow.ts` - E2E testing for cross-domain features¬∑
    ### references/
    - `references/auth-patterns.md` - Authentication best practices
    - `references/realtime-patterns.md` - WebSocket vs SSE tradeoffs
    - `references/file-upload-patterns.md` - Direct upload vs proxy upload¬∑
    ### assets/
    - `assets/fullstack-templates/` - Complete feature templates
    - `assets/e2e-tests/` - Playwright E2E test examples¬∑
    ## Related Skills¬∑
    - `api-design` - Backend API patterns
    - `component-patterns` - Frontend component architecture
    - `auth-security` - Security best practices
    - `workflow-orchestration` - Coordinating multi-agent work
    "

       99 |
      100 |         it('should have Key Patterns section', () => {
    > 101 |           expect(content).toContain('## Key Patterns');
          |                           ^
      102 |         });
      103 |
      104 |         it('should have code examples', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:101:27)

  ‚óè Skills Validation Suite ‚Ä∫ Skill Content Validation ‚Ä∫ cross-domain-patterns ‚Ä∫ should have implementation checklist

    expect(received).toMatch(expected)

    Expected pattern: /##\s+Implementation\s+Checklist/i
    Received string:  "---
    name: cross-domain-patterns
    description: Full-stack patterns combining frontend, backend, database skills. Use when building complete features, implementing end-to-end flows, or coordinating frontend + backend + database work. Covers authentication flows, real-time features, file uploads, and multi-tier architectures. Accelerates full-stack development by 45%.
    ---¬∑
    # Cross-Domain Patterns¬∑
    ## Overview¬∑
    Full-stack development patterns that combine frontend (James-Frontend), backend (Marcus-Backend), and database (Dana-Database) skills. Provides battle-tested patterns for complete feature implementation from UI to database.¬∑
    **Goal**: Build production-ready full-stack features with consistent patterns across all tiers¬∑
    ## When to Use This Skill¬∑
    Use this skill when:
    - Building complete features (UI + API + Database)
    - Implementing authentication/authorization flows
    - Creating real-time features (WebSockets, SSE)
    - Building file upload/download systems
    - Implementing search with filters and pagination
    - Creating multi-tenant applications
    - Building dashboards with live data
    - Coordinating frontend + backend + database agents¬∑
    **Triggers**: \"full-stack feature\", \"end-to-end\", \"authentication flow\", \"real-time\", \"file upload\", \"search feature\", \"multi-tier\"¬∑
    ---¬∑
    ## Quick Start: Full-Stack Pattern Selection¬∑
    ### Common Full-Stack Patterns¬∑
    **CRUD with Pagination** (Create, Read, Update, Delete):
    - ‚úÖ Standard resource management
    - ‚úÖ List with pagination, filtering, sorting
    - ‚úÖ Form validation on frontend + backend
    - ‚úÖ Best for: User management, content management¬∑
    **Authentication Flow** (Login, signup, password reset):
    - ‚úÖ JWT tokens or session-based auth
    - ‚úÖ OAuth2/OpenID Connect integration
    - ‚úÖ Protected routes on frontend + backend
    - ‚úÖ Best for: User authentication, third-party login¬∑
    **Real-Time Features** (Live updates):
    - ‚úÖ WebSocket or Server-Sent Events
    - ‚úÖ Optimistic UI updates
    - ‚úÖ State synchronization
    - ‚úÖ Best for: Chat, notifications, live dashboards¬∑
    **File Upload/Download** (Secure file handling):
    - ‚úÖ Direct upload to S3/Cloud Storage
    - ‚úÖ Signed URLs for security
    - ‚úÖ Progress tracking
    - ‚úÖ Best for: Profile pictures, document management¬∑
    **Search & Filters** (Advanced querying):
    - ‚úÖ Full-text search (Postgres, Elasticsearch)
    - ‚úÖ Dynamic filters
    - ‚úÖ Faceted search
    - ‚úÖ Best for: E-commerce, content discovery¬∑
    ---¬∑
    ## Pattern 1: Authentication Flow¬∑
    ### Frontend (React + React Router)¬∑
    ```typescript
    // frontend/auth/LoginForm.tsx
    import React, { useState } from 'react';
    import { useNavigate } from 'react-router-dom';
    import { useAuth } from './AuthContext';¬∑
    export function LoginForm() {
      const [email, setEmail] = useState('');
      const [password, setPassword] = useState('');
      const [error, setError] = useState('');
      const [loading, setLoading] = useState(false);¬∑
      const { login } = useAuth();
      const navigate = useNavigate();¬∑
      const handleSubmit = async (e: React.FormEvent) => {
        e.preventDefault();
        setError('');
        setLoading(true);¬∑
        try {
          await login(email, password);
          navigate('/dashboard');
        } catch (err: any) {
          setError(err.message || 'Login failed');
        } finally {
          setLoading(false);
        }
      };¬∑
      return (
        <form onSubmit={handleSubmit} className=\"login-form\">
          <h2>Login</h2>¬∑
          {error && <div className=\"error\">{error}</div>}¬∑
          <div className=\"form-group\">
            <label htmlFor=\"email\">Email</label>
            <input
              id=\"email\"
              type=\"email\"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              required
              disabled={loading}
            />
          </div>¬∑
          <div className=\"form-group\">
            <label htmlFor=\"password\">Password</label>
            <input
              id=\"password\"
              type=\"password\"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              required
              disabled={loading}
            />
          </div>¬∑
          <button type=\"submit\" disabled={loading}>
            {loading ? 'Logging in...' : 'Login'}
          </button>
        </form>
      );
    }¬∑
    // frontend/auth/AuthContext.tsx
    import React, { createContext, useContext, useState, useEffect } from 'react';
    import axios from 'axios';¬∑
    interface User {
      id: string;
      email: string;
      name: string;
    }¬∑
    interface AuthContextType {
      user: User | null;
      login: (email: string, password: string) => Promise<void>;
      logout: () => Promise<void>;
      loading: boolean;
    }¬∑
    const AuthContext = createContext<AuthContextType | undefined>(undefined);¬∑
    export function AuthProvider({ children }: { children: React.ReactNode }) {
      const [user, setUser] = useState<User | null>(null);
      const [loading, setLoading] = useState(true);¬∑
      // Check for existing session on mount
      useEffect(() => {
        const token = localStorage.getItem('auth_token');
        if (token) {
          // Set axios default header
          axios.defaults.headers.common['Authorization'] = `Bearer ${token}`;¬∑
          // Fetch current user
          fetchCurrentUser();
        } else {
          setLoading(false);
        }
      }, []);¬∑
      const fetchCurrentUser = async () => {
        try {
          const response = await axios.get('/api/auth/me');
          setUser(response.data);
        } catch (error) {
          // Token invalid, clear it
          localStorage.removeItem('auth_token');
          delete axios.defaults.headers.common['Authorization'];
        } finally {
          setLoading(false);
        }
      };¬∑
      const login = async (email: string, password: string) => {
        const response = await axios.post('/api/auth/login', { email, password });¬∑
        const { token, user } = response.data;¬∑
        // Store token
        localStorage.setItem('auth_token', token);¬∑
        // Set axios header
        axios.defaults.headers.common['Authorization'] = `Bearer ${token}`;¬∑
        setUser(user);
      };¬∑
      const logout = async () => {
        await axios.post('/api/auth/logout');¬∑
        // Clear token
        localStorage.removeItem('auth_token');
        delete axios.defaults.headers.common['Authorization'];¬∑
        setUser(null);
      };¬∑
      return (
        <AuthContext.Provider value={{ user, login, logout, loading }}>
          {children}
        </AuthContext.Provider>
      );
    }¬∑
    export function useAuth() {
      const context = useContext(AuthContext);
      if (!context) throw new Error('useAuth must be used within AuthProvider');
      return context;
    }¬∑
    // frontend/auth/ProtectedRoute.tsx
    import { Navigate } from 'react-router-dom';
    import { useAuth } from './AuthContext';¬∑
    export function ProtectedRoute({ children }: { children: React.ReactNode }) {
      const { user, loading } = useAuth();¬∑
      if (loading) return <div>Loading...</div>;¬∑
      if (!user) return <Navigate to=\"/login\" />;¬∑
      return <>{children}</>;
    }
    ```¬∑
    ### Backend (Express + JWT)¬∑
    ```typescript
    // backend/api/auth.ts
    import express from 'express';
    import bcrypt from 'bcryptjs';
    import jwt from 'jsonwebtoken';
    import { z } from 'zod';
    import { prisma } from '../db.js';¬∑
    const router = express.Router();¬∑
    const JWT_SECRET = process.env.JWT_SECRET!;
    const JWT_EXPIRES_IN = '7d';¬∑
    // Validation schemas
    const LoginSchema = z.object({
      email: z.string().email(),
      password: z.string().min(8)
    });¬∑
    const SignupSchema = z.object({
      email: z.string().email(),
      password: z.string().min(8),
      name: z.string().min(2)
    });¬∑
    // POST /api/auth/signup
    router.post('/signup', async (req, res) => {
      try {
        // Validate input
        const { email, password, name } = SignupSchema.parse(req.body);¬∑
        // Check if user exists
        const existingUser = await prisma.user.findUnique({ where: { email } });
        if (existingUser) {
          return res.status(409).json({ error: 'User already exists' });
        }¬∑
        // Hash password
        const passwordHash = await bcrypt.hash(password, 10);¬∑
        // Create user
        const user = await prisma.user.create({
          data: {
            email,
            password_hash: passwordHash,
            name
          },
          select: {
            id: true,
            email: true,
            name: true,
            created_at: true
          }
        });¬∑
        // Generate JWT
        const token = jwt.sign({ userId: user.id }, JWT_SECRET, {
          expiresIn: JWT_EXPIRES_IN
        });¬∑
        res.status(201).json({ token, user });¬∑
      } catch (error) {
        if (error instanceof z.ZodError) {
          return res.status(400).json({ error: 'Invalid input', details: error.errors });
        }
        console.error(error);
        res.status(500).json({ error: 'Signup failed' });
      }
    });¬∑
    // POST /api/auth/login
    router.post('/login', async (req, res) => {
      try {
        // Validate input
        const { email, password } = LoginSchema.parse(req.body);¬∑
        // Find user
        const user = await prisma.user.findUnique({ where: { email } });
        if (!user) {
          return res.status(401).json({ error: 'Invalid credentials' });
        }¬∑
        // Verify password
        const isValid = await bcrypt.compare(password, user.password_hash);
        if (!isValid) {
          return res.status(401).json({ error: 'Invalid credentials' });
        }¬∑
        // Generate JWT
        const token = jwt.sign({ userId: user.id }, JWT_SECRET, {
          expiresIn: JWT_EXPIRES_IN
        });¬∑
        res.json({
          token,
          user: {
            id: user.id,
            email: user.email,
            name: user.name
          }
        });¬∑
      } catch (error) {
        if (error instanceof z.ZodError) {
          return res.status(400).json({ error: 'Invalid input' });
        }
        console.error(error);
        res.status(500).json({ error: 'Login failed' });
      }
    });¬∑
    // GET /api/auth/me
    router.get('/me', authenticateToken, async (req, res) => {
      try {
        const user = await prisma.user.findUnique({
          where: { id: req.userId },
          select: {
            id: true,
            email: true,
            name: true,
            created_at: true
          }
        });¬∑
        if (!user) {
          return res.status(404).json({ error: 'User not found' });
        }¬∑
        res.json(user);¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to fetch user' });
      }
    });¬∑
    // Middleware: Authenticate JWT token
    export function authenticateToken(req: any, res: any, next: any) {
      const authHeader = req.headers['authorization'];
      const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN¬∑
      if (!token) {
        return res.status(401).json({ error: 'No token provided' });
      }¬∑
      jwt.verify(token, JWT_SECRET, (err: any, payload: any) => {
        if (err) {
          return res.status(403).json({ error: 'Invalid token' });
        }¬∑
        req.userId = payload.userId;
        next();
      });
    }¬∑
    export default router;
    ```¬∑
    ### Database (Prisma Schema)¬∑
    ```prisma
    // database/schema.prisma
    model User {
      id            String   @id @default(uuid())
      email         String   @unique
      password_hash String
      name          String
      created_at    DateTime @default(now())
      updated_at    DateTime @updatedAt¬∑
      // Relations
      sessions      Session[]
      posts         Post[]¬∑
      @@index([email])
    }¬∑
    model Session {
      id         String   @id @default(uuid())
      user_id    String
      token      String   @unique
      expires_at DateTime
      created_at DateTime @default(now())¬∑
      user User @relation(fields: [user_id], references: [id], onDelete: Cascade)¬∑
      @@index([user_id])
      @@index([token])
    }
    ```¬∑
    ---¬∑
    ## Pattern 2: Real-Time Features (WebSocket)¬∑
    ### Frontend (React + Socket.IO)¬∑
    ```typescript
    // frontend/realtime/useWebSocket.ts
    import { useEffect, useState } from 'react';
    import { io, Socket } from 'socket.io-client';¬∑
    export function useWebSocket(url: string) {
      const [socket, setSocket] = useState<Socket | null>(null);
      const [connected, setConnected] = useState(false);¬∑
      useEffect(() => {
        const token = localStorage.getItem('auth_token');¬∑
        const newSocket = io(url, {
          auth: { token },
          reconnection: true,
          reconnectionDelay: 1000
        });¬∑
        newSocket.on('connect', () => {
          console.log('WebSocket connected');
          setConnected(true);
        });¬∑
        newSocket.on('disconnect', () => {
          console.log('WebSocket disconnected');
          setConnected(false);
        });¬∑
        setSocket(newSocket);¬∑
        return () => {
          newSocket.close();
        };
      }, [url]);¬∑
      return { socket, connected };
    }¬∑
    // frontend/realtime/ChatRoom.tsx
    import React, { useState, useEffect } from 'react';
    import { useWebSocket } from './useWebSocket';¬∑
    interface Message {
      id: string;
      user: string;
      text: string;
      timestamp: string;
    }¬∑
    export function ChatRoom({ roomId }: { roomId: string }) {
      const [messages, setMessages] = useState<Message[]>([]);
      const [inputText, setInputText] = useState('');¬∑
      const { socket, connected } = useWebSocket('http://localhost:3000');¬∑
      useEffect(() => {
        if (!socket) return;¬∑
        // Join room
        socket.emit('join_room', { roomId });¬∑
        // Listen for messages
        socket.on('new_message', (message: Message) => {
          setMessages(prev => [...prev, message]);
        });¬∑
        // Load history
        socket.emit('get_history', { roomId }, (history: Message[]) => {
          setMessages(history);
        });¬∑
        return () => {
          socket.off('new_message');
          socket.emit('leave_room', { roomId });
        };
      }, [socket, roomId]);¬∑
      const sendMessage = () => {
        if (!socket || !inputText.trim()) return;¬∑
        socket.emit('send_message', {
          roomId,
          text: inputText
        });¬∑
        setInputText('');
      };¬∑
      return (
        <div className=\"chat-room\">
          <div className=\"status\">
            {connected ? 'üü¢ Connected' : 'üî¥ Disconnected'}
          </div>¬∑
          <div className=\"messages\">
            {messages.map(msg => (
              <div key={msg.id} className=\"message\">
                <strong>{msg.user}:</strong> {msg.text}
              </div>
            ))}
          </div>¬∑
          <div className=\"input\">
            <input
              type=\"text\"
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
              disabled={!connected}
            />
            <button onClick={sendMessage} disabled={!connected}>
              Send
            </button>
          </div>
        </div>
      );
    }
    ```¬∑
    ### Backend (Socket.IO)¬∑
    ```typescript
    // backend/realtime/socket-server.ts
    import { Server } from 'socket.io';
    import jwt from 'jsonwebtoken';
    import { prisma } from '../db.js';¬∑
    export function setupWebSocket(httpServer: any) {
      const io = new Server(httpServer, {
        cors: {
          origin: process.env.FRONTEND_URL,
          credentials: true
        }
      });¬∑
      // Authentication middleware
      io.use(async (socket, next) => {
        try {
          const token = socket.handshake.auth.token;¬∑
          if (!token) {
            return next(new Error('Authentication error'));
          }¬∑
          const payload = jwt.verify(token, process.env.JWT_SECRET!) as any;
          socket.data.userId = payload.userId;¬∑
          next();
        } catch (error) {
          next(new Error('Authentication error'));
        }
      });¬∑
      io.on('connection', (socket) => {
        console.log(`User connected: ${socket.data.userId}`);¬∑
        // Join room
        socket.on('join_room', async ({ roomId }) => {
          socket.join(roomId);
          console.log(`User ${socket.data.userId} joined room ${roomId}`);¬∑
          // Notify others
          socket.to(roomId).emit('user_joined', {
            userId: socket.data.userId
          });
        });¬∑
        // Leave room
        socket.on('leave_room', ({ roomId }) => {
          socket.leave(roomId);
          socket.to(roomId).emit('user_left', {
            userId: socket.data.userId
          });
        });¬∑
        // Send message
        socket.on('send_message', async ({ roomId, text }) => {
          // Save to database
          const message = await prisma.message.create({
            data: {
              room_id: roomId,
              user_id: socket.data.userId,
              text
            },
            include: {
              user: {
                select: { name: true }
              }
            }
          });¬∑
          // Broadcast to room
          io.to(roomId).emit('new_message', {
            id: message.id,
            user: message.user.name,
            text: message.text,
            timestamp: message.created_at
          });
        });¬∑
        // Get message history
        socket.on('get_history', async ({ roomId }, callback) => {
          const messages = await prisma.message.findMany({
            where: { room_id: roomId },
            include: {
              user: {
                select: { name: true }
              }
            },
            orderBy: { created_at: 'asc' },
            take: 100
          });¬∑
          callback(messages.map(msg => ({
            id: msg.id,
            user: msg.user.name,
            text: msg.text,
            timestamp: msg.created_at
          })));
        });¬∑
        socket.on('disconnect', () => {
          console.log(`User disconnected: ${socket.data.userId}`);
        });
      });¬∑
      return io;
    }
    ```¬∑
    ---¬∑
    ## Pattern 3: File Upload (Direct to S3)¬∑
    ### Frontend (React + Presigned URLs)¬∑
    ```typescript
    // frontend/upload/FileUpload.tsx
    import React, { useState } from 'react';
    import axios from 'axios';¬∑
    export function FileUpload() {
      const [file, setFile] = useState<File | null>(null);
      const [uploading, setUploading] = useState(false);
      const [progress, setProgress] = useState(0);
      const [uploadedUrl, setUploadedUrl] = useState('');¬∑
      const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        if (e.target.files && e.target.files[0]) {
          setFile(e.target.files[0]);
        }
      };¬∑
      const handleUpload = async () => {
        if (!file) return;¬∑
        setUploading(true);
        setProgress(0);¬∑
        try {
          // Step 1: Get presigned URL from backend
          const { data } = await axios.post('/api/upload/presigned-url', {
            filename: file.name,
            contentType: file.type
          });¬∑
          const { uploadUrl, fileUrl } = data;¬∑
          // Step 2: Upload directly to S3
          await axios.put(uploadUrl, file, {
            headers: {
              'Content-Type': file.type
            },
            onUploadProgress: (progressEvent) => {
              const percentCompleted = Math.round(
                (progressEvent.loaded * 100) / (progressEvent.total || 1)
              );
              setProgress(percentCompleted);
            }
          });¬∑
          // Step 3: Save file metadata to backend
          await axios.post('/api/upload/complete', {
            filename: file.name,
            fileUrl,
            size: file.size,
            contentType: file.type
          });¬∑
          setUploadedUrl(fileUrl);
          alert('Upload successful!');¬∑
        } catch (error) {
          console.error('Upload failed:', error);
          alert('Upload failed');
        } finally {
          setUploading(false);
        }
      };¬∑
      return (
        <div className=\"file-upload\">
          <input
            type=\"file\"
            onChange={handleFileChange}
            disabled={uploading}
          />¬∑
          <button onClick={handleUpload} disabled={!file || uploading}>
            {uploading ? `Uploading ${progress}%` : 'Upload'}
          </button>¬∑
          {uploadedUrl && (
            <div>
              <p>File uploaded successfully!</p>
              <a href={uploadedUrl} target=\"_blank\" rel=\"noopener noreferrer\">
                View File
              </a>
            </div>
          )}
        </div>
      );
    }
    ```¬∑
    ### Backend (Express + AWS S3)¬∑
    ```typescript
    // backend/api/upload.ts
    import express from 'express';
    import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
    import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
    import { v4 as uuidv4 } from 'uuid';
    import { authenticateToken } from './auth.js';
    import { prisma } from '../db.js';¬∑
    const router = express.Router();¬∑
    const s3Client = new S3Client({
      region: process.env.AWS_REGION!,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!
      }
    });¬∑
    const BUCKET_NAME = process.env.S3_BUCKET_NAME!;¬∑
    // POST /api/upload/presigned-url
    router.post('/presigned-url', authenticateToken, async (req, res) => {
      try {
        const { filename, contentType } = req.body;¬∑
        // Generate unique key
        const fileExtension = filename.split('.').pop();
        const key = `uploads/${req.userId}/${uuidv4()}.${fileExtension}`;¬∑
        // Create presigned URL (valid for 5 minutes)
        const command = new PutObjectCommand({
          Bucket: BUCKET_NAME,
          Key: key,
          ContentType: contentType
        });¬∑
        const uploadUrl = await getSignedUrl(s3Client, command, {
          expiresIn: 300
        });¬∑
        const fileUrl = `https://${BUCKET_NAME}.s3.amazonaws.com/${key}`;¬∑
        res.json({ uploadUrl, fileUrl, key });¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to generate presigned URL' });
      }
    });¬∑
    // POST /api/upload/complete
    router.post('/complete', authenticateToken, async (req, res) => {
      try {
        const { filename, fileUrl, size, contentType } = req.body;¬∑
        // Save file metadata to database
        const file = await prisma.file.create({
          data: {
            user_id: req.userId,
            filename,
            url: fileUrl,
            size,
            content_type: contentType
          }
        });¬∑
        res.json(file);¬∑
      } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Failed to save file metadata' });
      }
    });¬∑
    export default router;
    ```¬∑
    ---¬∑
    ## Resources¬∑
    ### scripts/
    - `generate-fullstack-crud.ts` - Scaffold complete CRUD feature
    - `test-fullstack-flow.ts` - E2E testing for cross-domain features¬∑
    ### references/
    - `references/auth-patterns.md` - Authentication best practices
    - `references/realtime-patterns.md` - WebSocket vs SSE tradeoffs
    - `references/file-upload-patterns.md` - Direct upload vs proxy upload¬∑
    ### assets/
    - `assets/fullstack-templates/` - Complete feature templates
    - `assets/e2e-tests/` - Playwright E2E test examples¬∑
    ## Related Skills¬∑
    - `api-design` - Backend API patterns
    - `component-patterns` - Frontend component architecture
    - `auth-security` - Security best practices
    - `workflow-orchestration` - Coordinating multi-agent work
    "

      109 |
      110 |         it('should have implementation checklist', () => {
    > 111 |           expect(content).toMatch(/##\s+Implementation\s+Checklist/i);
          |                           ^
      112 |         });
      113 |
      114 |         it('should be at least 500 lines (comprehensive documentation)', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:111:27)

  ‚óè Skills Validation Suite ‚Ä∫ Code Example Syntax Validation ‚Ä∫ testing-strategies code examples ‚Ä∫ should have valid TypeScript code blocks

    expect(received).toMatch(expected)

    Expected pattern: /import|const|function|interface|type|class/
    Received string:  "// vitest.config.ts
    export default defineConfig({
      test: {
        // Run tests in parallel (default)
        threads: true,¬∑
        // Max number of threads
        maxThreads: 8,¬∑
        // Isolate test environment for each file
        isolate: true
      }
    });
    "

      171 |
      172 |             // Must have either import, const, or function
    > 173 |             expect(code).toMatch(/import|const|function|interface|type|class/);
          |                          ^
      174 |           });
      175 |         });
      176 |

      at tests/integration/skills-validation.test.ts:173:26
          at Array.forEach (<anonymous>)
      at Object.<anonymous> (tests/integration/skills-validation.test.ts:165:20)

  ‚óè Skills Validation Suite ‚Ä∫ Code Example Syntax Validation ‚Ä∫ microservices code examples ‚Ä∫ should have valid TypeScript code blocks

    expect(received).toMatch(expected)

    Expected pattern: /import|const|function|interface|type|class/
    Received string:  "// Kubernetes liveness + readiness probes
    app.get('/health', async (req, res) => {
      // Liveness: Is the app running?
      res.status(200).json({ status: 'ok' });
    });¬∑
    app.get('/ready', async (req, res) => {
      // Readiness: Can the app serve traffic?
      try {
        await db.query('SELECT 1');  // Check database
        await kafka.admin().listTopics();  // Check Kafka
        res.status(200).json({ status: 'ready' });
      } catch (error) {
        res.status(503).json({ status: 'not ready', error: error.message });
      }
    });
    "

      171 |
      172 |             // Must have either import, const, or function
    > 173 |             expect(code).toMatch(/import|const|function|interface|type|class/);
          |                          ^
      174 |           });
      175 |         });
      176 |

      at tests/integration/skills-validation.test.ts:173:26
          at Array.forEach (<anonymous>)
      at Object.<anonymous> (tests/integration/skills-validation.test.ts:165:20)

  ‚óè Skills Validation Suite ‚Ä∫ Code Example Syntax Validation ‚Ä∫ rls-policies code examples ‚Ä∫ should have valid SQL code blocks (if applicable)

    expect(received).toMatch(expected)

    Expected pattern: /CREATE|SELECT|INSERT|UPDATE|DELETE|ALTER|DROP/i
    Received string:  "-- Always test policies with:
    -- 1. Owner of resource
    -- 2. Different user in same organization
    -- 3. User in different organization
    -- 4. Unauthenticated user
    -- 5. Admin/service role"

      200 |
      201 |               // Must have SQL keywords
    > 202 |               expect(code).toMatch(/CREATE|SELECT|INSERT|UPDATE|DELETE|ALTER|DROP/i);
          |                            ^
      203 |               expect(code).toContain(';'); // SQL statements end with semicolon
      204 |             });
      205 |           }

      at tests/integration/skills-validation.test.ts:202:28
          at Array.forEach (<anonymous>)
      at Object.<anonymous> (tests/integration/skills-validation.test.ts:198:23)

  ‚óè Skills Validation Suite ‚Ä∫ Validation Report Cross-Check ‚Ä∫ should have SKILLS_VALIDATION_REPORT.md file

    expect(received).toBe(expected) // Object.is equality

    Expected: true
    Received: false

      243 |     it('should have SKILLS_VALIDATION_REPORT.md file', () => {
      244 |       const reportPath = join(__dirname, '../../docs/SKILLS_VALIDATION_REPORT.md');
    > 245 |       expect(existsSync(reportPath)).toBe(true);
          |                                      ^
      246 |     });
      247 |
      248 |     it('should have validation scores for all 17 skills', () => {

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:245:38)

  ‚óè Skills Validation Suite ‚Ä∫ Validation Report Cross-Check ‚Ä∫ should have validation scores for all 17 skills

    ENOENT: no such file or directory, open '/Users/nissimmenashe/VERSATIL SDLC FW/docs/SKILLS_VALIDATION_REPORT.md'

      248 |     it('should have validation scores for all 17 skills', () => {
      249 |       const reportPath = join(__dirname, '../../docs/SKILLS_VALIDATION_REPORT.md');
    > 250 |       const reportContent = readFileSync(reportPath, 'utf-8');
          |                                         ^
      251 |
      252 |       EXPECTED_SKILLS.forEach((skill) => {
      253 |         // Each skill should be listed in the report

      at Object.<anonymous> (tests/integration/skills-validation.test.ts:250:41)

FAIL UNIT tests/unit/memory/context-stats-tracker.test.ts (54.161 s, 2458 MB heap size)
  ContextStatsTracker
    Initialization
      ‚úï should create stats directory on initialization (11 ms)
      ‚úì should handle missing stats directory gracefully (1 ms)
      ‚úï should load existing data on initialization (5 ms)
      ‚úì should handle corrupted data files gracefully (2 ms)
    Context Clear Event Tracking
      ‚úï should track context clear event (1 ms)
      ‚úï should track multiple clear events
      ‚úì should limit clear events to last 1000 (4363 ms)
      ‚úì should track clear events by agent (3 ms)
      ‚úï should persist clear events to disk (2 ms)
    Memory Operation Tracking
      ‚úï should track memory operation (2 ms)
      ‚úì should track multiple memory operations (1 ms)
      ‚úì should track failed operations (1 ms)
      ‚úì should limit memory operations to last 5000 (48639 ms)
      ‚úï should persist memory operations to disk (1 ms)
    Contract Event Tracking
      ‚úï should track contract event
      ‚úï should track contract lifecycle
      ‚úï should persist contract events to disk
    Statistics Calculation
      ‚úï should return default statistics when no data (1 ms)
      ‚úï should calculate correct averages
      ‚úï should group events by agent correctly
      ‚úì should group events by type correctly
    Report Generation
      ‚úï should generate comprehensive report (1 ms)
      ‚úï should handle empty data in report (16 ms)
    Cleanup Operations
      ‚úì should cleanup old data
      ‚úï should persist cleaned data (1 ms)
    Error Handling
      ‚úï should handle file write errors gracefully
      ‚úì should handle concurrent operations (8 ms)
    Singleton Pattern
      ‚úì should return same instance from getGlobalContextTracker
      ‚úì should initialize singleton automatically (1 ms)
    Edge Cases
      ‚úï should handle zero duration
      ‚úï should handle zero tokens cleared
      ‚úì should handle very long paths (3 ms)
      ‚úì should handle special characters in paths (1 ms)
      ‚úï should handle very large token counts (2 ms)

  ‚óè ContextStatsTracker ‚Ä∫ Initialization ‚Ä∫ should create stats directory on initialization

    TypeError: Cannot read properties of undefined (reading 'isDirectory')

      53 |     it('should create stats directory on initialization', async () => {
      54 |       const stats = await fs.stat(testStatsDir);
    > 55 |       expect(stats.isDirectory()).toBe(true);
         |                    ^
      56 |     });
      57 |
      58 |     it('should handle missing stats directory gracefully', async () => {

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:55:20)

  ‚óè ContextStatsTracker ‚Ä∫ Initialization ‚Ä∫ should load existing data on initialization

    expect(received).toBe(expected) // Object.is equality

    Expected: 1
    Received: 0

      77 |
      78 |       const stats = newTracker.getStatistics();
    > 79 |       expect(stats.totalClearEvents).toBe(1);
         |                                      ^
      80 |     });
      81 |
      82 |     it('should handle corrupted data files gracefully', async () => {

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:79:38)

  ‚óè ContextStatsTracker ‚Ä∫ Context Clear Event Tracking ‚Ä∫ should track context clear event

    expect(received).toBe(expected) // Object.is equality

    Expected: 75000
    Received: undefined

      105 |       const stats = tracker.getStatistics();
      106 |       expect(stats.totalClearEvents).toBe(1);
    > 107 |       expect(stats.avgTokensCleared).toBe(75000);
          |                                      ^
      108 |       expect(stats.avgClearDuration).toBe(600);
      109 |     });
      110 |

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:107:38)

  ‚óè ContextStatsTracker ‚Ä∫ Context Clear Event Tracking ‚Ä∫ should track multiple clear events

    expect(received).toBe(expected) // Object.is equality

    Expected: 62500
    Received: undefined

      130 |       const stats = tracker.getStatistics();
      131 |       expect(stats.totalClearEvents).toBe(2);
    > 132 |       expect(stats.avgTokensCleared).toBe(62500); // (60000 + 65000) / 2
          |                                      ^
      133 |       expect(stats.avgClearDuration).toBe(525); // (500 + 550) / 2
      134 |     });
      135 |

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:132:38)

  ‚óè ContextStatsTracker ‚Ä∫ Context Clear Event Tracking ‚Ä∫ should persist clear events to disk

    TypeError: Cannot read properties of undefined (reading 'then')

      196 |       // Verify file exists
      197 |       const eventsPath = path.join(testStatsDir, 'context-clear-events.jsonl');
    > 198 |       const fileExists = await fs.access(eventsPath).then(() => true).catch(() => false);
          |                                                     ^
      199 |       expect(fileExists).toBe(true);
      200 |
      201 |       // Verify file content

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:198:53)

  ‚óè ContextStatsTracker ‚Ä∫ Memory Operation Tracking ‚Ä∫ should track memory operation

    TypeError: Cannot read properties of undefined (reading 'alex-ba')

      224 |       expect(stats.totalMemoryOperations).toBe(1);
      225 |       expect(stats.memoryOperationsByType['create']).toBe(1);
    > 226 |       expect(stats.memoryOperationsByAgent['alex-ba']).toBe(1);
          |                                           ^
      227 |     });
      228 |
      229 |     it('should track multiple memory operations', async () => {

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:226:43)

  ‚óè ContextStatsTracker ‚Ä∫ Memory Operation Tracking ‚Ä∫ should persist memory operations to disk

    TypeError: Cannot read properties of undefined (reading 'then')

      288 |
      289 |       const opsPath = path.join(testStatsDir, 'memory-operations.jsonl');
    > 290 |       const fileExists = await fs.access(opsPath).then(() => true).catch(() => false);
          |                                                  ^
      291 |       expect(fileExists).toBe(true);
      292 |
      293 |       const content = await fs.readFile(opsPath, 'utf-8');

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:290:50)

  ‚óè ContextStatsTracker ‚Ä∫ Contract Event Tracking ‚Ä∫ should track contract event

    TypeError: tracker.trackContractEvent is not a function

      303 |   describe('Contract Event Tracking', () => {
      304 |     it('should track contract event', async () => {
    > 305 |       await tracker.trackContractEvent({
          |                     ^
      306 |         contractId: 'contract-123',
      307 |         eventType: 'created',
      308 |         sender: 'alex-ba',

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:305:21)

  ‚óè ContextStatsTracker ‚Ä∫ Contract Event Tracking ‚Ä∫ should track contract lifecycle

    TypeError: tracker.trackContractEvent is not a function

      322 |
      323 |       // Created
    > 324 |       await tracker.trackContractEvent({
          |                     ^
      325 |         contractId,
      326 |         eventType: 'created',
      327 |         sender: 'alex-ba',

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:324:21)

  ‚óè ContextStatsTracker ‚Ä∫ Contract Event Tracking ‚Ä∫ should persist contract events to disk

    TypeError: tracker.trackContractEvent is not a function

      360 |
      361 |     it('should persist contract events to disk', async () => {
    > 362 |       await tracker.trackContractEvent({
          |                     ^
      363 |         contractId: 'contract-789',
      364 |         eventType: 'created',
      365 |         sender: 'sarah-pm',

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:362:21)

  ‚óè ContextStatsTracker ‚Ä∫ Statistics Calculation ‚Ä∫ should return default statistics when no data

    expect(received).toBe(expected) // Object.is equality

    Expected: 0
    Received: undefined

      390 |       expect(stats.totalClearEvents).toBe(0);
      391 |       expect(stats.totalMemoryOperations).toBe(0);
    > 392 |       expect(stats.totalContractEvents).toBe(0);
          |                                         ^
      393 |       expect(stats.avgTokensCleared).toBe(0);
      394 |       expect(stats.avgClearDuration).toBe(0);
      395 |     });

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:392:41)

  ‚óè ContextStatsTracker ‚Ä∫ Statistics Calculation ‚Ä∫ should calculate correct averages

    expect(received).toBe(expected) // Object.is equality

    Expected: 65000
    Received: undefined

      416 |
      417 |       const stats = tracker.getStatistics();
    > 418 |       expect(stats.avgTokensCleared).toBe(65000); // (60000 + 70000) / 2
          |                                      ^
      419 |       expect(stats.avgClearDuration).toBe(600); // (500 + 700) / 2
      420 |     });
      421 |

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:418:38)

  ‚óè ContextStatsTracker ‚Ä∫ Statistics Calculation ‚Ä∫ should group events by agent correctly

    TypeError: Cannot read properties of undefined (reading 'maria-qa')

      449 |
      450 |       const stats = tracker.getStatistics();
    > 451 |       expect(stats.memoryOperationsByAgent['maria-qa']).toBe(2);
          |                                           ^
      452 |       expect(stats.memoryOperationsByAgent['james-frontend']).toBe(1);
      453 |     });
      454 |

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:451:43)

  ‚óè ContextStatsTracker ‚Ä∫ Report Generation ‚Ä∫ should generate comprehensive report

    TypeError: tracker.trackContractEvent is not a function

      508 |       });
      509 |
    > 510 |       await tracker.trackContractEvent({
          |                     ^
      511 |         contractId: 'contract-123',
      512 |         eventType: 'created',
      513 |         sender: 'alex-ba',

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:510:21)

  ‚óè ContextStatsTracker ‚Ä∫ Report Generation ‚Ä∫ should handle empty data in report

    expect(received).toContain(expected) // indexOf

    Expected substring: "Context Statistics Report"
    Received string:    "# Context Management Report¬∑
    **Generated**: 2025-10-29T16:53:25.448Z
    **Period**: All time to Now¬∑
    ## Summary Statistics¬∑
    - **Total Tokens Processed**: 0
    - **Total Clear Events**: 0
    - **Total Tokens Saved**: 0
    - **Avg Tokens Saved per Clear**: 0
    - **Total Memory Operations**: 0¬∑
    ## Clear Events by Agent¬∑¬∑¬∑
    ## Memory Operations by Type¬∑¬∑¬∑
    ## Recent Clear Events (Last 5)¬∑¬∑¬∑
    ## Efficiency Metrics¬∑
    - **Token Savings Rate**: 0%
    - **Memory Ops per Clear**: 0
    - **Uptime**: 0 seconds (0.00 hours)¬∑
    ---
    *Generated by VERSATIL Context Stats Tracker*"

      531 |       const report = await tracker.generateReport();
      532 |
    > 533 |       expect(report).toContain('Context Statistics Report');
          |                      ^
      534 |       expect(report).toContain('Total Clear Events: 0');
      535 |       expect(report).toContain('Total Memory Operations: 0');
      536 |       expect(report).toContain('Total Contract Events: 0');

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:533:22)

  ‚óè ContextStatsTracker ‚Ä∫ Cleanup Operations ‚Ä∫ should persist cleaned data

    TypeError: Cannot read properties of undefined (reading 'then')

      577 |       // Verify files still exist and are valid
      578 |       const opsPath = path.join(testStatsDir, 'memory-operations.jsonl');
    > 579 |       const fileExists = await fs.access(opsPath).then(() => true).catch(() => false);
          |                                                  ^
      580 |       expect(fileExists).toBe(true);
      581 |     });
      582 |   });

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:579:50)

  ‚óè ContextStatsTracker ‚Ä∫ Error Handling ‚Ä∫ should handle file write errors gracefully

    TypeError: fs.chmod is not a function

      585 |     it('should handle file write errors gracefully', async () => {
      586 |       // Make directory read-only to trigger write error
    > 587 |       await fs.chmod(testStatsDir, 0o444);
          |                ^
      588 |
      589 |       await expect(
      590 |         tracker.trackClearEvent({

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:587:16)

  ‚óè ContextStatsTracker ‚Ä∫ Edge Cases ‚Ä∫ should handle zero duration

    expect(received).toBe(expected) // Object.is equality

    Expected: 0
    Received: undefined

      659 |
      660 |       const stats = tracker.getStatistics();
    > 661 |       expect(stats.avgClearDuration).toBe(0);
          |                                      ^
      662 |     });
      663 |
      664 |     it('should handle zero tokens cleared', async () => {

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:661:38)

  ‚óè ContextStatsTracker ‚Ä∫ Edge Cases ‚Ä∫ should handle zero tokens cleared

    expect(received).toBe(expected) // Object.is equality

    Expected: 0
    Received: undefined

      673 |
      674 |       const stats = tracker.getStatistics();
    > 675 |       expect(stats.avgTokensCleared).toBe(0);
          |                                      ^
      676 |     });
      677 |
      678 |     it('should handle very long paths', async () => {

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:675:38)

  ‚óè ContextStatsTracker ‚Ä∫ Edge Cases ‚Ä∫ should handle very large token counts

    expect(received).toBe(expected) // Object.is equality

    Expected: 900000
    Received: undefined

      717 |
      718 |       const stats = tracker.getStatistics();
    > 719 |       expect(stats.avgTokensCleared).toBe(900000);
          |                                      ^
      720 |     });
      721 |   });
      722 | });

      at Object.<anonymous> (tests/unit/memory/context-stats-tracker.test.ts:719:38)

FAIL INTEGRATION tests/integration/agent-auto-activation-e2e.test.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/src/agents/opera/marcus-backend/enhanced-marcus.ts:42
    const __filename = (0, url_1.fileURLToPath)(import.meta.url);
          ^

    SyntaxError: Identifier '__filename' has already been declared

      15 | import { EnhancedMaria } from '../agents/opera/maria-qa/enhanced-maria.js';
      16 | import { EnhancedJames } from '../agents/opera/james-frontend/enhanced-james.js';
    > 17 | import { EnhancedMarcus } from '../agents/opera/marcus-backend/enhanced-marcus.js';
         | ^
      18 | import { getProactiveCapabilityEnhancer } from './proactive-capability-enhancer.js';
      19 | import type { RequiredCapabilities, EnhancementResult } from './proactive-capability-enhancer.js';
      20 |

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)
      at Object.<anonymous> (src/orchestration/proactive-agent-orchestrator.ts:17:1)
      at Object.<anonymous> (tests/integration/agent-auto-activation-e2e.test.ts:22:1)

FAIL INTEGRATION tests/integration/live-agent-activation.test.ts (87 MB heap size)
  Live Agent Auto-Activation (v7.2.0)
    ‚úï Test 1: Creating test file triggers Maria-QA suggestion (4 ms)
    ‚úï Test 2: Creating agent file triggers agent-creator template suggestion (5 ms)
    ‚úï Test 3: Auth intent triggers jwt-auth-cookies pattern suggestion (4 ms)
    ‚úï Test 4: Backend API file triggers Marcus-Backend suggestion (8 ms)
    ‚úï Test 5: Cross-skill relationships are suggested (3 ms)
    ‚úï Test 6: Hook execution time is under 100ms (6 ms)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 1: Creating test file triggers Maria-QA suggestion

    Command failed: echo '{"toolName":"Write","filePath":"/Users/nissimmenashe/VERSATIL SDLC FW/tests/fixtures/live-activation/inventory.test.ts","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-1"}' | .claude/hooks/dist/post-file-edit.cjs
    /bin/sh: .claude/hooks/dist/post-file-edit.cjs: No such file or directory

      56 |     });
      57 |
    > 58 |     const hookOutput = execSync(
         |                                ^
      59 |       `echo '${hookInput}' | .claude/hooks/dist/post-file-edit.cjs`,
      60 |       { encoding: 'utf-8' }
      61 |     );

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:58:32)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 2: Creating agent file triggers agent-creator template suggestion

    Command failed: echo '{"toolName":"Write","filePath":"/Users/nissimmenashe/VERSATIL SDLC FW/.claude/agents/test-live-agent.md","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-2"}' | .claude/hooks/dist/post-file-edit.cjs
    /bin/sh: .claude/hooks/dist/post-file-edit.cjs: No such file or directory

      93 |     });
      94 |
    > 95 |     const hookOutput = execSync(
         |                                ^
      96 |       `echo '${hookInput}' | .claude/hooks/dist/post-file-edit.cjs`,
      97 |       { encoding: 'utf-8' }
      98 |     );

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:95:32)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 3: Auth intent triggers jwt-auth-cookies pattern suggestion

    Command failed: echo '{"prompt":"Implement JWT authentication with cookies","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-3"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      125 |
      126 |     // Act: Run before-prompt hook
    > 127 |     const hookOutput = execSync(
          |                                ^
      128 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      129 |       { encoding: 'utf-8' }
      130 |     );

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:127:32)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 4: Backend API file triggers Marcus-Backend suggestion

    Command failed: echo '{"toolName":"Write","filePath":"/Users/nissimmenashe/VERSATIL SDLC FW/tests/fixtures/routes/users.ts","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-4"}' | .claude/hooks/dist/post-file-edit.cjs
    /bin/sh: .claude/hooks/dist/post-file-edit.cjs: No such file or directory

      162 |     });
      163 |
    > 164 |     const hookOutput = execSync(
          |                                ^
      165 |       `echo '${hookInput}' | .claude/hooks/dist/post-file-edit.cjs`,
      166 |       { encoding: 'utf-8' }
      167 |     );

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:164:32)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 5: Cross-skill relationships are suggested

    Command failed: echo '{"prompt":"I need to work with the rag library for pattern search","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-5"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      188 |
      189 |     // Act: Run before-prompt hook
    > 190 |     const hookOutput = execSync(
          |                                ^
      191 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      192 |       { encoding: 'utf-8' }
      193 |     );

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:190:32)

  ‚óè Live Agent Auto-Activation (v7.2.0) ‚Ä∫ Test 6: Hook execution time is under 100ms

    Command failed: echo '{"toolName":"Write","filePath":"/Users/nissimmenashe/VERSATIL SDLC FW/tests/fixtures/live-activation/perf-test.test.ts","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-session-6"}' | .claude/hooks/dist/post-file-edit.cjs
    /bin/sh: .claude/hooks/dist/post-file-edit.cjs: No such file or directory

      218 |     const start = Date.now();
      219 |     for (let i = 0; i < iterations; i++) {
    > 220 |       execSync(`echo '${hookInput}' | .claude/hooks/dist/post-file-edit.cjs`, {
          |               ^
      221 |         encoding: 'utf-8'
      222 |       });
      223 |     }

      at Object.<anonymous> (tests/integration/live-agent-activation.test.ts:220:15)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.test.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
FAIL INTEGRATION tests/integration/new-patterns.test.ts (90 MB heap size)
  New Named Patterns (v7.3.0)
    ‚úì Test 1: All 5 new patterns exist and are valid JSON (3 ms)
    ‚úï Test 2: OAuth intent triggers oauth2-integration pattern (15 ms)
    ‚úï Test 3: Migration intent triggers database-migration pattern + Dana-Database (25 ms)
    ‚úï Test 4: GraphQL intent triggers graphql-api pattern (57 ms)
    ‚úï Test 5: Component intent triggers react-component pattern + James-Frontend (42 ms)
    ‚úï Test 6: Docker intent triggers docker-deployment pattern (21 ms)
    ‚úì Test 7: Total pattern count is 54 (49 + 5 new) (37 ms)
    ‚úì Test 8: Pattern metrics are realistic (3 ms)

  ‚óè New Named Patterns (v7.3.0) ‚Ä∫ Test 2: OAuth intent triggers oauth2-integration pattern

    Command failed: echo '{"prompt":"Implement OAuth2 with Google and GitHub","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-oauth"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      71 |     });
      72 |
    > 73 |     const hookOutput = execSync(
         |                                ^
      74 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      75 |       { encoding: 'utf-8' }
      76 |     );

      at Object.<anonymous> (tests/integration/new-patterns.test.ts:73:32)

  ‚óè New Named Patterns (v7.3.0) ‚Ä∫ Test 3: Migration intent triggers database-migration pattern + Dana-Database

    Command failed: echo '{"prompt":"Create Prisma migration to add phone column to User table","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-migration"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      90 |     });
      91 |
    > 92 |     const hookOutput = execSync(
         |                                ^
      93 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      94 |       { encoding: 'utf-8' }
      95 |     );

      at Object.<anonymous> (tests/integration/new-patterns.test.ts:92:32)

  ‚óè New Named Patterns (v7.3.0) ‚Ä∫ Test 4: GraphQL intent triggers graphql-api pattern

    Command failed: echo '{"prompt":"Implement GraphQL API with Apollo Server and resolvers","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-graphql"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      110 |     });
      111 |
    > 112 |     const hookOutput = execSync(
          |                                ^
      113 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      114 |       { encoding: 'utf-8' }
      115 |     );

      at Object.<anonymous> (tests/integration/new-patterns.test.ts:112:32)

  ‚óè New Named Patterns (v7.3.0) ‚Ä∫ Test 5: Component intent triggers react-component pattern + James-Frontend

    Command failed: echo '{"prompt":"Create new React component for user profile card","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-component"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      129 |     });
      130 |
    > 131 |     const hookOutput = execSync(
          |                                ^
      132 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      133 |       { encoding: 'utf-8' }
      134 |     );

      at Object.<anonymous> (tests/integration/new-patterns.test.ts:131:32)

  ‚óè New Named Patterns (v7.3.0) ‚Ä∫ Test 6: Docker intent triggers docker-deployment pattern

    Command failed: echo '{"prompt":"Create Dockerfile with multi-stage build and docker-compose","workingDirectory":"/Users/nissimmenashe/VERSATIL SDLC FW","sessionId":"test-docker"}' | .claude/hooks/dist/before-prompt.cjs
    /bin/sh: .claude/hooks/dist/before-prompt.cjs: No such file or directory

      149 |     });
      150 |
    > 151 |     const hookOutput = execSync(
          |                                ^
      152 |       `echo '${hookInput}' | .claude/hooks/dist/before-prompt.cjs`,
      153 |       { encoding: 'utf-8' }
      154 |     );

      at Object.<anonymous> (tests/integration/new-patterns.test.ts:151:32)

FAIL INTEGRATION tests/integration/test-sdk-parallel.ts
  ‚óè Test suite failed to run

    Configuration error:

    Could not locate module ./src/core/versatil-orchestrator.js mapped as:
    $1.

    Please check your configuration for these entries:
    {
      "moduleNameMapper": {
        "/^(\.{1,2}\/.*)\.js$/": "$1"
      },
      "resolver": undefined
    }

      10 |  */
      11 |
    > 12 | import { VersatilOrchestrator } from './src/core/versatil-orchestrator.js';
         | ^
      13 | import { TaskType, Priority, SDLCPhase } from './src/orchestration/parallel-task-manager.js';
      14 |
      15 | async function testSDKParallelExecution() {

      at createNoMappedModuleFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:759:17)
      at Object.<anonymous> (tests/integration/test-sdk-parallel.ts:12:1)

FAIL INTEGRATION tests/integration/test-sdk-agents.ts
  ‚óè Test suite failed to run

    Configuration error:

    Could not locate module ./src/agents/opera/maria-qa/maria-sdk-agent.js mapped as:
    $1.

    Please check your configuration for these entries:
    {
      "moduleNameMapper": {
        "/^(\.{1,2}\/.*)\.js$/": "$1"
      },
      "resolver": undefined
    }

      4 |  */
      5 |
    > 6 | import { MariaSDKAgent } from './src/agents/opera/maria-qa/maria-sdk-agent.js';
        | ^
      7 | import { JamesSDKAgent } from './src/agents/opera/james-frontend/james-sdk-agent.js';
      8 | import { MarcusSDKAgent } from './src/agents/opera/marcus-backend/marcus-sdk-agent.js';
      9 | import { EnhancedVectorMemoryStore } from './src/rag/enhanced-vector-memory-store.js';

      at createNoMappedModuleFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:759:17)
      at Object.<anonymous> (tests/integration/test-sdk-agents.ts:6:1)

FAIL INTEGRATION tests/integration/introspective-integration.test.ts
  ‚óè Test suite failed to run

    Cannot find module '../../src/agents/introspective-agent' from 'tests/integration/introspective-integration.test.ts'

      3 |  */
      4 |
    > 5 | import {
        | ^
      6 |   IntrospectiveAgent,
      7 |   TestFileSystemProvider,
      8 |   TestCommandExecutor

      at Resolver._throwModNotFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:427:11)
      at Object.<anonymous> (tests/integration/introspective-integration.test.ts:5:1)

FAIL INTEGRATION tests/planning/todo-file-generator.test.ts (102 MB heap size)
  TodoFileGenerator
    ‚úï should generate todo file with correct naming
    ‚úï should generate TodoWrite items
    ‚úï should generate Mermaid dependency graph
    ‚úï should calculate total effort correctly
    ‚úï should detect execution waves

  ‚óè TodoFileGenerator ‚Ä∫ should generate todo file with correct naming

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/planning/todo-file-generator.test.ts:50:36)

  ‚óè TodoFileGenerator ‚Ä∫ should generate TodoWrite items

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/planning/todo-file-generator.test.ts:69:36)

  ‚óè TodoFileGenerator ‚Ä∫ should generate Mermaid dependency graph

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/planning/todo-file-generator.test.ts:102:36)

  ‚óè TodoFileGenerator ‚Ä∫ should calculate total effort correctly

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/planning/todo-file-generator.test.ts:136:36)

  ‚óè TodoFileGenerator ‚Ä∫ should detect execution waves

    Template not found at /Users/nissimmenashe/VERSATIL SDLC FW/todos-test/000-pending-p1-TEMPLATE.md

       95 |     } catch (error) {
       96 |       this.logger.error('Failed to load todo template', { error }, 'todo-generator');
    >  97 |       throw new Error(`Template not found at ${this.templatePath}`);
          |             ^
       98 |     }
       99 |   }
      100 |

      at TodoFileGenerator.loadTemplate (src/planning/todo-file-generator.ts:97:13)
      at TodoFileGenerator.generateTodos (src/planning/todo-file-generator.ts:134:27)
      at Object.<anonymous> (tests/planning/todo-file-generator.test.ts:167:36)

PASS INTEGRATION tests/agents/sdk-agents.test.ts (117 MB heap size)
  SDK Agent Definitions
    Maria-QA Agent
      ‚úì should have valid agent definition (1 ms)
      ‚úì should describe Quality Guardian role (1 ms)
      ‚úì should have comprehensive prompt
    James-Frontend Agent
      ‚úì should have valid agent definition
      ‚úì should describe Frontend Expert role (1 ms)
      ‚úì should have UI/UX focus in prompt (1 ms)
    Marcus-Backend Agent
      ‚úì should have valid agent definition
      ‚úì should describe Backend Architect role
      ‚úì should have API and security focus in prompt
    All Agent Definitions
      ‚úì should all have required fields (2 ms)
      ‚úì should all have non-empty prompts

PASS INTEGRATION tests/templates/template-matcher.test.ts (92 MB heap size)
  TemplateMatcher
    ‚úì should match "Add user authentication" to auth-system template (18 ms)
    ‚úì should match "Add products API" to crud-endpoint template (3 ms)
    ‚úì should support explicit template selection (2 ms)
    ‚úì should return no match for very different description (3 ms)
    ‚úì should load all available templates (3 ms)

PASS INTEGRATION tests/rag/pattern-search.test.ts (126 MB heap size)
  PatternSearchService
    ‚úì should return empty result when no patterns found (2520 ms)
    ‚úì should apply min_similarity filter
    ‚úì should limit results correctly

FAIL STRESS tests/stress/context-overflow.stress.test.ts (8.101 s, 132 MB heap size)
  Stress Test 1: Context Overflow Resilience
    ‚úï Handles 85% token usage gracefully (6003 ms)
    ‚úï Aggressive compaction at 95% token usage (1 ms)
    ‚úï Prevents 100% overflow with buffer
    ‚úï Never exceeds 200k token limit (2036 ms)
    ‚úï Preserves 99.5%+ critical patterns during clears (1 ms)
    ‚úì Recovers from critical state in <5 seconds (1 ms)

  ‚óè Stress Test 1: Context Overflow Resilience ‚Ä∫ Handles 85% token usage gracefully

    expect(received).toBeGreaterThan(expected)

    Expected: > 130000
    Received:   52000

      70 |     // Should clear to ~75% (150k tokens)
      71 |     expect(tokensAfter).toBeLessThan(150_000);
    > 72 |     expect(tokensAfter).toBeGreaterThan(130_000); // Don't over-clear
         |                         ^
      73 |
      74 |     // Verify critical risk detected
      75 |     expect(dashboard.risks).toContainEqual(

      at Object.<anonymous> (tests/stress/context-overflow.stress.test.ts:72:25)

  ‚óè Stress Test 1: Context Overflow Resilience ‚Ä∫ Aggressive compaction at 95% token usage

    expect(received).toBeGreaterThan(expected)

    Expected: > 0
    Received:   0

      113 |
      114 |     // Verify multiple risks detected
    > 115 |     expect(dashboard.risks.length).toBeGreaterThan(0);
          |                                    ^
      116 |     expect(dashboard.risks.filter(r => r.severity === 'critical').length).toBeGreaterThan(0);
      117 |
      118 |     // Verify recommendations provided

      at Object.<anonymous> (tests/stress/context-overflow.stress.test.ts:115:36)

  ‚óè Stress Test 1: Context Overflow Resilience ‚Ä∫ Prevents 100% overflow with buffer

    expect(received).toBeTruthy()

    Received: undefined

      152 |     // Verify auto-recovery time
      153 |     const clearEvent = statsTracker.getClearEvents()[0];
    > 154 |     expect(clearEvent).toBeTruthy();
          |                        ^
      155 |
      156 |     // Recovery should be instant (< 5 seconds)
      157 |     const recoveryTime = Date.now() - clearEvent.timestamp.getTime();

      at Object.<anonymous> (tests/stress/context-overflow.stress.test.ts:154:24)

  ‚óè Stress Test 1: Context Overflow Resilience ‚Ä∫ Never exceeds 200k token limit

    expect(received).toBeGreaterThan(expected)

    Expected: > 0
    Received:   0

      189 |
      190 |     // Should have triggered at least 1 compaction
    > 191 |     expect(statsTracker.getStatistics().totalClearEvents).toBeGreaterThan(0);
          |                                                           ^
      192 |
      193 |     // Final token count should be well below limit
      194 |     const finalTokens = measurements[measurements.length - 1];

      at Object.<anonymous> (tests/stress/context-overflow.stress.test.ts:191:59)

  ‚óè Stress Test 1: Context Overflow Resilience ‚Ä∫ Preserves 99.5%+ critical patterns during clears

    TypeError: (0 , agent_memory_manager_js_1.getAgentMemoryAPI) is not a function

      210 |     for (let i = 0; i < 100; i++) {
      211 |       const agent = agents[i % agents.length];
    > 212 |       const memory = getAgentMemoryAPI(agent as any);
          |                                       ^
      213 |
      214 |       const pattern = {
      215 |         title: `Critical Pattern ${i}`,

      at Object.<anonymous> (tests/stress/context-overflow.stress.test.ts:212:39)


  ‚óè  Cannot log after tests are done. Did you forget to wait for something async in your test?
    Attempted to log "[rag-memory] INFO: Enhanced vector memory store initialized {"memoryCount":0,"vectorBackend":"local","graphRAGEnabled":false,"gcpEnabled":false,"supabaseEnabled":false,"features":{"reranking":true,"multimodal":true,"hybridSearch":true}}".

      17 |       console.error(logMessage);
      18 |     } else {
    > 19 |       console.log(logMessage);
         |               ^
      20 |     }
      21 |   }
      22 |

      at console.log (node_modules/.pnpm/@jest+console@29.7.0/node_modules/@jest/console/build/CustomConsole.js:141:10)
      at VERSATILLogger.info (src/utils/logger.ts:19:15)
      at EnhancedVectorMemoryStore.initialize (src/rag/enhanced-vector-memory-store.ts:93:21)

FAIL INTEGRATION tests/integration/library-context-injection.test.ts (5.93 s, 2437 MB heap size)
  Library Context Injection
    Library Context Detection
      ‚úï should load agents/ context when user mentions "agents" (662 ms)
      ‚úï should load rag/ context when user mentions "rag" (474 ms)
      ‚úï should load testing/ context when user mentions "testing" (444 ms)
      ‚úï should load orchestration/ context when user mentions file path (350 ms)
    Multiple Library Detection
      ‚úï should load multiple library contexts when multiple libraries mentioned (336 ms)
      ‚úï should handle all 15 libraries being mentioned (343 ms)
    Context Content Validation
      ‚úï should include key sections from library context files (376 ms)
      ‚úï should include DO and DON'T rules (346 ms)
    No Match Scenarios
      ‚úì should not load library context when no libraries mentioned (349 ms)
      ‚úì should handle non-existent library gracefully (334 ms)
    Performance
      ‚úï should load library context in <100ms (331 ms)
      ‚úì should handle 5 libraries in <200ms (353 ms)
    Combined RAG + Library Context
      ‚úï should combine RAG patterns and library context when both match (351 ms)
    Integration with Claude Code
      ‚úì should format output as valid JSON for Claude Code ingestion (385 ms)

  ‚óè Library Context Injection ‚Ä∫ Library Context Detection ‚Ä∫ should load agents/ context when user mentions "agents"

    TypeError: Cannot read properties of null (reading 'role')

      66 |       // Assert
      67 |       expect(context).toBeDefined();
    > 68 |       expect(context.role).toBe('system');
         |                      ^
      69 |       expect(context.content).toContain('Library Context: agents/');
      70 |       expect(context.content).toContain('OPERA Agent System');
      71 |       expect(context.content).toContain('BaseAgent');

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:68:22)

  ‚óè Library Context Injection ‚Ä∫ Library Context Detection ‚Ä∫ should load rag/ context when user mentions "rag"

    TypeError: Cannot read properties of null (reading 'content')

      83 |       // Assert
      84 |       expect(context).toBeDefined();
    > 85 |       expect(context.content).toContain('Library Context: rag/');
         |                      ^
      86 |       expect(context.content).toContain('Retrieval-Augmented Generation');
      87 |       expect(context.content).toContain('PatternSearchService');
      88 |       expect(context.content).toContain('GraphRAG');

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:85:22)

  ‚óè Library Context Injection ‚Ä∫ Library Context Detection ‚Ä∫ should load testing/ context when user mentions "testing"

    TypeError: Cannot read properties of null (reading 'content')

       99 |       // Assert
      100 |       expect(context).toBeDefined();
    > 101 |       expect(context.content).toContain('Library Context: testing/');
          |                      ^
      102 |       expect(context.content).toContain('Quality Assurance Framework');
      103 |       expect(context.content).toContain('Maria-QA');
      104 |       expect(context.content).toContain('80%+ coverage');

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:101:22)

  ‚óè Library Context Injection ‚Ä∫ Library Context Detection ‚Ä∫ should load orchestration/ context when user mentions file path

    TypeError: Cannot read properties of null (reading 'content')

      115 |       // Assert
      116 |       expect(context).toBeDefined();
    > 117 |       expect(context.content).toContain('Library Context: orchestration/');
          |                      ^
      118 |       expect(context.content).toContain('Multi-Agent Workflow Coordination');
      119 |       expect(context.content).toContain('PlanFirstOrchestrator');
      120 |     });

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:117:22)

  ‚óè Library Context Injection ‚Ä∫ Multiple Library Detection ‚Ä∫ should load multiple library contexts when multiple libraries mentioned

    TypeError: Cannot read properties of null (reading 'content')

      132 |       // Assert
      133 |       expect(context).toBeDefined();
    > 134 |       expect(context.content).toContain('Library Context: agents/');
          |                      ^
      135 |       expect(context.content).toContain('Library Context: rag/');
      136 |       expect(context.content).toContain('Library Context: orchestration/');
      137 |     });

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:134:22)

  ‚óè Library Context Injection ‚Ä∫ Multiple Library Detection ‚Ä∫ should handle all 15 libraries being mentioned

    TypeError: Cannot read properties of null (reading 'content')

      156 |
      157 |       libraries.forEach(lib => {
    > 158 |         expect(context.content).toContain(`Library Context: ${lib}/`);
          |                        ^
      159 |       });
      160 |     });
      161 |   });

      at tests/integration/library-context-injection.test.ts:158:24
          at Array.forEach (<anonymous>)
      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:157:17)

  ‚óè Library Context Injection ‚Ä∫ Context Content Validation ‚Ä∫ should include key sections from library context files

    TypeError: Cannot read properties of null (reading 'content')

      174 |
      175 |       // Verify standard sections
    > 176 |       expect(context.content).toContain('## üìã Library Purpose');
          |                      ^
      177 |       expect(context.content).toContain('## üéØ Core Concepts');
      178 |       expect(context.content).toContain('## ‚úÖ Development Rules');
      179 |       expect(context.content).toContain('## üîß Common Patterns');

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:176:22)

  ‚óè Library Context Injection ‚Ä∫ Context Content Validation ‚Ä∫ should include DO and DON'T rules

    TypeError: Cannot read properties of null (reading 'content')

      191 |       // Assert
      192 |       expect(context).toBeDefined();
    > 193 |       expect(context.content).toMatch(/### DO ‚úì/);
          |                      ^
      194 |       expect(context.content).toMatch(/### DON'T ‚úó/);
      195 |     });
      196 |   });

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:193:22)

  ‚óè Library Context Injection ‚Ä∫ Performance ‚Ä∫ should load library context in <100ms

    expect(received).toBeLessThan(expected)

    Expected: < 100
    Received:   330

      235 |
      236 |       // Assert
    > 237 |       expect(duration).toBeLessThan(100); // <100ms target
          |                        ^
      238 |     });
      239 |
      240 |     it('should handle 5 libraries in <200ms', () => {

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:237:24)

  ‚óè Library Context Injection ‚Ä∫ Combined RAG + Library Context ‚Ä∫ should combine RAG patterns and library context when both match

    expect(received).not.toBeNull()

    Received: null

      263 |       // Assert
      264 |       expect(context).toBeDefined();
    > 265 |       expect(context).not.toBeNull();
          |                           ^
      266 |
      267 |       // Guard against null context
      268 |       if (!context || !context.content) {

      at Object.<anonymous> (tests/integration/library-context-injection.test.ts:265:27)

PASS UNIT tests/mcp/docs-cache.test.ts (150 MB heap size)
  DocsCache
    ETag Generation
      ‚úì should generate consistent ETags for same content (1 ms)
      ‚úì should generate different ETags for different content
    Cache Set and Get
      ‚úì should cache and retrieve content (1 ms)
      ‚úì should return null for cache miss
      ‚úì should store metadata with cache entry (1 ms)
      ‚úì should track cache hits
    Cache Expiration (TTL)
      ‚úì should expire cache entries after maxAge (1102 ms)
      ‚úì should not expire fresh cache entries (1 ms)
      ‚úì should validate cache freshness with isCacheValid (1101 ms)
    Compression
      ‚úì should pre-compress content with gzip (1 ms)
      ‚úì should pre-compress content with brotli (1 ms)
      ‚úì should retrieve compressed content when requested
      ‚úì should achieve good compression ratio (1 ms)
    Cache Eviction
      ‚úì should evict oldest entry when cache is full (1 ms)
      ‚úì should track eviction count in metrics (1 ms)
    Cache Metrics
      ‚úì should track cache hits and misses (1 ms)
      ‚úì should calculate hit rate correctly
      ‚úì should report total cache size (1 ms)
      ‚úì should report compressed size when compression is enabled
      ‚úì should reset metrics
    Cache Clear
      ‚úì should clear all cache entries (1 ms)
    ETag Validation (HTTP 304)
      ‚úì should validate ETag for cache hit
      ‚úì should invalidate with mismatched ETag
      ‚úì should increment hits when ETag matches (1 ms)
    Constructor Options
      ‚úì should respect custom maxAge (601 ms)
      ‚úì should respect custom maxEntries (1 ms)
      ‚úì should disable compression when requested

PASS UNIT tests/mcp/playwright-integration.test.ts (147 MB heap size)
  Playwright MCP Integration
    Basic Browser Automation
      ‚úì should navigate to a URL (101 ms)
      ‚úì should reject invalid URLs (7 ms)
      ‚úì should capture screenshot (102 ms)
      ‚úì should capture full-page screenshot (101 ms)
      ‚úì should perform click action (153 ms)
      ‚úì should throw error when clicking without navigation
    Accessibility Testing
      ‚úì should capture accessibility snapshot (101 ms)
      ‚úì should identify accessibility tree structure (100 ms)
      ‚úì should validate accessible names on elements (103 ms)
    Maria-QA Integration
      ‚úì should perform accessibility audit (102 ms)
      ‚úì should detect accessibility violations (101 ms)
      ‚úì should capture visual regression baseline (102 ms)
      ‚úì should test user interaction flow (303 ms)
      ‚úì should handle interaction flow failures (154 ms)
    Performance Validation
      ‚úì should measure navigation time (101 ms)
      ‚úì should measure screenshot capture time (101 ms)
      ‚úì should measure accessibility snapshot time (101 ms)
    Error Handling
      ‚úì should handle navigation errors (100 ms)
      ‚úì should handle screenshot errors when browser closed (1 ms)
      ‚úì should handle accessibility snapshot errors when browser closed
    Integration with OPERA Workflow
      ‚úì should support James-Frontend UI testing (101 ms)
      ‚úì should support Maria-QA quality gates (354 ms)

PASS UNIT tests/mcp/docs-rate-limiter.test.ts (2453 MB heap size)
  RateLimiter
    basic rate limiting
      ‚úì should allow requests within limit (1 ms)
      ‚úì should track remaining requests
      ‚úì should block requests after exceeding limit
      ‚úì should provide retry-after time when blocked
      ‚úì should isolate limits per key
    token refill
      ‚úì should refill tokens after time window (1102 ms)
      ‚úì should partially refill tokens over time (500 ms)
    status queries
      ‚úì should get status without consuming tokens (1 ms)
      ‚úì should get status for new key
    reset and clear
      ‚úì should reset rate limit for a key (1 ms)
      ‚úì should clear all rate limits
    key tracking
      ‚úì should track number of keys (1 ms)
  MultiTierRateLimiter
    tier management
      ‚úì should add and use different tiers
      ‚úì should enforce different limits per tier
      ‚úì should get all tier names (1 ms)
      ‚úì should throw error for non-existent tier (6 ms)
    tier isolation
      ‚úì should isolate keys between tiers
    reset and clear
      ‚úì should reset rate limit for specific tier
      ‚úì should clear all tiers
  Helper Functions
    createStandardTiers
      ‚úì should create standard tier configuration (2 ms)
      ‚úì should have different limits for each tier
    formatRateLimitHeaders
      ‚úì should format headers for allowed request (1 ms)
      ‚úì should include retry-after for blocked request
    createRateLimitError
      ‚úì should return empty string for allowed request
      ‚úì should create error message with seconds
      ‚úì should create error message with minutes (1 ms)
      ‚úì should create generic error for short wait

PASS UNIT tests/mcp/docs-performance.test.ts (161 MB heap size)
  DocsPerformanceMonitor
    Query Tracking
      ‚úì should track query metrics (1 ms)
      ‚úì should track multiple queries
      ‚úì should calculate cache hit rate correctly
      ‚úì should respect maxMetrics limit
    Index Build Tracking
      ‚úì should track index build metrics (1 ms)
      ‚úì should track multiple index builds
      ‚úì should keep last index build timestamp
    Percentile Calculation
      ‚úì should calculate p50 (median) correctly
      ‚úì should calculate p95 correctly
      ‚úì should calculate p99 correctly
      ‚úì should handle empty metrics gracefully (1 ms)
    Prometheus Export
      ‚úì should export metrics in Prometheus format
      ‚úì should include quantiles in Prometheus export
      ‚úì should format Prometheus metrics correctly
    Recent Queries
      ‚úì should return recent queries in reverse chronological order (1 ms)
      ‚úì should respect limit parameter
      ‚úì should include query metadata
    Slowest Queries
      ‚úì should return slowest queries sorted by duration
      ‚úì should respect limit parameter (1 ms)
    Time Window Queries
      ‚úì should count queries within time window (100 ms)
      ‚úì should calculate cache hit rate by time window (101 ms)
    Reset Metrics
      ‚úì should reset all metrics
      ‚úì should reset uptime on reset
    Uptime Tracking
      ‚úì should track uptime in milliseconds (102 ms)
      ‚úì should export uptime in seconds for Prometheus (504 ms)

PASS UNIT tests/mcp/docs-progress.test.ts (137 MB heap size)
  DocsProgressTracker
    startOperation
      ‚úì should start a new operation and return operation ID (1 ms)
      ‚úì should generate unique operation IDs
    reportProgress
      ‚úì should report progress for an operation (1 ms)
      ‚úì should calculate percentage correctly
      ‚úì should handle zero total
      ‚úì should throw error for non-existent operation (19 ms)
      ‚úì should throw error for non-running operation
      ‚úì should store metadata
    completeOperation
      ‚úì should mark operation as completed (1 ms)
      ‚úì should throw error for non-existent operation
    failOperation
      ‚úì should mark operation as failed with error
    subscribe and unsubscribe
      ‚úì should notify callback on progress update (3 ms)
      ‚úì should support multiple callbacks (2 ms)
      ‚úì should unsubscribe callback
      ‚úì should not throw on unsubscribe non-existent callback
      ‚úì should clear callbacks on complete
    getProgressHistory
      ‚úì should return all progress events (1 ms)
      ‚úì should return empty array for non-existent operation
    getOperationDuration
      ‚úì should return duration for completed operation (68 ms)
      ‚úì should return current duration for running operation
      ‚úì should return null for non-existent operation
    getActiveOperations
      ‚úì should return only running operations
    getOperationSummary
      ‚úì should return formatted summary
      ‚úì should show completed status (1 ms)
      ‚úì should show failed status (1 ms)
    formatProgressEvent
      ‚úì should format progress with bar
    cleanup
      ‚úì should remove old completed operations (108 ms)
      ‚úì should not remove running operations (4 ms)
    getStatistics
      ‚úì should return correct statistics (1 ms)
      ‚úì should calculate average duration (25 ms)
    reset
      ‚úì should clear all operations

FAIL UNIT tests/unit/quality-gates/coverage-enforcement.test.ts (2467 MB heap size)
  Coverage Enforcement
    Coverage Threshold Validation
      ‚úï should PASS when all coverage metrics are >= 80% (2 ms)
      ‚úì should FAIL when statements coverage is below 80% (42 ms)
      ‚úì should FAIL when branches coverage is below 80% (48 ms)
      ‚úì should FAIL when functions coverage is below 80% (132 ms)
      ‚úì should FAIL when lines coverage is below 80% (80 ms)
      ‚úï should FAIL when multiple metrics are below 80% (148 ms)
      ‚úì should PASS with exactly 80% coverage (boundary case) (110 ms)
    Error Handling
      ‚úì should ERROR when coverage report is missing (133 ms)
      ‚úì should provide helpful suggestions when coverage is low (68 ms)
    Output Format
      ‚úì should display all four coverage metrics (61 ms)
      ‚úï should show percentage values in output (1 ms)
      ‚úï should indicate threshold requirement (2 ms)

  ‚óè Coverage Enforcement ‚Ä∫ Coverage Threshold Validation ‚Ä∫ should PASS when all coverage metrics are >= 80%

    expect(received).toBe(expected) // Object.is equality

    Expected: 0
    Received: 1

      115 |       const result = runCoverageChecker(path.join(testCoverageDir, 'coverage-summary.json'));
      116 |
    > 117 |       expect(result.exitCode).toBe(0);
          |                               ^
      118 |       expect(result.output).toContain('‚úÖ');
      119 |       expect(result.output).toContain('Coverage meets 80% threshold');
      120 |     });

      at Object.<anonymous> (tests/unit/quality-gates/coverage-enforcement.test.ts:117:31)

  ‚óè Coverage Enforcement ‚Ä∫ Coverage Threshold Validation ‚Ä∫ should FAIL when multiple metrics are below 80%

    expect(received).toBe(expected) // Object.is equality

    Expected: 1
    Received: 2

      171 |       const result = runCoverageChecker(path.join(testCoverageDir, 'coverage-summary.json'));
      172 |
    > 173 |       expect(result.exitCode).toBe(1);
          |                               ^
      174 |       expect(result.output).toContain('‚ùå');
      175 |       expect(result.output).toContain('Coverage below 80% threshold');
      176 |

      at Object.<anonymous> (tests/unit/quality-gates/coverage-enforcement.test.ts:173:31)

  ‚óè Coverage Enforcement ‚Ä∫ Output Format ‚Ä∫ should show percentage values in output

    ENOENT: no such file or directory, open '/Users/nissimmenashe/VERSATIL SDLC FW/test-coverage-temp/coverage-summary.json'

      48 |
      49 |     const reportPath = path.join(testCoverageDir, 'coverage-summary.json');
    > 50 |     fs.writeFileSync(reportPath, JSON.stringify(coverageData, null, 2));
         |        ^
      51 |     return reportPath;
      52 |   }
      53 |

      at createMockCoverageReport (tests/unit/quality-gates/coverage-enforcement.test.ts:50:8)
      at Object.<anonymous> (tests/unit/quality-gates/coverage-enforcement.test.ts:230:7)

  ‚óè Coverage Enforcement ‚Ä∫ Output Format ‚Ä∫ should indicate threshold requirement

    expect(received).toContain(expected) // indexOf

    Expected substring: "80%"
    Received string:    "
    "

      241 |       const result = runCoverageChecker(path.join(testCoverageDir, 'coverage-summary.json'));
      242 |
    > 243 |       expect(result.output).toContain('80%');
          |                             ^
      244 |       expect(result.output).toContain('threshold');
      245 |     });
      246 |   });

      at Object.<anonymous> (tests/unit/quality-gates/coverage-enforcement.test.ts:243:29)

PASS UNIT tests/mcp/docs-streaming.test.ts (150 MB heap size)
  ResultStream
    basic streaming
      ‚úì should stream all results (6 ms)
      ‚úì should include chunk metadata
      ‚úì should emit timestamps
    chunk sizes
      ‚úì should respect chunk size (1 ms)
      ‚úì should handle single item chunks
      ‚úì should handle chunk size larger than results
    delays
      ‚úì should support delay between chunks (11 ms)
      ‚úì should not delay after last chunk (51 ms)
    abort signal
      ‚úì should support abort signal (25 ms)
      ‚úì should handle pre-aborted signal (1 ms)
    multiple subscribers
      ‚úì should support multiple subscribers
      ‚úì should handle callback errors gracefully (1 ms)
    state tracking
      ‚úì should track total count
      ‚úì should track current index
      ‚úì should prevent double start (10 ms)
    empty results
      ‚úì should handle empty result set (1 ms)
  StreamManager
    stream creation
      ‚úì should create and store stream (1 ms)
      ‚úì should generate unique stream IDs
    stream management
      ‚úì should remove stream
      ‚úì should count active streams
      ‚úì should cleanup completed streams
    statistics
      ‚úì should provide stream statistics (1 ms)
    reset
      ‚úì should clear all streams (1 ms)
  collectStreamResults
    ‚úì should collect all stream results
    ‚úì should work with empty stream

PASS UNIT src/example-auto-activation.test.ts (2476 MB heap size)
  Agent Auto-Activation Demo
    ‚úì should trigger Maria-QA automatically (1 ms)
    ‚úì should demonstrate auto-activation pattern
    ‚úì should validate test coverage
    ‚úì should trigger hook execution automatically (1 ms)

PASS UNIT tests/unit/config/config-wizard.test.ts (169 MB heap size)
  ConfigWizard
    wizardFlow - complete successfully
      ‚úì should complete quick setup wizard successfully (5 ms)
      ‚úì should complete wizard and save preferences (1 ms)
      ‚úì should switch to custom setup if quick setup is declined (4 ms)
    profileSelection - dev profile
      ‚úì should use balanced profile when selected (1 ms)
      ‚úì should display all available profiles (1 ms)
    profileSelection - production profile
      ‚úì should use conservative profile with stricter settings (3 ms)
      ‚úì should use aggressive profile with latest features (1 ms)
      ‚úì should handle invalid profile selection gracefully
    customConfiguration - user input
      ‚úì should collect all custom settings from user (4 ms)
      ‚úì should handle no backup scenario (4 ms)
      ‚úì should handle telemetry disabled scenario (3 ms)
    validationDuringWizard - invalid inputs
      ‚úì should handle invalid choice and use default (1 ms)
      ‚úì should handle empty input and use defaults (2 ms)
      ‚úì should parse numeric inputs correctly (10 ms)
      ‚úì should handle various yes/no input formats (5 ms)
    saveConfiguration - persist to disk
      ‚úì should save configuration to preferences file (2 ms)
      ‚úì should save custom configuration correctly (7 ms)
      ‚úì should display success message after saving (1 ms)
    runMinimal - automated setup
      ‚úì should run minimal wizard for CI environments
      ‚úì should save minimal configuration (1 ms)
    updatePreferences - interactive update
      ‚úì should update existing preferences
      ‚úì should handle reset to defaults (1 ms)
      ‚úì should handle view all settings
      ‚úì should update rollback settings (1 ms)
      ‚úì should update notification settings (2 ms)
      ‚úì should update telemetry settings (1 ms)
      ‚úì should not reset if user declines confirmation
    edgeCases - boundary conditions
      ‚úì should handle maximum backup points input (1 ms)
      ‚úì should handle zero backup points (3 ms)
      ‚úì should handle negative number input gracefully (1 ms)

PASS UNIT tests/mcp/docs-error-handling.test.ts (180 MB heap size)
  DocsFormatter - Error Handling
    Malformed Markdown
      ‚úì should handle unterminated code blocks gracefully (26 ms)
      ‚úì should handle empty code blocks
      ‚úì should handle excessively large code blocks
      ‚úì should handle code blocks without language (1 ms)
      ‚úì should handle multiple malformed blocks
    Edge Cases
      ‚úì should handle empty markdown
      ‚úì should handle markdown with only whitespace
      ‚úì should handle special characters in code (1 ms)
      ‚úì should handle nested backticks in code
      ‚úì should handle unicode in code blocks (1 ms)
    Error Recovery
      ‚úì should return empty array on regex timeout (1 ms)
      ‚úì should handle invalid UTF-8 sequences
      ‚úì should format markdown with broken syntax (1 ms)
    MCP Formatting
      ‚úì should remove HTML comments (1 ms)
      ‚úì should handle malformed HTML comments
      ‚úì should reduce excessive blank lines (1 ms)
      ‚úì should trim whitespace

PASS UNIT tests/unit/contracts/three-tier-handoff.test.ts (2449 MB heap size)
  ThreeTierHandoffBuilder
    Builder Construction
      ‚úì should create builder with requirements (13 ms)
      ‚úì should initialize with empty endpoints, tables, components (23 ms)
    Adding API Endpoints
      ‚úì should add API endpoint (10 ms)
      ‚úì should add multiple endpoints
      ‚úì should support endpoint with request/response schemas (3 ms)
      ‚úì should create work item for Marcus when endpoints added (1 ms)
    Adding Database Tables
      ‚úì should add database table (9 ms)
      ‚úì should add multiple tables (1 ms)
      ‚úì should support table with indexes (2 ms)
      ‚úì should support table with foreign keys (2 ms)
      ‚úì should create work item for Dana when tables added
      ‚úì should generate RLS policies for tables (3 ms)
      ‚úì should generate authentication check in RLS policies
    Adding UI Components
      ‚úì should add UI component (2 ms)
      ‚úì should add multiple components (2 ms)
      ‚úì should support component with props (1 ms)
      ‚úì should create work item for James when components added (4 ms)
      ‚úì should set accessibility requirement to AA (4 ms)
      ‚úì should set responsive breakpoints (1 ms)
    Memory Snapshot
      ‚úì should create minimal snapshot by default (6 ms)
      ‚úì should use provided memory snapshot (3 ms)
    Work Item Dependencies
      ‚úì should make Marcus depend on Dana when both have work (2 ms)
      ‚úì should make James depend on Marcus when both have work (4 ms)
    Integration Checkpoints
      ‚úì should create integration checkpoints (3 ms)
      ‚úì should create Database ‚Üí API checkpoint (6 ms)
      ‚úì should create API ‚Üí Frontend checkpoint (7 ms)
      ‚úì should create End-to-End checkpoint (3 ms)
    Contract Building
      ‚úì should build complete three-tier contract (8 ms)
      ‚úì should set correct receivers for three-tier (1 ms)
      ‚úì should set receiver roles (2 ms)
      ‚úì should set contract expiration to 24 hours (2 ms)
      ‚úì should include feature context
      ‚úì should include business context (2 ms)
      ‚úì should include technical context (1 ms)
    Build and Validate
      ‚úì should build and validate contract (6 ms)
      ‚úì should throw error if validation fails (34 ms)
    Quick Helper Function
      ‚úì should create three-tier handoff using helper (3 ms)
      ‚úì should use provided memory snapshot in helper (1 ms)
      ‚úì should throw on validation failure in helper (2 ms)
    Effort Estimation
      ‚úì should calculate total expected duration
      ‚úì should scale effort with number of endpoints
      ‚úì should scale effort with number of tables
      ‚úì should scale effort with number of components

PASS UNIT tests/unit/config/config-validator.test.ts (2465 MB heap size)
  ConfigValidator
    Scenario 1: Validate Update Behavior
      ‚úì should accept valid update behaviors
      ‚úì should reject invalid update behavior (1 ms)
      ‚úì should accept all valid update behaviors
    Scenario 2: Validate Update Channel
      ‚úì should accept valid update channels (1 ms)
      ‚úì should reject invalid update channel
    Scenario 3: Validate Safety Level
      ‚úì should accept valid safety levels
      ‚úì should reject invalid safety level (1 ms)
    Scenario 4: Validate Check Frequency
      ‚úì should accept valid check frequency
      ‚úì should reject negative check frequency
      ‚úì should warn about very frequent checks (1 ms)
      ‚úì should accept zero check frequency (disabled)
    Scenario 5: Validate Rollback Behavior
      ‚úì should accept valid rollback behaviors (1 ms)
      ‚úì should reject invalid rollback behavior
    Scenario 6: Validate Max Rollback Points
      ‚úì should accept valid max rollback points (1 ms)
      ‚úì should reject negative max rollback points
      ‚úì should warn when max rollback points is zero (1 ms)
      ‚úì should warn when max rollback points is very high
    Scenario 7: Check Logical Consistency
      ‚úì should warn about auto updates without rollback (1 ms)
      ‚úì should warn about alpha channel with conservative safety (1 ms)
      ‚úì should warn about auto updates without backups
      ‚úì should warn about skipping validation (1 ms)
      ‚úì should warn about manual updates with frequent checks
      ‚úì should warn about auto updates with no notifications (1 ms)
      ‚úì should warn about prerelease on stable channel
    Scenario 8: Generate Suggestions
      ‚úì should suggest for unstable channels (1 ms)
      ‚úì should suggest when telemetry is disabled
      ‚úì should suggest security auto-install (1 ms)
      ‚úì should suggest for fast safety level
    Scenario 9: Sanitize Preferences
      ‚úì should sanitize invalid update behavior to default
      ‚úì should sanitize invalid update channel to stable
      ‚úì should sanitize negative check frequency to zero
      ‚úì should cap max rollback points at 50 (1 ms)
      ‚úì should sanitize invalid safety level to balanced
      ‚úì should sanitize invalid rollback behavior to prompt
    Scenario 10: Generate Validation Report
      ‚úì should generate report with errors (1 ms)
      ‚úì should generate report with warnings
      ‚úì should generate report with suggestions (1 ms)
      ‚úì should show success when valid
    Scenario 11: Validate and Sanitize Combined
      ‚úì should validate and sanitize in one operation (1 ms)
      ‚úì should return valid report for good preferences
    Scenario 12: Validate Notification Level
      ‚úì should accept valid notification levels
      ‚úì should reject invalid notification level (1 ms)
      ‚úì should sanitize invalid notification level to important

PASS UNIT tests/unit/contracts/contract-validator.test.ts (2482 MB heap size)
  ContractValidator
    Schema Validation
      ‚úì should validate a complete valid contract (3 ms)
      ‚úì should reject contract without contractId (1 ms)
      ‚úì should reject contract without version (1 ms)
      ‚úì should warn on version mismatch
      ‚úì should reject contract without sender
      ‚úì should reject contract without receivers
      ‚úì should reject contract without type
      ‚úì should reject contract without work items
      ‚úì should reject contract without memory snapshot (1 ms)
    Business Logic Validation
      ‚úì should reject work item without id
      ‚úì should reject work item without description
      ‚úì should warn on work item without acceptance criteria
      ‚úì should reject circular dependencies
      ‚úì should warn on missing expected output (1 ms)
      ‚úì should warn on missing artifacts
      ‚úì should warn on missing success criteria
      ‚úì should warn on sequential handoff with multiple receivers (1 ms)
      ‚úì should warn on parallel handoff with single receiver
    Memory Snapshot Validation
      ‚úì should reject missing memory snapshot
      ‚úì should reject snapshot without agentId (1 ms)
      ‚úì should reject snapshot without timestamp
      ‚úì should warn on empty context summary
      ‚úì should warn on empty memory files
      ‚úì should warn on empty critical patterns
      ‚úì should warn on zero token estimate
      ‚úì should warn on large snapshot (1 ms)
    Quality Gates Validation
      ‚úì should warn on missing quality gates
      ‚úì should reject quality gate without name
      ‚úì should warn on quality gate without threshold (1 ms)
    Three-Tier Contract Validation
      ‚úì should validate complete three-tier contract (1 ms)
      ‚úì should reject three-tier contract without API endpoints
      ‚úì should reject three-tier contract without database tables
      ‚úì should reject three-tier contract without UI components (1 ms)
      ‚úì should warn on missing required agents
    Validation After Receive
      ‚úì should reject expired contract
      ‚úì should accept non-expired contract
      ‚úì should accept contract without expiration
    Strict Mode
      ‚úì should convert warnings to errors in strict mode
      ‚úì should enforce minimum quality score in strict mode (1 ms)
    Quality Score Calculation
      ‚úì should calculate perfect score for valid contract
      ‚úì should deduct points for errors
      ‚úì should deduct points for warnings (1 ms)
      ‚úì should clamp score between 0 and 100
    Validation Options
      ‚úì should skip schema validation when disabled (1 ms)
      ‚úì should skip business validation when disabled (1 ms)
      ‚úì should skip memory validation when disabled (1 ms)
      ‚úì should skip quality validation when disabled (2 ms)
    Quick Validation Helper
      ‚úì should validate contract using helper function
      ‚úì should accept options in helper function

FAIL UNIT tests/mcp/docs-audit-trail.test.ts (157 MB heap size)
  AuditTrail - Phase 4.4
    Request Tracking
      ‚úì should start and track a request (26 ms)
      ‚úì should complete a request successfully (3 ms)
      ‚úì should complete a request with failure (14 ms)
      ‚úì should track multiple active requests (7 ms)
    IP Access Control Integration
      ‚úì should allow request when IP is whitelisted (7 ms)
      ‚úì should deny request when IP is not whitelisted (2 ms)
      ‚úì should deny request when IP is blacklisted (2 ms)
    Rate Limiting Integration
      ‚úì should allow request within rate limit (12 ms)
      ‚úì should deny request when rate limit exceeded (15 ms)
      ‚úï should log rate limit violation to security logger (3 ms)
    Search Logging
      ‚úì should log search query with results (7 ms)
      ‚úì should log search to security logger (4 ms)
    Index Build Logging
      ‚úì should log successful index build (8 ms)
      ‚úì should log failed index build (18 ms)
      ‚úì should log index build to security logger with correct severity (6 ms)
    Comprehensive Statistics
      ‚úì should return comprehensive statistics (9 ms)
      ‚úì should query security logs (9 ms)
    Helper Functions
      ‚úì should format audit event correctly (6 ms)
      ‚úì should format different event types with correct emojis (12 ms)
      ‚úì should create full audit trail with all security features (18 ms)

  ‚óè AuditTrail - Phase 4.4 ‚Ä∫ Rate Limiting Integration ‚Ä∫ should log rate limit violation to security logger

    expect(received).toBeDefined()

    Received: undefined

      210 |       );
      211 |
    > 212 |       expect(suspiciousPatternLog).toBeDefined();
          |                                    ^
      213 |       expect(suspiciousPatternLog?.message).toContain('Rate limit exceeded');
      214 |     });
      215 |   });

      at Object.<anonymous> (tests/mcp/docs-audit-trail.test.ts:212:36)

PASS UNIT tests/unit/framework-self-test.test.ts (2492 MB heap size)
  VERSATIL Framework Self-Testing
    Framework Bootstrap
      ‚úì should prove framework is testing itself
      ‚úì should validate OPERA methodology is active (1 ms)
      ‚úì should meet Enhanced Maria-QA performance standards
    Quality Gates Self-Application
      ‚úì should enforce framework quality standards on itself
      ‚úì should validate self-referential architecture
    Agent System Validation
      ‚úì should validate Enhanced Maria-QA is active
      ‚úì should validate agent orchestration system

PASS UNIT tests/unit/config/preference-manager.test.ts (2461 MB heap size)
  PreferenceManager
    Scenario 1: Get Default Preferences
      ‚úì should return defaults when no preferences file exists (2 ms)
      ‚úì should return defaults from getDefaultPreferences() (1 ms)
    Scenario 2: Save Preferences
      ‚úì should save preferences successfully (2 ms)
      ‚úì should merge partial preferences with existing
      ‚úì should update lastModified timestamp
    Scenario 3: Get/Set Single Preference
      ‚úì should get specific preference
      ‚úì should set specific preference (1 ms)
      ‚úì should update lastModified when setting preference
    Scenario 4: Update Multiple Preferences
      ‚úì should update multiple preferences at once
    Scenario 5: Reset to Defaults
      ‚úì should reset preferences to defaults
      ‚úì should create directory when resetting
    Scenario 6: Validate Preferences
      ‚úì should validate correct preferences (1 ms)
      ‚úì should detect invalid update behavior
      ‚úì should detect invalid update channel
      ‚úì should detect invalid check frequency
      ‚úì should detect invalid max rollback points
    Scenario 7: Get Preferences Summary
      ‚úì should generate human-readable summary
      ‚úì should show custom preferences in summary (1 ms)
    Scenario 8: Export/Import Preferences
      ‚úì should export preferences to file
      ‚úì should import preferences from file (1 ms)
      ‚úì should reject invalid imported preferences (56 ms)
    Scenario 9: Migrate Preferences
      ‚úì should migrate old version preferences
      ‚úì should not migrate if version matches (1 ms)
    Scenario 10: Check Setup Wizard Requirement
      ‚úì should require setup wizard when no preferences exist
      ‚úì should not require setup wizard when preferences exist

FAIL UNIT tests/mcp/docs-security-logger.test.ts (176 MB heap size)
  SecurityLogger
    initialization
      ‚úì should create log directory on initialization (2 ms)
      ‚úì should emit initialized event (2 ms)
    logging events
      ‚úì should log a security event (11 ms)
      ‚úì should persist event to log file (4 ms)
      ‚úì should emit event for real-time monitoring (3 ms)
      ‚úì should emit high-severity event separately (3 ms)
    convenience methods
      ‚úì should log access granted (4 ms)
      ‚úì should log access denied (3 ms)
      ‚úì should log path traversal attempt (2 ms)
      ‚úï should log file size violation (16 ms)
    querying logs
      ‚úï should query all logs (5 ms)
      ‚úï should filter by event type (2 ms)
      ‚úï should filter by severity (1 ms)
      ‚úì should filter by date range (4 ms)
      ‚úï should support pagination (7 ms)
    statistics
      ‚úï should calculate total events (4 ms)
      ‚úï should count events by type (3 ms)
      ‚úï should count events by severity (3 ms)
      ‚úì should count suspicious activity (4 ms)
      ‚úï should track time range (2 ms)
    log management
      ‚úì should clear all logs (6 ms)
      ‚úì should emit logs-cleared event (1 ms)
    helper functions
      ‚úì should format security event for display (2 ms)
      ‚úì should format events with different severity emojis (4 ms)

  ‚óè SecurityLogger ‚Ä∫ convenience methods ‚Ä∫ should log file size violation

    ENOENT: no such file or directory, scandir '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs'

      413 |    */
      414 |   private async readAllLogs(): Promise<SecurityEvent[]> {
    > 415 |     const files = await fs.readdir(this.logDir);
          |                   ^
      416 |     const logFiles = files.filter(f => f.startsWith('security-') && f.endsWith('.log'));
      417 |
      418 |     const allEvents: SecurityEvent[] = [];

      at SecurityLogger.readAllLogs (src/mcp/docs-security-logger.ts:415:19)
      at SecurityLogger.queryLogs (src/mcp/docs-security-logger.ts:230:23)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:168:22)

  ‚óè SecurityLogger ‚Ä∫ querying logs ‚Ä∫ should query all logs

    expect(received).toHaveLength(expected)

    Expected length: 3
    Received length: 4
    Received array:  [{"details": {"metadata": {"reason": "No permission"}, "path": "doc2.md", "result": "failure"}, "id": "sec_1761756814736_1", "message": "Access denied to doc2.md: No permission", "severity": "medium", "timestamp": 2025-10-29T16:53:34.736Z, "type": "access_denied"}, {"details": {"path": "../etc/passwd", "result": "failure"}, "id": "sec_1761756814736_2", "message": "Path traversal attempt detected: ../etc/passwd", "severity": "critical", "timestamp": 2025-10-29T16:53:34.736Z, "type": "path_traversal_attempt"}, {"details": {"path": "docs/test.md", "result": "success", "user": "user123"}, "id": "sec_1761756814735_0", "message": "Access granted to docs/test.md", "severity": "low", "timestamp": 2025-10-29T16:53:34.735Z, "type": "access_granted"}, {"details": {"path": "doc1.md", "result": "success"}, "id": "sec_1761756814735_0", "message": "Access granted to doc1.md", "severity": "low", "timestamp": 2025-10-29T16:53:34.735Z, "type": "access_granted"}]

      182 |     it('should query all logs', async () => {
      183 |       const events = await logger.queryLogs();
    > 184 |       expect(events).toHaveLength(3);
          |                      ^
      185 |     });
      186 |
      187 |     it('should filter by event type', async () => {

      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:184:22)

  ‚óè SecurityLogger ‚Ä∫ querying logs ‚Ä∫ should filter by event type

    ENOENT: no such file or directory, stat '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs/security-2025-10-29.log'

      400 |     for (const file of logFiles) {
      401 |       const filePath = path.join(this.logDir, file);
    > 402 |       const stats = await fs.stat(filePath);
          |                     ^
      403 |
      404 |       if (stats.mtime < cutoffDate) {
      405 |         await fs.unlink(filePath);

      at SecurityLogger.cleanupOldLogs (src/mcp/docs-security-logger.ts:402:21)
      at SecurityLogger.initialize (src/mcp/docs-security-logger.ts:130:7)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:30:5)

  ‚óè SecurityLogger ‚Ä∫ querying logs ‚Ä∫ should filter by severity

    ENOENT: no such file or directory, mkdir '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs'

      124 |
      125 |     // Create log directory if it doesn't exist
    > 126 |     await fs.mkdir(this.logDir, { recursive: true });
          |     ^
      127 |
      128 |     // Clean up old logs
      129 |     if (this.autoRotate) {

      at SecurityLogger.initialize (src/mcp/docs-security-logger.ts:126:5)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:30:5)

  ‚óè SecurityLogger ‚Ä∫ querying logs ‚Ä∫ should support pagination

    expect(received).toHaveLength(expected)

    Expected length: 1
    Received length: 2
    Received array:  [{"details": {"path": "../etc/passwd", "result": "failure"}, "id": "sec_1761756814756_2", "message": "Path traversal attempt detected: ../etc/passwd", "severity": "critical", "timestamp": 2025-10-29T16:53:34.756Z, "type": "path_traversal_attempt"}, {"details": {"path": "doc1.md", "result": "success"}, "id": "sec_1761756814754_0", "message": "Access granted to doc1.md", "severity": "low", "timestamp": 2025-10-29T16:53:34.754Z, "type": "access_granted"}]

      217 |
      218 |       expect(page1).toHaveLength(2);
    > 219 |       expect(page2).toHaveLength(1);
          |                     ^
      220 |     });
      221 |   });
      222 |

      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:219:21)

  ‚óè SecurityLogger ‚Ä∫ statistics ‚Ä∫ should calculate total events

    ENOENT: no such file or directory, open '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs/security-2025-10-29.log'

      420 |     for (const file of logFiles) {
      421 |       const filePath = path.join(this.logDir, file);
    > 422 |       const content = await fs.readFile(filePath, 'utf-8');
          |                       ^
      423 |       const lines = content.trim().split('\n').filter(line => line.length > 0);
      424 |
      425 |       for (const line of lines) {

      at SecurityLogger.readAllLogs (src/mcp/docs-security-logger.ts:422:23)
      at SecurityLogger.getStatistics (src/mcp/docs-security-logger.ts:264:23)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:232:21)

  ‚óè SecurityLogger ‚Ä∫ statistics ‚Ä∫ should count events by type

    ENOENT: no such file or directory, scandir '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs'

      413 |    */
      414 |   private async readAllLogs(): Promise<SecurityEvent[]> {
    > 415 |     const files = await fs.readdir(this.logDir);
          |                   ^
      416 |     const logFiles = files.filter(f => f.startsWith('security-') && f.endsWith('.log'));
      417 |
      418 |     const allEvents: SecurityEvent[] = [];

      at SecurityLogger.readAllLogs (src/mcp/docs-security-logger.ts:415:19)
      at SecurityLogger.getStatistics (src/mcp/docs-security-logger.ts:264:23)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:237:21)

  ‚óè SecurityLogger ‚Ä∫ statistics ‚Ä∫ should count events by severity

    expect(received).toBe(expected) // Object.is equality

    Expected: 2
    Received: 1

      245 |       const stats = await logger.getStatistics();
      246 |
    > 247 |       expect(stats.eventsBySeverity[SecuritySeverity.LOW]).toBe(2);
          |                                                            ^
      248 |       expect(stats.eventsBySeverity[SecuritySeverity.MEDIUM]).toBe(1);
      249 |       expect(stats.eventsBySeverity[SecuritySeverity.CRITICAL]).toBe(1);
      250 |     });

      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:247:60)

  ‚óè SecurityLogger ‚Ä∫ statistics ‚Ä∫ should track time range

    ENOENT: no such file or directory, open '/Users/nissimmenashe/VERSATIL SDLC FW/.versatil/test-security-logs/security-2025-10-29.log'

      358 |     const logPath = this.getLogFilePath();
      359 |
    > 360 |     await fs.appendFile(logPath, logLine, 'utf-8');
          |     ^
      361 |   }
      362 |
      363 |   /**

      at SecurityLogger.writeEventToLog (src/mcp/docs-security-logger.ts:360:5)
      at SecurityLogger.logEvent (src/mcp/docs-security-logger.ts:158:5)
      at Object.<anonymous> (tests/mcp/docs-security-logger.test.ts:228:7)

PASS UNIT tests/mcp/docs-ip-access-control.test.ts (2475 MB heap size)
  IPAccessControl
    whitelist mode
      ‚úì should allow whitelisted IPs (2 ms)
      ‚úì should block non-whitelisted IPs
    blacklist mode
      ‚úì should block blacklisted IPs (1 ms)
      ‚úì should allow non-blacklisted IPs (1 ms)
    CIDR range support
      ‚úì should match IPs in CIDR range
      ‚úì should reject IPs outside CIDR range
    mixed mode
      ‚úì should prioritize whitelist over blacklist
      ‚úì should block blacklisted IPs not in whitelist
      ‚úì should default deny in mixed mode
    rule management
      ‚úì should add and remove whitelist rules
      ‚úì should add and remove blacklist rules (1 ms)
      ‚úì should clear all rules
      ‚úì should get all rules (2 ms)
    security logger integration
      ‚úì should log access decisions (15 ms)
    statistics
      ‚úì should provide accurate statistics (8 ms)
    persistence
      ‚úì should save and load rules (13 ms)
  Helper Functions
    isValidIP
      ‚úì should validate correct IPv4 addresses (6 ms)
      ‚úì should validate CIDR notation (20 ms)
      ‚úì should reject invalid IP addresses (1 ms)

PASS UNIT tests/mcp/github-integration.test.ts (190 MB heap size)
  GitHub MCP Integration
    Repository File Operations
      ‚úì should read file from repository (2 ms)
      ‚úì should read documentation file
      ‚úì should throw error for non-existent file (25 ms)
      ‚úì should handle different repositories (2 ms)
    Code Search
      ‚úì should search for code across repository (1 ms)
      ‚úì should search for code without specifying repository
      ‚úì should return matches with line numbers (1 ms)
      ‚úì should sort results by relevance
      ‚úì should return empty array for non-matching search (1 ms)
    Issue Management
      ‚úì should create new issue (3 ms)
      ‚úì should retrieve created issue
      ‚úì should throw error for non-existent issue (1 ms)
      ‚úì should track issue metadata
    Pull Request Operations
      ‚úì should list all pull requests (4 ms)
      ‚úì should list only open pull requests
      ‚úì should list only closed pull requests
      ‚úì should include branch information in PRs
    Sarah-PM Integration
      ‚úì should track feature development progress
      ‚úì should create milestone report
      ‚úì should create bug issue automatically (1 ms)
      ‚úì should apply severity labels correctly
      ‚úì should find code patterns
    Integration with OPERA Workflow
      ‚úì should support Alex-BA requirements research
      ‚úì should support Marcus-Backend code search
      ‚úì should support Sarah-PM project tracking (3 ms)

PASS UNIT tests/mcp/docs-errors-enhanced.test.ts (2492 MB heap size)
  Enhanced DocsSearchError
    error metadata
      ‚úì should include severity for each error code
      ‚úì should include category for each error code (1 ms)
      ‚úì should include suggestions for each error code
    user-friendly messages
      ‚úì should generate user-friendly message for DOCUMENT_NOT_FOUND
      ‚úì should generate user-friendly message for FILE_TOO_LARGE
      ‚úì should generate user-friendly message for PATH_TRAVERSAL_BLOCKED
    formatted error messages
      ‚úì should include severity emoji in formatted message (1 ms)
      ‚úì should include suggestions in formatted message
      ‚úì should include action steps in formatted message
      ‚úì should include links when available
    error categorization
      ‚úì should categorize DOCUMENT_NOT_FOUND as DOCUMENT_ACCESS
      ‚úì should categorize PATH_TRAVERSAL_BLOCKED as SECURITY
      ‚úì should categorize FILE_TOO_LARGE as SIZE_LIMIT
      ‚úì should categorize INDEX_NOT_BUILT as INDEX
    severity levels
      ‚úì should assign CRITICAL severity to security threats
      ‚úì should assign ERROR severity to access issues (1 ms)
      ‚úì should assign WARNING severity to size limit issues
    helper functions
      ‚úì should format error for console output
      ‚úì should identify recoverable errors
      ‚úì should identify non-recoverable errors
      ‚úì should get category display name
    JSON serialization
      ‚úì should serialize error to JSON (48 ms)
      ‚úì should include all error metadata in JSON
    all error codes
      ‚úì should have metadata for all error codes (2 ms)
      ‚úì should have at least one suggestion for each error code (1 ms)

PASS UNIT tests/mcp/docs-memory.test.ts (161 MB heap size)
  DocsMemoryTracker
    getMemoryUsage
      ‚úì should return current memory usage with index and cache sizes (4 ms)
      ‚úì should work with zero index and cache sizes
    takeSnapshot
      ‚úì should store memory snapshot
      ‚úì should store multiple snapshots
      ‚úì should limit snapshots to maxSnapshots (1 ms)
      ‚úì should keep most recent snapshots when limit exceeded
    detectMemoryLeaks
      ‚úì should return false with insufficient data (1 ms)
      ‚úì should detect consistent memory growth
      ‚úì should not detect leak with stable memory
      ‚úì should not detect leak with fluctuating memory
    getMemoryGrowthRate
      ‚úì should return null with insufficient data
      ‚úì should calculate growth rate in MB/min
      ‚úì should return zero for no growth
    getMemoryWarnings
      ‚úì should warn on high heap usage
      ‚úì should warn on absolute limit exceeded (1 ms)
      ‚úì should warn on memory leak detection
      ‚úì should return empty array when no issues
    getMemoryTimeSeries
      ‚úì should return all snapshots when no duration specified
      ‚úì should filter by duration
      ‚úì should return empty array when no snapshots
    getMemoryStats
      ‚úì should return zero stats when no snapshots
      ‚úì should calculate statistics from snapshots (1 ms)
    formatBytes
      ‚úì should format bytes correctly
      ‚úì should handle non-round numbers (1 ms)
    getMemoryUsageSummary
      ‚úì should return formatted summary string
      ‚úì should include warnings in summary
    reset
      ‚úì should clear all snapshots (1 ms)

PASS UNIT tests/mcp/docs-suggestions.test.ts (2505 MB heap size)
  SuggestionsEngine
    auto-complete suggestions
      ‚úì should suggest completions for partial terms
      ‚úì should rank completions by frequency
      ‚úì should not suggest exact matches
    typo corrections
      ‚úì should suggest corrections for misspelled terms (1 ms)
      ‚úì should calculate reasonable similarity scores
      ‚úì should not suggest corrections for correct terms
    related terms
      ‚úì should suggest related terms from context
      ‚úì should include source term in related suggestions (1 ms)
    combined suggestions
      ‚úì should combine all suggestion types
      ‚úì should respect maxSuggestions limit (1 ms)
      ‚úì should filter by minimum score
    statistics
      ‚úì should provide accurate statistics (1 ms)
      ‚úì should track term count
    helper functions
      ‚úì should format suggestions correctly
      ‚úì should format correction suggestions
      ‚úì should format related suggestions with source
      ‚úì should get best suggestion (17 ms)
      ‚úì should return null for empty suggestions
    edge cases
      ‚úì should handle empty query
      ‚úì should handle special characters (1 ms)
      ‚úì should be case-insensitive
      ‚úì should handle clear operation

PASS UNIT tests/unit/utils/logger.test.ts (171 MB heap size)
  VERSATILLogger
    Logging Methods
      ‚úì should log debug messages correctly (1 ms)
      ‚úì should log info messages correctly
      ‚úì should log warning messages correctly
      ‚úì should log error messages correctly
    Framework Self-Logging Validation
      ‚úì should support enhanced OPERA logging patterns
      ‚úì should handle structured logging for agent orchestration
    Performance Requirements
      ‚úì should log messages within performance thresholds (1 ms)

/Users/nissimmenashe/VERSATIL SDLC FW/node_modules/.pnpm/expect@29.7.0/node_modules/expect/build/index.js:314
      throw error;
      ^

JestAssertionError: expect(received).toBeGreaterThan(expected)

Expected: > 0
Received:   -59950.103759765625
    at Timeout._onTimeout (/Users/nissimmenashe/VERSATIL SDLC FW/tests/mcp/docs-memory.test.ts:128:49)
    at listOnTimeout (node:internal/timers:608:17)
    at processTimers (node:internal/timers:543:7) {
  matcherResult: {
    message: 'expect(received).toBeGreaterThan(expected)\n' +
      '\n' +
      'Expected: > 0\n' +
      'Received:   -59950.103759765625',
    pass: false
  }
}

Node.js v24.7.0
PASS UNIT tests/mcp/docs-security.test.ts (243 MB heap size)
  DocsSearchEngine - Security
    Path Traversal Protection
      ‚úì should block path traversal with ../ (8 ms)
      ‚úì should block path traversal with multiple ../ (1 ms)
      ‚úì should block absolute paths
      ‚úì should block Windows-style path traversal
      ‚úì should throw DocsSearchError with correct code (1 ms)
      ‚úì should allow valid relative paths (23 ms)
    File Size Limits
      ‚úì should have default file size limit (1 ms)
      ‚úì should reject documents exceeding size limit (383 ms)
      ‚úì should include size information in error (377 ms)
      ‚úì should allow documents within size limit (2045 ms)
    Access Control
      ‚úì should only allow access to files in docs directory (11 ms)
      ‚úì should throw error for non-existent documents (1 ms)
      ‚úì should throw DocsSearchError for missing documents
      ‚úì should validate file readability
    Input Validation
      ‚úì should handle empty path (1 ms)
      ‚úì should handle null-like paths
      ‚úì should handle paths with special characters
      ‚úì should normalize paths before validation (1 ms)
    Error Information
      ‚úì should provide structured error information
      ‚úì should include context in error details
    Concurrent Access Security
      ‚úì should handle concurrent access attempts safely (43 ms)
      ‚úì should handle mixed valid and invalid paths concurrently (1 ms)

FAIL UNIT tests/unit/rag/pattern-search.test.ts
  ‚óè Test suite failed to run

    Cannot find module '../../src/lib/graphrag-store' from 'tests/unit/rag/pattern-search.test.ts'

       7 |
       8 | // Mock GraphRAG store
    >  9 | jest.mock('../../src/lib/graphrag-store', () => ({
         |      ^
      10 |   graphRAGStore: {
      11 |     initialize: jest.fn().mockResolvedValue(undefined),
      12 |     query: jest.fn().mockResolvedValue([

      at Resolver._throwModNotFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:427:11)
      at Object.<anonymous> (tests/unit/rag/pattern-search.test.ts:9:6)

FAIL UNIT tests/unit/planning/todo-file-generator.test.ts
  ‚óè Test suite failed to run

    Cannot find module '../../src/planning/todo-file-generator' from 'tests/unit/planning/todo-file-generator.test.ts'

      4 |  */
      5 |
    > 6 | import { TodoFileGenerator, TodoFileSpec, TodoGenerationResult } from '../../src/planning/todo-file-generator';
        | ^
      7 | import * as fs from 'fs';
      8 | import * as path from 'path';
      9 |

      at Resolver._throwModNotFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:427:11)
      at Object.<anonymous> (tests/unit/planning/todo-file-generator.test.ts:6:1)

ts-jest[config] (WARN) 
    The "ts-jest" config option "isolatedModules" is deprecated and will be removed in v30.0.0. Please use "isolatedModules: true" in /Users/nissimmenashe/VERSATIL SDLC FW/tsconfig.json instead, see https://www.typescriptlang.org/tsconfig/#isolatedModules
  
FAIL UNIT tests/unit/templates/template-matcher.test.ts
  ‚óè Test suite failed to run

    Cannot find module '../../src/templates/template-matcher' from 'tests/unit/templates/template-matcher.test.ts'

      4 |  */
      5 |
    > 6 | import { TemplateMatcher, TemplateMatchResult } from '../../src/templates/template-matcher';
        | ^
      7 | import * as fs from 'fs';
      8 | import * as path from 'path';
      9 |

      at Resolver._throwModNotFoundError (node_modules/.pnpm/jest-resolve@29.7.0/node_modules/jest-resolve/build/resolver.js:427:11)
      at Object.<anonymous> (tests/unit/templates/template-matcher.test.ts:6:1)

FAIL UNIT tests/mcp/docs-tools-integration.test.ts
  ‚óè Test suite failed to run

    Jest encountered an unexpected token

    Jest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.

    Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.

    By default "node_modules" folder is ignored by transformers.

    Here's what you can do:
     ‚Ä¢ If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.
     ‚Ä¢ If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript
     ‚Ä¢ To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.
     ‚Ä¢ If you need a custom transformation specify a "transform" option in your config.
     ‚Ä¢ If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.

    You'll find more details and examples of these config options in the docs:
    https://jestjs.io/docs/configuration
    For information about custom transformations, see:
    https://jestjs.io/docs/code-transformation

    Details:

    /Users/nissimmenashe/VERSATIL SDLC FW/src/agents/opera/marcus-backend/enhanced-marcus.ts:42
    const __filename = (0, url_1.fileURLToPath)(import.meta.url);
          ^

    SyntaxError: Identifier '__filename' has already been declared

      3 | import { EnhancedMaria } from '../opera/maria-qa/enhanced-maria.js';
      4 | import { EnhancedJames } from '../opera/james-frontend/enhanced-james.js';
    > 5 | import { EnhancedMarcus } from '../opera/marcus-backend/enhanced-marcus.js';
        | ^
      6 | import { SarahPm } from '../opera/sarah-pm/sarah-pm.js';
      7 | import { AlexBa } from '../opera/alex-ba/alex-ba.js';
      8 | import { DrAiMl } from '../opera/dr-ai-ml/dr-ai-ml.js';

      at Runtime.createScriptFromCode (node_modules/.pnpm/jest-runtime@29.7.0/node_modules/jest-runtime/build/index.js:1505:14)
      at Object.<anonymous> (src/agents/core/agent-registry.ts:5:1)
      at Object.<anonymous> (tests/mcp/docs-tools-integration.test.ts:8:1)


**Occurrences**: 3 times in past 24h
**Root Cause Pattern**: root-cause-1761757665797-p47c

## Current Impact

- **Manual Interventions**: 21 per week
- **Time Spent**: 5.3h per week on manual fixes
- **Reliability Impact**: 12.4% improvement possible

## Suggested Enhancement

**Goal**: Automatically run npm audit fix for known vulnerabilities. Prevents 3 security issues per 24h.

**Category**: üîí Security
**Estimated Effort**: 8.5 hours
**Assigned Agent**: **Marcus-Backend**

## Implementation Steps

1. Run npm audit to identify vulnerabilities
2. Implement automated npm audit fix on schedule
3. Add breaking change detection and rollback
4. Notify on manual review requirements
5. Update Guardian telemetry to track fix success rate
6. Store learned pattern in RAG for future reference

## Expected Benefits

- ‚úÖ **Reduce manual intervention**: 21 interventions/week ‚Üí 0
- ‚úÖ **Save time**: 5.3h/week freed for feature development
- ‚úÖ **Improve reliability**: 12.4% reliability improvement
- ‚úÖ **Auto-remediation**: Partial - Requires monitoring

## Supporting Evidence

- **Verification Confidence**: 85%
- **Expected Success Rate**: 95%
- **Issue Occurrences**: 3

## ROI Calculation

```
Implementation Time: 8.5h
Time Saved per Week: 5.3h
Break-even: 1.6 weeks
Annual Savings: 276h/year
```

## ‚ö†Ô∏è Manual Review Required

This enhancement requires human judgment due to:
- Priority: CRITICAL
- Complexity: 6 implementation steps
- Confidence: 85% (< 90% threshold for full automation)

**Review Checklist**:
- [ ] Verify root cause analysis is accurate
- [ ] Confirm implementation steps are appropriate
- [ ] Check for potential side effects
- [ ] Validate estimated effort

## üß† Learning Opportunity

After implementing this enhancement:

1. Run `/learn "Implemented Auto-fix security vulnerabilities"`
2. Guardian will store the fix pattern in RAG
3. Similar issues will be auto-remediable in the future
4. Compounding engineering: Next similar issue will be 40% faster to fix

---

**Generated by Guardian Root Cause Learning Engine**
**Root Cause Pattern ID**: `root-cause-1761757665797-p47c`
**Detection Method**: Chain-of-Verification (CoVe) with 85% confidence
**Category**: security
**Priority**: CRITICAL